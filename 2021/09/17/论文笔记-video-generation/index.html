<!doctype html>
<html lang="zh"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>论文笔记-video generation - 潘小榭</title><link rel="manifest" href="/manifest.json"><meta name="theme-color" content="black"><meta name="application-name" content="panxiaoxie"><meta name="msapplication-TileImage" content="/img/avatar.png"><meta name="msapplication-TileColor" content="black"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="panxiaoxie"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="description" content="GenHFi: Generating high fidelity images with subscale pixel networks and multidimensional upscaling. (ICLR2019) paper2: Scaling autoregressive video models (ICLR2020) Video pixel networks. (CoRR2016)"><meta property="og:type" content="blog"><meta property="og:title" content="panxiaoxie"><meta property="og:url" content="https://github.com/PanXiebit"><meta property="og:site_name" content="panxiaoxie"><meta property="og:description" content="GenHFi: Generating high fidelity images with subscale pixel networks and multidimensional upscaling. (ICLR2019) paper2: Scaling autoregressive video models (ICLR2020) Video pixel networks. (CoRR2016)"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://www.qt86.com/cache/1625298592_187938.png"><meta property="article:published_time" content="2021-09-17T02:20:51.000Z"><meta property="article:modified_time" content="2021-10-31T12:31:21.633Z"><meta property="article:author" content="panxiaoxie"><meta property="article:tag" content="generation"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="https://www.qt86.com/cache/1625298592_187938.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"http://www.panxiaoxie.cn/2021/09/17/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-video-generation/"},"headline":"论文笔记-video generation","image":["http://www.panxiaoxie.cn/2021/09/17/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-video-generation/image-20210917141538042.png","http://www.panxiaoxie.cn/2021/09/17/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-video-generation/image-20210917151655745.png","http://www.panxiaoxie.cn/2021/09/17/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-video-generation/image-20211011164720045.png","http://www.panxiaoxie.cn/2021/09/17/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-video-generation/image-20211011170844464.png","http://www.panxiaoxie.cn/2021/09/17/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-video-generation/image-20211011170922547.png","http://www.panxiaoxie.cn/2021/09/17/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-video-generation/image-20211014163523446.png","http://www.panxiaoxie.cn/2021/09/17/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-video-generation/image-20211014163757924.png","http://www.panxiaoxie.cn/2021/09/17/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-video-generation/image-20211014164148058.png"],"datePublished":"2021-09-17T02:20:51.000Z","dateModified":"2021-10-31T12:31:21.633Z","author":{"@type":"Person","name":"Xie Pan"},"publisher":{"@type":"Organization","name":"潘小榭","logo":{"@type":"ImageObject","url":"http://www.panxiaoxie.cn/img/panxiaoxie.png"}},"description":"GenHFi: Generating high fidelity images with subscale pixel networks and multidimensional upscaling. (ICLR2019) paper2: Scaling autoregressive video models (ICLR2020) Video pixel networks. (CoRR2016)"}</script><link rel="canonical" href="http://www.panxiaoxie.cn/2021/09/17/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-video-generation/"><link rel="icon" href="/img/avatar.png"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/css/justifiedGallery.min.css"><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script><!--!--><!--!--><meta name="generator" content="Hexo 5.4.0"></head><body class="is-2-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/panxiaoxie.png" alt="潘小榭" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">主页</a><a class="navbar-item" href="/archives">归档</a><a class="navbar-item" href="/categories">分类</a><a class="navbar-item" href="/tags">标签</a><a class="navbar-item" href="/about">关于我</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/PanXiebit"><i class="fab fa-github"></i></a><a class="navbar-item is-hidden-tablet catalogue" title="目录" href="javascript:;"><i class="fas fa-list-ul"></i></a><a class="navbar-item search" title="搜索" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-10-widescreen"><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2021-09-17T02:20:51.000Z" title="2021/9/17 上午10:20:51">2021-09-17</time>发表</span><span class="level-item"><time dateTime="2021-10-31T12:31:21.633Z" title="2021/10/31 下午8:31:21">2021-10-31</time>更新</span><span class="level-item"><a class="link-muted" href="/categories/generation/">generation</a></span><span class="level-item">5 分钟读完 (大约746个字)</span></div></div><h1 class="title is-3 is-size-4-mobile">论文笔记-video generation</h1><div class="content"><ul>
<li><a href="#GenHFI">GenHFi</a>: Generating high fidelity images with subscale pixel networks and multidimensional upscaling. (ICLR2019)</li>
<li>paper2: Scaling autoregressive video models (ICLR2020)</li>
<li>Video pixel networks. (CoRR2016)</li>
<li><a href="#Parallel">Parallel</a>: Parallel multiscale autoregressive density estimation </li>
<li><a href="#vqgan">VQGAN</a>: Taming Transformers for High-Resolution Image Synthesis</li>
<li><a href="#TeCoGAN">TeCoGAN</a>:  Learning Temporal Coherence via Self-Supervision for GAN-based Video Generation</li>
<li>ImaGINator: Conditional Spatio-Temporal GAN for Video Generation</li>
<li>Temporal Shift GAN for Large Scale Video Generation</li>
<li><a href="#MoCoGAN">MoCoGAN</a>: Decomposing Motion and Content for Video Generation</li>
<li>Playable Video Generation (CVPR2021)</li>
</ul>
<span id="more"></span>



<h2 id="GenHFi"><a href="#GenHFi" class="headerlink" title="GenHFi "></a>GenHFi <a name="GenHFi"></a></h2><p>title: Generating high fidelity images with subscale pixel networks and multidimensional upscaling</p>
<h3 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract:"></a>Abstract:</h3><ul>
<li>Subscale Pixel Network (SPN): a conditional decoder architecture that generates an image as a sequence of sub-images of equal size</li>
<li>Multidimensional Upscaling: grow an image in both size and depth via intermediate stages utilising distinct SPNs</li>
</ul>
<h3 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h3><ul>
<li>The multi-facted relationship between MLE scores and the fidelity of samples<ul>
<li>MLE is a well-defined measure as improvements in held-out scores generally produce improvements in the visual fidelity of the samples.</li>
<li>MLE forces the model to support the entire empirical distribution. This guarantees the model’s ability to generalize at the cost of allotting capacity to parts of the distribution that are irrelevant to fidelity.</li>
</ul>
</li>
<li>A 256 × 256 × 3 image has a total of 196,608 positions that need to be architecturally connected in order to learn dependencies among them.</li>
</ul>
<h3 id="Contribution"><a href="#Contribution" class="headerlink" title="Contribution"></a>Contribution</h3><ul>
<li><p>Multidimensional Upscaling</p>
<ul>
<li>Small size, lower depth -&gt; large size, lower depth -&gt; large size, high depth</li>
</ul>
</li>
<li><p>Subscale Pixel Network (SPN) architecture</p>
<ul>
<li><p>divides an image of size $N\times N$ into sub-images of size $\dfrac{N}{S}\times \dfrac{N}{S}$ sliced out at interleaving positions</p>
<img src="/2021/09/17/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-video-generation/image-20210917141538042.png" style="zoom:50%;"></li>
<li><p>SPN consists of two networks, a conditioning network that embeds previous slices and a decoder proper that predicts a single target slice given the context embedding.</p>
</li>
</ul>
</li>
</ul>
<h3 id="Architecture"><a href="#Architecture" class="headerlink" title="Architecture"></a>Architecture</h3><img src="/2021/09/17/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-video-generation/image-20210917151655745.png" style="zoom:50%;">

<h3 id="VQ-GAN"><a href="#VQ-GAN" class="headerlink" title="VQ-GAN "></a>VQ-GAN <a name="vagan"></a></h3><img src="/2021/09/17/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-video-generation/image-20211011164720045.png" style="zoom:50%;">

<h4 id="Contribution-1"><a href="#Contribution-1" class="headerlink" title="Contribution"></a>Contribution</h4><ul>
<li><p>take the convolution and transformer together:</p>
<blockquote>
<p>use a convolutional approach to efficiently learn a codebook of context-rich visual parts and, subsequently, learn a model of their global compositions. The long-range interactions within these compositions require an expressive transformer architecture to model distributions over their consituent visual parts.</p>
</blockquote>
</li>
<li><p>utilize an adversarial approach to ensure that the dictionary of local parts captures perceptually important local structure to alleviate the need for modeling low-level statistics with the transformer architecture.</p>
</li>
</ul>
<h4 id="Approach"><a href="#Approach" class="headerlink" title="Approach"></a>Approach</h4><ul>
<li><p>Learning an Effective Codebook of Image Constituents </p>
<ul>
<li><p>VA-VAE:  $$\hat x = G(z_q) = G(q(E(x)))$$</p>
<img src="/2021/09/17/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-video-generation/image-20211011170844464.png" style="zoom:50%;"></li>
<li><p>Learning a Perceptually Rich Codebook using GAN and perception loss</p>
<img src="/2021/09/17/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-video-generation/image-20211011170922547.png" style="zoom:50%;"></li>
<li><p>Learning the Composition of Images with Transformers</p>
</li>
<li><p>latent transformer</p>
</li>
<li><p>Conditioned Synthesis</p>
</li>
</ul>
</li>
</ul>
<h3 id="TeCoGAN"><a href="#TeCoGAN" class="headerlink" title="TeCoGAN "></a>TeCoGAN <a name="TeCoGAN"></a></h3><p>paper: Learning Temporal Coherence via Self-Supervision for GAN-based Video Generation</p>
<h4 id="Contribution-2"><a href="#Contribution-2" class="headerlink" title="Contribution"></a>Contribution</h4><ul>
<li>propose a novel Ping-Pong loss to improve the long-term temporal consistency.<ul>
<li>It effectively prevents recurrent networks from accumulating artifacts temporally without depressing detailed features</li>
</ul>
</li>
<li>propose a first set of metrics to quantitatively evaluate the accuracy as well as the perceptual quality of the temporal evolution.</li>
</ul>
<h4 id="Related-works"><a href="#Related-works" class="headerlink" title="Related works"></a>Related works</h4><ul>
<li><p>Sequential generation tasks: [Kim et al. 2019; Xie et al. 2018].</p>
</li>
<li><p>Conditional video generation tasks [Jamriška et al. 2019; Sitzmann et al. 2018; Wronski et al. 2019; Zhang et al. 2019]</p>
</li>
<li><p>motion estimation [Dosovitskiy et al. 2015; Liu et al. 2019]</p>
</li>
<li><p>explicitly using variants of optical flow networks [Caballero et al. 2017; Sajjadi et al. 2018; Shi et al. 2016]</p>
</li>
<li><p>GANS:</p>
<ul>
<li>Zhu et al. [2017] focuses on images without temporal constrains</li>
<li>RecycleGAN [Bansal et al. 2018] proposes to use a prediction network in addition to a generator</li>
<li>a concurrent work [Chen et al. 2019] chose to learn motion translation in addition to the spatial content translation.</li>
</ul>
</li>
<li><p>Metrics:</p>
<ul>
<li>perceptual metrics [Prashnani et al. 2018; Zhang et al. 2018] are proposed to reliably consider semantic features instead of pixel-wise errors.</li>
</ul>
</li>
<li><p>Adversarial temporal losses: </p>
<ul>
<li>tempoGAN for fluid flow [Xie et al. 2018]</li>
<li>vid2vid for video translation [Wang et al. 2018a]</li>
</ul>
</li>
<li><p>3D discriminator</p>
<ul>
<li>DeepFovea [Kaplanyan et al. 2019]</li>
<li>Bashkirova et al. [2018]</li>
</ul>
</li>
<li><p>For tracking and optical flow estimation, L2-based time-cycle losses [Wang et al. 2019b]</p>
</li>
</ul>
<h4 id="Method"><a href="#Method" class="headerlink" title="Method"></a>Method</h4><h6 id="Spatio-Temporal-Adversarial-Learning"><a href="#Spatio-Temporal-Adversarial-Learning" class="headerlink" title="Spatio-Temporal Adversarial Learning"></a>Spatio-Temporal Adversarial Learning</h6><img src="/2021/09/17/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-video-generation/image-20211014163523446.png" style="zoom:50%;">

<p>Notation:</p>
<ul>
<li><p>$\alpha$ Input domain, $b$ target domain, $g$ generated domain</p>
</li>
<li><p>$w$ motion compensation, </p>
<img src="/2021/09/17/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-video-generation/image-20211014163757924.png" style="zoom:50%;"></li>
</ul>
<h5 id="Self-Supervision-for-Long-term-Temporal-Consistency"><a href="#Self-Supervision-for-Long-term-Temporal-Consistency" class="headerlink" title="Self-Supervision for Long-term Temporal Consistency"></a>Self-Supervision for Long-term Temporal Consistency</h5><img src="/2021/09/17/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-video-generation/image-20211014164148058.png" style="zoom:50%;">



<ul>
<li><p>When inferring this in a frame-recurrent manner, the generated result should not strengthen any invalid features from frame to frame. Rather, the result should stay close to valid information and be symmetric, i.e., the forward result $g_t=G(a_t, <em>{t-1})$ and the one generated from the reversed part, ${g_t}^{‘}=G(a_t, {g</em>{t+1}}^{‘})$, should be identical.</p>
</li>
<li><p>bi-directional “Ping-Pong” loss</p>
<p>​                $$\mathcal{L}<em>{pp}=\sum</em>{t=1}^{n-1}||g_t-{g_t}^{‘}||_2$$</p>
</li>
</ul>
<p>Parallel  multiscale<a name="Parallel"></a> </p>
</div><div class="article-licensing box"><div class="licensing-title"><p>论文笔记-video generation</p><p><a href="http://www.panxiaoxie.cn/2021/09/17/论文笔记-video-generation/">http://www.panxiaoxie.cn/2021/09/17/论文笔记-video-generation/</a></p></div><div class="licensing-meta level is-mobile"><div class="level-left"><div class="level-item is-narrow"><div><h6>作者</h6><p>Xie Pan</p></div></div><div class="level-item is-narrow"><div><h6>发布于</h6><p>2021-09-17</p></div></div><div class="level-item is-narrow"><div><h6>更新于</h6><p>2021-10-31</p></div></div><div class="level-item is-narrow"><div><h6>许可协议</h6><p><a class="icons" rel="noopener" target="_blank" title="Creative Commons" href="https://creativecommons.org/"><i class="icon fab fa-creative-commons"></i></a><a class="icons" rel="noopener" target="_blank" title="Attribution" href="https://creativecommons.org/licenses/by/4.0/"><i class="icon fab fa-creative-commons-by"></i></a><a class="icons" rel="noopener" target="_blank" title="Noncommercial" href="https://creativecommons.org/licenses/by-nc/4.0/"><i class="icon fab fa-creative-commons-nc"></i></a></p></div></div></div></div></div><div class="article-tags is-size-7 mb-4"><span class="mr-2">#</span><a class="link-muted mr-2" rel="tag" href="/tags/generation/">generation</a></div><!--!--></article></div><!--!--><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/2021/11/19/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-fast-transformer/"><i class="level-item fas fa-chevron-left"></i><span class="level-item">论文笔记-fast transformer</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/2021/09/12/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-Discrete-Latent-Variables-Based-Generation/"><span class="level-item">论文笔记-Discrete Latent Variables Based Generation</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><div class="card"><div class="card-content"><h3 class="title is-5">评论</h3><div id="disqus_thread"><noscript>Please enable JavaScript to view the <a target="_blank" rel="noopener" href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript></div><script>var disqus_config = function () {
            this.page.url = 'http://www.panxiaoxie.cn/2021/09/17/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-video-generation/';
            this.page.identifier = '2021/09/17/论文笔记-video-generation/';
        };
        (function() {
            var d = document, s = d.createElement('script');  
            s.src = '//' + 'panxie' + '.disqus.com/embed.js';
            s.setAttribute('data-timestamp', +new Date());
            (d.head || d.body).appendChild(s);
        })();</script></div></div></div><!--!--><div class="column column-right is-4-tablet is-4-desktop is-4-widescreen  order-3"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar" src="/img/avatar.png" alt="panxiaoxie"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">panxiaoxie</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Beijing, China</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">文章</p><a href="/archives"><p class="title">121</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">分类</p><a href="/categories"><p class="title">40</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">标签</p><a href="/tags"><p class="title">38</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/PanXiebit" target="_blank" rel="noopener">关注我</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/PanXiebit"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Email" href="/ftdpanxie@gmail.com"><i class="fa fa-envelope"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="RSS" href="/"><i class="fas fa-rss"></i></a></div></div></div><div class="card widget" id="toc" data-type="toc"><div class="card-content"><div class="menu"><h3 class="menu-label">目录</h3><ul class="menu-list"><li><a class="level is-mobile" href="#GenHFi"><span class="level-left"><span class="level-item">1</span><span class="level-item">GenHFi </span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#Abstract"><span class="level-left"><span class="level-item">1.1</span><span class="level-item">Abstract:</span></span></a></li><li><a class="level is-mobile" href="#Introduction"><span class="level-left"><span class="level-item">1.2</span><span class="level-item">Introduction</span></span></a></li><li><a class="level is-mobile" href="#Contribution"><span class="level-left"><span class="level-item">1.3</span><span class="level-item">Contribution</span></span></a></li><li><a class="level is-mobile" href="#Architecture"><span class="level-left"><span class="level-item">1.4</span><span class="level-item">Architecture</span></span></a></li><li><a class="level is-mobile" href="#VQ-GAN"><span class="level-left"><span class="level-item">1.5</span><span class="level-item">VQ-GAN </span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#Contribution-1"><span class="level-left"><span class="level-item">1.5.1</span><span class="level-item">Contribution</span></span></a></li><li><a class="level is-mobile" href="#Approach"><span class="level-left"><span class="level-item">1.5.2</span><span class="level-item">Approach</span></span></a></li></ul></li><li><a class="level is-mobile" href="#TeCoGAN"><span class="level-left"><span class="level-item">1.6</span><span class="level-item">TeCoGAN </span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#Contribution-2"><span class="level-left"><span class="level-item">1.6.1</span><span class="level-item">Contribution</span></span></a></li><li><a class="level is-mobile" href="#Related-works"><span class="level-left"><span class="level-item">1.6.2</span><span class="level-item">Related works</span></span></a></li><li><a class="level is-mobile" href="#Method"><span class="level-left"><span class="level-item">1.6.3</span><span class="level-item">Method</span></span></a></li></ul></li></ul></li></ul></div></div><style>#toc .menu-list > li > a.is-active + .menu-list { display: block; }#toc .menu-list > li > a + .menu-list { display: none; }</style><script src="/js/toc.js" defer></script></div><div class="card widget" data-type="links"><div class="card-content"><div class="menu"><h3 class="menu-label">链接</h3><ul class="menu-list"><li><a class="level is-mobile" href="https://github.com/PanXiebit" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">github</span></span><span class="level-right"><span class="level-item tag">github.com</span></span></a></li><li><a class="level is-mobile" href="ftdpanxie@gmail.com" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">email</span></span><span class="level-right"><span class="level-item tag">ftdpanxie@gmail.com</span></span></a></li></ul></div></div></div><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">分类</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/C/"><span class="level-start"><span class="level-item">C++</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/CSAPP/"><span class="level-start"><span class="level-item">CSAPP</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/DRL/"><span class="level-start"><span class="level-item">DRL</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/GAN/"><span class="level-start"><span class="level-item">GAN</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li><li><a class="level is-mobile" href="/categories/GAN-RL/"><span class="level-start"><span class="level-item">GAN, RL</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/ML/"><span class="level-start"><span class="level-item">ML</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/NLP/"><span class="level-start"><span class="level-item">NLP</span></span><span class="level-end"><span class="level-item tag">14</span></span></a></li><li><a class="level is-mobile" href="/categories/TensorFlow/"><span class="level-start"><span class="level-item">TensorFlow</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/cs224d/"><span class="level-start"><span class="level-item">cs224d</span></span><span class="level-end"><span class="level-item tag">10</span></span></a></li><li><a class="level is-mobile" href="/categories/generation/"><span class="level-start"><span class="level-item">generation</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/generative-models/"><span class="level-start"><span class="level-item">generative models</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/interview/"><span class="level-start"><span class="level-item">interview</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/machine-translation/"><span class="level-start"><span class="level-item">machine translation</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/python/"><span class="level-start"><span class="level-item">python</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/pytorch/"><span class="level-start"><span class="level-item">pytorch</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/reinforcement-learning/"><span class="level-start"><span class="level-item">reinforcement learning</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/sign-language-recognition/"><span class="level-start"><span class="level-item">sign language recognition</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/transfer-learning/"><span class="level-start"><span class="level-item">transfer learning</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/transformer/"><span class="level-start"><span class="level-item">transformer</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"><span class="level-start"><span class="level-item">数据结构与算法</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile" href="/categories/%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB/"><span class="level-start"><span class="level-item">文本分类</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"><span class="level-start"><span class="level-item">论文笔记</span></span><span class="level-end"><span class="level-item tag">40</span></span></a><ul><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/DL/"><span class="level-start"><span class="level-item">DL</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/ESA/"><span class="level-start"><span class="level-item">ESA</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/GAN/"><span class="level-start"><span class="level-item">GAN</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/MRC-and-QA/"><span class="level-start"><span class="level-item">MRC and QA</span></span><span class="level-end"><span class="level-item tag">7</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/Machine-Translation/"><span class="level-start"><span class="level-item">Machine Translation</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/NLP/"><span class="level-start"><span class="level-item">NLP</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/Transformer/"><span class="level-start"><span class="level-item">Transformer</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/capsules/"><span class="level-start"><span class="level-item">capsules</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/computer-vision/"><span class="level-start"><span class="level-item">computer vision</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/constrast-learning/"><span class="level-start"><span class="level-item">constrast learning</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/data-augmentation/"><span class="level-start"><span class="level-item">data augmentation</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/dialogue-system/"><span class="level-start"><span class="level-item">dialogue system</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/language-model/"><span class="level-start"><span class="level-item">language model</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/machine-translation/"><span class="level-start"><span class="level-item">machine translation</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/open-set-recognition/"><span class="level-start"><span class="level-item">open set recognition</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/sentence-embedding/"><span class="level-start"><span class="level-item">sentence embedding</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/text-matching/"><span class="level-start"><span class="level-item">text matching</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/vision-language/"><span class="level-start"><span class="level-item">vision-language</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li></ul></div></div></div></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/panxiaoxie.png" alt="潘小榭" height="28"></a><p class="is-size-7"><span>&copy; 2022 Xie Pan</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("zh-CN");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="回到顶端" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "此网站使用Cookie来改善您的体验。",
          dismiss: "知道了！",
          allow: "允许使用Cookie",
          deny: "拒绝",
          link: "了解更多",
          policy: "Cookie政策",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.5/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="想要查找什么..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"想要查找什么...","untitled":"(无标题)","posts":"文章","pages":"页面","categories":"分类","tags":"标签"});
        });</script></body></html>