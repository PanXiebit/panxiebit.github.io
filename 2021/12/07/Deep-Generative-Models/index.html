<!doctype html>
<html lang="zh"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>Deep Generative Models - æ½˜å°æ¦­</title><link rel="manifest" href="/manifest.json"><meta name="theme-color" content="black"><meta name="application-name" content="panxiaoxie"><meta name="msapplication-TileImage" content="/img/avatar.png"><meta name="msapplication-TileColor" content="black"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="panxiaoxie"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="description" content="Catalog:   Autoregressive Models (ARMs) Flow-based models (flows): RealNVP and IDFs (Integer Discrete Flows) Variational Auto-Encoders (VAEs): a plain VAE and various priors, a hierarchical VAE Hybrid"><meta property="og:type" content="blog"><meta property="og:title" content="panxiaoxie"><meta property="og:url" content="https://github.com/PanXiebit"><meta property="og:site_name" content="panxiaoxie"><meta property="og:description" content="Catalog:   Autoregressive Models (ARMs) Flow-based models (flows): RealNVP and IDFs (Integer Discrete Flows) Variational Auto-Encoders (VAEs): a plain VAE and various priors, a hierarchical VAE Hybrid"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://www.qt86.com/cache/1625298592_187938.png"><meta property="article:published_time" content="2021-12-07T12:05:04.000Z"><meta property="article:modified_time" content="2022-04-10T15:12:53.645Z"><meta property="article:author" content="panxiaoxie"><meta property="article:tag" content="generation"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="https://www.qt86.com/cache/1625298592_187938.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"http://www.panxiaoxie.cn/2021/12/07/Deep-Generative-Models/"},"headline":"Deep Generative Models","image":["http://www.panxiaoxie.cn/2021/12/07/Deep-Generative-Models/lvm_diagram.png","http://www.panxiaoxie.cn/2021/12/07/Deep-Generative-Models/elbo.png","http://www.panxiaoxie.cn/2021/12/07/Deep-Generative-Models/reparameter_trick.png","http://www.panxiaoxie.cn/2021/12/07/Deep-Generative-Models/kl.png","http://www.panxiaoxie.cn/2021/12/07/Deep-Generative-Models/latent_variable_likelihood_all.png","http://www.panxiaoxie.cn/2021/12/07/Deep-Generative-Models/latent_variable_likelihood_constrained.png","http://www.panxiaoxie.cn/2021/12/07/Deep-Generative-Models/2level_vae.png","http://www.panxiaoxie.cn/2021/12/07/Deep-Generative-Models/diffusion_model2.png","http://www.panxiaoxie.cn/2021/12/07/Deep-Generative-Models/cat_ddgm.png"],"datePublished":"2021-12-07T12:05:04.000Z","dateModified":"2022-04-10T15:12:53.645Z","author":{"@type":"Person","name":"Xie Pan"},"publisher":{"@type":"Organization","name":"æ½˜å°æ¦­","logo":{"@type":"ImageObject","url":"http://www.panxiaoxie.cn/img/panxiaoxie.png"}},"description":"Catalog:   Autoregressive Models (ARMs) Flow-based models (flows): RealNVP and IDFs (Integer Discrete Flows) Variational Auto-Encoders (VAEs): a plain VAE and various priors, a hierarchical VAE Hybrid"}</script><link rel="canonical" href="http://www.panxiaoxie.cn/2021/12/07/Deep-Generative-Models/"><link rel="icon" href="/img/avatar.png"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/css/justifiedGallery.min.css"><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script><!--!--><!--!--><meta name="generator" content="Hexo 5.4.0"></head><body class="is-2-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/panxiaoxie.png" alt="æ½˜å°æ¦­" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">ä¸»é¡µ</a><a class="navbar-item" href="/archives">å½’æ¡£</a><a class="navbar-item" href="/categories">åˆ†ç±»</a><a class="navbar-item" href="/tags">æ ‡ç­¾</a><a class="navbar-item" href="/about">å…³äºæˆ‘</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/PanXiebit"><i class="fab fa-github"></i></a><a class="navbar-item is-hidden-tablet catalogue" title="ç›®å½•" href="javascript:;"><i class="fas fa-list-ul"></i></a><a class="navbar-item search" title="æœç´¢" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-10-widescreen"><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2021-12-07T12:05:04.000Z" title="2021/12/7 ä¸‹åˆ8:05:04">2021-12-07</time>å‘è¡¨</span><span class="level-item"><time dateTime="2022-04-10T15:12:53.645Z" title="2022/4/10 ä¸‹åˆ11:12:53">2022-04-10</time>æ›´æ–°</span><span class="level-item"><a class="link-muted" href="/categories/generation/">generation</a></span><span class="level-item">42 åˆ†é’Ÿè¯»å®Œ (å¤§çº¦6320ä¸ªå­—)</span></div></div><h1 class="title is-3 is-size-4-mobile">Deep Generative Models</h1><div class="content"><p>Catalog: </p>
<ul>
<li>Autoregressive Models (ARMs)</li>
<li><a href="#flow_based">Flow-based models (flows)</a>: RealNVP and IDFs (Integer Discrete Flows)</li>
<li><a href="#vaes">Variational Auto-Encoders (VAEs)</a>: a plain VAE and various priors, a hierarchical VAE</li>
<li>Hybrid modeling</li>
<li><a href="#energy">Energy-based Models</a></li>
<li><a href="#gans">Generative Adversarial Networks (GANs)</a></li>
<li>Diffusion-based Deep Generative Models (DDGMs): a Gaussian forward diffusion</li>
<li>Neural Compression with Deep Generative Modeling</li>
</ul>
<span id="more"></span>

<h2 id="VAEs"><a href="#VAEs" class="headerlink" title="VAEs  "></a>VAEs  <a name="vaes"></a></h2><p>ä»¥å›¾åƒç”Ÿæˆä¸ºä¾‹ï¼Œæƒ³è±¡ä¸€ä¸‹è¿™ä¸ªåœºæ™¯ï¼Œæˆ‘ä»¬ç°åœ¨æœ‰ä¸€å †é©¬ğŸçš„å›¾ç‰‡ï¼Œæˆ‘ä»¬ç°åœ¨å¸Œæœ›å­¦ä¹  $p(x)$ï¼Œä»è€Œç”Ÿæˆæ–°çš„å›¾ç‰‡ã€‚é‚£ä¹ˆæˆ‘ä»¬å¯ä»¥é—®ä¸‹è‡ªå·±ï¼Œæˆ‘ä»¬å¦‚ä½•å»ç”»å‡ºé©¬çš„å›¾ç‰‡å‘¢ï¼Ÿæ¢å¥è¯è¯´ï¼Œæˆ‘ä»¬æŠŠè‡ªå·±å½“ä½œä¸€ä¸ªç”Ÿæˆæ¨¡å‹ï¼Œæˆ‘ä»¬å¦‚ä½•åšè¿™ä»¶äº‹å‘¢ï¼Ÿä¹Ÿè®¸æˆ‘ä»¬ä¼šå…ˆå‹¾å‹’å‡ºä¸€åŒ¹é©¬çš„å¤§è‡´è½®å»“ï¼Œå®ƒçš„å¤§å°å’Œå½¢çŠ¶ï¼Œç„¶åæ·»åŠ é©¬è¹„ï¼Œå¡«å……å¤´éƒ¨çš„ç»†èŠ‚ï¼Œç»™å®ƒä¸Šè‰²ç­‰ç­‰ã€‚æœ€åï¼Œæˆ‘ä»¬å¯ä»¥è€ƒè™‘èƒŒæ™¯ã€‚ä¸€èˆ¬æ¥è¯´ï¼Œæˆ‘ä»¬å¯ä»¥è¯´æ•°æ®ä¸­æœ‰ä¸€äº›å› ç´ ï¼ˆä¾‹å¦‚è½®å»“ã€é¢œè‰²ã€èƒŒæ™¯ï¼‰å¯¹äºç”Ÿæˆå¯¹è±¡ï¼ˆè¿™é‡Œæ˜¯é©¬ï¼‰è‡³å…³é‡è¦ã€‚ ä¸€æ—¦æˆ‘ä»¬å†³å®šäº†è¿™äº›å› ç´ ï¼Œæˆ‘ä»¬å°±å¯ä»¥é€šè¿‡æ·»åŠ ç»†èŠ‚æ¥ç”Ÿæˆå®ƒä»¬ã€‚ å½“æˆ‘ä»¬ç”»æŸç‰©æ—¶ï¼Œè¿™æˆ–å¤šæˆ–å°‘æ˜¯æˆ‘ä»¬ç”Ÿæˆä¸€å¹…ç”»çš„è¿‡ç¨‹ã€‚</p>
<p>æˆ‘ä»¬ç°åœ¨ç”¨æ•°å­¦æ¥è¡¨è¾¾è¿™ä¸ªç”Ÿæˆè¿‡ç¨‹ã€‚ ä¹Ÿå°±æ˜¯è¯´ï¼Œæˆ‘ä»¬æœ‰æˆ‘ä»¬æ„Ÿå…´è¶£çš„é«˜ç»´å¯¹è±¡ $x\in \mathcal{X}^D$ï¼ˆä¾‹å¦‚ï¼Œå¯¹äºå›¾åƒï¼Œ$\mathcal{X}\in {0,1,2,â€¦,255}$ï¼‰å’Œä¸€ä¸ªä½ç»´æ½œåœ¨å˜é‡ $z\in\mathcal{Z}^M$ï¼ˆä¾‹å¦‚ï¼Œ$\mathcal{Z}=\mathbb{R}$)ï¼Œæˆ‘ä»¬å¯ä»¥ç§°ä¹‹ä¸ºæ•°æ®ä¸­çš„éšè—å› ç´ ã€‚ åœ¨æ•°å­¦ä¸Šï¼Œæˆ‘ä»¬å¯ä»¥å°†$\mathcal{Z}^M$ç§°ä¸ºä½ç»´æµå½¢ã€‚ é‚£ä¹ˆï¼Œç”Ÿæˆè¿‡ç¨‹å¯ä»¥è¡¨ç¤ºä¸ºï¼š</p>
<ol>
<li>$z\sim p(z)$ (Figure1, In red)</li>
<li>$x\sim p(x|z)$(Figure1, In Blue)</li>
</ol>
<img src="/2021/12/07/Deep-Generative-Models/lvm_diagram.png" alt="img" style="zoom:20%;">

<center><p>Figure 1. æ½œåœ¨å˜é‡æ¨¡å‹å’Œç”Ÿæˆè¿‡ç¨‹çš„ç®€å›¾. æ³¨æ„åµŒå…¥åœ¨é«˜ç»´ç©ºé—´(æ­¤å¤„ä¸º3D)ä¸­çš„ä½ç»´æµå½¢(æ­¤å¤„ä¸º2D)</p></center>

<p>ç®€å•æ¥è¯´ï¼Œæˆ‘ä»¬é¦–å…ˆé‡‡æ ·ğ³ï¼ˆä¾‹å¦‚ï¼Œæˆ‘ä»¬æƒ³è±¡æˆ‘çš„é©¬çš„å¤§å°ã€å½¢çŠ¶å’Œé¢œè‰²ï¼‰ï¼Œç„¶ååˆ›å»ºå…·æœ‰æ‰€æœ‰å¿…è¦ç»†èŠ‚çš„å›¾åƒï¼Œå³ï¼Œæˆ‘ä»¬ä»æ¡ä»¶åˆ†å¸ƒ $p(x|z)$ä¸­é‡‡æ ·å¾—åˆ°xã€‚ ç”±äºè®¸å¤šå„ç§å¤–éƒ¨å› ç´ ï¼Œåˆ›å»ºä¸¤æ¬¡å®Œå…¨ç›¸åŒçš„å›¾åƒå‡ ä¹æ˜¯ä¸å¯èƒ½çš„ã€‚ </p>
<p>æ½œåœ¨å˜é‡æ¨¡å‹èƒŒåçš„ideaæ˜¯æˆ‘ä»¬å¼•å…¥äº†æ½œåœ¨å˜é‡ $z$ ï¼Œå¹¶ä¸”è”åˆåˆ†å¸ƒè¢«åˆ†è§£å¦‚ä¸‹ï¼š$ ğ‘(ğ±,ğ³)=ğ‘(ğ±|ğ³)ğ‘(ğ³)$. è¿™ä¸ªå…¬å¼è¡¨è¾¾çš„å°±æ˜¯ä¸Šè¿°çš„ç”Ÿæˆè¿‡ç¨‹ã€‚ ä½†æ˜¯åœ¨è®­ç»ƒæ—¶æˆ‘ä»¬åªèƒ½è®¿é—®æ ·æœ¬ $x$ã€‚ å› æ­¤ï¼Œæ ¹æ®æ¦‚ç‡æ¨ç†ï¼Œæˆ‘ä»¬åº”è¯¥å¯¹æœªçŸ¥çš„æ½œåœ¨å˜é‡ï¼Œä¹Ÿå°±æ˜¯ğ³ ï¼Œè¿›è¡Œæ±‚å’Œï¼ˆsum out, ä¹Ÿå«è¾¹ç¼˜åŒ– marginalize outï¼‰ã€‚æœ€åï¼Œå…¶è¾¹ç¼˜ä¼¼ç„¶å‡½æ•°å¦‚ä¸‹ï¼š</p>
<p>$$p({x}) = \int p({x} | {z}) p({z})\ \mathrm{d} {z} $$</p>
<p>é‚£ä¹ˆé—®é¢˜æ¥äº†ï¼Œå¦‚ä½•è®¡ç®—è¿™ä¸ªç§¯åˆ†å‘¢ï¼Ÿæ€»çš„æ¥è¯´ï¼Œè¿™æ˜¯ä¸ªéå¸¸å¤æ‚çš„ä»»åŠ¡ã€‚æœ‰ä¸¤ä¸ªå¯èƒ½çš„è§£å†³æ–¹æ³•ï¼š1. ç›´æ¥å¤„ç†è¿™ä¸ªç§¯åˆ† (<strong>Probabilistic PCA</strong> )ï¼›2. åˆ©ç”¨è¿‘ä¼¼çš„æ–¹æ³•ä¹Ÿæ¥è§£å†³ï¼Œä¹Ÿå°±æ˜¯å˜åˆ†æ¨æ–­ <strong>(variational inference)</strong>.</p>
<h3 id="Probabilistic-PCA"><a href="#Probabilistic-PCA" class="headerlink" title="Probabilistic PCA"></a>Probabilistic PCA</h3><p>å¯¹äº $p(x|z)$æ˜¯çº¿æ€§æ¨¡å‹æ—¶ï¼Œå¯ä»¥ç›´æ¥æ±‚è§£ã€‚ä½†æ¨å¯¼è¿‡ç¨‹æ²¡çœ‹æ‡‚ï¼Œå…ˆä¸å†™äº†ã€‚</p>
<h3 id="Variational-Inference-for-Non-linear-Latent-Variable-Models"><a href="#Variational-Inference-for-Non-linear-Latent-Variable-Models" class="headerlink" title="Variational Inference for Non-linear Latent Variable Models"></a>Variational Inference for Non-linear Latent Variable Models</h3><p>è®©æˆ‘ä»¬å†çœ‹ä¸€æ¬¡ç§¯åˆ†ï¼Œæ˜¾ç„¶æˆ‘ä»¬æ— æ³•å‡†ç¡®è®¡ç®—ç§¯åˆ†ã€‚ æœ€ç®€å•çš„æ–¹æ³•æ˜¯ä½¿ç”¨è’™ç‰¹å¡ç½—è¿‘ä¼¼ï¼š<br>$$<br>\begin{align}<br>p(\mathbf{x}) &amp;= \int p(\mathbf{x} | \mathbf{z})\ p(\mathbf{z})\ \mathrm{d} \mathbf{z} \\<br>    &amp;= E_{\mathbf{z}\sim p(\mathbf{z})} \left[ p(\mathbf{x} | \mathbf{z}) \right] \\<br>    &amp;\approx \frac{1}{K} \sum_{k} p(\mathbf{x} | \mathbf{z}_{k}) \end{align}<br>$$<br>å…¶ä¸­ï¼Œåœ¨æœ€åä¸€è¡Œæˆ‘ä»¬é‡‡ç”¨è¿‘ä¼¼çš„æ–¹æ³•æ¥æ¨¡æ‹Ÿè¿™ä¸ªæœŸæœ›/ç§¯åˆ†å‡½æ•°ã€‚æˆ‘ä»¬åŸºäºæ½œåœ¨å˜é‡çš„çš„å…ˆéªŒæ¦‚ç‡æ¥å¾—åˆ°samplesï¼Œ$z_k\sim p(z)$. åœ¨å½“å‰è®¡ç®—æœºè¶Šæ¥è¶Šå¿«çš„æƒ…å†µä¸‹ï¼Œè¿™ä¸ªæ–¹æ³•æ˜¯ç›¸å¯¹ç®€å•çš„ï¼Œæˆ‘ä»¬å¯ä»¥åœ¨çŸ­æ—¶é—´å†…é‡‡æ ·å‡ºæ— æ•°çš„ç‚¹ã€‚ç„¶è€Œï¼Œæˆ‘ä»¬å­¦è¿‡çš„ç»Ÿè®¡å­¦çŸ¥è¯†å‘Šè¯‰æˆ‘ä»¬ï¼Œå½“æ½œåœ¨ç©ºé—´æ˜¯$z\in\mathcal{Z}^M$å¤šç»´ï¼Œä¸”$M$å¾ˆå¤§çš„æ—¶å€™ï¼Œæˆ‘ä»¬ä¼šé™·å…¥ç»´åº¦ç¾éš¾ã€‚ä¸ºäº†coverä½æ ·æœ¬ç©ºé—´ï¼Œæˆ‘ä»¬æ‰€éœ€é‡‡æ ·çš„æ ·æœ¬æ˜¯Mçš„æŒ‡æ•°å½¢å¼ã€‚å¦‚æœæˆ‘ä»¬é‡‡æ ·çš„æ ·æœ¬æ•°ä¸å¤Ÿï¼Œé‚£ä¹ˆè¿™ä¸ªè¿‘ä¼¼æ•ˆæœå°±ä¸å¥½ã€‚</p>
<p>æˆ‘ä»¬å½“ç„¶å¯ä»¥é‡‡ç”¨ä¸€äº›æ›´å…ˆè¿›çš„è’™ç‰¹å¡æ´›æ–¹æ³•ï¼Œç„¶è€Œï¼Œå®ƒä»¬å§‹ç»ˆä¼šå—åˆ°ç»´åº¦ç¾éš¾çš„å½±å“ã€‚å¦ä¸€ä¸ªå¯é€‰æ‹©çš„è¿‘ä¼¼æ–¹æ³•æ˜¯å˜åˆ†æ¨æ–­<strong>variational inference</strong> (Jordan et al., 1999). æˆ‘ä»¬è€ƒè™‘ä¸€ç»„ç”± $\phi$ å‚æ•°åŒ–çš„å˜åˆ†åˆ†å¸ƒï¼Œ${q_{\phi}(z)}$. æ¯”å¦‚ï¼Œæˆ‘ä»¬å‡è®¾$\phi$ä¸ºé«˜æ–¯åˆ†å¸ƒï¼Œ $\phi={\mu, \sigma^2}$. æˆ‘ä»¬çŸ¥é“è¿™äº›åˆ†å¸ƒçš„å½¢å¼ï¼Œå¹¶å‡è®¾å®ƒä»¬å°†éé›¶çš„æ¦‚ç‡åˆ†é…ç»™æ‰€æœ‰çš„æ½œåœ¨å˜é‡ $z\in \mathcal{Z}^{M}$. ç„¶åï¼Œè¿™ä¸ªè¾¹ç¼˜æ¦‚ç‡åˆ†å¸ƒå¯ä»¥è¿‘ä¼¼æ¨å¯¼å¦‚ä¸‹ï¼š<br>$$<br>\begin{align}<br>\ln p(x) &amp;= ln\int p(x|z)p(z)dz \\<br>&amp;= ln\int \dfrac{q_{\phi}(z)}{q_{\phi}(z)}p(x|z)p(z)dz \\<br>&amp;= lnE_{z\sim q_{\phi}(z)}[\dfrac{p(x|z)p(z)}{q_{\phi}(z)}] \\<br>&amp;\ge E_{z\sim q_{\phi}(z)}ln[\dfrac{p(x|z)p(z)}{q_{\phi}(z)}] \\<br>&amp;= E_{z\sim q_{\phi}(z)} [lnp(x|z)+lnp(z)-lnq_{\phi}(z)] \\<br>&amp;= E_{z\sim q_{\phi}(z)} [lnp(x|z)] - E_{z\sim q_{\phi}(z)}[lnq_{\phi}(z) - lnp(z)]<br>\end{align}<br>$$<br>ç¬¬4è¡Œä½¿ç”¨äº†<strong>Jensenâ€™s inequality</strong>. ä¸Šè¿°æ¨å¯¼è¿‡ç¨‹ï¼Œæˆ‘ä»¬æŠŠ $q_{\phi}(z)$ æ¢æˆ <strong>amortized variational posterior</strong>ï¼Œä¹Ÿå°±æ˜¯ $q_{\phi}(z|x)$ æ˜¯ä¸å½±å“æ¨å¯¼è¿‡ç¨‹çš„ï¼Œå› æ­¤æˆ‘ä»¬å¯ä»¥å¾—åˆ°ï¼š</p>
<p>$$lnp(z)\ge E_{z\sim q_{\phi}(z|x)} [lnp(x|z)] - E_{z\sim q_{\phi}(z|x)}[lnq_{\phi}(z|x) - lnp(z)]$$</p>
<p>amortized variational posterior éå¸¸æœ‰ç”¨ï¼Œå› ä¸ºæˆ‘ä»¬å¯ä»¥åˆ©ç”¨ç¥ç»ç½‘ç»œå¾—åˆ°è¿™æ ·ä¸€ä¸ªæ¨¡å‹ï¼Œç»™å®šè¾“å…¥ $x$ï¼Œç„¶åè¾“å‡ºå¯¹åº”åˆ†å¸ƒçš„å‚æ•°ã€‚åœ¨  (Kim et al., 2018) ä¸­ï¼Œä½œè€…ä½¿ç”¨äº†ä¸€ç§ semi-amortized variational inference. </p>
<p>æœ€åï¼Œæˆ‘ä»¬å¾—åˆ°ä¸€ä¸ªauto encoder-likeæ¨¡å‹ï¼Œå…¶åŒ…æ‹¬ä¸€ä¸ªencoder, $q_{\phi}(z|x)$ å’Œ ä¸€ä¸ª decoder, $p(x|z)$. æˆ‘ä»¬ç”¨éšæœºæ€§æ¥å¼ºè°ƒencoderå’Œdecoderå…¶å®å°±æ˜¯æ¦‚ç‡åˆ†å¸ƒï¼Œ<strong>è¿™ä¸deterministic auto-encoderæ˜¯æœ‰åŒºåˆ«çš„ï¼ˆè¿™é‡Œæ²¡å¤ªæ‡‚ï¼‰</strong>ã€‚è¿™ä¸ªå¸¦æœ‰  <strong>amortized variational posterior</strong>çš„è‡ªç¼–ç æ¨¡å‹å°±æ˜¯å˜åˆ†è‡ªç¼–ç  <strong>Variational Auto-Encoder</strong> (Kingma &amp; Welling, 2013; Rezende et al., 2014). å…¶ä¼¼ç„¶å‡½æ•°çš„ä¸‹ç•Œå°±æ˜¯ Evidence LOwer Bound (<strong>ELBO</strong>).</p>
<p>ELBOçš„ç¬¬ä¸€é¡¹æ˜¯ <strong>reconstruction error</strong>,$E_{z\sim q_{\phi}(z|x)} [lnp(x|z)]$ ; ç¬¬äºŒé¡¹æ˜¯<strong>regularizer</strong>ï¼Œ$E_{z\sim q_{\phi}(z|x)}[lnq_{\phi}(z|x) - lnp(z)]$,æ°å¥½å°±æ˜¯KLæ•£åº¦ï¼Œæ‰€ä»¥ä¹Ÿå¯ä»¥æˆä¸ºKL item. ä½†åœ¨æ›´å¤æ‚çš„æ¨¡å‹ä¸­ï¼Œè¿™ä¸€é¡¹å¹¶ä¸ä¸€å®šæ˜¯ KL termï¼Œå› æ­¤ç§°ä½œregularizeræ›´é€šç”¨ä¸€ç‚¹ã€‚</p>
<blockquote>
<p>å›é¡¾ä¸‹ï¼šç†µ $\rightarrow$ äº¤å‰ç†µ $\rightarrow$ ç›¸å¯¹ç†µ/KLæ•£åº¦</p>
<ol>
<li><p>ä¿¡æ¯é‡ä¸æ¦‚ç‡æˆåæ¯”ï¼Œå½“æ¦‚ç‡è¶Šå¤§æ—¶ï¼Œä¿¡æ¯é‡è¶Šå°ï¼›å¹¶ä¸”ä¿¡æ¯é‡ä¸ºéè´Ÿæ•°ã€‚å› æ­¤ï¼Œå®šä¹‰ä¿¡æ¯é‡ä¸º $log\dfrac{1}{p}$. ç†µæ˜¯ä¿¡æ¯é‡çš„æœŸæœ›ï¼š$E_{x\sim p(x)}ln\dfrac{1}{p(x)}$</p>
</li>
<li><p>äº¤å‰ç†µæŒ‡çš„æ˜¯ï¼šæ ¹æ®çœŸå®åˆ†å¸ƒpæ¥è¡¡é‡é¢„æµ‹åˆ†å¸ƒqçš„åº¦é‡ã€‚åŒæ ·çš„æˆ‘ä»¬ä¹Ÿç”¨ä¿¡æ¯é‡çš„æœŸæœ›æ¥è¡¡é‡è¿™ä¸ªäº¤å‰ç†µåº¦é‡ï¼Œæˆ‘ä»¬å¸Œæœ›äº¤å‰ç†µè¶Šå°æ—¶ï¼Œé¢„æµ‹çš„qè¶Šå‡†ç¡®ï¼Œä¹Ÿå°±æ˜¯è¶Šæ¥è¿‘äº1ã€‚ç±»ä¼¼åœ°ï¼Œäº¤å‰ç†µå¯ä»¥å†™æˆ  $H(p, q) = E_{x\sim p(x)}ln\dfrac{1}{q(x)}$. å®é™…ä¸Šï¼Œæˆ‘ä»¬æ˜¯æ— æ³•çŸ¥é“çœŸå®åˆ†å¸ƒpçš„ï¼Œåªèƒ½ä¾æ®ç°æœ‰çš„æ ·æœ¬ç»Ÿè®¡å¾—åˆ°ã€‚</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line">   </span><br><span class="line">size = <span class="number">3</span></span><br><span class="line"><span class="built_in">input</span> = torch.randn(<span class="number">2</span>, size)</span><br><span class="line">target = torch.Tensor([<span class="number">0</span>, <span class="number">2</span>]).long()</span><br><span class="line">   </span><br><span class="line"><span class="comment"># use loss function</span></span><br><span class="line">loss_fn = nn.CrossEntropyLoss(reduction=<span class="string">&quot;mean&quot;</span>)</span><br><span class="line">loss = loss_fn(<span class="built_in">input</span>, target)</span><br><span class="line">   </span><br><span class="line"><span class="comment"># computer nll loss step by step</span></span><br><span class="line">score = torch.log_softmax(<span class="built_in">input</span>, dim=<span class="number">1</span>)</span><br><span class="line">my_nll = torch.<span class="built_in">sum</span>(-score * F.one_hot(target, size)) / target.size(<span class="number">0</span>)</span><br><span class="line"><span class="comment"># use nll loss</span></span><br><span class="line">   </span><br><span class="line">nll_loss_fn = nn.NLLLoss()</span><br><span class="line">nll_loss = nll_loss_fn(score, target)</span><br><span class="line">   </span><br><span class="line"><span class="built_in">print</span>(nll_loss == loss == my_nll) <span class="comment"># True</span></span><br></pre></td></tr></table></figure></li>
<li><p>ç›¸å¯¹ç†µï¼š æ ¹æ®<a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Gibbs%27_inequality">Gibbsâ€™ inequality</a>ä¸Šè¿°ä¾‹å­ä¸­çš„ $H(p,q) &gt;= H(p)$ æ’æˆç«‹ã€‚å½“ä¸”ä»…å½“q=pæ—¶ï¼Œè¿™ä¸ªç­‰å·æ‰æˆç«‹ã€‚é‚£ä¹ˆç†µH(p,q)ç›¸æ¯”ç†µH(q)å¤šå‡ºæ¥çš„éƒ¨åˆ†å°±æ˜¯ç›¸å¯¹ç†µ ï¼Œä¹Ÿç§°ä¸ºKLæ•£åº¦(Kullbackâ€“Leibler divergenceï¼ŒKLD).</p>
</li>
</ol>
<p>$$<br>D(p||q)=H(p,q)-H(p)=\sum_{x\sim p(x)}[ln\dfrac{1}{q(x)} - ln\dfrac{1}{p(x)}]=E_{x\sim p(x)}[ln\dfrac{p(x)}{q(x)}]=\int_{x}p(x)[ln\dfrac{p(x)}{q(x)}]<br>$$</p>
</blockquote>
<h3 id="A-different-perspective-on-the-ELBO"><a href="#A-different-perspective-on-the-ELBO" class="headerlink" title="A different perspective on the ELBO"></a>A different perspective on the ELBO</h3><p>ä¸‹é¢æä¾›ä¸€ç§æ–°çš„æ¨å¯¼æ–¹æ³•ï¼Œä¸ªäººè§‰å¾—æ›´èƒ½ç†è§£ELBO:<br>$$<br>\begin{align}<br>\ln p(\mathbf{x}) &amp;= E_{\mathbf{z} \sim q_{\phi}(\mathbf{z}|\mathbf{x})} \left[ \ln p(\mathbf{x}) \right] \\<br>&amp;= E_{\mathbf{z} \sim q_{\phi}(\mathbf{z}|\mathbf{x})} \left[ \ln \frac{p(\mathbf{z}|\mathbf{x}) p(\mathbf{x})}{p(\mathbf{z}|\mathbf{x})} \right] \\<br>&amp;= E_{\mathbf{z} \sim q_{\phi}(\mathbf{z}|\mathbf{x})} \left[ \ln \frac{p(\mathbf{x}|\mathbf{z}) p(\mathbf{z})}{p(\mathbf{z}|\mathbf{x})} \right] \quad \text{æ ¹æ®è´å¶æ–¯å…¬å¼p(z|x)p(x)=p(x|z)p(z)}\\<br>&amp;= E_{\mathbf{z} \sim q_{\phi}(\mathbf{z}|\mathbf{x})} \left[ \ln \frac{p(\mathbf{x}|\mathbf{z}) p(\mathbf{z})}{p(\mathbf{z}|\mathbf{x})} \frac{q_{\phi}(\mathbf{z}|\mathbf{x})}{q_{\phi}(\mathbf{z}|\mathbf{x})}\right] \quad \text{è¿™ä¸€æ­¥å¾ˆå…³é”®, } 1 = \frac{q_{\phi(z|x)}}{q_{\phi(z|x)}}, q_{\phi(z|x)} æ˜¯ç”¨æ¥è¿‘ä¼¼çœŸå®åéªŒæ¦‚ç‡çš„å˜åˆ†åéªŒæ¦‚ç‡ \\<br>&amp;= E_{\mathbf{z} \sim q_{\phi}(\mathbf{z}|\mathbf{x})} \left[ \ln p(\mathbf{x}|\mathbf{z}) \frac{p(\mathbf{z})}{q_{\phi}(\mathbf{z}|\mathbf{x})}  \frac{q_{\phi}(\mathbf{z}|\mathbf{x})}{p(\mathbf{z}|\mathbf{x})} \right] \\<br>&amp;= E_{\mathbf{z} \sim q_{\phi}(\mathbf{z}|\mathbf{x})} \left[ \ln p(\mathbf{x}|\mathbf{z}) - \ln \frac{q_{\phi}(\mathbf{z}|\mathbf{x})}{p(\mathbf{z})} + \ln \frac{q_{\phi}(\mathbf{z}|\mathbf{x})}{p(\mathbf{z}|\mathbf{x})} \right] \quad \text{åˆ°è¿™é‡Œèƒ½çœ‹å‡ºKLæ•£åº¦äº†}\\<br>&amp;= E_{\mathbf{z} \sim q_{\phi}(\mathbf{z}|\mathbf{x})} \left[ \ln p(\mathbf{x}|\mathbf{z}) \right] - KL\left[ q_{\phi}(\mathbf{z}|\mathbf{x}) | p(\mathbf{z}) \right] + KL \left[ q_{\phi}(\mathbf{z}|\mathbf{x}) |p(\mathbf{z}|\mathbf{x}) \right] .<br>\end{align}<br>$$<br>å‰ä¸¤é¡¹å°±æ˜¯ ELBOï¼Œæœ€åä¸€é¡¹ä¸­ $p(z|x)$ è¿™ä¸ªè¡¨ç¤ºçœŸå®çš„åéªŒæ¦‚ç‡ real posterior, $q_{\phi}(z|x)$ è¡¨ç¤ºå˜åˆ†åéªŒæ¦‚ç‡ variational posterior. æˆ‘ä»¬å¹¶ä¸çŸ¥é“çœŸå®çš„åéªŒæ¦‚ç‡ï¼Œä½†æ˜¯æˆ‘ä»¬å¯ä»¥è·³è¿‡è¿™ä¸€é¡¹ï¼Œå› ä¸ºKLæ•£åº¦ä¸€å®šå¤§äºç­‰äº0. å»æ‰æœ€åä¸€é¡¹ï¼Œæˆ‘ä»¬å¾—åˆ°ELBOï¼ŒåŒæ—¶æˆ‘ä»¬çŸ¥é“ ELBOå’ŒçœŸå®çš„å¯¹æ•°ä¼¼ç„¶ä¹‹é—´çš„é—´éš”æ˜¯  $KL \left[ q_{\phi}({z}|{x}) |p({z}|{x}) \right] $.<br>$$<br>\begin{align}<br>\ln p(\mathbf{x}) &amp;= E_{\mathbf{z} \sim q_{\phi}(\mathbf{z}|\mathbf{x})} \left[ \ln p(\mathbf{x}|\mathbf{z}) \right] - KL\left[ q_{\phi}(\mathbf{z}|\mathbf{x}) | p(\mathbf{z}) \right] + KL \left[ q_{\phi}(\mathbf{z}|\mathbf{x}) |p(\mathbf{z}|\mathbf{x}) \right] \\<br>&amp;\ge E_{\mathbf{z} \sim q_{\phi}(\mathbf{z}|\mathbf{x})} \left[ \ln p(\mathbf{x}|\mathbf{z}) \right] - KL\left[ q_{\phi}(\mathbf{z}|\mathbf{x}) | p(\mathbf{z}) \right]<br>\end{align}<br>$$<br>Beautiful! ä½†åŒæ ·æˆ‘ä»¬èƒ½çœ‹å‡ºä¸€äº›é—®é¢˜ï¼Œå¦‚æœ $q_{\phi}({z}|{x})$ å’Œ $p(z|x)$ è·ç¦»å¾ˆå¤§ï¼Œé‚£ä¹ˆELBOä¼˜åŒ–çš„å†å¥½ï¼ŒELBOå’ŒçœŸå®çš„å¯¹æ•°ä¼¼ç„¶ä¹‹é—´çš„å·®è·ä¾ç„¶å¾ˆå¤§ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œå¦‚æœæˆ‘ä»¬é‡‡ç”¨å¾ˆç®€å•çš„åéªŒæ¦‚ç‡ï¼Œæˆ‘ä»¬ä¼šå¾—åˆ°ä¸€ä¸ªä¸å¤ªå¥½çš„VAEæ¨¡å‹ã€‚</p>
<img src="/2021/12/07/Deep-Generative-Models/elbo.png" style="zoom:30%;">

<center><p>Figure 2. ELBOæ˜¯å¯¹æ•°ä¼¼ç„¶çš„ä¸‹ç•Œã€‚ELBOæœ€å¤§æ—¶å¯¹åº”çš„ $\hat {\theta}$ å¹¶ä¸ä¸€å®šä¹Ÿèƒ½è®©å¯¹æ•°ä¼¼ç„¶æœ€å¤§ã€‚ELBO è¶Šlosserï¼Œè¿™å¯¹æ¨¡å‹å‚æ•°çš„æœ€å¤§ä¼¼ç„¶ä¼°è®¡çš„åå·®è¶Šå¤§ã€‚ </p></center>



<h3 id="Components-of-VAEs"><a href="#Components-of-VAEs" class="headerlink" title="Components of VAEs"></a><strong>Components of VAEs</strong></h3><ul>
<li>æˆ‘ä»¬ä½¿ç”¨amortized variational posteriors ${q_{\phi}(z|x)}_{\phi}$ æ¥è¿‘ä¼¼çœŸå®çš„åéªŒåˆ†å¸ƒ $p(z|x)$. è¿™ä¸ªæ¦‚ç‡åˆ†å¸ƒå¯ä»¥çœ‹ä½œæ˜¯ <strong>encoder</strong>.</li>
<li>conditional likelihood p(x|z) å¯¹åº”çš„æ¦‚ç‡åˆ†å¸ƒå¯ä»¥çœ‹ä½œæ˜¯ <strong>decoder</strong></li>
<li>$p(z)$ æ˜¯å¯¹äºæ½œåœ¨å˜é‡çš„è¾¹ç¼˜åˆ†å¸ƒï¼Œä¹Ÿå¯ä»¥çœ‹ä½œæ˜¯ <strong>prior</strong> æ¨¡å‹</li>
</ul>
<p>è‡³æ­¤ï¼Œè¿˜æœ‰ä¸¤ä¸ªé—®é¢˜éœ€è¦è§£å†³ï¼š</p>
<ol>
<li>å¦‚ä½•å‚æ•°åŒ–è¿™äº›distributions?</li>
<li>å¦‚ä½•è®¡ç®—è¿™äº›æœŸæœ›å‘¢ï¼Ÿä¹Ÿå°±æ˜¯ç§¯åˆ†ã€‚</li>
</ol>
<h4 id="Parameterization-of-distributions"><a href="#Parameterization-of-distributions" class="headerlink" title="Parameterization of distributions"></a>Parameterization of distributions</h4><p>æ˜¾ç„¶ï¼Œæˆ‘ä»¬ç”¨Neural Networksæ¥è¡¨è¾¾ä¸Šè¿°ä¸¤ä¸ªdistributions: encoder å’Œ decoderã€‚åœ¨VAEæ¡†æ¶ä¸‹ï¼Œå¤§éƒ¨åˆ†æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ä»»ä½•distributions. ä½†æ˜¯ï¼Œæˆ‘ä»¬ä¹Ÿå¿…é¡»æ»¡è¶³å¯¹åº”çš„ä»»åŠ¡ã€‚</p>
<ol>
<li>å¯¹äºdecoderåˆ†å¸ƒ $p_{\theta}(x|z)$ æ˜¾ç„¶ä¸å¯èƒ½æ˜¯æ­£æ€åˆ†å¸ƒï¼Œå› ä¸ºimageçš„pixel valuesæ˜¯ç¦»æ•£çš„ã€‚ä¸€ä¸ªå¯èƒ½çš„distributionå¯ä»¥æ˜¯ <strong>categorical distribution</strong>:</li>
</ol>
<p>â€‹    $$p_{\theta}(x|ğ³)=\text{Categorical}(ğ±|\theta(ğ³))$$ </p>
<p>â€‹    å…¶ä¸­ $\theta(z) = \text{softmax}(NN(z))$. è¿™é‡ŒæŠŠé‡æ„å½“ä½œåˆ†ç±»ä»»åŠ¡æ¥åšï¼Œå½“ç„¶ä¹Ÿå¯ä»¥æ˜¯å›å½’ä»»åŠ¡ã€‚</p>
<ol start="2">
<li>å¯¹äºæ½œåœ¨å˜é‡çš„åˆ†å¸ƒï¼Œä¸ºäº†æ–¹ä¾¿ï¼Œé€šå¸¸ $z$ å¯è§†ä¸ºè¿ç»­éšæœºå˜é‡çš„å‘é‡ï¼Œ$z\in \mathbb{R}^M$. å› æ­¤ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ Gaussians æ¥è¡¨ç¤º variational posterior å’Œ prior.<br>$$<br>\begin{align}<br>q_{\phi}(\mathbf{z}|\mathbf{x}) &amp;= \mathcal{N}\left(\mathbf{z} | \mu_{\phi}(\mathbf{x}), \mathrm{diag}\left[ \sigma_{\phi}^2(\mathbf{x}) \right] \right) \\<br>p(\mathbf{z}) &amp;= \mathcal{N}\left(\mathbf{z} | 0, \mathbf{I} \right)<br>\end{align}<br>$$<br>å…¶ä¸­ $\mu_{phi}(x), \sigma_{\phi}(x)$ æ˜¯ç¥ç»ç½‘ç»œçš„è¾“å‡ºã€‚åœ¨å®é™…ä½¿ç”¨ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨NNå¾—åˆ° $2M$ çš„ values $\in R^{1\times 2M}$ï¼Œå…¶ä¸­ $R^{1\times M}$ è¡¨ç¤º meansï¼Œ$R^{1\times M}$ è¡¨ç¤º variances. </li>
</ol>
<h4 id="Reparameterization-trick"><a href="#Reparameterization-trick" class="headerlink" title="Reparameterization trick"></a>Reparameterization trick</h4><p>åˆ°ç›®å‰ä¸ºæ­¢ï¼Œæˆ‘ä»¬å­¦ä¹ äº†log-likelihoodå’ŒELBOã€‚ä½†æ˜¯ä»ç„¶æœ‰ä¸€ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬ç”¨encoder $q_{\phi}(z|x)$ å¾—åˆ°å…³äºæ½œåœ¨å˜é‡çš„åˆ†å¸ƒï¼Œæˆ‘ä»¬è¯¥å¦‚ä½•è®¡ç®—$E_{z\sim q_{\phi}(z|x)}(x|z)$è¿™ä¸ªç§¯åˆ†å‘¢ï¼Ÿæ˜¾ç„¶ï¼Œ$z\sim q_{\phi}(z|x)$è¿™ä¸ªé‡‡æ ·è¿‡ç¨‹æ˜¯ä¸å¯å¯¼çš„ï¼Œæˆ‘ä»¬å¯ä»¥é‡‡ç”¨MC-approximation,ä½†æ˜¯è¿™æ ·ä»ç„¶æœ‰ä¸ªé—®é¢˜ï¼Œä»è¿™ä¸ªå˜åˆ†åéªŒsampleå¾—åˆ°çš„zï¼Œåœ¨ELBOçš„è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œåœ¨è®¡ç®—å…³äº$\phi$çš„æ¢¯åº¦æ—¶ï¼Œæ¢¯åº¦çš„æ–¹å·®ç‰¹åˆ«å¤§ã€‚</p>
<p>å› æ­¤ï¼Œå¦ä¸€ä¸ªå¯èƒ½çš„æ–¹æ³•æ˜¯<strong>reparameterizing</strong>è¿™ä¸ªåˆ†å¸ƒ(Devroye, 1996).  å…·ä½“åœ°ï¼Œæˆ‘ä»¬å¯ä»¥å°†éšæœºå˜é‡ $z$ è¡¨ç¤ºä¸ºå…·æœ‰ç®€å•åˆ†å¸ƒçš„ç‹¬ç«‹éšæœºå˜é‡çš„åŸå§‹å˜æ¢ï¼ˆä¾‹å¦‚ç®—æœ¯è¿ç®—ã€å¯¹æ•°ç­‰ï¼‰çš„ç»„åˆã€‚æ¢å¥è¯è¯´ï¼Œæˆ‘ä»¬ä½¿ç”¨é‡å‚æ•°æŠ€å·§è¡¨è¾¾ä¸ºç¡®å®šæ€§çš„å˜é‡:<br>$$<br>z = \mu + \sigma \cdot \epsilon<br>$$<br>å…¶ä¸­ $\epsilon \sim {N}(\epsilon|0,1)$ .</p>
<img src="/2021/12/07/Deep-Generative-Models/reparameter_trick.png" style="zoom:50%;">

<p>ä½¿ç”¨Reparameterizationæ–¹æ³•èƒ½å¤Ÿæ˜¾è‘—å‡å°æ¢¯åº¦çš„æ–¹æ³•ã€‚Whyï¼Ÿå› ä¸ºéšæœºæ€§æ¥è‡ªç‹¬ç«‹çš„åˆ†å¸ƒ$p(\epsilon)$ï¼Œæˆ‘ä»¬è®¡ç®—æ¢¯åº¦æ˜¯å…³äºç¡®å®šæ€§å‡½æ•°ï¼ˆå³ç¥ç»ç½‘ç»œï¼‰ï¼Œè€Œä¸æ˜¯éšæœºçš„å¯¹è±¡$z\sim q_{\phi}(z|x)$ã€‚ æ›´æ£’çš„æ˜¯ï¼Œç”±äºæˆ‘ä»¬ä½¿ç”¨éšæœºæ¢¯åº¦ä¸‹é™æ¥å­¦ä¹  VAEï¼Œå› æ­¤åœ¨è®­ç»ƒæœŸé—´ä»…é‡‡æ ·ä¸€æ¬¡ $z$ å°±è¶³å¤Ÿäº†ï¼</p>
<p>ç»¼ä¸Šï¼ŒVAEæ¡†æ¶ä¸»è¦åŒ…æ‹¬ï¼š</p>
<ol>
<li>variational posterior  $q_{\phi}(z|x)$ using encoder</li>
<li>sample z from   $q_{\phi}(z|x)$ and feed it to decoder, using  reparameterization trick</li>
<li>conditional likelihood $p_{\theta}(x|z)$ using decoder</li>
<li>reconstruction loss</li>
<li>kl loss between variational posterior and prior $p_{\theta}$. å…¶ä¸­ $q_{\phi}(z|x)\sim {N}(z|\mu, \sigma^2I)$ å¤šç»´é«˜æ–¯åˆ†å¸ƒï¼Œ$p_{\theta}\sim {N}(0,1)$ æ˜¯æ­£æ€åˆ†å¸ƒã€‚</li>
</ol>
<p>KL æ•£åº¦çš„æ¨å¯¼å¦‚ä¸‹ï¼š</p>
<p><img src="/2021/12/07/Deep-Generative-Models/kl.png" alt="image-20211209135812911"></p>
<p>ä»£ç å¦‚ä¸‹ï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">VariationalEncoder</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, latent_dims</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(VariationalEncoder, self).__init__()</span><br><span class="line">        self.linear1 = nn.Linear(<span class="number">784</span>, <span class="number">512</span>)</span><br><span class="line">        self.linear2 = nn.Linear(<span class="number">512</span>, latent_dims)</span><br><span class="line">        self.linear3 = nn.Linear(<span class="number">512</span>, latent_dims)</span><br><span class="line">        </span><br><span class="line">        self.kl = <span class="number">0</span></span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        x = torch.flatten(x, start_dim=<span class="number">1</span>)</span><br><span class="line">        x = F.relu(self.linear1(x))</span><br><span class="line">        mu =  self.linear2(x)</span><br><span class="line">        sigma = torch.exp(self.linear3(x))</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># reparameterization trick</span></span><br><span class="line">        z = mu + sigma*torch.randn_like(sigma)</span><br><span class="line">        </span><br><span class="line">        self.kl = <span class="number">0.5</span>*(sigma**<span class="number">2</span> + mu**<span class="number">2</span> - torch.log(sigma) - <span class="number">1</span>).<span class="built_in">sum</span>()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> z</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Decoder</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, latent_dims</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(Decoder, self).__init__()</span><br><span class="line">        self.linear1 = nn.Linear(latent_dims, <span class="number">512</span>)</span><br><span class="line">        self.linear2 = nn.Linear(<span class="number">512</span>, <span class="number">784</span>)</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, z</span>):</span></span><br><span class="line">        x_hat = F.relu(self.linear1(z))</span><br><span class="line">        x_hat = torch.sigmoid(self.linear2(x_hat))</span><br><span class="line">        <span class="keyword">return</span> x_hat.reshape((-<span class="number">1</span>, <span class="number">1</span>, <span class="number">28</span>, <span class="number">28</span>))</span><br><span class="line">      </span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">VariationalAutoencoder</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, latent_dims</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(VariationalAutoencoder, self).__init__()</span><br><span class="line">        self.encoder = VariationalEncoder(latent_dims)</span><br><span class="line">        self.decoder = Decoder(latent_dims)</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        z = self.encoder(x)</span><br><span class="line">        <span class="keyword">return</span> self.decoder(z)</span><br><span class="line">      </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train</span>(<span class="params">model, data, epochs=<span class="number">20</span></span>):</span></span><br><span class="line">    opt = torch.optim.Adam(model.parameters())</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(epochs):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;epoch: <span class="subst">&#123;epoch+<span class="number">1</span>&#125;</span>/<span class="subst">&#123;epochs&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="keyword">for</span> x, y <span class="keyword">in</span> data:</span><br><span class="line">            x = x.to(device) <span class="comment"># GPU</span></span><br><span class="line">            opt.zero_grad()</span><br><span class="line">            x_hat = model(x)</span><br><span class="line">            loss = ((x - x_hat)**<span class="number">2</span>).<span class="built_in">sum</span>() + model.encoder.kl</span><br><span class="line">            loss.backward()</span><br><span class="line">            opt.step()</span><br><span class="line">    <span class="keyword">return</span> model</span><br><span class="line">      </span><br><span class="line">latent_dims = <span class="number">2</span></span><br><span class="line">vae = VariationalAutoencoder(latent_dims).to(device) <span class="comment"># GPU</span></span><br><span class="line">vae = train(vae, data)</span><br></pre></td></tr></table></figure>



<h3 id="More-about-VAEs"><a href="#More-about-VAEs" class="headerlink" title="More about VAEs!"></a>More about VAEs!</h3><ul>
<li><p><strong>Estimation of the log-likelihood using importance weighting</strong> æˆ‘ä»¬å‰é¢æåˆ°è¿‡ ELBO åªæ˜¯å¯¹æ•°ä¼¼ç„¶çš„ä¸‹ç•Œï¼Œå®ƒä¸åº”è¯¥è¢«ç”¨ä½œå¯¹æ•°ä¼¼ç„¶çš„è‰¯å¥½ä¼°è®¡ã€‚(Burda et al., 2015; Rezende et al., 2014) é‡‡ç”¨äº†ä¸€ç§ importance weighting procedure æ–¹æ³•ã€‚</p>
</li>
<li><p><strong>Enhancing VAEs: Better encoders</strong> æ„å‘³ç€æ›´å¥½çš„åéªŒæ¦‚ç‡, ä¸€ä¸ªå¾ˆé‡è¦çš„æ–¹å‘æ˜¯ conditional flow-based models (van den Berg et al., 2018; Hoogeboom et al., 2020; Kingma et al., 2016; Rezende &amp; Mohamed, 2015; Tomczak &amp; Welling, 2016; Tomczak &amp; Welling, 2017). </p>
</li>
<li><p><strong>Enhancing VAEs: Better decoders</strong> å¯ä»¥ä½¿ç”¨ä¸åŒçš„æ¨¡å‹æˆ–è€…loss functionæ¥æ‹ŸåˆåŸå§‹çš„æ•°æ®ï¼Œæ¯”å¦‚pixel-CNN, transformerç­‰ã€‚</p>
</li>
<li><p><strong>Enhancing VAEs: Better priors</strong> è®¾å®šä¸€ä¸ªå¥½çš„å…ˆéªŒä¹Ÿæ˜¯å¾ˆé‡è¦çš„ï¼Œèƒ½å¤Ÿå‡å°ä¸å˜åˆ†åéªŒçš„gapã€‚å¾ˆå¤šç ”ç©¶å°è¯•è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæ¯”å¦‚ï¼šusing a multimodal prior mimicking the aggregated posterior (known as the VampPrior) (Tomczak &amp; Welling, 2018), or a flow-based prior (e.g., (Gatopoulos &amp; Tomczak, 2020)), an ARM-based prior (Chen et al., 2016) or using an idea of resampling (Bauer &amp; Mnih, 2019).</p>
</li>
<li><p><strong>VAEs for non-image data</strong> ä¸ä»…ä»…æ˜¯å›¾åƒæ•°æ®ï¼Œæ–‡æœ¬ã€åºåˆ—æ•°æ®ç­‰ä¹Ÿå¯ä»¥ã€‚</p>
</li>
<li><p><strong>Extending VAEs</strong> Here, we present the unsupervised version of VAEs. However, there is no restriction to that and we can introduce labels or other variables. In (Kingma et al., 2014) a semi-supervised VAE was proposed. This idea was further extended to the concept of fair representations (Louizos et al., 2015). In (Ilse et al., 2020), the authors proposed a specific latent representation that allows domain generalization in VAEs. In (Blundell et al., 2015) variational inference and the reparameterization trick were used for Bayesian Neural Nets. This paper is not necessarily introducing a VAE, but a VAE-like way of dealing with Bayesian neural nets.</p>
</li>
<li><p><strong>Different latent spaces</strong> in (Davidson et al., 2018; Davidson et al., 2019) a hyperspherical latent-space was used, and in (Mathieu et al., 2019) the hyperbolic latent space was utilized.</p>
</li>
<li><p>**The posterior collapse ** There were many ideas proposed to deal with the posterior collapse. For instance, (He et al., 2019) propose to update variational posteriors more often than the decoder. In (Dieng et al., 2019) a new architecture of the decoder is proposed by introducing <em>skip connection</em> to avoiding the posterior collapse.</p>
</li>
<li><p><strong>Various perspectives on the objective</strong> The core of the VAE is the ELBO. However, we can consider different objectives. For instance, (Dieng et al., 2017) propose an upper-bound to the log-likelihood that is based on the chi-square divergence (CUBO). In (Alemi et al., 2018) an information-theoretic perspective on the ELBO is presented. (Higgins et al., 2016) introduced the ğ›½Î²-VAE where the regularization term is weighted by a fudge factor ğ›½Î². The objective does not correspond to the lowe-bound of the log-likelihood though.</p>
</li>
<li><p><strong>Deterministic Regularized Auto-Encoders</strong>: We can take look at the VAE and the objective, as mentioned before, and think of it as a regularized version of an auto-encoder with a stochastic encoder and a stochastic decoder. (Ghosh et al., 2020) â€œpeeled offâ€ VAEs from all stochasticity and indicated similarities between deterministic regularized auto-encoders and VAEs, and highlited potential issues with VAEs. Moreover, they brilliantly pointed out that even with a deterministic encoders, due to stochasticity of the empirical distribution, we can fit a model to the aggregated posterior. As a result, the deterministic (regularized) auto-encoder could be turned into a generative model by sampling from our model, ğ‘ğœ†(<strong>ğ³</strong>)pÎ»(z), and then, deterministically, mapping <strong>ğ³</strong>z to the space of observable <strong>ğ±</strong>x. In my opinion, this direction should be further explored and an important question is whether we indeed need any stochasticity at all.</p>
</li>
<li><p><strong>Hierarchical VAEs</strong> Very recently, there are many VAEs with a deep, hierarchical structure of latent variables that achieved remarkable results! The most important ones are definitely BIVA (MaalÃ¸e et al., 2019), NVA (Vahdat &amp; Kautz, 2020), and very deep VAEs (Child, 2020). Another interesting perspective on a deep, hierarchical VAE was presented in (Gatopoulos &amp; Tomczak, 2020) where, additionally, a series of deterministic functions was used.</p>
</li>
<li><p><strong>Adversarial Auto-Encoders</strong> Another interesting perspective on VAEs is presented in (Makhzani et al., 2015). Since learning the aggregated posterior as the prior is an important component mentioned in some papers (e.g., (Tomczak &amp; Welling, 2018)), a different approach would be to train the prior with an adversarial loss. Further, (Makhzani et al., 2015) present various ideas how auto-encoders could benefit from adverarial learning.</p>
</li>
</ul>
<h2 id="Hierarchical-Variational-Auto-Encoders"><a href="#Hierarchical-Variational-Auto-Encoders" class="headerlink" title="Hierarchical Variational Auto-Encoders"></a>Hierarchical Variational Auto-Encoders</h2><p>äº¤å‰ç†µï¼š$p_{data}(x)$ æ˜¯çœŸå®åˆ†å¸ƒï¼Œ$p_{\theta}(x)$æ˜¯é¢„æµ‹åˆ†å¸ƒ<br>$$<br>\begin{align}<br>\mathbb{CE}[p_{data}(x)|p_{\theta}(x)] &amp;= E_{x\sim p_{data}(x)}[ln\dfrac{1}{p_{\theta}(x)}] \\<br>&amp;= -\frac{1}{N}\sum_{1}^{N}lnp_{\theta}(x_n)<br>\end{align}<br>$$<br>ç›¸å¯¹ç†µï¼š<br>$$<br>\begin{align}<br>\mathbb{KL}[p_{data}(x)|p_{\theta}(x)] &amp;= -\mathbb{H}[p_{data}(x)] + \mathbb{CE}[p_{data}(x)|p_{\theta}(x)] \\<br>&amp;= const + \mathbb{CE}[p_{data}(x)|p_{\theta}(x)]<br>\end{align}<br>$$</p>
<p><strong>æ½œåœ¨å˜é‡æ¨¡å‹å­˜åœ¨ä¸€ä¸ªé—®é¢˜</strong>ï¼š [åéªŒå´©å¡Œ**(posteroir collapse)**](<a target="_blank" rel="noopener" href="https://datascience.stackexchange.com/questions/48962/what-is-posterior-collapse-phenomenon">python - What is â€œposterior collapseâ€ phenomenon? - Data Science Stack Exchange</a>). å½“åéªŒæœªå‡ºç°å´©å¡Œæ—¶ï¼Œ$z_d$(dç»´æ½œåœ¨å˜é‡)é€šè¿‡encoderé‡‡æ ·å¾—åˆ° $q_{\phi}(z|x)={N}(z|\mu, \sigma^2)$ï¼Œ å…¶ä¸­ $\mu, \sigma$æ˜¯å…³äºè¾“å…¥ $x$ çš„ç¨³å®šçš„å‡½æ•°ã€‚ä¹Ÿå°±æ˜¯encoderä»è¾“å…¥ä¸­æå–åˆ°äº†æœ‰ç”¨çš„ä¿¡æ¯èµ‹äºˆåˆ° $\mu,\sigma$ä¸­ã€‚</p>
<p>å½“å‡ºç°åéªŒå´©å¡Œæ—¶ï¼Œé€šè¿‡encoderä»è¾“å…¥ $x$ æå–åˆ°çš„ä¿¡æ¯å¾ˆå¼±æˆ–è€…å™ªå£°å¤ªå¤§**(too weak or too noisy)**. ä¹Ÿå°±æ˜¯è¯´decoderåœ¨ç”Ÿæˆå›¾åƒæ—¶ï¼Œä¼šå¿½ç•¥æ½œåœ¨å˜é‡ $z$ çš„ä¿¡æ¯ã€‚too noisyæ„å‘³ç€ $\mu,\sigma$ä¸ç¨³å®šï¼Œ too weakæ„å‘³ç€:<br>$$<br>q_{\phi}(z|x) \approx q_{\phi}(z) = \mathcal{N}(a,b)<br>$$<br>å…¶ä¸­ $a,b$ æ˜¯å¸¸é‡ã€‚</p>
<p>ä»å¯è§†åŒ–çš„è§’åº¦çœ‹è¿™ä¸ªé—®é¢˜ï¼š</p>
<img src="/2021/12/07/Deep-Generative-Models/latent_variable_likelihood_all.png" alt="image-20211209135812911" style="zoom:50%;">

<p>æ¨ªè½´æ˜¯é‡æ„lossï¼Œçºµè½´æ˜¯ æ½œåœ¨å˜é‡æ¨¡å‹$p_{\theta}(z|x)$ çš„å‚ä¸åº¦ã€‚å½“å¤„äºä¸Šå›¾çš„å·¦ä¸‹è§’æ—¶ï¼Œè¡¨æ˜é‡æ„losså¾ˆå°ï¼Œä½†æ˜¯åéªŒæ¦‚ç‡å¹¶ä¸é‡è¦ï¼Œä¹Ÿå°±æ˜¯å‡ºç°äº†åéªŒå´©å¡Œã€‚æ‰€ä»¥é—®é¢˜æ¥äº†ï¼Œåœ¨ä¼˜åŒ–è¿‡ç¨‹ä¸­ï¼Œä¸€å®šå­˜åœ¨è¿™æ ·çš„æ¨¡å‹åœ¨å®Œå…¨æŠ›å¼ƒæ½œåœ¨å˜é‡æ¨¡å‹çš„æƒ…å†µä¸‹ä½¿å¾—KLå¾ˆå°ã€‚ä½†æ˜¯åœ¨å®é™…ä½¿ç”¨è¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬å‘ç°æ½œåœ¨å˜é‡æ˜¯æœ‰ç”¨çš„ï¼Œå…¶åŸå› æ˜¯æˆ‘ä»¬æ‰€é€‰æ‹©çš„æ¨¡å‹å­˜åœ¨å½’çº³åç½®**(inductive bia)**,è¿™ä½¿å¾—æ½œåœ¨å˜é‡ä¸€å®šä¼šå­¦åˆ°æœ‰ç”¨çš„ä¿¡æ¯ã€‚</p>
<img src="/2021/12/07/Deep-Generative-Models/latent_variable_likelihood_constrained.png" style="zoom:45%;">

<p><strong>How to define a <em>proper</em> class of models?</strong> è¯¥å¦‚ä½•å®šä¹‰è¿™ä¸€ç±»æ¨¡å‹ï¼Œä½¿å¾—æ½œåœ¨å˜é‡ä¸€å®šèƒ½å­¦åˆ°æœ‰ç”¨çš„ä¿¡æ¯å‘¢ï¼Ÿè¿™å®šä¹‰äº†ä¸€ä¸ªconstrained optimization problem (Phuong et al., 2018; Rezende &amp; Viola, 2018) å’Œæ­£åˆ™åŒ–é—®é¢˜  an auxiliary regularizer (Sinha &amp; Dieng, 2021; Tomczak, 2016) to (implicitly) define <em>usefulness</em> of the latents.</p>
<p>åœ¨ä¸‹æ–‡ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨å±‚æ¬¡åŒ–çš„ç»“æ„ <strong>hierarchical architectures</strong> æ¥ç¼“è§£è¿™ä¸€é—®é¢˜ã€‚æˆ‘ä»¬åœ¨å‰é¢æåˆ°æ½œåœ¨å˜é‡å¯ä»¥ç†è§£æˆæ„æˆç›®å‰çš„ä¸€äº›å› ç´ /æ¦‚ç‡ï¼Œè€Œè¿™äº›å› ç´ å¯ä»¥æ˜¯å±‚æ¬¡åŒ–ç»“æ„çš„ã€‚å¦‚æœæ½œåœ¨å˜é‡æ¨¡å‹å­˜åœ¨å±‚æ¬¡åŒ–ç»“æ„ï¼Œèƒ½å¤Ÿå¼•å…¥å½’çº³åç½®ï¼Œè¿›å…¥é™åˆ¶æˆ‘ä»¬çš„VAEæ¨¡å‹ï¼Œå¼ºåˆ¶ä¿¡æ¯åœ¨æ½œåœ¨å˜é‡å’Œè§‚æµ‹ç›®æ ‡ä¸­æµåŠ¨ã€‚</p>
<h3 id="Hierarchical-Variational-Auto-Encoders-1"><a href="#Hierarchical-Variational-Auto-Encoders-1" class="headerlink" title="Hierarchical Variational Auto-Encoders"></a>Hierarchical Variational Auto-Encoders</h3><p><strong>Two-level VAE</strong>: </p>
<img src="/2021/12/07/Deep-Generative-Models/2level_vae.png" style="zoom:100%;">

<p>è¿™é‡Œæœ‰ä¸€ä¸ªå‡è®¾å°±æ˜¯ $z_2\rightarrow z_1\rightarrow x$ æ˜¯ä¸€é˜¶éšé©¬å°”å¯å¤«é“¾ï¼Œä¹Ÿå°±æ˜¯ $x$ ä¸å— $x_2$çš„å½±å“ã€‚é‚£ä¹ˆæœ‰ï¼š<br>$$<br>p(x,z_1,z_2) = p(x|z_1,z_2)p(z_1,z_2) = p(x|z_1)p(z_1|z_2)p(z_2)<br>$$<br>é‚£ä¹ˆå¯¹åº”çš„æ¨¡å‹ï¼ˆæ¦‚ç‡åˆ†å¸ƒï¼‰å¯ä»¥è¡¨ç¤ºæˆ:<br>$$<br>\begin{align}<br>p(z_1|z_2) &amp;= N(z_1|\mu(z_2), \sigma^2(z_2)) \\<br>p(z_2) &amp;= N(z_2|0,1) \\<br>q(z_1|z_2) &amp;= N(z_1|\mu(x), \sigma^2(x)) \\<br>q(z_2|z_1) &amp;= N(z_2|\mu(z_1), \sigma^2(z_1))<br>\end{align}<br>$$<br>å…¶ä¸­ $p(z_1|z_2)$ æ˜¯ç”¨NNè¡¨ç¤ºçš„æ¨¡å‹ï¼Œ$p(z_2)$æ˜¯å…ˆéªŒæ¨¡å‹ï¼Œ$q(z_1|x)$ å’Œ $q(z_2|z_1)$æ˜¯åéªŒæ¦‚ç‡æ¨¡å‹ã€‚</p>
<p>æˆ‘ä»¬ä½¿ç”¨å±‚æ¬¡æ¨¡å‹çš„ç›®çš„æ˜¯ä¿è¯æ½œåœ¨å˜é‡å­¦åˆ°æœ‰ç”¨çš„ä¿¡æ¯ï¼Œå¯æ˜¯æˆ‘ä»¬åšåˆ°äº†å—ï¼Ÿç­”æ¡ˆæ˜¯NOï¼Œå› ä¸ºå‰é¢æåˆ°çš„é—®é¢˜ä¾ç„¶è¿˜æ˜¯å­˜åœ¨ã€‚è¿™é‡Œæˆ‘ä»¬å…ˆæ¨å¯¼ä¸‹å±‚æ¬¡æ¨¡å‹çš„ELBOï¼Œåœ¨è¿›ä¸€æ­¥åˆ†æè¿™ä¸ªé—®é¢˜ï¼š</p>
<p>åœ¨æ¨å¯¼ä¹‹å‰æœ‰è¿™ä¹ˆä¸€ä¸ªå…¬å¼ä¼šç”¨åˆ°ï¼Œè¿™ä¸€æ­¥çš„å…¬å¼ç”¨åˆ°äº†ä¸€é˜¶é©¬å°”å¯å¤«é“¾çš„ç‰¹æ€§ï¼Œä¹Ÿå°±æ˜¯$z_2$ä¸$x$æ— å…³ï¼š<br>$$<br>q(z_1,z_2|x) = q((z_2|z_1)|x)q(z_1|x) = q(z_2|z_1)q(z_1|x)<br>$$</p>
<p>$$<br>\begin{align}<br>p(x) &amp;= \int p(x|z_1,z_2)p(z_1,z_2)d(z_1,z_2) \\<br>ELBO(x) &amp;= E_{(z_1,z_2)\sim q_{\phi}(z_1,z_2|x)}[lnp(x|z_1,z_2)-KL[q_{\phi}(z_1,z_2|x)||p(z_1,z_2)]] \quad \text{åˆ©ç”¨ä¸€å±‚VAEçš„æ¨å¯¼å¯å¾—åˆ°} \\<br>&amp;= E_{(z_1,z_2)\sim q_{\phi}(z_1,z_2|x)}[lnp(x|z_1)-ln\dfrac{q(z_1,z_2|x)}{p(z_1,z_2)}] \quad x \text{ä¸ä¾èµ–äº} z_2ï¼Œä»¥åŠKLæ•£åº¦å…¬å¼ \\<br>&amp;= E_{(z_1,z_2)\sim q_{\phi}(z_1,z_2|x)}[lnp(x|z_1) - ln\dfrac{q(z_1|x)q(z_2|z_1)}{p(z_2)p(z_1|z_2)}] \quad \text{è´å¶æ–¯å…¬å¼ï¼Œä»¥åŠä¸Šä¸€ä¸ªå…¬å¼} \\<br>&amp;= E_{(z_1,z_2)\sim q_{\phi}(z_1,z_2|x)}[lnp(x|z_1) - ln\dfrac{q(z_1|x)}{p(z_1|z_2)} - ln\dfrac{q(z_2|z_1)}{p(z_2)} \\<br>&amp;= E_{(z_1,z_2)\sim q_{\phi}(z_1,z_2|x)}[lnp(x|z_1) - KL[q(z_1|x)||p(z_1|z_2) - KL[q(z_2|z_1)||p(z_2)]]<br>\end{align}<br>$$</p>
<p>æˆ‘ä»¬å‘ç°åéªŒå´©å¡Œçš„é—®é¢˜ä¾ç„¶å­˜åœ¨ï¼Œ$z_2$ å¤§å¤šæ•°æƒ…å†µä¸ä¼šè¢«ä½¿ç”¨(Burda et al., 2015; Maaloe et al., 2017).</p>
<h2 id="Diffusion-Model"><a href="#Diffusion-Model" class="headerlink" title="Diffusion Model"></a>Diffusion Model</h2><p>å­¦è¿‡ Hierarchical VAEä¹‹åå†æ¥çœ‹diffusion modelå°±å¾ˆå®¹æ˜“ç†è§£è¿™äº›å…¬å¼èƒŒåçš„æ„ä¹‰äº†ã€‚è¿™é‡Œç¬”è€…å‚ç…§H-VAEç”»äº†ä¸ªå›¾ï¼Œä¸H-VAEçš„å…³ç³»å°±ä¸€ç›®äº†ç„¶äº†ï¼š</p>
<img src="/2021/12/07/Deep-Generative-Models/diffusion_model2.png" style="zoom:90%;">

<p>åœ¨VAEæ¨¡å‹ä¸­ï¼ŒåéªŒæ¦‚ç‡ $q_{\phi}(z|x)$ æ˜¯é€šè¿‡NNå­¦ä¹ å¾—åˆ°çš„ï¼Œä½†æ˜¯åœ¨diffusion modelï¼Œ (Sohl-Dickstein et al., 2015; Ho et al., 2020)å°†è¿™ä¸ªGaussian diffusion process å®šä¸ºç¡®å®šæ€§çš„ï¼Œæ¯”å¦‚åœ¨ (Ho et al., 2020) å°†å…¶è®¾ç½®ä¸º $\beta_i=10^{-4}$ to $\beta_T=0.02$.</p>
<p>Gaussian diffusion process çš„æ ·æœ¬å¯è§†åŒ–å¦‚ä¸‹ï¼š</p>
<p><img src="/2021/12/07/Deep-Generative-Models/cat_ddgm.png"></p>
<p>DDGMçš„ç›®æ ‡å‡½æ•°å’ŒH-VAEçš„åŒºåˆ«åœ¨äºæ½œåœ¨å˜é‡çš„ç»´åº¦ï¼Œä½†åŸºæœ¬æ¨å¯¼æ˜¯å®Œå…¨ä¸€è‡´çš„ã€‚<br>$$<br>ln p_{\theta}(x)=ln\int Q_{z_{\phi}(z_{1:T}|x)}\dfrac{p_{\theta}(x,z_{1:T})}{Q_{\phi(z_{1:T}|x)}}\mathrm{d}z_{1:T}<br>$$<br>æ ¹æ®H-VAEçš„æ¨å¯¼è¿‡ç¨‹ï¼ŒDDGMçš„ELBOå¯ä»¥ç›´æ¥å†™å‡ºå¦‚ä¸‹ï¼š<br>$$<br>ELBO(x;\theta,\phi) = E_{Q_{\phi}(z_{1:T}|x)}[lnp_{\theta}(x|z_1)-KL[q(z_1|x)||p(z_1|z_2)] - \sum_{i=2}^{T-1}KL[q(z_i|z_{i-1})||p(z_i|z_{i+1})] - KL[q(z_T|z_{T-1})||p(z_T)]]<br>$$<br>å…¶ä¸­:<br>$$<br>p_{\theta}(z_T) = {N}(z_T|0, I)<br>$$<br>åˆ°ç›®å‰ä½ç½®ï¼Œæˆ‘ä»¬å­¦äº†H-VAEå’ŒDDGMï¼Œä»–ä»¬éƒ½æ˜¯é‡‡ç”¨å˜åˆ†æ¨æ–­çš„æ–¹æ³•æ¥è¿‘ä¼¼å­¦ä¹ log-likelihood. ä½†æ˜¯ä¸ºä»€ä¹ˆè¿™ç§å±‚æ¬¡åŒ–çš„æ–¹å¼èƒ½ç¼“è§£æˆ‘ä»¬åœ¨VAEä¸­æåˆ°çš„åéªŒå´©å¡Œé—®é¢˜ï¼š å¦‚ä½•ä¿è¯æ½œåœ¨å˜é‡å­¦åˆ°æœ‰ç”¨çš„ä¿¡æ¯ï¼Ÿ</p>
<p>Reference:</p>
</div><div class="article-licensing box"><div class="licensing-title"><p>Deep Generative Models</p><p><a href="http://www.panxiaoxie.cn/2021/12/07/Deep-Generative-Models/">http://www.panxiaoxie.cn/2021/12/07/Deep-Generative-Models/</a></p></div><div class="licensing-meta level is-mobile"><div class="level-left"><div class="level-item is-narrow"><div><h6>ä½œè€…</h6><p>Xie Pan</p></div></div><div class="level-item is-narrow"><div><h6>å‘å¸ƒäº</h6><p>2021-12-07</p></div></div><div class="level-item is-narrow"><div><h6>æ›´æ–°äº</h6><p>2022-04-10</p></div></div><div class="level-item is-narrow"><div><h6>è®¸å¯åè®®</h6><p><a class="icons" rel="noopener" target="_blank" title="Creative Commons" href="https://creativecommons.org/"><i class="icon fab fa-creative-commons"></i></a><a class="icons" rel="noopener" target="_blank" title="Attribution" href="https://creativecommons.org/licenses/by/4.0/"><i class="icon fab fa-creative-commons-by"></i></a><a class="icons" rel="noopener" target="_blank" title="Noncommercial" href="https://creativecommons.org/licenses/by-nc/4.0/"><i class="icon fab fa-creative-commons-nc"></i></a></p></div></div></div></div></div><div class="article-tags is-size-7 mb-4"><span class="mr-2">#</span><a class="link-muted mr-2" rel="tag" href="/tags/generation/">generation</a></div><!--!--></article></div><!--!--><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/2022/04/05/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-Denoising-Diffusion-Probabilistic-Models/"><i class="level-item fas fa-chevron-left"></i><span class="level-item">è®ºæ–‡ç¬”è®°-Denoising Diffusion Probabilistic Models</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/2021/11/29/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-Autoencoders-Are-Vision-Learners/"><span class="level-item">è®ºæ–‡ç¬”è®°-Autoencoders Are Vision Learners</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><div class="card"><div class="card-content"><h3 class="title is-5">è¯„è®º</h3><div id="disqus_thread"><noscript>Please enable JavaScript to view the <a target="_blank" rel="noopener" href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript></div><script>var disqus_config = function () {
            this.page.url = 'http://www.panxiaoxie.cn/2021/12/07/Deep-Generative-Models/';
            this.page.identifier = '2021/12/07/Deep-Generative-Models/';
        };
        (function() {
            var d = document, s = d.createElement('script');  
            s.src = '//' + 'panxie' + '.disqus.com/embed.js';
            s.setAttribute('data-timestamp', +new Date());
            (d.head || d.body).appendChild(s);
        })();</script></div></div></div><!--!--><div class="column column-right is-4-tablet is-4-desktop is-4-widescreen  order-3"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar" src="/img/avatar.png" alt="panxiaoxie"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">panxiaoxie</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Beijing, China</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">æ–‡ç« </p><a href="/archives"><p class="title">120</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">åˆ†ç±»</p><a href="/categories"><p class="title">40</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">æ ‡ç­¾</p><a href="/tags"><p class="title">37</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/PanXiebit" target="_blank" rel="noopener">å…³æ³¨æˆ‘</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/PanXiebit"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Email" href="/ftdpanxie@gmail.com"><i class="fa fa-envelope"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="RSS" href="/"><i class="fas fa-rss"></i></a></div></div></div><div class="card widget" id="toc" data-type="toc"><div class="card-content"><div class="menu"><h3 class="menu-label">ç›®å½•</h3><ul class="menu-list"><li><a class="level is-mobile" href="#VAEs"><span class="level-left"><span class="level-item">1</span><span class="level-item">VAEs  </span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#Probabilistic-PCA"><span class="level-left"><span class="level-item">1.1</span><span class="level-item">Probabilistic PCA</span></span></a></li><li><a class="level is-mobile" href="#Variational-Inference-for-Non-linear-Latent-Variable-Models"><span class="level-left"><span class="level-item">1.2</span><span class="level-item">Variational Inference for Non-linear Latent Variable Models</span></span></a></li><li><a class="level is-mobile" href="#A-different-perspective-on-the-ELBO"><span class="level-left"><span class="level-item">1.3</span><span class="level-item">A different perspective on the ELBO</span></span></a></li><li><a class="level is-mobile" href="#Components-of-VAEs"><span class="level-left"><span class="level-item">1.4</span><span class="level-item">Components of VAEs</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#Parameterization-of-distributions"><span class="level-left"><span class="level-item">1.4.1</span><span class="level-item">Parameterization of distributions</span></span></a></li><li><a class="level is-mobile" href="#Reparameterization-trick"><span class="level-left"><span class="level-item">1.4.2</span><span class="level-item">Reparameterization trick</span></span></a></li></ul></li><li><a class="level is-mobile" href="#More-about-VAEs"><span class="level-left"><span class="level-item">1.5</span><span class="level-item">More about VAEs!</span></span></a></li></ul></li><li><a class="level is-mobile" href="#Hierarchical-Variational-Auto-Encoders"><span class="level-left"><span class="level-item">2</span><span class="level-item">Hierarchical Variational Auto-Encoders</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#Hierarchical-Variational-Auto-Encoders-1"><span class="level-left"><span class="level-item">2.1</span><span class="level-item">Hierarchical Variational Auto-Encoders</span></span></a></li></ul></li><li><a class="level is-mobile" href="#Diffusion-Model"><span class="level-left"><span class="level-item">3</span><span class="level-item">Diffusion Model</span></span></a></li></ul></div></div><style>#toc .menu-list > li > a.is-active + .menu-list { display: block; }#toc .menu-list > li > a + .menu-list { display: none; }</style><script src="/js/toc.js" defer></script></div><div class="card widget" data-type="links"><div class="card-content"><div class="menu"><h3 class="menu-label">é“¾æ¥</h3><ul class="menu-list"><li><a class="level is-mobile" href="https://github.com/PanXiebit" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">github</span></span><span class="level-right"><span class="level-item tag">github.com</span></span></a></li><li><a class="level is-mobile" href="ftdpanxie@gmail.com" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">email</span></span><span class="level-right"><span class="level-item tag">ftdpanxie@gmail.com</span></span></a></li></ul></div></div></div><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">åˆ†ç±»</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/C/"><span class="level-start"><span class="level-item">C++</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/CSAPP/"><span class="level-start"><span class="level-item">CSAPP</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/DRL/"><span class="level-start"><span class="level-item">DRL</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/GAN/"><span class="level-start"><span class="level-item">GAN</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li><li><a class="level is-mobile" href="/categories/GAN-RL/"><span class="level-start"><span class="level-item">GAN, RL</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/ML/"><span class="level-start"><span class="level-item">ML</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/NLP/"><span class="level-start"><span class="level-item">NLP</span></span><span class="level-end"><span class="level-item tag">14</span></span></a></li><li><a class="level is-mobile" href="/categories/TensorFlow/"><span class="level-start"><span class="level-item">TensorFlow</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/cs224d/"><span class="level-start"><span class="level-item">cs224d</span></span><span class="level-end"><span class="level-item tag">10</span></span></a></li><li><a class="level is-mobile" href="/categories/generation/"><span class="level-start"><span class="level-item">generation</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/generative-models/"><span class="level-start"><span class="level-item">generative models</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/interview/"><span class="level-start"><span class="level-item">interview</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/machine-translation/"><span class="level-start"><span class="level-item">machine translation</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/python/"><span class="level-start"><span class="level-item">python</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/pytorch/"><span class="level-start"><span class="level-item">pytorch</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/reinforcement-learning/"><span class="level-start"><span class="level-item">reinforcement learning</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/sign-language-recognition/"><span class="level-start"><span class="level-item">sign language recognition</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/transfer-learning/"><span class="level-start"><span class="level-item">transfer learning</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/transformer/"><span class="level-start"><span class="level-item">transformer</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"><span class="level-start"><span class="level-item">æ•°æ®ç»“æ„ä¸ç®—æ³•</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile" href="/categories/%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB/"><span class="level-start"><span class="level-item">æ–‡æœ¬åˆ†ç±»</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"><span class="level-start"><span class="level-item">è®ºæ–‡ç¬”è®°</span></span><span class="level-end"><span class="level-item tag">40</span></span></a><ul><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/DL/"><span class="level-start"><span class="level-item">DL</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/ESA/"><span class="level-start"><span class="level-item">ESA</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/GAN/"><span class="level-start"><span class="level-item">GAN</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/MRC-and-QA/"><span class="level-start"><span class="level-item">MRC and QA</span></span><span class="level-end"><span class="level-item tag">7</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/Machine-Translation/"><span class="level-start"><span class="level-item">Machine Translation</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/NLP/"><span class="level-start"><span class="level-item">NLP</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/Transformer/"><span class="level-start"><span class="level-item">Transformer</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/capsules/"><span class="level-start"><span class="level-item">capsules</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/computer-vision/"><span class="level-start"><span class="level-item">computer vision</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/constrast-learning/"><span class="level-start"><span class="level-item">constrast learning</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/data-augmentation/"><span class="level-start"><span class="level-item">data augmentation</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/dialogue-system/"><span class="level-start"><span class="level-item">dialogue system</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/language-model/"><span class="level-start"><span class="level-item">language model</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/machine-translation/"><span class="level-start"><span class="level-item">machine translation</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/open-set-recognition/"><span class="level-start"><span class="level-item">open set recognition</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/sentence-embedding/"><span class="level-start"><span class="level-item">sentence embedding</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/text-matching/"><span class="level-start"><span class="level-item">text matching</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/vision-language/"><span class="level-start"><span class="level-item">vision-language</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li></ul></div></div></div></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/panxiaoxie.png" alt="æ½˜å°æ¦­" height="28"></a><p class="is-size-7"><span>&copy; 2022 Xie Pan</span>Â Â Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>Â &amp;Â <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("zh-CN");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="å›åˆ°é¡¶ç«¯" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "æ­¤ç½‘ç«™ä½¿ç”¨Cookieæ¥æ”¹å–„æ‚¨çš„ä½“éªŒã€‚",
          dismiss: "çŸ¥é“äº†ï¼",
          allow: "å…è®¸ä½¿ç”¨Cookie",
          deny: "æ‹’ç»",
          link: "äº†è§£æ›´å¤š",
          policy: "Cookieæ”¿ç­–",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.5/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="æƒ³è¦æŸ¥æ‰¾ä»€ä¹ˆ..."></div><a class="searchbox-close" href="javascript:;">Ã—</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"æƒ³è¦æŸ¥æ‰¾ä»€ä¹ˆ...","untitled":"(æ— æ ‡é¢˜)","posts":"æ–‡ç« ","pages":"é¡µé¢","categories":"åˆ†ç±»","tags":"æ ‡ç­¾"});
        });</script></body></html>