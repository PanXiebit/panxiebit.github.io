<!doctype html>
<html lang="zh"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>Deep Generative Models - 潘小榭</title><link rel="manifest" href="/manifest.json"><meta name="theme-color" content="black"><meta name="application-name" content="panxiaoxie"><meta name="msapplication-TileImage" content="/img/avatar.png"><meta name="msapplication-TileColor" content="black"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="panxiaoxie"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="description" content="Catalog:   Autoregressive Models (ARMs) Flow-based models (flows): RealNVP and IDFs (Integer Discrete Flows) Variational Auto-Encoders (VAEs): a plain VAE and various priors, a hierarchical VAE Hybrid"><meta property="og:type" content="blog"><meta property="og:title" content="panxiaoxie"><meta property="og:url" content="https://github.com/PanXiebit"><meta property="og:site_name" content="panxiaoxie"><meta property="og:description" content="Catalog:   Autoregressive Models (ARMs) Flow-based models (flows): RealNVP and IDFs (Integer Discrete Flows) Variational Auto-Encoders (VAEs): a plain VAE and various priors, a hierarchical VAE Hybrid"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://www.qt86.com/cache/1625298592_187938.png"><meta property="article:published_time" content="2021-12-07T12:05:04.000Z"><meta property="article:modified_time" content="2022-04-10T15:12:53.645Z"><meta property="article:author" content="panxiaoxie"><meta property="article:tag" content="generation"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="https://www.qt86.com/cache/1625298592_187938.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"http://www.panxiaoxie.cn/2021/12/07/Deep-Generative-Models/"},"headline":"Deep Generative Models","image":["http://www.panxiaoxie.cn/2021/12/07/Deep-Generative-Models/lvm_diagram.png","http://www.panxiaoxie.cn/2021/12/07/Deep-Generative-Models/elbo.png","http://www.panxiaoxie.cn/2021/12/07/Deep-Generative-Models/reparameter_trick.png","http://www.panxiaoxie.cn/2021/12/07/Deep-Generative-Models/kl.png","http://www.panxiaoxie.cn/2021/12/07/Deep-Generative-Models/latent_variable_likelihood_all.png","http://www.panxiaoxie.cn/2021/12/07/Deep-Generative-Models/latent_variable_likelihood_constrained.png","http://www.panxiaoxie.cn/2021/12/07/Deep-Generative-Models/2level_vae.png","http://www.panxiaoxie.cn/2021/12/07/Deep-Generative-Models/diffusion_model2.png","http://www.panxiaoxie.cn/2021/12/07/Deep-Generative-Models/cat_ddgm.png"],"datePublished":"2021-12-07T12:05:04.000Z","dateModified":"2022-04-10T15:12:53.645Z","author":{"@type":"Person","name":"Xie Pan"},"publisher":{"@type":"Organization","name":"潘小榭","logo":{"@type":"ImageObject","url":"http://www.panxiaoxie.cn/img/panxiaoxie.png"}},"description":"Catalog:   Autoregressive Models (ARMs) Flow-based models (flows): RealNVP and IDFs (Integer Discrete Flows) Variational Auto-Encoders (VAEs): a plain VAE and various priors, a hierarchical VAE Hybrid"}</script><link rel="canonical" href="http://www.panxiaoxie.cn/2021/12/07/Deep-Generative-Models/"><link rel="icon" href="/img/avatar.png"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/css/justifiedGallery.min.css"><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script><!--!--><!--!--><meta name="generator" content="Hexo 5.4.0"></head><body class="is-2-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/panxiaoxie.png" alt="潘小榭" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">主页</a><a class="navbar-item" href="/archives">归档</a><a class="navbar-item" href="/categories">分类</a><a class="navbar-item" href="/tags">标签</a><a class="navbar-item" href="/about">关于我</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/PanXiebit"><i class="fab fa-github"></i></a><a class="navbar-item is-hidden-tablet catalogue" title="目录" href="javascript:;"><i class="fas fa-list-ul"></i></a><a class="navbar-item search" title="搜索" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-10-widescreen"><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2021-12-07T12:05:04.000Z" title="2021/12/7 下午8:05:04">2021-12-07</time>发表</span><span class="level-item"><time dateTime="2022-04-10T15:12:53.645Z" title="2022/4/10 下午11:12:53">2022-04-10</time>更新</span><span class="level-item"><a class="link-muted" href="/categories/generation/">generation</a></span><span class="level-item">42 分钟读完 (大约6320个字)</span></div></div><h1 class="title is-3 is-size-4-mobile">Deep Generative Models</h1><div class="content"><p>Catalog: </p>
<ul>
<li>Autoregressive Models (ARMs)</li>
<li><a href="#flow_based">Flow-based models (flows)</a>: RealNVP and IDFs (Integer Discrete Flows)</li>
<li><a href="#vaes">Variational Auto-Encoders (VAEs)</a>: a plain VAE and various priors, a hierarchical VAE</li>
<li>Hybrid modeling</li>
<li><a href="#energy">Energy-based Models</a></li>
<li><a href="#gans">Generative Adversarial Networks (GANs)</a></li>
<li>Diffusion-based Deep Generative Models (DDGMs): a Gaussian forward diffusion</li>
<li>Neural Compression with Deep Generative Modeling</li>
</ul>
<span id="more"></span>

<h2 id="VAEs"><a href="#VAEs" class="headerlink" title="VAEs  "></a>VAEs  <a name="vaes"></a></h2><p>以图像生成为例，想象一下这个场景，我们现在有一堆马🐎的图片，我们现在希望学习 $p(x)$，从而生成新的图片。那么我们可以问下自己，我们如何去画出马的图片呢？换句话说，我们把自己当作一个生成模型，我们如何做这件事呢？也许我们会先勾勒出一匹马的大致轮廓，它的大小和形状，然后添加马蹄，填充头部的细节，给它上色等等。最后，我们可以考虑背景。一般来说，我们可以说数据中有一些因素（例如轮廓、颜色、背景）对于生成对象（这里是马）至关重要。 一旦我们决定了这些因素，我们就可以通过添加细节来生成它们。 当我们画某物时，这或多或少是我们生成一幅画的过程。</p>
<p>我们现在用数学来表达这个生成过程。 也就是说，我们有我们感兴趣的高维对象 $x\in \mathcal{X}^D$（例如，对于图像，$\mathcal{X}\in {0,1,2,…,255}$）和一个低维潜在变量 $z\in\mathcal{Z}^M$（例如，$\mathcal{Z}=\mathbb{R}$)，我们可以称之为数据中的隐藏因素。 在数学上，我们可以将$\mathcal{Z}^M$称为低维流形。 那么，生成过程可以表示为：</p>
<ol>
<li>$z\sim p(z)$ (Figure1, In red)</li>
<li>$x\sim p(x|z)$(Figure1, In Blue)</li>
</ol>
<img src="/2021/12/07/Deep-Generative-Models/lvm_diagram.png" alt="img" style="zoom:20%;">

<center><p>Figure 1. 潜在变量模型和生成过程的简图. 注意嵌入在高维空间(此处为3D)中的低维流形(此处为2D)</p></center>

<p>简单来说，我们首先采样𝐳（例如，我们想象我的马的大小、形状和颜色），然后创建具有所有必要细节的图像，即，我们从条件分布 $p(x|z)$中采样得到x。 由于许多各种外部因素，创建两次完全相同的图像几乎是不可能的。 </p>
<p>潜在变量模型背后的idea是我们引入了潜在变量 $z$ ，并且联合分布被分解如下：$ 𝑝(𝐱,𝐳)=𝑝(𝐱|𝐳)𝑝(𝐳)$. 这个公式表达的就是上述的生成过程。 但是在训练时我们只能访问样本 $x$。 因此，根据概率推理，我们应该对未知的潜在变量，也就是𝐳 ，进行求和（sum out, 也叫边缘化 marginalize out）。最后，其边缘似然函数如下：</p>
<p>$$p({x}) = \int p({x} | {z}) p({z})\ \mathrm{d} {z} $$</p>
<p>那么问题来了，如何计算这个积分呢？总的来说，这是个非常复杂的任务。有两个可能的解决方法：1. 直接处理这个积分 (<strong>Probabilistic PCA</strong> )；2. 利用近似的方法也来解决，也就是变分推断 <strong>(variational inference)</strong>.</p>
<h3 id="Probabilistic-PCA"><a href="#Probabilistic-PCA" class="headerlink" title="Probabilistic PCA"></a>Probabilistic PCA</h3><p>对于 $p(x|z)$是线性模型时，可以直接求解。但推导过程没看懂，先不写了。</p>
<h3 id="Variational-Inference-for-Non-linear-Latent-Variable-Models"><a href="#Variational-Inference-for-Non-linear-Latent-Variable-Models" class="headerlink" title="Variational Inference for Non-linear Latent Variable Models"></a>Variational Inference for Non-linear Latent Variable Models</h3><p>让我们再看一次积分，显然我们无法准确计算积分。 最简单的方法是使用蒙特卡罗近似：<br>$$<br>\begin{align}<br>p(\mathbf{x}) &amp;= \int p(\mathbf{x} | \mathbf{z})\ p(\mathbf{z})\ \mathrm{d} \mathbf{z} \\<br>    &amp;= E_{\mathbf{z}\sim p(\mathbf{z})} \left[ p(\mathbf{x} | \mathbf{z}) \right] \\<br>    &amp;\approx \frac{1}{K} \sum_{k} p(\mathbf{x} | \mathbf{z}_{k}) \end{align}<br>$$<br>其中，在最后一行我们采用近似的方法来模拟这个期望/积分函数。我们基于潜在变量的的先验概率来得到samples，$z_k\sim p(z)$. 在当前计算机越来越快的情况下，这个方法是相对简单的，我们可以在短时间内采样出无数的点。然而，我们学过的统计学知识告诉我们，当潜在空间是$z\in\mathcal{Z}^M$多维，且$M$很大的时候，我们会陷入维度灾难。为了cover住样本空间，我们所需采样的样本是M的指数形式。如果我们采样的样本数不够，那么这个近似效果就不好。</p>
<p>我们当然可以采用一些更先进的蒙特卡洛方法，然而，它们始终会受到维度灾难的影响。另一个可选择的近似方法是变分推断<strong>variational inference</strong> (Jordan et al., 1999). 我们考虑一组由 $\phi$ 参数化的变分分布，${q_{\phi}(z)}$. 比如，我们假设$\phi$为高斯分布， $\phi={\mu, \sigma^2}$. 我们知道这些分布的形式，并假设它们将非零的概率分配给所有的潜在变量 $z\in \mathcal{Z}^{M}$. 然后，这个边缘概率分布可以近似推导如下：<br>$$<br>\begin{align}<br>\ln p(x) &amp;= ln\int p(x|z)p(z)dz \\<br>&amp;= ln\int \dfrac{q_{\phi}(z)}{q_{\phi}(z)}p(x|z)p(z)dz \\<br>&amp;= lnE_{z\sim q_{\phi}(z)}[\dfrac{p(x|z)p(z)}{q_{\phi}(z)}] \\<br>&amp;\ge E_{z\sim q_{\phi}(z)}ln[\dfrac{p(x|z)p(z)}{q_{\phi}(z)}] \\<br>&amp;= E_{z\sim q_{\phi}(z)} [lnp(x|z)+lnp(z)-lnq_{\phi}(z)] \\<br>&amp;= E_{z\sim q_{\phi}(z)} [lnp(x|z)] - E_{z\sim q_{\phi}(z)}[lnq_{\phi}(z) - lnp(z)]<br>\end{align}<br>$$<br>第4行使用了<strong>Jensen’s inequality</strong>. 上述推导过程，我们把 $q_{\phi}(z)$ 换成 <strong>amortized variational posterior</strong>，也就是 $q_{\phi}(z|x)$ 是不影响推导过程的，因此我们可以得到：</p>
<p>$$lnp(z)\ge E_{z\sim q_{\phi}(z|x)} [lnp(x|z)] - E_{z\sim q_{\phi}(z|x)}[lnq_{\phi}(z|x) - lnp(z)]$$</p>
<p>amortized variational posterior 非常有用，因为我们可以利用神经网络得到这样一个模型，给定输入 $x$，然后输出对应分布的参数。在  (Kim et al., 2018) 中，作者使用了一种 semi-amortized variational inference. </p>
<p>最后，我们得到一个auto encoder-like模型，其包括一个encoder, $q_{\phi}(z|x)$ 和 一个 decoder, $p(x|z)$. 我们用随机性来强调encoder和decoder其实就是概率分布，<strong>这与deterministic auto-encoder是有区别的（这里没太懂）</strong>。这个带有  <strong>amortized variational posterior</strong>的自编码模型就是变分自编码 <strong>Variational Auto-Encoder</strong> (Kingma &amp; Welling, 2013; Rezende et al., 2014). 其似然函数的下界就是 Evidence LOwer Bound (<strong>ELBO</strong>).</p>
<p>ELBO的第一项是 <strong>reconstruction error</strong>,$E_{z\sim q_{\phi}(z|x)} [lnp(x|z)]$ ; 第二项是<strong>regularizer</strong>，$E_{z\sim q_{\phi}(z|x)}[lnq_{\phi}(z|x) - lnp(z)]$,恰好就是KL散度，所以也可以成为KL item. 但在更复杂的模型中，这一项并不一定是 KL term，因此称作regularizer更通用一点。</p>
<blockquote>
<p>回顾下：熵 $\rightarrow$ 交叉熵 $\rightarrow$ 相对熵/KL散度</p>
<ol>
<li><p>信息量与概率成反比，当概率越大时，信息量越小；并且信息量为非负数。因此，定义信息量为 $log\dfrac{1}{p}$. 熵是信息量的期望：$E_{x\sim p(x)}ln\dfrac{1}{p(x)}$</p>
</li>
<li><p>交叉熵指的是：根据真实分布p来衡量预测分布q的度量。同样的我们也用信息量的期望来衡量这个交叉熵度量，我们希望交叉熵越小时，预测的q越准确，也就是越接近于1。类似地，交叉熵可以写成  $H(p, q) = E_{x\sim p(x)}ln\dfrac{1}{q(x)}$. 实际上，我们是无法知道真实分布p的，只能依据现有的样本统计得到。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line">   </span><br><span class="line">size = <span class="number">3</span></span><br><span class="line"><span class="built_in">input</span> = torch.randn(<span class="number">2</span>, size)</span><br><span class="line">target = torch.Tensor([<span class="number">0</span>, <span class="number">2</span>]).long()</span><br><span class="line">   </span><br><span class="line"><span class="comment"># use loss function</span></span><br><span class="line">loss_fn = nn.CrossEntropyLoss(reduction=<span class="string">&quot;mean&quot;</span>)</span><br><span class="line">loss = loss_fn(<span class="built_in">input</span>, target)</span><br><span class="line">   </span><br><span class="line"><span class="comment"># computer nll loss step by step</span></span><br><span class="line">score = torch.log_softmax(<span class="built_in">input</span>, dim=<span class="number">1</span>)</span><br><span class="line">my_nll = torch.<span class="built_in">sum</span>(-score * F.one_hot(target, size)) / target.size(<span class="number">0</span>)</span><br><span class="line"><span class="comment"># use nll loss</span></span><br><span class="line">   </span><br><span class="line">nll_loss_fn = nn.NLLLoss()</span><br><span class="line">nll_loss = nll_loss_fn(score, target)</span><br><span class="line">   </span><br><span class="line"><span class="built_in">print</span>(nll_loss == loss == my_nll) <span class="comment"># True</span></span><br></pre></td></tr></table></figure></li>
<li><p>相对熵： 根据<a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Gibbs%27_inequality">Gibbs’ inequality</a>上述例子中的 $H(p,q) &gt;= H(p)$ 恒成立。当且仅当q=p时，这个等号才成立。那么熵H(p,q)相比熵H(q)多出来的部分就是相对熵 ，也称为KL散度(Kullback–Leibler divergence，KLD).</p>
</li>
</ol>
<p>$$<br>D(p||q)=H(p,q)-H(p)=\sum_{x\sim p(x)}[ln\dfrac{1}{q(x)} - ln\dfrac{1}{p(x)}]=E_{x\sim p(x)}[ln\dfrac{p(x)}{q(x)}]=\int_{x}p(x)[ln\dfrac{p(x)}{q(x)}]<br>$$</p>
</blockquote>
<h3 id="A-different-perspective-on-the-ELBO"><a href="#A-different-perspective-on-the-ELBO" class="headerlink" title="A different perspective on the ELBO"></a>A different perspective on the ELBO</h3><p>下面提供一种新的推导方法，个人觉得更能理解ELBO:<br>$$<br>\begin{align}<br>\ln p(\mathbf{x}) &amp;= E_{\mathbf{z} \sim q_{\phi}(\mathbf{z}|\mathbf{x})} \left[ \ln p(\mathbf{x}) \right] \\<br>&amp;= E_{\mathbf{z} \sim q_{\phi}(\mathbf{z}|\mathbf{x})} \left[ \ln \frac{p(\mathbf{z}|\mathbf{x}) p(\mathbf{x})}{p(\mathbf{z}|\mathbf{x})} \right] \\<br>&amp;= E_{\mathbf{z} \sim q_{\phi}(\mathbf{z}|\mathbf{x})} \left[ \ln \frac{p(\mathbf{x}|\mathbf{z}) p(\mathbf{z})}{p(\mathbf{z}|\mathbf{x})} \right] \quad \text{根据贝叶斯公式p(z|x)p(x)=p(x|z)p(z)}\\<br>&amp;= E_{\mathbf{z} \sim q_{\phi}(\mathbf{z}|\mathbf{x})} \left[ \ln \frac{p(\mathbf{x}|\mathbf{z}) p(\mathbf{z})}{p(\mathbf{z}|\mathbf{x})} \frac{q_{\phi}(\mathbf{z}|\mathbf{x})}{q_{\phi}(\mathbf{z}|\mathbf{x})}\right] \quad \text{这一步很关键, } 1 = \frac{q_{\phi(z|x)}}{q_{\phi(z|x)}}, q_{\phi(z|x)} 是用来近似真实后验概率的变分后验概率 \\<br>&amp;= E_{\mathbf{z} \sim q_{\phi}(\mathbf{z}|\mathbf{x})} \left[ \ln p(\mathbf{x}|\mathbf{z}) \frac{p(\mathbf{z})}{q_{\phi}(\mathbf{z}|\mathbf{x})}  \frac{q_{\phi}(\mathbf{z}|\mathbf{x})}{p(\mathbf{z}|\mathbf{x})} \right] \\<br>&amp;= E_{\mathbf{z} \sim q_{\phi}(\mathbf{z}|\mathbf{x})} \left[ \ln p(\mathbf{x}|\mathbf{z}) - \ln \frac{q_{\phi}(\mathbf{z}|\mathbf{x})}{p(\mathbf{z})} + \ln \frac{q_{\phi}(\mathbf{z}|\mathbf{x})}{p(\mathbf{z}|\mathbf{x})} \right] \quad \text{到这里能看出KL散度了}\\<br>&amp;= E_{\mathbf{z} \sim q_{\phi}(\mathbf{z}|\mathbf{x})} \left[ \ln p(\mathbf{x}|\mathbf{z}) \right] - KL\left[ q_{\phi}(\mathbf{z}|\mathbf{x}) | p(\mathbf{z}) \right] + KL \left[ q_{\phi}(\mathbf{z}|\mathbf{x}) |p(\mathbf{z}|\mathbf{x}) \right] .<br>\end{align}<br>$$<br>前两项就是 ELBO，最后一项中 $p(z|x)$ 这个表示真实的后验概率 real posterior, $q_{\phi}(z|x)$ 表示变分后验概率 variational posterior. 我们并不知道真实的后验概率，但是我们可以跳过这一项，因为KL散度一定大于等于0. 去掉最后一项，我们得到ELBO，同时我们知道 ELBO和真实的对数似然之间的间隔是  $KL \left[ q_{\phi}({z}|{x}) |p({z}|{x}) \right] $.<br>$$<br>\begin{align}<br>\ln p(\mathbf{x}) &amp;= E_{\mathbf{z} \sim q_{\phi}(\mathbf{z}|\mathbf{x})} \left[ \ln p(\mathbf{x}|\mathbf{z}) \right] - KL\left[ q_{\phi}(\mathbf{z}|\mathbf{x}) | p(\mathbf{z}) \right] + KL \left[ q_{\phi}(\mathbf{z}|\mathbf{x}) |p(\mathbf{z}|\mathbf{x}) \right] \\<br>&amp;\ge E_{\mathbf{z} \sim q_{\phi}(\mathbf{z}|\mathbf{x})} \left[ \ln p(\mathbf{x}|\mathbf{z}) \right] - KL\left[ q_{\phi}(\mathbf{z}|\mathbf{x}) | p(\mathbf{z}) \right]<br>\end{align}<br>$$<br>Beautiful! 但同样我们能看出一些问题，如果 $q_{\phi}({z}|{x})$ 和 $p(z|x)$ 距离很大，那么ELBO优化的再好，ELBO和真实的对数似然之间的差距依然很大。也就是说，如果我们采用很简单的后验概率，我们会得到一个不太好的VAE模型。</p>
<img src="/2021/12/07/Deep-Generative-Models/elbo.png" style="zoom:30%;">

<center><p>Figure 2. ELBO是对数似然的下界。ELBO最大时对应的 $\hat {\theta}$ 并不一定也能让对数似然最大。ELBO 越losser，这对模型参数的最大似然估计的偏差越大。 </p></center>



<h3 id="Components-of-VAEs"><a href="#Components-of-VAEs" class="headerlink" title="Components of VAEs"></a><strong>Components of VAEs</strong></h3><ul>
<li>我们使用amortized variational posteriors ${q_{\phi}(z|x)}_{\phi}$ 来近似真实的后验分布 $p(z|x)$. 这个概率分布可以看作是 <strong>encoder</strong>.</li>
<li>conditional likelihood p(x|z) 对应的概率分布可以看作是 <strong>decoder</strong></li>
<li>$p(z)$ 是对于潜在变量的边缘分布，也可以看作是 <strong>prior</strong> 模型</li>
</ul>
<p>至此，还有两个问题需要解决：</p>
<ol>
<li>如何参数化这些distributions?</li>
<li>如何计算这些期望呢？也就是积分。</li>
</ol>
<h4 id="Parameterization-of-distributions"><a href="#Parameterization-of-distributions" class="headerlink" title="Parameterization of distributions"></a>Parameterization of distributions</h4><p>显然，我们用Neural Networks来表达上述两个distributions: encoder 和 decoder。在VAE框架下，大部分情况下，我们可以使用任何distributions. 但是，我们也必须满足对应的任务。</p>
<ol>
<li>对于decoder分布 $p_{\theta}(x|z)$ 显然不可能是正态分布，因为image的pixel values是离散的。一个可能的distribution可以是 <strong>categorical distribution</strong>:</li>
</ol>
<p>​    $$p_{\theta}(x|𝐳)=\text{Categorical}(𝐱|\theta(𝐳))$$ </p>
<p>​    其中 $\theta(z) = \text{softmax}(NN(z))$. 这里把重构当作分类任务来做，当然也可以是回归任务。</p>
<ol start="2">
<li>对于潜在变量的分布，为了方便，通常 $z$ 可视为连续随机变量的向量，$z\in \mathbb{R}^M$. 因此，我们可以使用 Gaussians 来表示 variational posterior 和 prior.<br>$$<br>\begin{align}<br>q_{\phi}(\mathbf{z}|\mathbf{x}) &amp;= \mathcal{N}\left(\mathbf{z} | \mu_{\phi}(\mathbf{x}), \mathrm{diag}\left[ \sigma_{\phi}^2(\mathbf{x}) \right] \right) \\<br>p(\mathbf{z}) &amp;= \mathcal{N}\left(\mathbf{z} | 0, \mathbf{I} \right)<br>\end{align}<br>$$<br>其中 $\mu_{phi}(x), \sigma_{\phi}(x)$ 是神经网络的输出。在实际使用中，我们使用NN得到 $2M$ 的 values $\in R^{1\times 2M}$，其中 $R^{1\times M}$ 表示 means，$R^{1\times M}$ 表示 variances. </li>
</ol>
<h4 id="Reparameterization-trick"><a href="#Reparameterization-trick" class="headerlink" title="Reparameterization trick"></a>Reparameterization trick</h4><p>到目前为止，我们学习了log-likelihood和ELBO。但是仍然有一个问题，我们用encoder $q_{\phi}(z|x)$ 得到关于潜在变量的分布，我们该如何计算$E_{z\sim q_{\phi}(z|x)}(x|z)$这个积分呢？显然，$z\sim q_{\phi}(z|x)$这个采样过程是不可导的，我们可以采用MC-approximation,但是这样仍然有个问题，从这个变分后验sample得到的z，在ELBO的训练过程中，在计算关于$\phi$的梯度时，梯度的方差特别大。</p>
<p>因此，另一个可能的方法是<strong>reparameterizing</strong>这个分布(Devroye, 1996).  具体地，我们可以将随机变量 $z$ 表示为具有简单分布的独立随机变量的原始变换（例如算术运算、对数等）的组合。换句话说，我们使用重参数技巧表达为确定性的变量:<br>$$<br>z = \mu + \sigma \cdot \epsilon<br>$$<br>其中 $\epsilon \sim {N}(\epsilon|0,1)$ .</p>
<img src="/2021/12/07/Deep-Generative-Models/reparameter_trick.png" style="zoom:50%;">

<p>使用Reparameterization方法能够显著减小梯度的方法。Why？因为随机性来自独立的分布$p(\epsilon)$，我们计算梯度是关于确定性函数（即神经网络），而不是随机的对象$z\sim q_{\phi}(z|x)$。 更棒的是，由于我们使用随机梯度下降来学习 VAE，因此在训练期间仅采样一次 $z$ 就足够了！</p>
<p>综上，VAE框架主要包括：</p>
<ol>
<li>variational posterior  $q_{\phi}(z|x)$ using encoder</li>
<li>sample z from   $q_{\phi}(z|x)$ and feed it to decoder, using  reparameterization trick</li>
<li>conditional likelihood $p_{\theta}(x|z)$ using decoder</li>
<li>reconstruction loss</li>
<li>kl loss between variational posterior and prior $p_{\theta}$. 其中 $q_{\phi}(z|x)\sim {N}(z|\mu, \sigma^2I)$ 多维高斯分布，$p_{\theta}\sim {N}(0,1)$ 是正态分布。</li>
</ol>
<p>KL 散度的推导如下：</p>
<p><img src="/2021/12/07/Deep-Generative-Models/kl.png" alt="image-20211209135812911"></p>
<p>代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">VariationalEncoder</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, latent_dims</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(VariationalEncoder, self).__init__()</span><br><span class="line">        self.linear1 = nn.Linear(<span class="number">784</span>, <span class="number">512</span>)</span><br><span class="line">        self.linear2 = nn.Linear(<span class="number">512</span>, latent_dims)</span><br><span class="line">        self.linear3 = nn.Linear(<span class="number">512</span>, latent_dims)</span><br><span class="line">        </span><br><span class="line">        self.kl = <span class="number">0</span></span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        x = torch.flatten(x, start_dim=<span class="number">1</span>)</span><br><span class="line">        x = F.relu(self.linear1(x))</span><br><span class="line">        mu =  self.linear2(x)</span><br><span class="line">        sigma = torch.exp(self.linear3(x))</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># reparameterization trick</span></span><br><span class="line">        z = mu + sigma*torch.randn_like(sigma)</span><br><span class="line">        </span><br><span class="line">        self.kl = <span class="number">0.5</span>*(sigma**<span class="number">2</span> + mu**<span class="number">2</span> - torch.log(sigma) - <span class="number">1</span>).<span class="built_in">sum</span>()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> z</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Decoder</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, latent_dims</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(Decoder, self).__init__()</span><br><span class="line">        self.linear1 = nn.Linear(latent_dims, <span class="number">512</span>)</span><br><span class="line">        self.linear2 = nn.Linear(<span class="number">512</span>, <span class="number">784</span>)</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, z</span>):</span></span><br><span class="line">        x_hat = F.relu(self.linear1(z))</span><br><span class="line">        x_hat = torch.sigmoid(self.linear2(x_hat))</span><br><span class="line">        <span class="keyword">return</span> x_hat.reshape((-<span class="number">1</span>, <span class="number">1</span>, <span class="number">28</span>, <span class="number">28</span>))</span><br><span class="line">      </span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">VariationalAutoencoder</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, latent_dims</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(VariationalAutoencoder, self).__init__()</span><br><span class="line">        self.encoder = VariationalEncoder(latent_dims)</span><br><span class="line">        self.decoder = Decoder(latent_dims)</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        z = self.encoder(x)</span><br><span class="line">        <span class="keyword">return</span> self.decoder(z)</span><br><span class="line">      </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train</span>(<span class="params">model, data, epochs=<span class="number">20</span></span>):</span></span><br><span class="line">    opt = torch.optim.Adam(model.parameters())</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(epochs):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;epoch: <span class="subst">&#123;epoch+<span class="number">1</span>&#125;</span>/<span class="subst">&#123;epochs&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="keyword">for</span> x, y <span class="keyword">in</span> data:</span><br><span class="line">            x = x.to(device) <span class="comment"># GPU</span></span><br><span class="line">            opt.zero_grad()</span><br><span class="line">            x_hat = model(x)</span><br><span class="line">            loss = ((x - x_hat)**<span class="number">2</span>).<span class="built_in">sum</span>() + model.encoder.kl</span><br><span class="line">            loss.backward()</span><br><span class="line">            opt.step()</span><br><span class="line">    <span class="keyword">return</span> model</span><br><span class="line">      </span><br><span class="line">latent_dims = <span class="number">2</span></span><br><span class="line">vae = VariationalAutoencoder(latent_dims).to(device) <span class="comment"># GPU</span></span><br><span class="line">vae = train(vae, data)</span><br></pre></td></tr></table></figure>



<h3 id="More-about-VAEs"><a href="#More-about-VAEs" class="headerlink" title="More about VAEs!"></a>More about VAEs!</h3><ul>
<li><p><strong>Estimation of the log-likelihood using importance weighting</strong> 我们前面提到过 ELBO 只是对数似然的下界，它不应该被用作对数似然的良好估计。(Burda et al., 2015; Rezende et al., 2014) 采用了一种 importance weighting procedure 方法。</p>
</li>
<li><p><strong>Enhancing VAEs: Better encoders</strong> 意味着更好的后验概率, 一个很重要的方向是 conditional flow-based models (van den Berg et al., 2018; Hoogeboom et al., 2020; Kingma et al., 2016; Rezende &amp; Mohamed, 2015; Tomczak &amp; Welling, 2016; Tomczak &amp; Welling, 2017). </p>
</li>
<li><p><strong>Enhancing VAEs: Better decoders</strong> 可以使用不同的模型或者loss function来拟合原始的数据，比如pixel-CNN, transformer等。</p>
</li>
<li><p><strong>Enhancing VAEs: Better priors</strong> 设定一个好的先验也是很重要的，能够减小与变分后验的gap。很多研究尝试解决这个问题，比如：using a multimodal prior mimicking the aggregated posterior (known as the VampPrior) (Tomczak &amp; Welling, 2018), or a flow-based prior (e.g., (Gatopoulos &amp; Tomczak, 2020)), an ARM-based prior (Chen et al., 2016) or using an idea of resampling (Bauer &amp; Mnih, 2019).</p>
</li>
<li><p><strong>VAEs for non-image data</strong> 不仅仅是图像数据，文本、序列数据等也可以。</p>
</li>
<li><p><strong>Extending VAEs</strong> Here, we present the unsupervised version of VAEs. However, there is no restriction to that and we can introduce labels or other variables. In (Kingma et al., 2014) a semi-supervised VAE was proposed. This idea was further extended to the concept of fair representations (Louizos et al., 2015). In (Ilse et al., 2020), the authors proposed a specific latent representation that allows domain generalization in VAEs. In (Blundell et al., 2015) variational inference and the reparameterization trick were used for Bayesian Neural Nets. This paper is not necessarily introducing a VAE, but a VAE-like way of dealing with Bayesian neural nets.</p>
</li>
<li><p><strong>Different latent spaces</strong> in (Davidson et al., 2018; Davidson et al., 2019) a hyperspherical latent-space was used, and in (Mathieu et al., 2019) the hyperbolic latent space was utilized.</p>
</li>
<li><p>**The posterior collapse ** There were many ideas proposed to deal with the posterior collapse. For instance, (He et al., 2019) propose to update variational posteriors more often than the decoder. In (Dieng et al., 2019) a new architecture of the decoder is proposed by introducing <em>skip connection</em> to avoiding the posterior collapse.</p>
</li>
<li><p><strong>Various perspectives on the objective</strong> The core of the VAE is the ELBO. However, we can consider different objectives. For instance, (Dieng et al., 2017) propose an upper-bound to the log-likelihood that is based on the chi-square divergence (CUBO). In (Alemi et al., 2018) an information-theoretic perspective on the ELBO is presented. (Higgins et al., 2016) introduced the 𝛽β-VAE where the regularization term is weighted by a fudge factor 𝛽β. The objective does not correspond to the lowe-bound of the log-likelihood though.</p>
</li>
<li><p><strong>Deterministic Regularized Auto-Encoders</strong>: We can take look at the VAE and the objective, as mentioned before, and think of it as a regularized version of an auto-encoder with a stochastic encoder and a stochastic decoder. (Ghosh et al., 2020) “peeled off” VAEs from all stochasticity and indicated similarities between deterministic regularized auto-encoders and VAEs, and highlited potential issues with VAEs. Moreover, they brilliantly pointed out that even with a deterministic encoders, due to stochasticity of the empirical distribution, we can fit a model to the aggregated posterior. As a result, the deterministic (regularized) auto-encoder could be turned into a generative model by sampling from our model, 𝑝𝜆(<strong>𝐳</strong>)pλ(z), and then, deterministically, mapping <strong>𝐳</strong>z to the space of observable <strong>𝐱</strong>x. In my opinion, this direction should be further explored and an important question is whether we indeed need any stochasticity at all.</p>
</li>
<li><p><strong>Hierarchical VAEs</strong> Very recently, there are many VAEs with a deep, hierarchical structure of latent variables that achieved remarkable results! The most important ones are definitely BIVA (Maaløe et al., 2019), NVA (Vahdat &amp; Kautz, 2020), and very deep VAEs (Child, 2020). Another interesting perspective on a deep, hierarchical VAE was presented in (Gatopoulos &amp; Tomczak, 2020) where, additionally, a series of deterministic functions was used.</p>
</li>
<li><p><strong>Adversarial Auto-Encoders</strong> Another interesting perspective on VAEs is presented in (Makhzani et al., 2015). Since learning the aggregated posterior as the prior is an important component mentioned in some papers (e.g., (Tomczak &amp; Welling, 2018)), a different approach would be to train the prior with an adversarial loss. Further, (Makhzani et al., 2015) present various ideas how auto-encoders could benefit from adverarial learning.</p>
</li>
</ul>
<h2 id="Hierarchical-Variational-Auto-Encoders"><a href="#Hierarchical-Variational-Auto-Encoders" class="headerlink" title="Hierarchical Variational Auto-Encoders"></a>Hierarchical Variational Auto-Encoders</h2><p>交叉熵：$p_{data}(x)$ 是真实分布，$p_{\theta}(x)$是预测分布<br>$$<br>\begin{align}<br>\mathbb{CE}[p_{data}(x)|p_{\theta}(x)] &amp;= E_{x\sim p_{data}(x)}[ln\dfrac{1}{p_{\theta}(x)}] \\<br>&amp;= -\frac{1}{N}\sum_{1}^{N}lnp_{\theta}(x_n)<br>\end{align}<br>$$<br>相对熵：<br>$$<br>\begin{align}<br>\mathbb{KL}[p_{data}(x)|p_{\theta}(x)] &amp;= -\mathbb{H}[p_{data}(x)] + \mathbb{CE}[p_{data}(x)|p_{\theta}(x)] \\<br>&amp;= const + \mathbb{CE}[p_{data}(x)|p_{\theta}(x)]<br>\end{align}<br>$$</p>
<p><strong>潜在变量模型存在一个问题</strong>： [后验崩塌**(posteroir collapse)**](<a target="_blank" rel="noopener" href="https://datascience.stackexchange.com/questions/48962/what-is-posterior-collapse-phenomenon">python - What is “posterior collapse” phenomenon? - Data Science Stack Exchange</a>). 当后验未出现崩塌时，$z_d$(d维潜在变量)通过encoder采样得到 $q_{\phi}(z|x)={N}(z|\mu, \sigma^2)$， 其中 $\mu, \sigma$是关于输入 $x$ 的稳定的函数。也就是encoder从输入中提取到了有用的信息赋予到 $\mu,\sigma$中。</p>
<p>当出现后验崩塌时，通过encoder从输入 $x$ 提取到的信息很弱或者噪声太大**(too weak or too noisy)**. 也就是说decoder在生成图像时，会忽略潜在变量 $z$ 的信息。too noisy意味着 $\mu,\sigma$不稳定， too weak意味着:<br>$$<br>q_{\phi}(z|x) \approx q_{\phi}(z) = \mathcal{N}(a,b)<br>$$<br>其中 $a,b$ 是常量。</p>
<p>从可视化的角度看这个问题：</p>
<img src="/2021/12/07/Deep-Generative-Models/latent_variable_likelihood_all.png" alt="image-20211209135812911" style="zoom:50%;">

<p>横轴是重构loss，纵轴是 潜在变量模型$p_{\theta}(z|x)$ 的参与度。当处于上图的左下角时，表明重构loss很小，但是后验概率并不重要，也就是出现了后验崩塌。所以问题来了，在优化过程中，一定存在这样的模型在完全抛弃潜在变量模型的情况下使得KL很小。但是在实际使用过程中，我们发现潜在变量是有用的，其原因是我们所选择的模型存在归纳偏置**(inductive bia)**,这使得潜在变量一定会学到有用的信息。</p>
<img src="/2021/12/07/Deep-Generative-Models/latent_variable_likelihood_constrained.png" style="zoom:45%;">

<p><strong>How to define a <em>proper</em> class of models?</strong> 该如何定义这一类模型，使得潜在变量一定能学到有用的信息呢？这定义了一个constrained optimization problem (Phuong et al., 2018; Rezende &amp; Viola, 2018) 和正则化问题  an auxiliary regularizer (Sinha &amp; Dieng, 2021; Tomczak, 2016) to (implicitly) define <em>usefulness</em> of the latents.</p>
<p>在下文中，我们使用层次化的结构 <strong>hierarchical architectures</strong> 来缓解这一问题。我们在前面提到潜在变量可以理解成构成目前的一些因素/概率，而这些因素可以是层次化结构的。如果潜在变量模型存在层次化结构，能够引入归纳偏置，进入限制我们的VAE模型，强制信息在潜在变量和观测目标中流动。</p>
<h3 id="Hierarchical-Variational-Auto-Encoders-1"><a href="#Hierarchical-Variational-Auto-Encoders-1" class="headerlink" title="Hierarchical Variational Auto-Encoders"></a>Hierarchical Variational Auto-Encoders</h3><p><strong>Two-level VAE</strong>: </p>
<img src="/2021/12/07/Deep-Generative-Models/2level_vae.png" style="zoom:100%;">

<p>这里有一个假设就是 $z_2\rightarrow z_1\rightarrow x$ 是一阶隐马尔可夫链，也就是 $x$ 不受 $x_2$的影响。那么有：<br>$$<br>p(x,z_1,z_2) = p(x|z_1,z_2)p(z_1,z_2) = p(x|z_1)p(z_1|z_2)p(z_2)<br>$$<br>那么对应的模型（概率分布）可以表示成:<br>$$<br>\begin{align}<br>p(z_1|z_2) &amp;= N(z_1|\mu(z_2), \sigma^2(z_2)) \\<br>p(z_2) &amp;= N(z_2|0,1) \\<br>q(z_1|z_2) &amp;= N(z_1|\mu(x), \sigma^2(x)) \\<br>q(z_2|z_1) &amp;= N(z_2|\mu(z_1), \sigma^2(z_1))<br>\end{align}<br>$$<br>其中 $p(z_1|z_2)$ 是用NN表示的模型，$p(z_2)$是先验模型，$q(z_1|x)$ 和 $q(z_2|z_1)$是后验概率模型。</p>
<p>我们使用层次模型的目的是保证潜在变量学到有用的信息，可是我们做到了吗？答案是NO，因为前面提到的问题依然还是存在。这里我们先推导下层次模型的ELBO，在进一步分析这个问题：</p>
<p>在推导之前有这么一个公式会用到，这一步的公式用到了一阶马尔可夫链的特性，也就是$z_2$与$x$无关：<br>$$<br>q(z_1,z_2|x) = q((z_2|z_1)|x)q(z_1|x) = q(z_2|z_1)q(z_1|x)<br>$$</p>
<p>$$<br>\begin{align}<br>p(x) &amp;= \int p(x|z_1,z_2)p(z_1,z_2)d(z_1,z_2) \\<br>ELBO(x) &amp;= E_{(z_1,z_2)\sim q_{\phi}(z_1,z_2|x)}[lnp(x|z_1,z_2)-KL[q_{\phi}(z_1,z_2|x)||p(z_1,z_2)]] \quad \text{利用一层VAE的推导可得到} \\<br>&amp;= E_{(z_1,z_2)\sim q_{\phi}(z_1,z_2|x)}[lnp(x|z_1)-ln\dfrac{q(z_1,z_2|x)}{p(z_1,z_2)}] \quad x \text{不依赖于} z_2，以及KL散度公式 \\<br>&amp;= E_{(z_1,z_2)\sim q_{\phi}(z_1,z_2|x)}[lnp(x|z_1) - ln\dfrac{q(z_1|x)q(z_2|z_1)}{p(z_2)p(z_1|z_2)}] \quad \text{贝叶斯公式，以及上一个公式} \\<br>&amp;= E_{(z_1,z_2)\sim q_{\phi}(z_1,z_2|x)}[lnp(x|z_1) - ln\dfrac{q(z_1|x)}{p(z_1|z_2)} - ln\dfrac{q(z_2|z_1)}{p(z_2)} \\<br>&amp;= E_{(z_1,z_2)\sim q_{\phi}(z_1,z_2|x)}[lnp(x|z_1) - KL[q(z_1|x)||p(z_1|z_2) - KL[q(z_2|z_1)||p(z_2)]]<br>\end{align}<br>$$</p>
<p>我们发现后验崩塌的问题依然存在，$z_2$ 大多数情况不会被使用(Burda et al., 2015; Maaloe et al., 2017).</p>
<h2 id="Diffusion-Model"><a href="#Diffusion-Model" class="headerlink" title="Diffusion Model"></a>Diffusion Model</h2><p>学过 Hierarchical VAE之后再来看diffusion model就很容易理解这些公式背后的意义了。这里笔者参照H-VAE画了个图，与H-VAE的关系就一目了然了：</p>
<img src="/2021/12/07/Deep-Generative-Models/diffusion_model2.png" style="zoom:90%;">

<p>在VAE模型中，后验概率 $q_{\phi}(z|x)$ 是通过NN学习得到的，但是在diffusion model， (Sohl-Dickstein et al., 2015; Ho et al., 2020)将这个Gaussian diffusion process 定为确定性的，比如在 (Ho et al., 2020) 将其设置为 $\beta_i=10^{-4}$ to $\beta_T=0.02$.</p>
<p>Gaussian diffusion process 的样本可视化如下：</p>
<p><img src="/2021/12/07/Deep-Generative-Models/cat_ddgm.png"></p>
<p>DDGM的目标函数和H-VAE的区别在于潜在变量的维度，但基本推导是完全一致的。<br>$$<br>ln p_{\theta}(x)=ln\int Q_{z_{\phi}(z_{1:T}|x)}\dfrac{p_{\theta}(x,z_{1:T})}{Q_{\phi(z_{1:T}|x)}}\mathrm{d}z_{1:T}<br>$$<br>根据H-VAE的推导过程，DDGM的ELBO可以直接写出如下：<br>$$<br>ELBO(x;\theta,\phi) = E_{Q_{\phi}(z_{1:T}|x)}[lnp_{\theta}(x|z_1)-KL[q(z_1|x)||p(z_1|z_2)] - \sum_{i=2}^{T-1}KL[q(z_i|z_{i-1})||p(z_i|z_{i+1})] - KL[q(z_T|z_{T-1})||p(z_T)]]<br>$$<br>其中:<br>$$<br>p_{\theta}(z_T) = {N}(z_T|0, I)<br>$$<br>到目前位置，我们学了H-VAE和DDGM，他们都是采用变分推断的方法来近似学习log-likelihood. 但是为什么这种层次化的方式能缓解我们在VAE中提到的后验崩塌问题： 如何保证潜在变量学到有用的信息？</p>
<p>Reference:</p>
</div><div class="article-licensing box"><div class="licensing-title"><p>Deep Generative Models</p><p><a href="http://www.panxiaoxie.cn/2021/12/07/Deep-Generative-Models/">http://www.panxiaoxie.cn/2021/12/07/Deep-Generative-Models/</a></p></div><div class="licensing-meta level is-mobile"><div class="level-left"><div class="level-item is-narrow"><div><h6>作者</h6><p>Xie Pan</p></div></div><div class="level-item is-narrow"><div><h6>发布于</h6><p>2021-12-07</p></div></div><div class="level-item is-narrow"><div><h6>更新于</h6><p>2022-04-10</p></div></div><div class="level-item is-narrow"><div><h6>许可协议</h6><p><a class="icons" rel="noopener" target="_blank" title="Creative Commons" href="https://creativecommons.org/"><i class="icon fab fa-creative-commons"></i></a><a class="icons" rel="noopener" target="_blank" title="Attribution" href="https://creativecommons.org/licenses/by/4.0/"><i class="icon fab fa-creative-commons-by"></i></a><a class="icons" rel="noopener" target="_blank" title="Noncommercial" href="https://creativecommons.org/licenses/by-nc/4.0/"><i class="icon fab fa-creative-commons-nc"></i></a></p></div></div></div></div></div><div class="article-tags is-size-7 mb-4"><span class="mr-2">#</span><a class="link-muted mr-2" rel="tag" href="/tags/generation/">generation</a></div><!--!--></article></div><!--!--><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/2022/04/05/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-Denoising-Diffusion-Probabilistic-Models/"><i class="level-item fas fa-chevron-left"></i><span class="level-item">论文笔记-Denoising Diffusion Probabilistic Models</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/2021/11/29/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-Autoencoders-Are-Vision-Learners/"><span class="level-item">论文笔记-Autoencoders Are Vision Learners</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><div class="card"><div class="card-content"><h3 class="title is-5">评论</h3><div id="disqus_thread"><noscript>Please enable JavaScript to view the <a target="_blank" rel="noopener" href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript></div><script>var disqus_config = function () {
            this.page.url = 'http://www.panxiaoxie.cn/2021/12/07/Deep-Generative-Models/';
            this.page.identifier = '2021/12/07/Deep-Generative-Models/';
        };
        (function() {
            var d = document, s = d.createElement('script');  
            s.src = '//' + 'panxie' + '.disqus.com/embed.js';
            s.setAttribute('data-timestamp', +new Date());
            (d.head || d.body).appendChild(s);
        })();</script></div></div></div><!--!--><div class="column column-right is-4-tablet is-4-desktop is-4-widescreen  order-3"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar" src="/img/avatar.png" alt="panxiaoxie"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">panxiaoxie</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Beijing, China</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">文章</p><a href="/archives"><p class="title">120</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">分类</p><a href="/categories"><p class="title">40</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">标签</p><a href="/tags"><p class="title">37</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/PanXiebit" target="_blank" rel="noopener">关注我</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/PanXiebit"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Email" href="/ftdpanxie@gmail.com"><i class="fa fa-envelope"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="RSS" href="/"><i class="fas fa-rss"></i></a></div></div></div><div class="card widget" id="toc" data-type="toc"><div class="card-content"><div class="menu"><h3 class="menu-label">目录</h3><ul class="menu-list"><li><a class="level is-mobile" href="#VAEs"><span class="level-left"><span class="level-item">1</span><span class="level-item">VAEs  </span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#Probabilistic-PCA"><span class="level-left"><span class="level-item">1.1</span><span class="level-item">Probabilistic PCA</span></span></a></li><li><a class="level is-mobile" href="#Variational-Inference-for-Non-linear-Latent-Variable-Models"><span class="level-left"><span class="level-item">1.2</span><span class="level-item">Variational Inference for Non-linear Latent Variable Models</span></span></a></li><li><a class="level is-mobile" href="#A-different-perspective-on-the-ELBO"><span class="level-left"><span class="level-item">1.3</span><span class="level-item">A different perspective on the ELBO</span></span></a></li><li><a class="level is-mobile" href="#Components-of-VAEs"><span class="level-left"><span class="level-item">1.4</span><span class="level-item">Components of VAEs</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#Parameterization-of-distributions"><span class="level-left"><span class="level-item">1.4.1</span><span class="level-item">Parameterization of distributions</span></span></a></li><li><a class="level is-mobile" href="#Reparameterization-trick"><span class="level-left"><span class="level-item">1.4.2</span><span class="level-item">Reparameterization trick</span></span></a></li></ul></li><li><a class="level is-mobile" href="#More-about-VAEs"><span class="level-left"><span class="level-item">1.5</span><span class="level-item">More about VAEs!</span></span></a></li></ul></li><li><a class="level is-mobile" href="#Hierarchical-Variational-Auto-Encoders"><span class="level-left"><span class="level-item">2</span><span class="level-item">Hierarchical Variational Auto-Encoders</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#Hierarchical-Variational-Auto-Encoders-1"><span class="level-left"><span class="level-item">2.1</span><span class="level-item">Hierarchical Variational Auto-Encoders</span></span></a></li></ul></li><li><a class="level is-mobile" href="#Diffusion-Model"><span class="level-left"><span class="level-item">3</span><span class="level-item">Diffusion Model</span></span></a></li></ul></div></div><style>#toc .menu-list > li > a.is-active + .menu-list { display: block; }#toc .menu-list > li > a + .menu-list { display: none; }</style><script src="/js/toc.js" defer></script></div><div class="card widget" data-type="links"><div class="card-content"><div class="menu"><h3 class="menu-label">链接</h3><ul class="menu-list"><li><a class="level is-mobile" href="https://github.com/PanXiebit" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">github</span></span><span class="level-right"><span class="level-item tag">github.com</span></span></a></li><li><a class="level is-mobile" href="ftdpanxie@gmail.com" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">email</span></span><span class="level-right"><span class="level-item tag">ftdpanxie@gmail.com</span></span></a></li></ul></div></div></div><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">分类</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/C/"><span class="level-start"><span class="level-item">C++</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/CSAPP/"><span class="level-start"><span class="level-item">CSAPP</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/DRL/"><span class="level-start"><span class="level-item">DRL</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/GAN/"><span class="level-start"><span class="level-item">GAN</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li><li><a class="level is-mobile" href="/categories/GAN-RL/"><span class="level-start"><span class="level-item">GAN, RL</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/ML/"><span class="level-start"><span class="level-item">ML</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/NLP/"><span class="level-start"><span class="level-item">NLP</span></span><span class="level-end"><span class="level-item tag">14</span></span></a></li><li><a class="level is-mobile" href="/categories/TensorFlow/"><span class="level-start"><span class="level-item">TensorFlow</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/cs224d/"><span class="level-start"><span class="level-item">cs224d</span></span><span class="level-end"><span class="level-item tag">10</span></span></a></li><li><a class="level is-mobile" href="/categories/generation/"><span class="level-start"><span class="level-item">generation</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/generative-models/"><span class="level-start"><span class="level-item">generative models</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/interview/"><span class="level-start"><span class="level-item">interview</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/machine-translation/"><span class="level-start"><span class="level-item">machine translation</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/python/"><span class="level-start"><span class="level-item">python</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/pytorch/"><span class="level-start"><span class="level-item">pytorch</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/reinforcement-learning/"><span class="level-start"><span class="level-item">reinforcement learning</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/sign-language-recognition/"><span class="level-start"><span class="level-item">sign language recognition</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/transfer-learning/"><span class="level-start"><span class="level-item">transfer learning</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/transformer/"><span class="level-start"><span class="level-item">transformer</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"><span class="level-start"><span class="level-item">数据结构与算法</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile" href="/categories/%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB/"><span class="level-start"><span class="level-item">文本分类</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"><span class="level-start"><span class="level-item">论文笔记</span></span><span class="level-end"><span class="level-item tag">40</span></span></a><ul><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/DL/"><span class="level-start"><span class="level-item">DL</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/ESA/"><span class="level-start"><span class="level-item">ESA</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/GAN/"><span class="level-start"><span class="level-item">GAN</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/MRC-and-QA/"><span class="level-start"><span class="level-item">MRC and QA</span></span><span class="level-end"><span class="level-item tag">7</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/Machine-Translation/"><span class="level-start"><span class="level-item">Machine Translation</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/NLP/"><span class="level-start"><span class="level-item">NLP</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/Transformer/"><span class="level-start"><span class="level-item">Transformer</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/capsules/"><span class="level-start"><span class="level-item">capsules</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/computer-vision/"><span class="level-start"><span class="level-item">computer vision</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/constrast-learning/"><span class="level-start"><span class="level-item">constrast learning</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/data-augmentation/"><span class="level-start"><span class="level-item">data augmentation</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/dialogue-system/"><span class="level-start"><span class="level-item">dialogue system</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/language-model/"><span class="level-start"><span class="level-item">language model</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/machine-translation/"><span class="level-start"><span class="level-item">machine translation</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/open-set-recognition/"><span class="level-start"><span class="level-item">open set recognition</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/sentence-embedding/"><span class="level-start"><span class="level-item">sentence embedding</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/text-matching/"><span class="level-start"><span class="level-item">text matching</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/vision-language/"><span class="level-start"><span class="level-item">vision-language</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li></ul></div></div></div></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/panxiaoxie.png" alt="潘小榭" height="28"></a><p class="is-size-7"><span>&copy; 2022 Xie Pan</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("zh-CN");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="回到顶端" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "此网站使用Cookie来改善您的体验。",
          dismiss: "知道了！",
          allow: "允许使用Cookie",
          deny: "拒绝",
          link: "了解更多",
          policy: "Cookie政策",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.5/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="想要查找什么..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"想要查找什么...","untitled":"(无标题)","posts":"文章","pages":"页面","categories":"分类","tags":"标签"});
        });</script></body></html>