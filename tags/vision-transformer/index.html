<!doctype html>
<html lang="de"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>Tag: vision transformer - 潘小榭</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="潘小榭"><meta name="msapplication-TileImage" content="/img/favicon.svg"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="潘小榭"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta property="og:type" content="blog"><meta property="og:title" content="潘小榭"><meta property="og:url" content="http://www.panxiaoxie.cn/"><meta property="og:site_name" content="潘小榭"><meta property="og:image" content="http://www.panxiaoxie.cn/img/og_image.png"><meta property="article:author" content="Xie Pan"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="/img/og_image.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"http://www.panxiaoxie.cn"},"headline":"潘小榭","image":["http://www.panxiaoxie.cn/img/og_image.png"],"author":{"@type":"Person","name":"Xie Pan"},"publisher":{"@type":"Organization","name":"潘小榭","logo":{"@type":"ImageObject","url":"http://www.panxiaoxie.cn/img/logo.svg"}},"description":null}</script><link rel="icon" href="/img/favicon.svg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/css/justifiedGallery.min.css"><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script><!--!--><!--!--><meta name="generator" content="Hexo 5.4.0"></head><body class="is-2-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/logo.svg" alt="潘小榭" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-8-widescreen"><div class="card"><div class="card-content"><nav class="breadcrumb" aria-label="breadcrumbs"><ul><li><a href="/tags">Tags</a></li><li class="is-active"><a href="#" aria-current="page">vision transformer</a></li></ul></nav></div></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2021-04-29T01:07:08.000Z" title="2021/4/29 上午9:07:08">2021-04-29</time></span><span class="level-item">Updated&nbsp;<time dateTime="2021-07-01T02:08:18.921Z" title="2021/7/1 上午10:08:18">2021-07-01</time></span><span class="level-item">a minute read (About 178 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2021/04/29/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-video-transformer/">论文笔记-video transformer</a></h1><div class="content"><p>paper list:  </p>
<ul>
<li>Training data-efficient image transformers &amp; distillation through attention.</li>
<li>An image is worth 16x16 words: Transformers for image recognition at scale.  </li>
<li>ViViT: A Video Vision Transformer.    </li>
<li>Is space-time attention all you need for video understanding  </li>
<li>Video transformer network.  </li>
</ul>
<h2 id="DeiT"><a href="#DeiT" class="headerlink" title="DeiT"></a>DeiT</h2><p>利用attention机制设计了一种特殊的知识蒸馏方式，效果不错。</p>
<h2 id="ViViT-A-Video-Vision-Transformer"><a href="#ViViT-A-Video-Vision-Transformer" class="headerlink" title="ViViT: A Video Vision Transformer"></a>ViViT: A Video Vision Transformer</h2><p>作者通过大量实验来研究 vision transformer，并探索最合适的且efficient的结构使其能适用于small datasets. 其中，主要包括以下三个方面的探索：    </p>
<ul>
<li>tokenization strategies  </li>
<li>model architecture  </li>
<li>regularisation methods.</li>
</ul>
<p>transformer-based architecture的缺点：相比卷积网络，transformer缺乏了一定的归纳偏置能力，比如平移不变性。因此，需要大量的数据来学习。</p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2021-04-12T08:16:35.000Z" title="2021/4/12 下午4:16:35">2021-04-12</time></span><span class="level-item">Updated&nbsp;<time dateTime="2021-06-29T05:19:29.449Z" title="2021/6/29 下午1:19:29">2021-06-29</time></span><span class="level-item">15 minutes read (About 2186 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2021/04/12/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-Deformable-DETR/">论文笔记-DETR and Deformable DETR</a></h1><div class="content"><ul>
<li>DETR: End-to-End Object Detection with Transformers  </li>
<li>Deformable DETR： Deformable Transformer for End-to-End Object Detection</li>
</ul>
<h2 id="DETR-End-to-End-Object-Detection-with-Transformers"><a href="#DETR-End-to-End-Object-Detection-with-Transformers" class="headerlink" title="DETR: End-to-End Object Detection with Transformers"></a>DETR: End-to-End Object Detection with Transformers</h2><p>paper link: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2005.12872">https://arxiv.org/abs/2005.12872</a></p>
<h3 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h3><p>传统的目标检测范式：</p>
<ul>
<li>使用CNN Backbone提取feature map;  </li>
<li>使用 Region Proposal Network (RPN) 在feature map上枚举所有的windows,输出N个候选boxes  </li>
<li>使用分类器对每个box进行分类  </li>
</ul>
<p><img src="/2021/04/12/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-Deformable-DETR/faster_rcnn.png"></p>
<p>这样存在很多问题：</p>
<p><strong>问题1：Enumerate candidate boxes in RPN</strong></p>
<ul>
<li>枚举所有的pixel  </li>
<li>对每个pixel，枚举出所有预定义大小的boxes  </li>
<li>大部分的候选框都是无效的，因此 Inefficient, slow<br><img src="/2021/04/12/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-Deformable-DETR/rpn.png"></li>
</ul>
<p><strong>问题2：Redundant boxes and NMS</strong></p>
<ul>
<li>RPN 输出大量的boxes  </li>
<li>Non-maximum suppression (NMS) merges/removes redundant boxes  </li>
<li>These hand-designed components have a few hyperparameters    </li>
<li>Model tuning is complex<br><img src="/2021/04/12/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-Deformable-DETR/nms.png"></li>
</ul>
<h3 id="Architecture-of-DETR"><a href="#Architecture-of-DETR" class="headerlink" title="Architecture of DETR"></a>Architecture of DETR</h3><p>因此，作者提出了更为简单的end-to-end的目标检测模型：<br><img src="/2021/04/12/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-Deformable-DETR/detr_vs_fast_rcnn.png"></p>
<h4 id="Self-attention-vs-Convolution-in-Vision"><a href="#Self-attention-vs-Convolution-in-Vision" class="headerlink" title="Self-attention vs. Convolution in Vision"></a>Self-attention vs. Convolution in Vision</h4><p>Transformer 已经非常熟悉了，就不详细介绍了。这里对比下 self-attention 和 CNN 在视觉领域的应用</p>
<ul>
<li>每个pixel可以看作是自然语言中的 token  </li>
<li>convolution is used to integrate pixels  <ul>
<li>Recognize patterns within a small window of pixels  </li>
<li>Difficult to integrate non-local pixels  </li>
<li>Have to make network very deep to “see the big picture”  </li>
</ul>
</li>
<li>Self-attention (transformer) also integrates multiple pixels  <ul>
<li>Works when the correlated pixels are non-local  </li>
<li>Trunk, tail, legs of an elephant to a whole elephant  </li>
</ul>
</li>
</ul>
<p><img src="/2021/04/12/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-Deformable-DETR/elephant.png"></p>
<h4 id="Architecture"><a href="#Architecture" class="headerlink" title="Architecture"></a>Architecture</h4><p><img src="/2021/04/12/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-Deformable-DETR/detr_arch.png"></p>
<p>整个结构可以看作四部分：</p>
<ul>
<li>CNN backbone  </li>
<li>Transformer Encoder  </li>
<li>Transformer Decoder  </li>
<li>bipartite matching loss</li>
</ul>
<h5 id="CNN-backbone-Transformer-Encoder"><a href="#CNN-backbone-Transformer-Encoder" class="headerlink" title="CNN backbone + Transformer Encoder"></a>CNN backbone + Transformer Encoder</h5><p>前两个好理解，需要注意的是 position encoding 与NLP中不同。考虑到输入是二维图像，对应的位置 (x,y) 也是二维的。</p>
<p>总结下和原始transformer编码器不同的地方：  </p>
<ul>
<li>输入编码器的位置编码需要考虑2-D空间位置。  </li>
<li>位置编码向量需要加入到每个Encoder Layer中。  </li>
<li>在编码器内部位置编码Positional Encoding仅仅作用于Query和Key，即只与Query和Key相加，Value不做任何处理。</li>
</ul>
<h4 id="Transformer-Decoder"><a href="#Transformer-Decoder" class="headerlink" title="Transformer Decoder"></a>Transformer Decoder</h4><p>decoder与原始的transformer decoder的区别在于两点：  </p>
<ul>
<li>其输入是 Object queries. 是可学习的 nn.Embedding, 维度为 [100, bsz, 256]. 其实可以理解成可学习的位置编码。  </li>
<li>非自回归的可并行解码。</li>
</ul>
<h4 id="bipartite-matching-loss"><a href="#bipartite-matching-loss" class="headerlink" title="bipartite matching loss"></a>bipartite matching loss</h4><p>decoder 的输出张量的维度是 分类分支：[bsz, 100, class + 1] 和回归分支：[bsz, 100, 4]. 其中 class + 1 表示类别总数+背景。有物体的boxes计算回归任务；没有物体的背景框，则不用回归。</p>
<p><strong>问题来了：</strong><br>这100个候选框如何去与 不确定数量的 targets 进行匹配呢，预测框和真值是怎么一一对应的？换句话说：你怎么知道第47个预测框对应图片里的狗，第88个预测框对应图片里的车？等等。</p>
<blockquote>
<p>相比Faster R-CNN等做法，DETR最大特点是将目标检测问题转化为无序集合预测问题(set prediction)。论文中特意指出Faster R-CNN这种设置一大堆anchor，然后基于anchor进行分类和回归其实属于代理做法即不是最直接做法，目标检测任务就是输出无序集合，而Faster R-CNN等算法通过各种操作，并结合复杂后处理最终才得到无序集合属于绕路了，而DETR就比较纯粹了。现在核心问题来了：输出的 [bsz, 100] 个检测结果是无序的，如何和 ground-truth bounding box 计算loss？这就需要用到经典的双边匹配算法了，也就是常说的 <strong>匈牙利算法</strong>，该算法广泛应用于最优分配问题。</p>
</blockquote>
<p>整个loss function的计算分为两个步骤：  </p>
<ul>
<li><ol>
<li>依据匈牙利算法先找到最优的匹配  </li>
</ol>
</li>
<li><ol start="2">
<li>根据找到的匹配，计算最终的loss  </li>
</ol>
</li>
</ul>
<p><strong>如何找到最优的匹配呢？</strong><br>假设一张图片有3个目标：dog, cat, car. 那么我们可以得到一个 [100, 3] 的矩阵, 矩阵的值分别表示这100个候选token为其中某一目标的“损失”. 让这个损失最小的匹配就是我们要找的最优匹配。这个过程就是匈牙利算法。</p>
<p><img src="/2021/04/12/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-Deformable-DETR/loss.png"></p>
<p>再介绍匈牙利算法之前，我们要知道这个矩阵对应的损失值是啥呢？也就是怎么衡量这个候选token是某个目标的损失值？</p>
<p>假设 $y_i$ 对应的预测是 $\hat y_{\sigma_i}$,那么这个构成这个搭配的损失就是 $\hat y_{\sigma_i}$ 对应的类别为 $c_i$ 以及 box 的 mse 值。</p>
<p>$$L_{match}(y_i, \hat y_{\sigma(i)})=-\mathbb{1}<em>{c_i\ne \varnothing}\hat p</em>{\sigma(i)}(c_i) + 1_{c_i\ne \varnothing}L_{box}(b_i, \hat b_{\sigma_i})$$</p>
<p>$L_{match}$ 就是矩阵中的元素。然后通过匈牙利算法找到对应的匹配。</p>
<p><strong>找到匹配之后计算最终的loss</strong></p>
<p><img src="/2021/04/12/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-Deformable-DETR/loss_last.png"></p>
<h2 id="Deformable-DETR"><a href="#Deformable-DETR" class="headerlink" title="Deformable DETR"></a>Deformable DETR</h2><p>DETR 的优缺点：</p>
<ul>
<li>优点<ol>
<li>纯端到端，不需要手工设计的NMS之类</li>
</ol>
</li>
<li>DETR 缺点：<ol>
<li>小目标检测的低精度，高精度的feature map的复杂度是DETR所不能忍受的。<ol>
<li>这是因为 attention 机制的原因，复杂度是 O(L^2)</li>
</ol>
</li>
<li>收敛速度慢，slow convergence。原因是 pattern 是稀疏的，很难快速学到吧<ol>
<li>when $N_k$ is large, it will lead $N_k$<br>to ambiguous gradients for input features. Thus, long training schedules are required so that the attention weights can focus on specific keys.</li>
</ol>
</li>
</ol>
</li>
</ul>
<p>Deformable DETR 的设计初衷：</p>
<ol>
<li>motivation: mitigates the slow convergence and high complexity issues of DETR</li>
</ol>
<ul>
<li>具体设计方法<ol>
<li>融合Deformable conv的空间稀疏采样和transformer的关系建模的优势 combines the best of the sparse spatial sampling of deformable convo- lution, and the relation modeling capability of Transformers</li>
</ol>
</li>
<li>deformable attention modules： 代替Transformer attention module</li>
</ul>
<h3 id="Multi-Head-Attention-in-Transformers"><a href="#Multi-Head-Attention-in-Transformers" class="headerlink" title="Multi-Head Attention in Transformers"></a>Multi-Head Attention in Transformers</h3><p>常规的 attention:</p>
<p><img src="/2021/04/12/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-Deformable-DETR/attention.png"></p>
<ul>
<li>$A_{mqk}$ 是attention matrix.   </li>
<li>$z_q\in R^C$ 是query feature.  </li>
<li>$x_k\in R^C$ 是key/value feature. $\Omega_k$ 是key index的集合.   </li>
<li>$m$ 是attention head index.  </li>
</ul>
<p><img src="/2021/04/12/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-Deformable-DETR/computation.png"></p>
<p>总的计算量是: $O(N_qC^2) + 2O(N_kC^2) + 2O(N_qN_kC^2)$</p>
<p>复杂度：$O(N_qC^2 + N_kC^2 + N_qN_kC)$</p>
<p>在长文本，或者image patched之后，$N_q=N_k &gt;&gt; C$. 所以复杂度取决于 $O(N_qN_kC)$</p>
<h3 id="Deformable-attention-module"><a href="#Deformable-attention-module" class="headerlink" title="Deformable attention module"></a>Deformable attention module</h3><p><img src="/2021/04/12/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-Deformable-DETR/deformable_attention.png"></p>
<p>相比常规的attention, 需要考虑所有的key features，也就是 HW 个。 deformable attention只考虑K个keys. 如下面两个公式所示 $\sum_{k\in \Omega_k} \rightarrow \sum_{k=1}^K$. 因此复杂度会大大降低，收敛速度也会加快。</p>
<p><img src="/2021/04/12/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-Deformable-DETR/attention.png"></p>
<p><img src="/2021/04/12/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-Deformable-DETR/deformable_attention_formulation.png"></p>
<p>其中：  </p>
<ul>
<li>m 表示attention head index  </li>
<li>$z_q$ 表示query feature  </li>
<li>$K &lt;&lt; HW$ 表示sampling number  </li>
<li>$p_q$ 表示 $z_q$ 对应的参考2D点  </li>
<li>$\Delta p_{mqk}$ 表示相对参考点的sampling offset  </li>
<li>$A_{mqk}$ 则是对应采样点的weights, $\sum_{k=1}^{K}A_{mqk}=1$  </li>
</ul>
<p>现在的问题在于，这K个keys是怎么选择的呢？也就是 offset $\Delta p_{mqk}$ 是怎么来的？文中是这么解释的：</p>
<p><img src="/2021/04/12/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-Deformable-DETR/k_selector.png"></p>
<p>这个过程如图2所示：  </p>
<ul>
<li>通过 linear projection 得到 2D 实数值 $\Delta p_{mqk}$， 然后通过线性插值得到 $p_q + \Delta p_{mqk}$.    </li>
<li>对应的权重 $A_{mqk}$ 也是通过linear projection得到的。</li>
</ul>
<p>这样 deformable attention 的复杂度：$N_qC^2 + O(N_qKC)$.</p>
<h3 id="Multi-scale-Deformable-Attention-Module"><a href="#Multi-scale-Deformable-Attention-Module" class="headerlink" title="Multi-scale Deformable Attention Module"></a>Multi-scale Deformable Attention Module</h3><p>Deformable attention 可以很自然的拓展到multi-scale情况下。</p>
<p><img src="/2021/04/12/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-Deformable-DETR/multi_scale_formulation.png">  </p>
<ul>
<li>m 表示 attention head index  </li>
<li>l 表示 input feature level  </li>
<li>k 表示 sampling index   </li>
<li>$A_{mlqk}$ 表示 $k^{th}$ sampling point在 $m^{th}$ head和 $l^{th}$ level的权重, $\sum_{l=1}^{L}\sum_{k=1}^{K}A_{mlqk}=1$.  </li>
<li>$\Delta p_{mlqk}$ 表示sampling offset  </li>
</ul>
<p>为了确保multi-scale中 point的对应关系，作者用 normalized coordinates $\hat p_q\in [0,1]^2$ 来表示参考点。 $(0,0), (1,1)$ 表示top-left和bottom-right. $\phi_l(\hat p_q)$ 表示将归一化之后的 $\hat p_q$ rescale 到 $l^{th}$ level feature中。</p>
<h3 id="Deformable-Transformer-Encoder"><a href="#Deformable-Transformer-Encoder" class="headerlink" title="Deformable Transformer Encoder"></a>Deformable Transformer Encoder</h3><p>从 resnet $C_3$ 到 $C_5$ 抽取multi-scale特征图. 其中 $C_l$ 表示分辨率是输入图像的 $\dfrac{1}{2^l}$. 这样就有3层feature map了，然后最后一层feature map是通过 kernel=$3\times 3$, stride=$3$ 的卷积在 $C_5$ 上得到的。 总共4 levels feature map.</p>
<p>key和query来自feature map中的pixels. 对于每一个query pixel, 其reference point是其本身。除了位置编码之外，作者还加入了level编码 $e_l$，用来表示在哪一层level. 位置编码是固定的，level编码是可训练的。</p>
</div></article></div></div><div class="column column-left is-4-tablet is-4-desktop is-4-widescreen  order-1"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar" src="/img/avatar.png" alt="潘小榭"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">潘小榭</p><p class="is-size-6 is-block">Blogging is happier than writing essays!</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Beijing</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">Posts</p><a href="/archives"><p class="title">111</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Categories</p><a href="/categories"><p class="title">33</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Tags</p><a href="/tags"><p class="title">32</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/ppoffice" target="_blank" rel="noopener">Follow</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/ppoffice"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Facebook" href="https://facebook.com"><i class="fab fa-facebook"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Twitter" href="https://twitter.com"><i class="fab fa-twitter"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Dribbble" href="https://dribbble.com"><i class="fab fa-dribbble"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="RSS" href="/"><i class="fas fa-rss"></i></a></div></div></div><!--!--><div class="card widget" data-type="links"><div class="card-content"><div class="menu"><h3 class="menu-label">Links</h3><ul class="menu-list"><li><a class="level is-mobile" href="https://github.com/PanXiebit" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">github</span></span><span class="level-right"><span class="level-item tag">github.com</span></span></a></li><li><a class="level is-mobile" href="ftdpanxie@gmail.com" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">email</span></span><span class="level-right"><span class="level-item tag">ftdpanxie@gmail.com</span></span></a></li></ul></div></div></div><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">Categories</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/C/"><span class="level-start"><span class="level-item">C++</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/CSAPP/"><span class="level-start"><span class="level-item">CSAPP</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/DRL/"><span class="level-start"><span class="level-item">DRL</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/GAN/"><span class="level-start"><span class="level-item">GAN</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li><li><a class="level is-mobile" href="/categories/GAN-RL/"><span class="level-start"><span class="level-item">GAN, RL</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/ML/"><span class="level-start"><span class="level-item">ML</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/NLP/"><span class="level-start"><span class="level-item">NLP</span></span><span class="level-end"><span class="level-item tag">14</span></span></a></li><li><a class="level is-mobile" href="/categories/TensorFlow/"><span class="level-start"><span class="level-item">TensorFlow</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/cs224d/"><span class="level-start"><span class="level-item">cs224d</span></span><span class="level-end"><span class="level-item tag">10</span></span></a></li><li><a class="level is-mobile" href="/categories/interview/"><span class="level-start"><span class="level-item">interview</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/machine-translation/"><span class="level-start"><span class="level-item">machine translation</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/python/"><span class="level-start"><span class="level-item">python</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/pytorch/"><span class="level-start"><span class="level-item">pytorch</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/reinforcement-learning/"><span class="level-start"><span class="level-item">reinforcement learning</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/sign-language-recognition/"><span class="level-start"><span class="level-item">sign language recognition</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/transfer-learning/"><span class="level-start"><span class="level-item">transfer learning</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"><span class="level-start"><span class="level-item">数据结构与算法</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile" href="/categories/%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB/"><span class="level-start"><span class="level-item">文本分类</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"><span class="level-start"><span class="level-item">论文笔记</span></span><span class="level-end"><span class="level-item tag">34</span></span></a><ul><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/DL/"><span class="level-start"><span class="level-item">DL</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/ESA/"><span class="level-start"><span class="level-item">ESA</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/GAN/"><span class="level-start"><span class="level-item">GAN</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/MRC-and-QA/"><span class="level-start"><span class="level-item">MRC and QA</span></span><span class="level-end"><span class="level-item tag">7</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/Machine-Translation/"><span class="level-start"><span class="level-item">Machine Translation</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/NLP/"><span class="level-start"><span class="level-item">NLP</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/capsules/"><span class="level-start"><span class="level-item">capsules</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/data-augmentation/"><span class="level-start"><span class="level-item">data augmentation</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/dialogue-system/"><span class="level-start"><span class="level-item">dialogue system</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/language-model/"><span class="level-start"><span class="level-item">language model</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/machine-translation/"><span class="level-start"><span class="level-item">machine translation</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/open-set-recognition/"><span class="level-start"><span class="level-item">open set recognition</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/sentence-embedding/"><span class="level-start"><span class="level-item">sentence embedding</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/text-matching/"><span class="level-start"><span class="level-item">text matching</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li></ul></div></div></div><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">Recents</h3><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-05-05T02:03:16.000Z">2021-05-05</time></p><p class="title"><a href="/2021/05/05/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-contrastive-learning/">论文笔记-image-based contrastive learning</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-04-29T01:07:08.000Z">2021-04-29</time></p><p class="title"><a href="/2021/04/29/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-video-transformer/">论文笔记-video transformer</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-04-29T01:05:10.000Z">2021-04-29</time></p><p class="title"><a href="/2021/04/29/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-dynamic-convolution-and-involution/">论文笔记-dynamic convolution and involution</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-04-16T07:48:48.000Z">2021-04-16</time></p><p class="title"><a href="/2021/04/16/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-unlikelihood-training/">论文笔记-unlikelihood training</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-04-12T08:16:35.000Z">2021-04-12</time></p><p class="title"><a href="/2021/04/12/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-Deformable-DETR/">论文笔记-DETR and Deformable DETR</a></p></div></article></div></div><div class="card widget" data-type="archives"><div class="card-content"><div class="menu"><h3 class="menu-label">Archives</h3><ul class="menu-list"><li><a class="level is-mobile" href="/archives/2021/05/"><span class="level-start"><span class="level-item">May 2021</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2021/04/"><span class="level-start"><span class="level-item">April 2021</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/archives/2020/09/"><span class="level-start"><span class="level-item">September 2020</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2019/11/"><span class="level-start"><span class="level-item">November 2019</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2019/10/"><span class="level-start"><span class="level-item">October 2019</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2019/08/"><span class="level-start"><span class="level-item">August 2019</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2019/06/"><span class="level-start"><span class="level-item">June 2019</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/archives/2019/05/"><span class="level-start"><span class="level-item">May 2019</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2019/04/"><span class="level-start"><span class="level-item">April 2019</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2019/03/"><span class="level-start"><span class="level-item">March 2019</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile" href="/archives/2019/02/"><span class="level-start"><span class="level-item">February 2019</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/archives/2019/01/"><span class="level-start"><span class="level-item">January 2019</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li><li><a class="level is-mobile" href="/archives/2018/12/"><span class="level-start"><span class="level-item">December 2018</span></span><span class="level-end"><span class="level-item tag">16</span></span></a></li><li><a class="level is-mobile" href="/archives/2018/11/"><span class="level-start"><span class="level-item">November 2018</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2018/10/"><span class="level-start"><span class="level-item">October 2018</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2018/09/"><span class="level-start"><span class="level-item">September 2018</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/archives/2018/08/"><span class="level-start"><span class="level-item">August 2018</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile" href="/archives/2018/07/"><span class="level-start"><span class="level-item">July 2018</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/archives/2018/06/"><span class="level-start"><span class="level-item">June 2018</span></span><span class="level-end"><span class="level-item tag">10</span></span></a></li><li><a class="level is-mobile" href="/archives/2018/05/"><span class="level-start"><span class="level-item">May 2018</span></span><span class="level-end"><span class="level-item tag">11</span></span></a></li><li><a class="level is-mobile" href="/archives/2018/04/"><span class="level-start"><span class="level-item">April 2018</span></span><span class="level-end"><span class="level-item tag">16</span></span></a></li><li><a class="level is-mobile" href="/archives/2018/03/"><span class="level-start"><span class="level-item">March 2018</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li></ul></div></div></div><div class="card widget" data-type="tags"><div class="card-content"><div class="menu"><h3 class="menu-label">Tags</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/C/"><span class="tag">C++</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/CSAPP/"><span class="tag">CSAPP</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/DL/"><span class="tag">DL</span><span class="tag">8</span></a></div><div class="control"><a class="tags has-addons" href="/tags/ESA/"><span class="tag">ESA</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/GAN/"><span class="tag">GAN</span><span class="tag">9</span></a></div><div class="control"><a class="tags has-addons" href="/tags/GAN%EF%BC%8CRL/"><span class="tag">GAN，RL</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/ML/"><span class="tag">ML</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/MRC-and-QA/"><span class="tag">MRC and QA</span><span class="tag">7</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Machine-Translation/"><span class="tag">Machine Translation</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/NLP/"><span class="tag">NLP</span><span class="tag">14</span></a></div><div class="control"><a class="tags has-addons" href="/tags/TensorFlow/"><span class="tag">TensorFlow</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Tensorflow/"><span class="tag">Tensorflow</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/ai-challenger/"><span class="tag">ai challenger</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/capsules/"><span class="tag">capsules</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/contrastive-learning/"><span class="tag">contrastive learning</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/cs224d/"><span class="tag">cs224d</span><span class="tag">10</span></a></div><div class="control"><a class="tags has-addons" href="/tags/data-augmentation/"><span class="tag">data augmentation</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/interview/"><span class="tag">interview</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/language-model/"><span class="tag">language model</span><span class="tag">6</span></a></div><div class="control"><a class="tags has-addons" href="/tags/machine-translation/"><span class="tag">machine translation</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/open-set-recognition/"><span class="tag">open set recognition</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/python/"><span class="tag">python</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/pytorch/"><span class="tag">pytorch</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/reinforcement-learning/"><span class="tag">reinforcement learning</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/sentence-embedding/"><span class="tag">sentence embedding</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/sentiment-classification/"><span class="tag">sentiment classification</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/sign-language-recognition/"><span class="tag">sign language recognition</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/text-matching/"><span class="tag">text matching</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/transfer-learning/"><span class="tag">transfer learning</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/vision-transformer/"><span class="tag">vision transformer</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"><span class="tag">数据结构与算法</span><span class="tag">6</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB/"><span class="tag">文本分类</span><span class="tag">8</span></a></div></div></div></div></div><div class="card widget" data-type="subscribe-email"><div class="card-content"><div class="menu"><h3 class="menu-label">Subscribe for updates</h3><form action="https://feedburner.google.com/fb/a/mailverify" method="post" target="popupwindow" onsubmit="window.open(&#039;https://feedburner.google.com/fb/a/mailverify?uri=&#039;,&#039;popupwindow&#039;,&#039;scrollbars=yes,width=550,height=520&#039;);return true"><input type="hidden" value="" name="uri"><input type="hidden" name="loc" value="en_US"><div class="field has-addons"><div class="control has-icons-left is-expanded"><input class="input" name="email" type="email" placeholder="Email"><span class="icon is-small is-left"><i class="fas fa-envelope"></i></span></div><div class="control"><input class="button" type="submit" value="Subscribe"></div></div></form></div></div></div></div><!--!--></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/logo.svg" alt="潘小榭" height="28"></a><p class="is-size-7"><span>&copy; 2021 Xie Pan</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("default");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "This website uses cookies to improve your experience.",
          dismiss: "Got it!",
          allow: "Allow cookies",
          deny: "Decline",
          link: "Learn more",
          policy: "Cookie Policy",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.5/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script></body></html>