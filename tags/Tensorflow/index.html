<!doctype html>
<html lang="de"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>Tag: TensorFlow - 潘小榭</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="潘小榭"><meta name="msapplication-TileImage" content="/img/favicon.svg"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="潘小榭"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta property="og:type" content="blog"><meta property="og:title" content="潘小榭"><meta property="og:url" content="http://www.panxiaoxie.cn/"><meta property="og:site_name" content="潘小榭"><meta property="og:image" content="http://www.panxiaoxie.cn/img/og_image.png"><meta property="article:author" content="Xie Pan"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="/img/og_image.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"http://www.panxiaoxie.cn"},"headline":"潘小榭","image":["http://www.panxiaoxie.cn/img/og_image.png"],"author":{"@type":"Person","name":"Xie Pan"},"publisher":{"@type":"Organization","name":"潘小榭","logo":{"@type":"ImageObject","url":"http://www.panxiaoxie.cn/img/logo.svg"}},"description":null}</script><link rel="icon" href="/img/favicon.svg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/css/justifiedGallery.min.css"><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script><!--!--><!--!--><meta name="generator" content="Hexo 5.4.0"></head><body class="is-2-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/logo.svg" alt="潘小榭" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a><a class="navbar-item search" title="Suche" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-8-widescreen"><div class="card"><div class="card-content"><nav class="breadcrumb" aria-label="breadcrumbs"><ul><li><a href="/tags">Tags</a></li><li class="is-active"><a href="#" aria-current="page">TensorFlow</a></li></ul></nav></div></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Gepostet vor&nbsp;<time dateTime="2018-09-01T09:49:53.000Z" title="2018/9/1 下午5:49:53">2018-09-01</time></span><span class="level-item">Aktualisiert vor&nbsp;<time dateTime="2021-06-29T08:12:09.141Z" title="2021/6/29 下午4:12:09">2021-06-29</time></span><span class="level-item"><a class="link-muted" href="/categories/TensorFlow/">TensorFlow</a></span><span class="level-item">44 minutes lesen (Über 6574 Wörter)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2018/09/01/tensorflow-rnn-api-%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB/">Tensorflow RNN API 源码阅读</a></h1><div class="content"><p>在三星研究院实习一段时间发现在公司写代码和在学校还是有差别的。一是在公司要追求效率，会使用很多官方封装好的api，而在学校的时候因为要去理解内部原理，更多的是在造轮子，导致对很多 api 不是很熟悉。但实际上官方api不仅在速度，以及全面性上都比自己写的还是好很多的。二是，在公司对代码的复用率要求比较高，模型跑到哪一个版本了，对应的参数都要留下来，随时可以跑起来，而不是重新训练，这对模型、参数的保存要求很重要。以及在测试集上的性能指标都要在代码上很完整，而不是仅仅看看 loss 和 accuracy 就可以的。</p>
<p>这节内容主要是详细过一遍 tensorflow 里面的 rnn api，根据<a target="_blank" rel="noopener" href="https://tensorflow.google.cn/api_guides/python/contrib.rnn#Core_RNN_Cells_for_use_with_TensorFlow_s_core_RNN_methods">RNN and Cells (contrib)</a>这里的顺序逐步深入研究</p>
<h2 id="先回顾一下-RNN-LSTM-GRU"><a href="#先回顾一下-RNN-LSTM-GRU" class="headerlink" title="先回顾一下 RNN/LSTM/GRU:"></a>先回顾一下 RNN/LSTM/GRU:</h2><p>参考之前 cs224d 的笔记  </p>
<ul>
<li><p><a target="_blank" rel="noopener" href="https://panxiaoxie.cn/2018/05/07/cs224d-lecture9-machine-translation/">cs224d-lecture9 机器翻译</a>   </p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://panxiaoxie.cn/2018/05/04/cs224d-lecture8-RNN/">cs224d-lecture8-RNN</a> 发现有些小错误，但不影响自己复习。。</p>
</li>
</ul>
<p>basic rnn：  </p>
<p><img src="https://panxiaoxie.cn/2018/05/04/cs224d-lecture8-RNN/rnn16.png"></p>
<p>$$h_t = \sigma(W_{hh}h_{t-1}+W_{hx}x_{|t|})$$</p>
<h2 id="先看-tf-contrib-rnn-RNNCell"><a href="#先看-tf-contrib-rnn-RNNCell" class="headerlink" title="先看 tf.contrib.rnn.RNNCell"></a>先看 tf.contrib.rnn.RNNCell</h2><p><a target="_blank" rel="noopener" href="https://github.com/tensorflow/tensorflow/blob/4dcfddc5d12018a5a0fdca652b9221ed95e9eb23/tensorflow/python/ops/rnn_cell_impl.py#L170">https://github.com/tensorflow/tensorflow/blob/4dcfddc5d12018a5a0fdca652b9221ed95e9eb23/tensorflow/python/ops/rnn_cell_impl.py#L170</a>)</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="meta">@tf_export(<span class="params"><span class="string">&quot;nn.rnn_cell.RNNCell&quot;</span></span>)</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">RNNCell</span>(<span class="params">base_layer.Layer</span>):</span></span><br><span class="line"></span><br><span class="line">  <span class="string">&quot;&quot;&quot;Abstract object representing an RNN cell.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  Every `RNNCell` must have the properties below and implement `call` with</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  the signature `(output, next_state) = call(input, state)`.  </span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  RNNCell 是一个抽象的父类，之后更复杂的 RNN/LSTM/GRU 都是重新实现 call 函数，也就是更新隐藏状态</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  的方式改变了。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  The optional third input argument, `scope`, is allowed for backwards compatibility</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  purposes; but should be left off for new subclasses.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  scope 这个参数管理变量，在反向传播中变量是否可训练。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  This definition of cell differs from the definition used in the literature.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  In the literature, &#x27;cell&#x27; refers to an object with a single scalar output.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  This definition refers to a horizontal array of such units.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  这里的 cell 的概念和一些论文中是不一样的。在论文中，cell 表示一个神经元，也就是单个值。而这里表示的是</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  一组神经元，比如隐藏状态[batch, num_units].</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  An RNN cell, in the most abstract setting, is anything that has</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  a state and performs some operation that takes a matrix of inputs.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  This operation results in an output matrix with `self.output_size` columns.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  If `self.state_size` is an integer, this operation also results in a new</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  state matrix with `self.state_size` columns.  If `self.state_size` is a</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  (possibly nested tuple of) TensorShape object(s), then it should return a</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  matching structure of Tensors having shape `[batch_size].concatenate(s)`</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  for each `s` in `self.batch_size`.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  rnn cell 的输入是一个状态 state 和 input 矩阵，参数有 self.output_size 和 self.state_size.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  分别表示输出层和隐藏层的维度。其中 state_size 可能是 tuple，这个之后在看。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__call__</span>(<span class="params">self, inputs, state, scope=<span class="literal">None</span></span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Run this RNN cell on inputs, starting from the given state.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">      inputs: `2-D` tensor with shape `[batch_size, input_size]`.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">      state: if `self.state_size` is an integer, this should be a `2-D Tensor`</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        with shape `[batch_size, self.state_size]`.  Otherwise, if</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        `self.state_size` is a tuple of integers, this should be a tuple</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        with shapes `[batch_size, s] for s in self.state_size`.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">      scope: VariableScope for the created subgraph; defaults to class name.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">      A pair containing:</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">      - Output: A `2-D` tensor with shape `[batch_size, self.output_size]`.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">      - New state: Either a single `2-D` tensor, or a tuple of tensors matching</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        the arity and shapes of `state`.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> scope <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line"></span><br><span class="line">      <span class="keyword">with</span> vs.variable_scope(scope,</span><br><span class="line"></span><br><span class="line">                             custom_getter=self._rnn_get_variable) <span class="keyword">as</span> scope:</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">super</span>(RNNCell, self).__call__(inputs, state, scope=scope)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line"></span><br><span class="line">      scope_attrname = <span class="string">&quot;rnncell_scope&quot;</span></span><br><span class="line"></span><br><span class="line">      scope = <span class="built_in">getattr</span>(self, scope_attrname, <span class="literal">None</span>)</span><br><span class="line"></span><br><span class="line">      <span class="keyword">if</span> scope <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line"></span><br><span class="line">        scope = vs.variable_scope(vs.get_variable_scope(),</span><br><span class="line"></span><br><span class="line">                                  custom_getter=self._rnn_get_variable)</span><br><span class="line"></span><br><span class="line">        <span class="built_in">setattr</span>(self, scope_attrname, scope)</span><br><span class="line"></span><br><span class="line">      <span class="keyword">with</span> scope:</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">super</span>(RNNCell, self).__call__(inputs, state)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">_rnn_get_variable</span>(<span class="params">self, getter, *args, **kwargs</span>):</span></span><br><span class="line"></span><br><span class="line">    variable = getter(*args, **kwargs)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> context.executing_eagerly():</span><br><span class="line"></span><br><span class="line">      trainable = variable._trainable  <span class="comment"># pylint: disable=protected-access</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line"></span><br><span class="line">      trainable = (</span><br><span class="line"></span><br><span class="line">          variable <span class="keyword">in</span> tf_variables.trainable_variables() <span class="keyword">or</span></span><br><span class="line"></span><br><span class="line">          (<span class="built_in">isinstance</span>(variable, tf_variables.PartitionedVariable) <span class="keyword">and</span></span><br><span class="line"></span><br><span class="line">           <span class="built_in">list</span>(variable)[<span class="number">0</span>] <span class="keyword">in</span> tf_variables.trainable_variables()))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> trainable <span class="keyword">and</span> variable <span class="keyword">not</span> <span class="keyword">in</span> self._trainable_weights:</span><br><span class="line"></span><br><span class="line">      self._trainable_weights.append(variable)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">elif</span> <span class="keyword">not</span> trainable <span class="keyword">and</span> variable <span class="keyword">not</span> <span class="keyword">in</span> self._non_trainable_weights:</span><br><span class="line"></span><br><span class="line">      self._non_trainable_weights.append(variable)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> variable</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">  @property</span></span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">state_size</span>(<span class="params">self</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="string">&quot;&quot;&quot;size(s) of state(s) used by this cell.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    It can be represented by an Integer, a TensorShape or a tuple of Integers</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    or TensorShapes.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">raise</span> NotImplementedError(<span class="string">&quot;Abstract method&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">  @property</span></span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">output_size</span>(<span class="params">self</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Integer or TensorShape: size of outputs produced by this cell.&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">raise</span> NotImplementedError(<span class="string">&quot;Abstract method&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">build</span>(<span class="params">self, _</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># This tells the parent Layer object that it&#x27;s OK to call</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># self.add_variable() inside the call() method.</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">zero_state</span>(<span class="params">self, batch_size, dtype</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Return zero-filled state tensor(s).</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">      batch_size: int, float, or unit Tensor representing the batch size.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">      dtype: the data type to use for the state.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">      If `state_size` is an int or TensorShape, then the return value is a</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">      `N-D` tensor of shape `[batch_size, state_size]` filled with zeros.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">      If `state_size` is a nested list or tuple, then the return value is</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">      a nested list or tuple (of the same structure) of `2-D` tensors with</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">      the shapes `[batch_size, s]` for each s in `state_size`.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Try to use the last cached zero_state. This is done to avoid recreating</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># zeros, especially when eager execution is enabled.</span></span><br><span class="line"></span><br><span class="line">    state_size = self.state_size</span><br><span class="line"></span><br><span class="line">    is_eager = context.executing_eagerly()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> is_eager <span class="keyword">and</span> <span class="built_in">hasattr</span>(self, <span class="string">&quot;_last_zero_state&quot;</span>):</span><br><span class="line"></span><br><span class="line">      (last_state_size, last_batch_size, last_dtype,</span><br><span class="line"></span><br><span class="line">       last_output) = <span class="built_in">getattr</span>(self, <span class="string">&quot;_last_zero_state&quot;</span>)</span><br><span class="line"></span><br><span class="line">      <span class="keyword">if</span> (last_batch_size == batch_size <span class="keyword">and</span></span><br><span class="line"></span><br><span class="line">          last_dtype == dtype <span class="keyword">and</span></span><br><span class="line"></span><br><span class="line">          last_state_size == state_size):</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> last_output</span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> ops.name_scope(<span class="built_in">type</span>(self).__name__ + <span class="string">&quot;ZeroState&quot;</span>, values=[batch_size]):</span><br><span class="line"></span><br><span class="line">      output = _zero_state_tensors(state_size, batch_size, dtype)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> is_eager:</span><br><span class="line"></span><br><span class="line">      self._last_zero_state = (state_size, batch_size, dtype, output)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> output</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>







<p>两个属性 output_size, state_size 分别表示输出层的维度和隐藏层的维度。call 函数用来表示计算下一个时间步的隐藏状态和输出，zero_state 函数用来初始化初始状态全为 0, 这里 state_size 有两种情况，一种是 int 或 tensorshape,那么 [batch, state_size]. 如果是多层嵌套 rnn, 那么初始状态 <code>[batch, s] for s in state_size</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">LayerRNNCell</span>(<span class="params">RNNCell</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Subclass of RNNCells that act like proper `tf.Layer` objects.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    def __call__(self, inputs, state, scope=None, *args, **kwargs):</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span>Run this RNN cell on inputs, starting <span class="keyword">from</span> the given state.</span><br><span class="line"></span><br><span class="line">    Args:</span><br><span class="line"></span><br><span class="line">      inputs: `<span class="number">2</span>-D` tensor <span class="keyword">with</span> shape `[batch_size, input_size]`.</span><br><span class="line"></span><br><span class="line">      state: <span class="keyword">if</span> `self.state_size` <span class="keyword">is</span> an integer, this should be a `<span class="number">2</span>-D Tensor`</span><br><span class="line"></span><br><span class="line">        <span class="keyword">with</span> shape `[batch_size, self.state_size]`.  Otherwise, <span class="keyword">if</span></span><br><span class="line"></span><br><span class="line">        `self.state_size` <span class="keyword">is</span> a <span class="built_in">tuple</span> of integers, this should be a <span class="built_in">tuple</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">with</span> shapes `[batch_size, s] <span class="keyword">for</span> s <span class="keyword">in</span> self.state_size`.</span><br><span class="line"></span><br><span class="line">      scope: optional cell scope.</span><br><span class="line"></span><br><span class="line">      *args: Additional positional arguments.</span><br><span class="line"></span><br><span class="line">      **kwargs: Additional keyword arguments.</span><br><span class="line"></span><br><span class="line">    Returns:</span><br><span class="line"></span><br><span class="line">      A pair containing:</span><br><span class="line"></span><br><span class="line">      - Output: A `<span class="number">2</span>-D` tensor <span class="keyword">with</span> shape `[batch_size, self.output_size]`.</span><br><span class="line"></span><br><span class="line">      - New state: Either a single `<span class="number">2</span>-D` tensor, <span class="keyword">or</span> a <span class="built_in">tuple</span> of tensors matching</span><br><span class="line"></span><br><span class="line">        the arity <span class="keyword">and</span> shapes of `state`.</span><br><span class="line"></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    # Bypass RNNCell&#x27;s variable capturing semantics for LayerRNNCell.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    # Instead, it is up to subclasses to provide a proper build</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    # method.  See the class docstring for more details.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    return base_layer.Layer.__call__(self, inputs, state, scope=scope,</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">                                     *args, **kwargs)</span></span><br><span class="line"><span class="string"></span></span><br></pre></td></tr></table></figure>



<h2 id="再看-Core-RNN-Cells"><a href="#再看-Core-RNN-Cells" class="headerlink" title="再看 Core RNN Cells"></a>再看 Core RNN Cells</h2><ul>
<li><p>tf.contrib.rnn.BasicRNNCell</p>
</li>
<li><p>tf.contrib.rnn.BasicLSTMCell</p>
</li>
<li><p>tf.contrib.rnn.GRUCell</p>
</li>
<li><p>tf.contrib.rnn.LSTMCell</p>
</li>
<li><p>tf.contrib.rnn.LayerNormBasicLSTMCell</p>
</li>
</ul>
<h3 id="tf-contrib-rnn-BasicRNNCell"><a href="#tf-contrib-rnn-BasicRNNCell" class="headerlink" title="tf.contrib.rnn.BasicRNNCell"></a>tf.contrib.rnn.BasicRNNCell</h3><p>直接扒源码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="meta">@tf_export(<span class="params"><span class="string">&quot;nn.rnn_cell.BasicRNNCell&quot;</span></span>)</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">BasicRNNCell</span>(<span class="params">LayerRNNCell</span>):</span></span><br><span class="line"></span><br><span class="line">  <span class="string">&quot;&quot;&quot;The most basic RNN cell.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  Args:</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    num_units: int, The number of units in the RNN cell.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    activation: Nonlinearity to use.  Default: `tanh`.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    reuse: (optional) Python boolean describing whether to reuse variables</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">     in an existing scope.  If not `True`, and the existing scope already has</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">     the given variables, an error is raised.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    name: String, the name of the layer. Layers with the same name will</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">      share weights, but to avoid mistakes we require reuse=True in such</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">      cases.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    dtype: Default dtype of the layer (default of `None` means use the type</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">      of the first input). Required when `build` is called before `call`.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self,</span></span></span><br><span class="line"><span class="params"><span class="function"></span></span></span><br><span class="line"><span class="params"><span class="function">               num_units,</span></span></span><br><span class="line"><span class="params"><span class="function"></span></span></span><br><span class="line"><span class="params"><span class="function">               activation=<span class="literal">None</span>,</span></span></span><br><span class="line"><span class="params"><span class="function"></span></span></span><br><span class="line"><span class="params"><span class="function">               reuse=<span class="literal">None</span>,</span></span></span><br><span class="line"><span class="params"><span class="function"></span></span></span><br><span class="line"><span class="params"><span class="function">               name=<span class="literal">None</span>,</span></span></span><br><span class="line"><span class="params"><span class="function"></span></span></span><br><span class="line"><span class="params"><span class="function">               dtype=<span class="literal">None</span></span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="built_in">super</span>(BasicRNNCell, self).__init__(_reuse=reuse, name=name, dtype=dtype)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Inputs must be 2-dimensional.</span></span><br><span class="line"></span><br><span class="line">    self.input_spec = base_layer.InputSpec(ndim=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    self._num_units = num_units</span><br><span class="line"></span><br><span class="line">    self._activation = activation <span class="keyword">or</span> math_ops.tanh</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">  @property</span></span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">state_size</span>(<span class="params">self</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> self._num_units</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">  @property</span></span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">output_size</span>(<span class="params">self</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> self._num_units</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">build</span>(<span class="params">self, inputs_shape</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> inputs_shape[<span class="number">1</span>].value <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line"></span><br><span class="line">      <span class="keyword">raise</span> ValueError(<span class="string">&quot;Expected inputs.shape[-1] to be known, saw shape: %s&quot;</span></span><br><span class="line"></span><br><span class="line">                       % inputs_shape)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    input_depth = inputs_shape[<span class="number">1</span>].value</span><br><span class="line"></span><br><span class="line">    self._kernel = self.add_variable(</span><br><span class="line"></span><br><span class="line">        _WEIGHTS_VARIABLE_NAME,</span><br><span class="line"></span><br><span class="line">        shape=[input_depth + self._num_units, self._num_units])</span><br><span class="line"></span><br><span class="line">    self._bias = self.add_variable(</span><br><span class="line"></span><br><span class="line">        _BIAS_VARIABLE_NAME,</span><br><span class="line"></span><br><span class="line">        shape=[self._num_units],</span><br><span class="line"></span><br><span class="line">        initializer=init_ops.zeros_initializer(dtype=self.dtype))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    self.built = <span class="literal">True</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">call</span>(<span class="params">self, inputs, state</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Most basic RNN: output = new_state = act(W * input + U * state + B).&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    gate_inputs = math_ops.matmul(</span><br><span class="line"></span><br><span class="line">        array_ops.concat([inputs, state], <span class="number">1</span>), self._kernel)</span><br><span class="line"></span><br><span class="line">    gate_inputs = nn_ops.bias_add(gate_inputs, self._bias)</span><br><span class="line"></span><br><span class="line">    output = self._activation(gate_inputs)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> output, output</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>



<p>可以发现 state_size = output_size = num_units, 以及输出就是下一个隐藏状态 output = new_state = act(W * input + U * state + B) = act(W[input, state] + b) 其中 self._kernel 表示 W, 其维度是 [input_depth + num_units, num_units]</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> tensorflow.contrib.eager <span class="keyword">as</span> tfe</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">tf.enable_eager_execution()</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(tfe.executing_eagerly())</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<pre><code>True
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">cell = tf.contrib.rnn.BasicRNNCell(num_units=<span class="number">128</span>, activation=<span class="literal">None</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(cell.state_size, cell.output_size)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<pre><code>128 128
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">inputs = tf.random_normal(shape=[<span class="number">32</span>, <span class="number">100</span>], dtype=tf.float32)</span><br><span class="line"></span><br><span class="line">h0 = cell.zero_state(batch_size=<span class="number">32</span>, dtype=tf.float32)</span><br><span class="line"></span><br><span class="line">output, state = cell(inputs=inputs, state=h0)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(output.shape, state.shape)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<pre><code>(32, 128) (32, 128)
</code></pre>
<h3 id="tf-contrib-rnn-BasicLSTMCell"><a href="#tf-contrib-rnn-BasicLSTMCell" class="headerlink" title="tf.contrib.rnn.BasicLSTMCell"></a>tf.contrib.rnn.BasicLSTMCell</h3><p>先回顾下 LSTM:</p>
<p><img src="https://panxiaoxie.cn/2018/05/07/cs224d-lecture9-machine-translation/lstm.png"></p>
<p>自己试着手敲公式～ 看着图还是简单，不看图是否也可以呢？</p>
<p>三个gate：遗忘门，输入/更新门，输出门</p>
<p>$$f_t=\sigma(W^{f}x_t + U^{f}h_{t-1})$$</p>
<p>$$i_t=\sigma(W^{i}x_t + U^{i}h_{t-1})$$</p>
<p>$$o_t=\sigma(W^{o}x_t + U^{o}h_{t-1})$$</p>
<p>new memory cell:</p>
<p>$$\hat c=tanh(W^cx_t + U^ch_{t-1})$$</p>
<p>输入门作用于新的记忆细胞,遗忘门作用于上一个记忆细胞，并得到最终的记忆细胞:</p>
<p>$$c_t=f_t\circ c_{t-1} + i_t\circ\hat c$$</p>
<p>用新的memory cell 和输出门得到新的隐藏状态：</p>
<p>$$h_t = tanh(o_t\circ c_t)$$</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">BasicLSTMCell</span>(<span class="params">LayerRNNCell</span>):</span></span><br><span class="line"></span><br><span class="line">  <span class="string">&quot;&quot;&quot;Basic LSTM recurrent network cell.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  The implementation is based on: http://arxiv.org/abs/1409.2329.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  We add forget_bias (default: 1) to the biases of the forget gate in order to</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  reduce the scale of forgetting in the beginning of the training.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  It does not allow cell clipping, a projection layer, and does not</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  use peep-hole connections: it is the basic baseline.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  For advanced models, please use the full @&#123;tf.nn.rnn_cell.LSTMCell&#125;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  that follows.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self,</span></span></span><br><span class="line"><span class="params"><span class="function"></span></span></span><br><span class="line"><span class="params"><span class="function">               num_units,</span></span></span><br><span class="line"><span class="params"><span class="function"></span></span></span><br><span class="line"><span class="params"><span class="function">               forget_bias=<span class="number">1.0</span>,</span></span></span><br><span class="line"><span class="params"><span class="function"></span></span></span><br><span class="line"><span class="params"><span class="function">               state_is_tuple=<span class="literal">True</span>,</span></span></span><br><span class="line"><span class="params"><span class="function"></span></span></span><br><span class="line"><span class="params"><span class="function">               activation=<span class="literal">None</span>,</span></span></span><br><span class="line"><span class="params"><span class="function"></span></span></span><br><span class="line"><span class="params"><span class="function">               reuse=<span class="literal">None</span>,</span></span></span><br><span class="line"><span class="params"><span class="function"></span></span></span><br><span class="line"><span class="params"><span class="function">               name=<span class="literal">None</span>,</span></span></span><br><span class="line"><span class="params"><span class="function"></span></span></span><br><span class="line"><span class="params"><span class="function">               dtype=<span class="literal">None</span></span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Initialize the basic LSTM cell.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">      num_units: int, The number of units in the LSTM cell.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">      forget_bias: float, The bias added to forget gates (see above).</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Must set to `0.0` manually when restoring from CudnnLSTM-trained</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        checkpoints.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">      state_is_tuple: If True, accepted and returned states are 2-tuples of</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        the `c_state` and `m_state`.  If False, they are concatenated</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        along the column axis.  The latter behavior will soon be deprecated.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">      activation: Activation function of the inner states.  Default: `tanh`.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">      reuse: (optional) Python boolean describing whether to reuse variables</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        in an existing scope.  If not `True`, and the existing scope already has</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        the given variables, an error is raised.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">      name: String, the name of the layer. Layers with the same name will</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        share weights, but to avoid mistakes we require reuse=True in such</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        cases.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">      dtype: Default dtype of the layer (default of `None` means use the type</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        of the first input). Required when `build` is called before `call`.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">      When restoring from CudnnLSTM-trained checkpoints, must use</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">      `CudnnCompatibleLSTMCell` instead.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="built_in">super</span>(BasicLSTMCell, self).__init__(_reuse=reuse, name=name, dtype=dtype)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> state_is_tuple:</span><br><span class="line"></span><br><span class="line">      logging.warn(<span class="string">&quot;%s: Using a concatenated state is slower and will soon be &quot;</span></span><br><span class="line"></span><br><span class="line">                   <span class="string">&quot;deprecated.  Use state_is_tuple=True.&quot;</span>, self)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Inputs must be 2-dimensional.</span></span><br><span class="line"></span><br><span class="line">    self.input_spec = base_layer.InputSpec(ndim=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    self._num_units = num_units</span><br><span class="line"></span><br><span class="line">    self._forget_bias = forget_bias</span><br><span class="line"></span><br><span class="line">    self._state_is_tuple = state_is_tuple</span><br><span class="line"></span><br><span class="line">    self._activation = activation <span class="keyword">or</span> math_ops.tanh</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">  @property</span></span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">state_size</span>(<span class="params">self</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> (LSTMStateTuple(self._num_units, self._num_units)</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> self._state_is_tuple <span class="keyword">else</span> <span class="number">2</span> * self._num_units)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">  @property</span></span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">output_size</span>(<span class="params">self</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> self._num_units</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">build</span>(<span class="params">self, inputs_shape</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> inputs_shape[<span class="number">1</span>].value <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line"></span><br><span class="line">      <span class="keyword">raise</span> ValueError(<span class="string">&quot;Expected inputs.shape[-1] to be known, saw shape: %s&quot;</span></span><br><span class="line"></span><br><span class="line">                       % inputs_shape)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    input_depth = inputs_shape[<span class="number">1</span>].value</span><br><span class="line"></span><br><span class="line">    h_depth = self._num_units</span><br><span class="line"></span><br><span class="line">    self._kernel = self.add_variable(</span><br><span class="line"></span><br><span class="line">        _WEIGHTS_VARIABLE_NAME,</span><br><span class="line"></span><br><span class="line">        shape=[input_depth + h_depth, <span class="number">4</span> * self._num_units])</span><br><span class="line"></span><br><span class="line">    self._bias = self.add_variable(</span><br><span class="line"></span><br><span class="line">        _BIAS_VARIABLE_NAME,</span><br><span class="line"></span><br><span class="line">        shape=[<span class="number">4</span> * self._num_units],</span><br><span class="line"></span><br><span class="line">        initializer=init_ops.zeros_initializer(dtype=self.dtype))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    self.built = <span class="literal">True</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">call</span>(<span class="params">self, inputs, state</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Long short-term memory cell (LSTM).</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">      inputs: `2-D` tensor with shape `[batch_size, input_size]`.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">      state: An `LSTMStateTuple` of state tensors, each shaped</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        `[batch_size, num_units]`, if `state_is_tuple` has been set to</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        `True`.  Otherwise, a `Tensor` shaped</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        `[batch_size, 2 * num_units]`.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">      A pair containing the new hidden state, and the new state (either a</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        `LSTMStateTuple` or a concatenated state, depending on</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        `state_is_tuple`).</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    sigmoid = math_ops.sigmoid</span><br><span class="line"></span><br><span class="line">    one = constant_op.constant(<span class="number">1</span>, dtype=dtypes.int32)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Parameters of gates are concatenated into one multiply for efficiency.</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> self._state_is_tuple:</span><br><span class="line"></span><br><span class="line">      c, h = state</span><br><span class="line"></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line"></span><br><span class="line">      c, h = array_ops.split(value=state, num_or_size_splits=<span class="number">2</span>, axis=one)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    gate_inputs = math_ops.matmul(</span><br><span class="line"></span><br><span class="line">        array_ops.concat([inputs, h], <span class="number">1</span>), self._kernel)</span><br><span class="line"></span><br><span class="line">    gate_inputs = nn_ops.bias_add(gate_inputs, self._bias)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment"># i = input_gate, j = new_input, f = forget_gate, o = output_gate</span></span><br><span class="line"></span><br><span class="line">    i, j, f, o = array_ops.split(</span><br><span class="line"></span><br><span class="line">        value=gate_inputs, num_or_size_splits=<span class="number">4</span>, axis=one)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    forget_bias_tensor = constant_op.constant(self._forget_bias, dtype=f.dtype)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Note that using `add` and `multiply` instead of `+` and `*` gives a</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># performance improvement. So using those at the cost of readability.</span></span><br><span class="line"></span><br><span class="line">    add = math_ops.add</span><br><span class="line"></span><br><span class="line">    multiply = math_ops.multiply</span><br><span class="line"></span><br><span class="line">    new_c = add(multiply(c, sigmoid(add(f, forget_bias_tensor))),</span><br><span class="line"></span><br><span class="line">                multiply(sigmoid(i), self._activation(j)))</span><br><span class="line"></span><br><span class="line">    new_h = multiply(self._activation(new_c), sigmoid(o))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> self._state_is_tuple:</span><br><span class="line"></span><br><span class="line">      new_state = LSTMStateTuple(new_c, new_h)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line"></span><br><span class="line">      new_state = array_ops.concat([new_c, new_h], <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> new_h, new_state</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<p>阅读源码可以发现具体实现与上面的公式还是有点差别的。  </p>
<ul>
<li><p>先 concat[input, h], 然后 gate_input = matmul(concat[input, h], self._kernel)+self._bias,多了偏置项,这里的矩阵维度 [input_depth + h_depth,4*num_units]. 然后 i,j,f,o = split(gate_input, 4, axis=1). 其中 j 表示 new memory cell. 然后计算 new_c，其中 i,f,o 对应的激活函数确定是 sigmoid,因为其范围只能在(0,1)之间。但是 j 的激活函数self._activation 可以选择，默认是 tanh.  </p>
</li>
<li><p>与公式的差别之二在于 self._forget_bias.遗忘门在激活函数 $\sigma$ 之前加了偏置，目的是避免在训练初期丢失太多信息。    </p>
</li>
<li><p>要注意 state 的形式，取决于参数 self._state_is_tuple. 其中 c,h=state，表示 $c_{t-1},h_{t-1}$</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">lstm_cell = tf.contrib.rnn.BasicLSTMCell(num_units=<span class="number">128</span>, forget_bias=<span class="number">1.0</span>, state_is_tuple=<span class="literal">True</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<pre><code>WARNING:tensorflow:From &lt;ipython-input-9-3f4ca183c5d7&gt;:1: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.

Instructions for updating:

This class is deprecated, please use tf.nn.rnn_cell.LSTMCell, which supports all the feature this cell currently has. Please replace the existing code with tf.nn.rnn_cell.LSTMCell(name=&#39;basic_lstm_cell&#39;).
</code></pre>
<p>提示要更新了，那就换成最新的吧</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">lstm_cell = tf.nn.rnn_cell.LSTMCell(num_units=<span class="number">128</span>, forget_bias=<span class="number">1.0</span>, state_is_tuple=<span class="literal">True</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>





<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">lstm_cell.output_size, lstm_cell.state_size</span><br><span class="line"></span><br></pre></td></tr></table></figure>









<pre><code>(128, LSTMStateTuple(c=128, h=128))
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">h0 = lstm_cell.zero_state(batch_size=<span class="number">30</span>, dtype=tf.float32)</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<p>我们发现 lstm 的状态 state 是一个tuple,分别对应 c_t 和 h_t.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">LSTMStateTuple</span>(<span class="params">_LSTMStateTuple</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Tuple used by LSTM Cells for `state_size`, `zero_state`, and output state.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Stores two elements: `(c, h)`, in that order. Where `c` is the hidden state</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    and `h` is the output.</span></span><br><span class="line"><span class="string"></span></span><br></pre></td></tr></table></figure>

<p>这里的解释感觉是有点问题的，<code>c</code> is the hidden state and <code>h</code> is the output. 看源码</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">new_c = add(multiply(c, sigmoid(add(f, forget_bias_tensor))),</span><br><span class="line"></span><br><span class="line">            multiply(sigmoid(i), self._activation(j)))</span><br><span class="line"></span><br><span class="line">new_h = multiply(self._activation(new_c), sigmoid(o))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> self._state_is_tuple:</span><br><span class="line"></span><br><span class="line">  new_state = LSTMStateTuple(new_c, new_h)</span><br><span class="line"></span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line"></span><br><span class="line">  new_state = array_ops.concat([new_c, new_h], <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> new_h, new_state</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<p>发现 c 表示的就是 new memory cell, 而 h 表示的是最后的隐藏状态。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment"># 计算下一步的 output 和 state</span></span><br><span class="line"></span><br><span class="line">inputs = tf.random_normal(shape=[<span class="number">30</span>, <span class="number">100</span>], dtype=tf.float32)</span><br><span class="line"></span><br><span class="line">output, state = lstm_cell(inputs, h0)</span><br><span class="line"></span><br></pre></td></tr></table></figure>





<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">output.shape, state[<span class="number">0</span>].shape, state[<span class="number">1</span>].shape</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<pre><code>(TensorShape([Dimension(30), Dimension(128)]),

 TensorShape([Dimension(30), Dimension(128)]),

 TensorShape([Dimension(30), Dimension(128)]))
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">state.c, state.h  <span class="comment"># c 和 h 的值是不一样的</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>



<pre><code>(&lt;tf.Tensor: id=108, shape=(30, 128), dtype=float32, numpy=

 array([[ 0.08166471,  0.14020835,  0.07970127, ..., -0.1540019 ,

          0.38848224, -0.0842322 ],

        [-0.03643086, -0.20558938,  0.1503458 , ...,  0.01846285,

          0.15610473,  0.04408235],

        [-0.0933667 ,  0.03454542, -0.09073547, ..., -0.12701994,

         -0.34669587,  0.09373946],

        ...,

        [-0.00752909,  0.22412673, -0.270195  , ...,  0.09341058,

         -0.20986181, -0.18622127],

        [ 0.18778914,  0.37687936, -0.24727295, ..., -0.06409463,

          0.00218048,  0.5940756 ],

        [ 0.04073388, -0.08431841,  0.35944715, ...,  0.14135318,

          0.08472287, -0.11058106]], dtype=float32)&gt;,

 &lt;tf.Tensor: id=111, shape=(30, 128), dtype=float32, numpy=

 array([[ 0.04490132,  0.07412361,  0.03662094, ..., -0.07611651,

          0.17290959, -0.0277745 ],

        [-0.02212535, -0.13554382,  0.08272093, ...,  0.00918258,

          0.0861209 ,  0.02614526],

        [-0.05723168,  0.01372226, -0.02919216, ..., -0.06374882,

         -0.1918035 ,  0.03912015],

        ...,

        [-0.00377504,  0.15181372, -0.14555399, ...,  0.06073361,

         -0.09804281, -0.07492835],

        [ 0.10244624,  0.17440473, -0.09896267, ..., -0.03794969,

          0.00123257,  0.21985768],

        [ 0.01832823, -0.03795732,  0.1654894 , ...,  0.05827027,

          0.02769112, -0.05957894]], dtype=float32)&gt;)
</code></pre>
<h3 id="tf-nn-rnn-cell-GRUCell"><a href="#tf-nn-rnn-cell-GRUCell" class="headerlink" title="tf.nn.rnn_cell.GRUCell"></a>tf.nn.rnn_cell.GRUCell</h3><p>先回顾下 GRU.</p>
<p><img src="https://panxiaoxie.cn/2018/05/07/cs224d-lecture9-machine-translation/mt15.png"></p>
<p>手敲 GRU 公式：</p>
<p>$$r_t=\sigma(W^rx_t + U^rh_{t-1})$$</p>
<p>$$z_t=\sigma(W^zx_t + U^zh_{t-1})$$</p>
<p>$$\tilde h_t = tanh(Wx_t + r_t\circ h_{t-1})$$</p>
<p>$$h_t=(1-z_t)\circ\tilde h_t + z_t\circ h_{t-1}$$</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="meta">@tf_export(<span class="params"><span class="string">&quot;nn.rnn_cell.GRUCell&quot;</span></span>)</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">GRUCell</span>(<span class="params">LayerRNNCell</span>):</span></span><br><span class="line"></span><br><span class="line">  <span class="string">&quot;&quot;&quot;Gated Recurrent Unit cell (cf. http://arxiv.org/abs/1406.1078).</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  Args:</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    num_units: int, The number of units in the GRU cell.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    activation: Nonlinearity to use.  Default: `tanh`.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    reuse: (optional) Python boolean describing whether to reuse variables</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">     in an existing scope.  If not `True`, and the existing scope already has</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">     the given variables, an error is raised.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    kernel_initializer: (optional) The initializer to use for the weight and</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    projection matrices.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    bias_initializer: (optional) The initializer to use for the bias.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    name: String, the name of the layer. Layers with the same name will</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">      share weights, but to avoid mistakes we require reuse=True in such</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">      cases.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    dtype: Default dtype of the layer (default of `None` means use the type</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">      of the first input). Required when `build` is called before `call`.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self,</span></span></span><br><span class="line"><span class="params"><span class="function"></span></span></span><br><span class="line"><span class="params"><span class="function">               num_units,</span></span></span><br><span class="line"><span class="params"><span class="function"></span></span></span><br><span class="line"><span class="params"><span class="function">               activation=<span class="literal">None</span>,</span></span></span><br><span class="line"><span class="params"><span class="function"></span></span></span><br><span class="line"><span class="params"><span class="function">               reuse=<span class="literal">None</span>,</span></span></span><br><span class="line"><span class="params"><span class="function"></span></span></span><br><span class="line"><span class="params"><span class="function">               kernel_initializer=<span class="literal">None</span>,</span></span></span><br><span class="line"><span class="params"><span class="function"></span></span></span><br><span class="line"><span class="params"><span class="function">               bias_initializer=<span class="literal">None</span>,</span></span></span><br><span class="line"><span class="params"><span class="function"></span></span></span><br><span class="line"><span class="params"><span class="function">               name=<span class="literal">None</span>,</span></span></span><br><span class="line"><span class="params"><span class="function"></span></span></span><br><span class="line"><span class="params"><span class="function">               dtype=<span class="literal">None</span></span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="built_in">super</span>(GRUCell, self).__init__(_reuse=reuse, name=name, dtype=dtype)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Inputs must be 2-dimensional.</span></span><br><span class="line"></span><br><span class="line">    self.input_spec = base_layer.InputSpec(ndim=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    self._num_units = num_units</span><br><span class="line"></span><br><span class="line">    self._activation = activation <span class="keyword">or</span> math_ops.tanh</span><br><span class="line"></span><br><span class="line">    self._kernel_initializer = kernel_initializer</span><br><span class="line"></span><br><span class="line">    self._bias_initializer = bias_initializer</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">  @property</span></span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">state_size</span>(<span class="params">self</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> self._num_units</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">  @property</span></span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">output_size</span>(<span class="params">self</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> self._num_units</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">build</span>(<span class="params">self, inputs_shape</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> inputs_shape[<span class="number">1</span>].value <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line"></span><br><span class="line">      <span class="keyword">raise</span> ValueError(<span class="string">&quot;Expected inputs.shape[-1] to be known, saw shape: %s&quot;</span></span><br><span class="line"></span><br><span class="line">                       % inputs_shape)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    input_depth = inputs_shape[<span class="number">1</span>].value</span><br><span class="line"></span><br><span class="line">    self._gate_kernel = self.add_variable(</span><br><span class="line"></span><br><span class="line">        <span class="string">&quot;gates/%s&quot;</span> % _WEIGHTS_VARIABLE_NAME,</span><br><span class="line"></span><br><span class="line">        shape=[input_depth + self._num_units, <span class="number">2</span> * self._num_units],</span><br><span class="line"></span><br><span class="line">        initializer=self._kernel_initializer)</span><br><span class="line"></span><br><span class="line">    self._gate_bias = self.add_variable(</span><br><span class="line"></span><br><span class="line">        <span class="string">&quot;gates/%s&quot;</span> % _BIAS_VARIABLE_NAME,</span><br><span class="line"></span><br><span class="line">        shape=[<span class="number">2</span> * self._num_units],</span><br><span class="line"></span><br><span class="line">        initializer=(</span><br><span class="line"></span><br><span class="line">            self._bias_initializer</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> self._bias_initializer <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">            <span class="keyword">else</span> init_ops.constant_initializer(<span class="number">1.0</span>, dtype=self.dtype)))</span><br><span class="line"></span><br><span class="line">    self._candidate_kernel = self.add_variable(</span><br><span class="line"></span><br><span class="line">        <span class="string">&quot;candidate/%s&quot;</span> % _WEIGHTS_VARIABLE_NAME,</span><br><span class="line"></span><br><span class="line">        shape=[input_depth + self._num_units, self._num_units],</span><br><span class="line"></span><br><span class="line">        initializer=self._kernel_initializer)</span><br><span class="line"></span><br><span class="line">    self._candidate_bias = self.add_variable(</span><br><span class="line"></span><br><span class="line">        <span class="string">&quot;candidate/%s&quot;</span> % _BIAS_VARIABLE_NAME,</span><br><span class="line"></span><br><span class="line">        shape=[self._num_units],</span><br><span class="line"></span><br><span class="line">        initializer=(</span><br><span class="line"></span><br><span class="line">            self._bias_initializer</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> self._bias_initializer <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">            <span class="keyword">else</span> init_ops.zeros_initializer(dtype=self.dtype)))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    self.built = <span class="literal">True</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">call</span>(<span class="params">self, inputs, state</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Gated recurrent unit (GRU) with nunits cells.&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    gate_inputs = math_ops.matmul(</span><br><span class="line"></span><br><span class="line">        array_ops.concat([inputs, state], <span class="number">1</span>), self._gate_kernel)</span><br><span class="line"></span><br><span class="line">    gate_inputs = nn_ops.bias_add(gate_inputs, self._gate_bias)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    value = math_ops.sigmoid(gate_inputs)</span><br><span class="line"></span><br><span class="line">    r, u = array_ops.split(value=value, num_or_size_splits=<span class="number">2</span>, axis=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    r_state = r * state</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    candidate = math_ops.matmul(</span><br><span class="line"></span><br><span class="line">        array_ops.concat([inputs, r_state], <span class="number">1</span>), self._candidate_kernel)</span><br><span class="line"></span><br><span class="line">    candidate = nn_ops.bias_add(candidate, self._candidate_bias)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    c = self._activation(candidate)</span><br><span class="line"></span><br><span class="line">    new_h = u * state + (<span class="number">1</span> - u) * c</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> new_h, new_h</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">_LSTMStateTuple = collections.namedtuple(<span class="string">&quot;LSTMStateTuple&quot;</span>, (<span class="string">&quot;c&quot;</span>, <span class="string">&quot;h&quot;</span>))</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<p>仔细阅读源码发现在 $sigma$ 计算 gate，以及 tanh 计算 candidate 之前都有偏置项，不过公式中都没写出来。而且在不设置 bias 的初始值时，默认的 GRU 中 gate_bias 的初始值是 1, 而 LSTM 中 gate_bias 的初始值是 0.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">gru_cell = tf.nn.rnn_cell.GRUCell(num_units=<span class="number">128</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>





<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">gru_cell.state_size, gru_cell.output_size</span><br><span class="line"></span><br></pre></td></tr></table></figure>





<pre><code>(128, 128)
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">h0 = gru_cell.zero_state(batch_size=<span class="number">30</span>, dtype=tf.float32)</span><br><span class="line"></span><br></pre></td></tr></table></figure>





<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">inputs = tf.random_normal(shape=[<span class="number">30</span>, <span class="number">100</span>], dtype=tf.float32)</span><br><span class="line"></span><br><span class="line">output, state = gru_cell(inputs, h0)</span><br><span class="line"></span><br><span class="line">output.shape, state.shape</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<pre><code>(TensorShape([Dimension(30), Dimension(128)]),

 TensorShape([Dimension(30), Dimension(128)]))
</code></pre>
<p>出现个很神奇的现象，如果我写成这样：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">output, state = gru_cell.call(inputs, h0) <span class="comment"># 会报错的，gru_cell 没有 self._gate_kernel 这个属性，很神奇，</span></span><br><span class="line"></span><br><span class="line">                                          <span class="comment"># 不过这里先运行上面那行代码，所以没有出现报错</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h3 id="tf-nn-rnn-cell-LSTMCell-tf-contrib-rnn-LSTMCell"><a href="#tf-nn-rnn-cell-LSTMCell-tf-contrib-rnn-LSTMCell" class="headerlink" title="tf.nn.rnn_cell.LSTMCell, tf.contrib.rnn.LSTMCell"></a>tf.nn.rnn_cell.LSTMCell, tf.contrib.rnn.LSTMCell</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="meta">@tf_export(<span class="params"><span class="string">&quot;nn.rnn_cell.LSTMCell&quot;</span></span>)</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">LSTMCell</span>(<span class="params">LayerRNNCell</span>):</span></span><br><span class="line"></span><br><span class="line">  <span class="string">&quot;&quot;&quot;Long short-term memory unit (LSTM) recurrent network cell.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  The default non-peephole implementation is based on:</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    http://www.bioinf.jku.at/publications/older/2604.pdf</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  S. Hochreiter and J. Schmidhuber.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  &quot;Long Short-Term Memory&quot;. Neural Computation, 9(8):1735-1780, 1997.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  The peephole implementation is based on:</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    https://research.google.com/pubs/archive/43905.pdf</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  Hasim Sak, Andrew Senior, and Francoise Beaufays.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  &quot;Long short-term memory recurrent neural network architectures for</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">   large scale acoustic modeling.&quot; INTERSPEECH, 2014.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  The class uses optional peep-hole connections, optional cell clipping, and</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  an optional projection layer.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, num_units,</span></span></span><br><span class="line"><span class="params"><span class="function"></span></span></span><br><span class="line"><span class="params"><span class="function">               use_peepholes=<span class="literal">False</span>, cell_clip=<span class="literal">None</span>,</span></span></span><br><span class="line"><span class="params"><span class="function"></span></span></span><br><span class="line"><span class="params"><span class="function">               initializer=<span class="literal">None</span>, num_proj=<span class="literal">None</span>, proj_clip=<span class="literal">None</span>,</span></span></span><br><span class="line"><span class="params"><span class="function"></span></span></span><br><span class="line"><span class="params"><span class="function">               num_unit_shards=<span class="literal">None</span>, num_proj_shards=<span class="literal">None</span>,</span></span></span><br><span class="line"><span class="params"><span class="function"></span></span></span><br><span class="line"><span class="params"><span class="function">               forget_bias=<span class="number">1.0</span>, state_is_tuple=<span class="literal">True</span>,</span></span></span><br><span class="line"><span class="params"><span class="function"></span></span></span><br><span class="line"><span class="params"><span class="function">               activation=<span class="literal">None</span>, reuse=<span class="literal">None</span>, name=<span class="literal">None</span>, dtype=<span class="literal">None</span></span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Initialize the parameters for an LSTM cell.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="built_in">super</span>(LSTMCell, self).__init__(_reuse=reuse, name=name, dtype=dtype)</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<p>相比 BasicLSTMCell 多了这四个参数：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">Args:</span><br><span class="line"></span><br><span class="line">    use_peepholes: <span class="built_in">bool</span>, <span class="built_in">set</span> <span class="literal">True</span> to enable diagonal/peephole connections.</span><br><span class="line"></span><br><span class="line">    cell_clip: (optional) A <span class="built_in">float</span> value, <span class="keyword">if</span> provided the cell state <span class="keyword">is</span> clipped</span><br><span class="line"></span><br><span class="line">        by this value prior to the cell output activation.</span><br><span class="line"></span><br><span class="line">    num_proj: (optional) <span class="built_in">int</span>, The output dimensionality <span class="keyword">for</span> the projection</span><br><span class="line"></span><br><span class="line">        matrices.  If <span class="literal">None</span>, no projection <span class="keyword">is</span> performed.</span><br><span class="line"></span><br><span class="line">    proj_clip: (optional) A <span class="built_in">float</span> value.  If `num_proj &gt; <span class="number">0</span>` <span class="keyword">and</span> `proj_clip` <span class="keyword">is</span></span><br><span class="line"></span><br><span class="line">        provided, then the projected values are clipped elementwise to within</span><br><span class="line"></span><br><span class="line">        `[-proj_clip, proj_clip]`.</span><br><span class="line"></span><br><span class="line">````</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">其中 cell_clip 很好理解，就是限制隐藏状态的大小，也就是 output 和 state 的大小。 而 num_proj 呢？</span><br><span class="line"></span><br><span class="line">```python</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> num_proj:</span><br><span class="line"></span><br><span class="line">      self._state_size = (</span><br><span class="line"></span><br><span class="line">          LSTMStateTuple(num_units, num_proj)</span><br><span class="line"></span><br><span class="line">          <span class="keyword">if</span> state_is_tuple <span class="keyword">else</span> num_units + num_proj)</span><br><span class="line"></span><br><span class="line">      self._output_size = num_proj</span><br><span class="line"></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line"></span><br><span class="line">      self._state_size = (</span><br><span class="line"></span><br><span class="line">          LSTMStateTuple(num_units, num_units)</span><br><span class="line"></span><br><span class="line">          <span class="keyword">if</span> state_is_tuple <span class="keyword">else</span> <span class="number">2</span> * num_units)</span><br><span class="line"></span><br><span class="line">      self._output_size = num_units</span><br><span class="line"></span><br><span class="line"> ````</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">通过源码可以发现，如果有 num_proj 那么 state 还要加一个全链接， state_size = num_units + num_proj. 而 proj_clip 是限制这个全链接的输出的。</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">BacisLSTMCell 和 LSTMCell 区别还在于后者增加了 peephole 和 cell_clip</span><br><span class="line"></span><br><span class="line">![](https://img-blog.csdn.net/<span class="number">20171201095120010</span>?watermark/<span class="number">2</span>/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvYWJjbGhxMjAwNQ==/font/5a6L5L2T/fontsize/<span class="number">400</span>/fill/I0JBQkFCMA==/dissolve/<span class="number">70</span>/gravity/SouthEast)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">输入输出的shape，以及状态都是一样的，只不过内部计算方式更加复杂了。对于 peephole 是值得计算 gate 时，考虑到了 $c_&#123;t-<span class="number">1</span>&#125;$ 和 $c_t$.</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">```python</span><br><span class="line"></span><br><span class="line">cell = tf.nn.rnn_cell.LSTMCell(num_units=<span class="number">64</span>,cell_clip=<span class="number">0.000000001</span>, num_proj=<span class="number">128</span>, proj_clip=<span class="number">0.001</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>





<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">cell.state_size, cell.output_size</span><br><span class="line"></span><br></pre></td></tr></table></figure>









<pre><code>(LSTMStateTuple(c=64, h=128), 128)
</code></pre>
<p>发现 state_size 中的 h 维度发生了变化，相当于在每一个时间步得到的 state.h 之后再添加一个全链接。 在 decoder 中可以将 num_proj 设置为词表的大小，那么输出就是对应时间步的词表的分布。在此基础上在 softmax 就可以吧？ 但是下一个时间步的输入的隐藏状态 $h_{t-1}$ 岂不是维度为词表大小。。。感觉最好还是不用这个参数吧</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">h0 = cell.zero_state(batch_size=<span class="number">30</span>, dtype=tf.float32)</span><br><span class="line"></span><br><span class="line">h0.c.shape, h0.h.shape</span><br><span class="line"></span><br></pre></td></tr></table></figure>









<pre><code>(TensorShape([Dimension(30), Dimension(64)]),

 TensorShape([Dimension(30), Dimension(128)]))
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">inputs = tf.ones(shape=[<span class="number">30</span>,<span class="number">50</span>])</span><br><span class="line"></span><br></pre></td></tr></table></figure>





<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">output, state = cell(inputs=inputs, state=h0)</span><br><span class="line"></span><br></pre></td></tr></table></figure>





<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">output.shape, state.c.shape, state.h.shape</span><br><span class="line"></span><br></pre></td></tr></table></figure>









<pre><code>(TensorShape([Dimension(30), Dimension(128)]),

 TensorShape([Dimension(30), Dimension(64)]),

 TensorShape([Dimension(30), Dimension(128)]))
</code></pre>
<h2 id="封装了-RNN-的其他组件"><a href="#封装了-RNN-的其他组件" class="headerlink" title="封装了 RNN 的其他组件"></a>封装了 RNN 的其他组件</h2><p>Core RNN Cell wrappers (RNNCells that wrap other RNNCells)</p>
<ul>
<li><p>tf.contrib.rnn.MultiRNNCell  </p>
</li>
<li><p>tf.contrib.rnn.LSTMBlockWrapper  </p>
</li>
<li><p>tf.contrib.rnn.DropoutWrapper  </p>
</li>
<li><p>tf.contrib.rnn.EmbeddingWrapper  </p>
</li>
<li><p>tf.contrib.rnn.InputProjectionWrapper  </p>
</li>
<li><p>tf.contrib.rnn.OutputProjectionWrapper  </p>
</li>
<li><p>tf.contrib.rnn.DeviceWrapper  </p>
</li>
<li><p>tf.contrib.rnn.ResidualWrapper  </p>
</li>
</ul>
<p>主要看 <code>tf.contrib.rnn.MultiRNNCell</code> 和 <code>tf.contrib.rnn.DropoutWrapper</code>吧，其他的封装的太好了也不好，用的其实也少。</p>
<h3 id="tf-contrib-rnn-MultiRNNCell"><a href="#tf-contrib-rnn-MultiRNNCell" class="headerlink" title="tf.contrib.rnn.MultiRNNCell"></a>tf.contrib.rnn.MultiRNNCell</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MultiRNNCell</span>(<span class="params">RNNCell</span>):</span></span><br><span class="line"></span><br><span class="line">  <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  RNN cell composed sequentially of multiple simple cells.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, cells, state_is_tuple=<span class="literal">True</span></span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Create a RNN cell composed sequentially of a number of RNNCells.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">      cells: list of RNNCells that will be composed in this order.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">      state_is_tuple: If True, accepted and returned states are n-tuples, where</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        `n = len(cells)`.  If False, the states are all</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        concatenated along the column axis.  This latter behavior will soon be</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        deprecated.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Raises:</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">      ValueError: if cells is empty (not allowed), or at least one of the cells</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        returns a state tuple but the flag `state_is_tuple` is `False`.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="built_in">super</span>(MultiRNNCell, self).__init__()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> cells:</span><br><span class="line"></span><br><span class="line">      <span class="keyword">raise</span> ValueError(<span class="string">&quot;Must specify at least one cell for MultiRNNCell.&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> nest.is_sequence(cells):</span><br><span class="line"></span><br><span class="line">      <span class="keyword">raise</span> TypeError(</span><br><span class="line"></span><br><span class="line">          <span class="string">&quot;cells must be a list or tuple, but saw: %s.&quot;</span> % cells)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    self._cells = cells</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> cell_number, cell <span class="keyword">in</span> <span class="built_in">enumerate</span>(self._cells):</span><br><span class="line"></span><br><span class="line">      <span class="comment"># Add Checkpointable dependencies on these cells so their variables get</span></span><br><span class="line"></span><br><span class="line">      <span class="comment"># saved with this object when using object-based saving.</span></span><br><span class="line"></span><br><span class="line">      <span class="keyword">if</span> <span class="built_in">isinstance</span>(cell, checkpointable.CheckpointableBase):</span><br><span class="line"></span><br><span class="line">        <span class="comment"># TODO(allenl): Track down non-Checkpointable callers.</span></span><br><span class="line"></span><br><span class="line">        self._track_checkpointable(cell, name=<span class="string">&quot;cell-%d&quot;</span> % (cell_number,))</span><br><span class="line"></span><br><span class="line">    self._state_is_tuple = state_is_tuple</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> state_is_tuple:</span><br><span class="line"></span><br><span class="line">      <span class="keyword">if</span> <span class="built_in">any</span>(nest.is_sequence(c.state_size) <span class="keyword">for</span> c <span class="keyword">in</span> self._cells):</span><br><span class="line"></span><br><span class="line">        <span class="keyword">raise</span> ValueError(<span class="string">&quot;Some cells return tuples of states, but the flag &quot;</span></span><br><span class="line"></span><br><span class="line">                         <span class="string">&quot;state_is_tuple is not set.  State sizes are: %s&quot;</span></span><br><span class="line"></span><br><span class="line">                         % <span class="built_in">str</span>([c.state_size <span class="keyword">for</span> c <span class="keyword">in</span> self._cells]))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">  @property</span></span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">state_size</span>(<span class="params">self</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> self._state_is_tuple:</span><br><span class="line"></span><br><span class="line">      <span class="keyword">return</span> <span class="built_in">tuple</span>(cell.state_size <span class="keyword">for</span> cell <span class="keyword">in</span> self._cells)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line"></span><br><span class="line">      <span class="keyword">return</span> <span class="built_in">sum</span>([cell.state_size <span class="keyword">for</span> cell <span class="keyword">in</span> self._cells])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">  @property</span></span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">output_size</span>(<span class="params">self</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> self._cells[-<span class="number">1</span>].output_size</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">zero_state</span>(<span class="params">self, batch_size, dtype</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> ops.name_scope(<span class="built_in">type</span>(self).__name__ + <span class="string">&quot;ZeroState&quot;</span>, values=[batch_size]):</span><br><span class="line"></span><br><span class="line">      <span class="keyword">if</span> self._state_is_tuple:</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">tuple</span>(cell.zero_state(batch_size, dtype) <span class="keyword">for</span> cell <span class="keyword">in</span> self._cells)</span><br><span class="line"></span><br><span class="line">      <span class="keyword">else</span>:</span><br><span class="line"></span><br><span class="line">        <span class="comment"># We know here that state_size of each cell is not a tuple and</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># presumably does not contain TensorArrays or anything else fancy</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">super</span>(MultiRNNCell, self).zero_state(batch_size, dtype)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">call</span>(<span class="params">self, inputs, state</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Run this multi-layer cell on inputs, starting from state.&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    cur_state_pos = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    cur_inp = inputs</span><br><span class="line"></span><br><span class="line">    new_states = []</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i, cell <span class="keyword">in</span> <span class="built_in">enumerate</span>(self._cells):</span><br><span class="line"></span><br><span class="line">      <span class="keyword">with</span> vs.variable_scope(<span class="string">&quot;cell_%d&quot;</span> % i):</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> self._state_is_tuple:</span><br><span class="line"></span><br><span class="line">          <span class="keyword">if</span> <span class="keyword">not</span> nest.is_sequence(state):</span><br><span class="line"></span><br><span class="line">            <span class="keyword">raise</span> ValueError(</span><br><span class="line"></span><br><span class="line">                <span class="string">&quot;Expected state to be a tuple of length %d, but received: %s&quot;</span> %</span><br><span class="line"></span><br><span class="line">                (<span class="built_in">len</span>(self.state_size), state))</span><br><span class="line"></span><br><span class="line">          cur_state = state[i]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line"></span><br><span class="line">          cur_state = array_ops.<span class="built_in">slice</span>(state, [<span class="number">0</span>, cur_state_pos],</span><br><span class="line"></span><br><span class="line">                                      [-<span class="number">1</span>, cell.state_size])</span><br><span class="line"></span><br><span class="line">          cur_state_pos += cell.state_size</span><br><span class="line"></span><br><span class="line">        cur_inp, new_state = cell(cur_inp, cur_state)</span><br><span class="line"></span><br><span class="line">        new_states.append(new_state)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    new_states = (<span class="built_in">tuple</span>(new_states) <span class="keyword">if</span> self._state_is_tuple <span class="keyword">else</span></span><br><span class="line"></span><br><span class="line">                  array_ops.concat(new_states, <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> cur_inp, new_states</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<p>参数 cell 是元素为 RNNCell对象 的 list 或 tuple. 其实还是只是计算一个时间步的 state</p>
<p><img src="https://panxiaoxie.cn/2018/05/04/cs224d-lecture8-RNN/rnn12.png"></p>
<p>这里先不考虑双向，只考虑 deep. 也就是使用 MultiRNNCell</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">num_units = [<span class="number">64</span>, <span class="number">128</span>]</span><br><span class="line"></span><br><span class="line">stack_rnns = [tf.nn.rnn_cell.BasicLSTMCell(num_units=i) <span class="keyword">for</span> i <span class="keyword">in</span> num_units]</span><br><span class="line"></span><br><span class="line">stack_rnn_cell = tf.nn.rnn_cell.MultiRNNCell(stack_rnns)</span><br><span class="line"></span><br></pre></td></tr></table></figure>





<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">h0 = [cell.zero_state(batch_size=<span class="number">32</span>, dtype=tf.float32) <span class="keyword">for</span> cell <span class="keyword">in</span> stack_rnn]</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">inputs = tf.random_normal(shape=[<span class="number">32</span>, <span class="number">100</span>], dtype=tf.float32)</span><br><span class="line"></span><br><span class="line">output, state = stack_rnn_cell(inputs=inputs, state=h0)</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">output.shape</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<pre><code>TensorShape([Dimension(32), Dimension(128)])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">state[<span class="number">0</span>].c.shape, state[<span class="number">0</span>].h.shape</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<pre><code>(TensorShape([Dimension(32), Dimension(64)]),

 TensorShape([Dimension(32), Dimension(64)]))
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">state[<span class="number">1</span>].c.shape, state[<span class="number">1</span>].h.shape</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<pre><code>(TensorShape([Dimension(32), Dimension(128)]),

 TensorShape([Dimension(32), Dimension(128)]))
</code></pre>
<p>源码中的一部分：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">cur_inp, new_state = cell(cur_inp, cur_state)</span><br><span class="line"></span><br><span class="line">new_states.append(new_state)</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<p>其中从源码中也可以发现把每一层的 state 都储存起来了，而 output 要作为下一层的输入，最后得到的 output 是最后一层的输出。</p>
<h3 id="tf-contrib-rnn-DropoutWrapper"><a href="#tf-contrib-rnn-DropoutWrapper" class="headerlink" title="tf.contrib.rnn.DropoutWrapper"></a>tf.contrib.rnn.DropoutWrapper</h3><p>参考paper: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1512.05287">A Theoretically Grounded Application of Dropout in Recurrent Neural Networks</a></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="meta">@tf_export(<span class="params"><span class="string">&quot;nn.rnn_cell.DropoutWrapper&quot;</span></span>)</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DropoutWrapper</span>(<span class="params">RNNCell</span>):</span></span><br><span class="line"></span><br><span class="line">  <span class="string">&quot;&quot;&quot;Operator adding dropout to inputs and outputs of the given cell.&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, cell, input_keep_prob=<span class="number">1.0</span>, output_keep_prob=<span class="number">1.0</span>,</span></span></span><br><span class="line"><span class="params"><span class="function"></span></span></span><br><span class="line"><span class="params"><span class="function">               state_keep_prob=<span class="number">1.0</span>, variational_recurrent=<span class="literal">False</span>,</span></span></span><br><span class="line"><span class="params"><span class="function"></span></span></span><br><span class="line"><span class="params"><span class="function">               input_size=<span class="literal">None</span>, dtype=<span class="literal">None</span>, seed=<span class="literal">None</span>,</span></span></span><br><span class="line"><span class="params"><span class="function"></span></span></span><br><span class="line"><span class="params"><span class="function">               dropout_state_filter_visitor=<span class="literal">None</span></span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Create a cell with added input, state, and/or output dropout.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    If `variational_recurrent` is set to `True` (**NOT** the default behavior),</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    then the same dropout mask is applied at every step, as described in:</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Y. Gal, Z Ghahramani.  &quot;A Theoretically Grounded Application of Dropout in</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Recurrent Neural Networks&quot;.  https://arxiv.org/abs/1512.05287</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    如果参数 variational_recurrent 设置为 True，那么 dropout 在每一个时间步都会执行 dropout，</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Otherwise a different dropout mask is applied at every time step.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Note, by default (unless a custom `dropout_state_filter` is provided),</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    the memory state (`c` component of any `LSTMStateTuple`) passing through</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    a `DropoutWrapper` is never modified.  This behavior is described in the</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    above article.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">      cell: an RNNCell, a projection to output_size is added to it.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">      input_keep_prob: unit Tensor or float between 0 and 1, input keep</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        probability; if it is constant and 1, no input dropout will be added.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">      output_keep_prob: unit Tensor or float between 0 and 1, output keep</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        probability; if it is constant and 1, no output dropout will be added.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">      state_keep_prob: unit Tensor or float between 0 and 1, output keep</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        probability; if it is constant and 1, no output dropout will be added.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        State dropout is performed on the outgoing states of the cell.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        **Note** the state components to which dropout is applied when</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        `state_keep_prob` is in `(0, 1)` are also determined by</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        the argument `dropout_state_filter_visitor` (e.g. by default dropout</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        is never applied to the `c` component of an `LSTMStateTuple`).</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">      上面三个参数分别表示 input，output，state 是否 dropout，以及 dropout 率。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">      variational_recurrent: Python bool.  If `True`, then the same</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        dropout pattern is applied across all time steps per run call.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        If this parameter is set, `input_size` **must** be provided.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">      这个参数如果为 True，那么每一个时间步都需要 dropout.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">      input_size: (optional) (possibly nested tuple of) `TensorShape` objects</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        containing the depth(s) of the input tensors expected to be passed in to</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        the `DropoutWrapper`.  Required and used **iff**</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">         `variational_recurrent = True` and `input_keep_prob &lt; 1`.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">      dtype: (optional) The `dtype` of the input, state, and output tensors.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Required and used **iff** `variational_recurrent = True`.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">      seed: (optional) integer, the randomness seed.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">      dropout_state_filter_visitor: (optional), default: (see below).  Function</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        that takes any hierarchical level of the state and returns</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        a scalar or depth=1 structure of Python booleans describing</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        which terms in the state should be dropped out.  In addition, if the</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        function returns `True`, dropout is applied across this sublevel.  If</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        the function returns `False`, dropout is not applied across this entire</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        sublevel.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Default behavior: perform dropout on all terms except the memory (`c`)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        state of `LSTMCellState` objects, and don&#x27;t try to apply dropout to</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        `TensorArray` objects:</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Raises:</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">      TypeError: if `cell` is not an `RNNCell`, or `keep_state_fn` is provided</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        but not `callable`.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">      ValueError: if any of the keep_probs are not between 0 and 1.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>



<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">cell = tf.nn.rnn_cell.DropoutWrapper(cell=tf.nn.rnn_cell.LSTMCell(num_units=<span class="number">128</span>),</span><br><span class="line"></span><br><span class="line">                                     input_keep_prob=<span class="number">1.0</span>,</span><br><span class="line"></span><br><span class="line">                                     output_keep_prob=<span class="number">1.0</span>,</span><br><span class="line"></span><br><span class="line">                                     state_keep_prob=<span class="number">1.0</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>





<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">cell.state_size, cell.output_size</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<pre><code>(LSTMStateTuple(c=128, h=128), 128)
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment"># 多层 rnn</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> tensorflow.nn.rnn_cell <span class="keyword">import</span> *</span><br><span class="line"></span><br><span class="line">NUM_UNITS = [<span class="number">32</span>,<span class="number">64</span>, <span class="number">128</span>]</span><br><span class="line"></span><br><span class="line">rnn = MultiRNNCell([DropoutWrapper(LSTMCell(num_units=n), output_keep_prob=<span class="number">0.8</span>) <span class="keyword">for</span> n <span class="keyword">in</span> NUM_UNITS])</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">rnn.output_size, rnn.state_size</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<pre><code>(128,

 (LSTMStateTuple(c=32, h=32),

  LSTMStateTuple(c=64, h=64),

  LSTMStateTuple(c=128, h=128)))
</code></pre>
<h2 id="tf-nn-dynamic-rnn"><a href="#tf-nn-dynamic-rnn" class="headerlink" title="tf.nn.dynamic_rnn"></a>tf.nn.dynamic_rnn</h2><p>最后前面说了这么多 class，他们都只是一种计算当前时间步的 output 和 state 的方式，但是 rnn 处理的都是序列，所以怎么将这些 cell 对象封装到序列 rnn 中</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">dynamic_rnn</span>(<span class="params">cell, inputs, sequence_length=<span class="literal">None</span>, initial_state=<span class="literal">None</span>,</span></span></span><br><span class="line"><span class="params"><span class="function"></span></span></span><br><span class="line"><span class="params"><span class="function">                dtype=<span class="literal">None</span>, parallel_iterations=<span class="literal">None</span>, swap_memory=<span class="literal">False</span>,</span></span></span><br><span class="line"><span class="params"><span class="function"></span></span></span><br><span class="line"><span class="params"><span class="function">                time_major=<span class="literal">False</span>, scope=<span class="literal">None</span></span>):</span></span><br><span class="line"></span><br><span class="line">  <span class="string">&quot;&quot;&quot;Creates a recurrent neural network specified by RNNCell `cell`.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  Performs fully dynamic unrolling of `inputs`.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  &quot;&quot;&quot;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>



<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">rnn_layers = [tf.nn.rnn_cell.DropoutWrapper(tf.nn.rnn_cell.LSTMCell(num_units=n)) <span class="keyword">for</span> n <span class="keyword">in</span> [<span class="number">32</span>, <span class="number">64</span>]]</span><br><span class="line"></span><br><span class="line">cell = tf.nn.rnn_cell.MultiRNNCell(rnn_layers)</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">inputs = tf.random_normal(shape=[<span class="number">30</span>, <span class="number">10</span>, <span class="number">100</span>])</span><br><span class="line"></span><br></pre></td></tr></table></figure>





<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">initial_state = cell.zero_state(batch_size=<span class="number">30</span>, dtype=tf.float32)</span><br><span class="line"></span><br></pre></td></tr></table></figure>





<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">output, state = tf.nn.dynamic_rnn(cell,inputs=inputs, initial_state=initial_state, dtype=tf.float32)</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">output.shape</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<pre><code>TensorShape([Dimension(30), Dimension(10), Dimension(64)])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">cell.state_size</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<pre><code>(LSTMStateTuple(c=32, h=32), LSTMStateTuple(c=64, h=64))
</code></pre>
<p>所以目前为止，暂时ojbk了～～ 接下来就是在 attention 封装 rnn 了</p>
</div></article></div></div><div class="column column-left is-4-tablet is-4-desktop is-4-widescreen  order-1"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar" src="/img/avatar.png" alt="潘小榭"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">潘小榭</p><p class="is-size-6 is-block">Blogging is happier than writing essays!</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Beijing</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">Seiten</p><a href="/archives"><p class="title">111</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Kategorien</p><a href="/categories"><p class="title">33</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Tags</p><a href="/tags"><p class="title">32</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/ppoffice" target="_blank" rel="noopener">Folgen</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/ppoffice"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Facebook" href="https://facebook.com"><i class="fab fa-facebook"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Twitter" href="https://twitter.com"><i class="fab fa-twitter"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Dribbble" href="https://dribbble.com"><i class="fab fa-dribbble"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="RSS" href="/"><i class="fas fa-rss"></i></a></div></div></div><!--!--><div class="card widget" data-type="links"><div class="card-content"><div class="menu"><h3 class="menu-label">Links</h3><ul class="menu-list"><li><a class="level is-mobile" href="https://github.com/PanXiebit" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">github</span></span><span class="level-right"><span class="level-item tag">github.com</span></span></a></li><li><a class="level is-mobile" href="ftdpanxie@gmail.com" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">email</span></span><span class="level-right"><span class="level-item tag">ftdpanxie@gmail.com</span></span></a></li></ul></div></div></div><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">Kategorien</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/C/"><span class="level-start"><span class="level-item">C++</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/CSAPP/"><span class="level-start"><span class="level-item">CSAPP</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/DRL/"><span class="level-start"><span class="level-item">DRL</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/GAN/"><span class="level-start"><span class="level-item">GAN</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li><li><a class="level is-mobile" href="/categories/GAN-RL/"><span class="level-start"><span class="level-item">GAN, RL</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/ML/"><span class="level-start"><span class="level-item">ML</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/NLP/"><span class="level-start"><span class="level-item">NLP</span></span><span class="level-end"><span class="level-item tag">14</span></span></a></li><li><a class="level is-mobile" href="/categories/TensorFlow/"><span class="level-start"><span class="level-item">TensorFlow</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/cs224d/"><span class="level-start"><span class="level-item">cs224d</span></span><span class="level-end"><span class="level-item tag">10</span></span></a></li><li><a class="level is-mobile" href="/categories/interview/"><span class="level-start"><span class="level-item">interview</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/machine-translation/"><span class="level-start"><span class="level-item">machine translation</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/python/"><span class="level-start"><span class="level-item">python</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/pytorch/"><span class="level-start"><span class="level-item">pytorch</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/reinforcement-learning/"><span class="level-start"><span class="level-item">reinforcement learning</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/sign-language-recognition/"><span class="level-start"><span class="level-item">sign language recognition</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/transfer-learning/"><span class="level-start"><span class="level-item">transfer learning</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"><span class="level-start"><span class="level-item">数据结构与算法</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile" href="/categories/%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB/"><span class="level-start"><span class="level-item">文本分类</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"><span class="level-start"><span class="level-item">论文笔记</span></span><span class="level-end"><span class="level-item tag">34</span></span></a><ul><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/DL/"><span class="level-start"><span class="level-item">DL</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/ESA/"><span class="level-start"><span class="level-item">ESA</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/GAN/"><span class="level-start"><span class="level-item">GAN</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/MRC-and-QA/"><span class="level-start"><span class="level-item">MRC and QA</span></span><span class="level-end"><span class="level-item tag">7</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/Machine-Translation/"><span class="level-start"><span class="level-item">Machine Translation</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/NLP/"><span class="level-start"><span class="level-item">NLP</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/capsules/"><span class="level-start"><span class="level-item">capsules</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/data-augmentation/"><span class="level-start"><span class="level-item">data augmentation</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/dialogue-system/"><span class="level-start"><span class="level-item">dialogue system</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/language-model/"><span class="level-start"><span class="level-item">language model</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/machine-translation/"><span class="level-start"><span class="level-item">machine translation</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/open-set-recognition/"><span class="level-start"><span class="level-item">open set recognition</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/sentence-embedding/"><span class="level-start"><span class="level-item">sentence embedding</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/text-matching/"><span class="level-start"><span class="level-item">text matching</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li></ul></div></div></div><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">Letzte Einträge</h3><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-05-05T02:03:16.000Z">2021-05-05</time></p><p class="title"><a href="/2021/05/05/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-contrastive-learning/">论文笔记-contrastive learning</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-04-29T01:07:08.000Z">2021-04-29</time></p><p class="title"><a href="/2021/04/29/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-video-transformer/">论文笔记-video transformer</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-04-29T01:05:10.000Z">2021-04-29</time></p><p class="title"><a href="/2021/04/29/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-dynamic-convolution-and-involution/">论文笔记-dynamic convolution and involution</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-04-16T07:48:48.000Z">2021-04-16</time></p><p class="title"><a href="/2021/04/16/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-unlikelihood-training/">论文笔记-unlikelihood training</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-04-12T08:16:35.000Z">2021-04-12</time></p><p class="title"><a href="/2021/04/12/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-Deformable-DETR/">论文笔记-DETR and Deformable DETR</a></p></div></article></div></div><div class="card widget" data-type="archives"><div class="card-content"><div class="menu"><h3 class="menu-label">Archive</h3><ul class="menu-list"><li><a class="level is-mobile" href="/archives/2021/05/"><span class="level-start"><span class="level-item">May 2021</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2021/04/"><span class="level-start"><span class="level-item">April 2021</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/archives/2020/09/"><span class="level-start"><span class="level-item">September 2020</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2019/11/"><span class="level-start"><span class="level-item">November 2019</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2019/10/"><span class="level-start"><span class="level-item">October 2019</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2019/08/"><span class="level-start"><span class="level-item">August 2019</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2019/06/"><span class="level-start"><span class="level-item">June 2019</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/archives/2019/05/"><span class="level-start"><span class="level-item">May 2019</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2019/04/"><span class="level-start"><span class="level-item">April 2019</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2019/03/"><span class="level-start"><span class="level-item">March 2019</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile" href="/archives/2019/02/"><span class="level-start"><span class="level-item">February 2019</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/archives/2019/01/"><span class="level-start"><span class="level-item">January 2019</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li><li><a class="level is-mobile" href="/archives/2018/12/"><span class="level-start"><span class="level-item">December 2018</span></span><span class="level-end"><span class="level-item tag">16</span></span></a></li><li><a class="level is-mobile" href="/archives/2018/11/"><span class="level-start"><span class="level-item">November 2018</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2018/10/"><span class="level-start"><span class="level-item">October 2018</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2018/09/"><span class="level-start"><span class="level-item">September 2018</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/archives/2018/08/"><span class="level-start"><span class="level-item">August 2018</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile" href="/archives/2018/07/"><span class="level-start"><span class="level-item">July 2018</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/archives/2018/06/"><span class="level-start"><span class="level-item">June 2018</span></span><span class="level-end"><span class="level-item tag">10</span></span></a></li><li><a class="level is-mobile" href="/archives/2018/05/"><span class="level-start"><span class="level-item">May 2018</span></span><span class="level-end"><span class="level-item tag">11</span></span></a></li><li><a class="level is-mobile" href="/archives/2018/04/"><span class="level-start"><span class="level-item">April 2018</span></span><span class="level-end"><span class="level-item tag">16</span></span></a></li><li><a class="level is-mobile" href="/archives/2018/03/"><span class="level-start"><span class="level-item">March 2018</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li></ul></div></div></div><div class="card widget" data-type="tags"><div class="card-content"><div class="menu"><h3 class="menu-label">Tags</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/C/"><span class="tag">C++</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/CSAPP/"><span class="tag">CSAPP</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/DL/"><span class="tag">DL</span><span class="tag">8</span></a></div><div class="control"><a class="tags has-addons" href="/tags/ESA/"><span class="tag">ESA</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/GAN/"><span class="tag">GAN</span><span class="tag">9</span></a></div><div class="control"><a class="tags has-addons" href="/tags/GAN%EF%BC%8CRL/"><span class="tag">GAN，RL</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/ML/"><span class="tag">ML</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/MRC-and-QA/"><span class="tag">MRC and QA</span><span class="tag">7</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Machine-Translation/"><span class="tag">Machine Translation</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/NLP/"><span class="tag">NLP</span><span class="tag">14</span></a></div><div class="control"><a class="tags has-addons" href="/tags/TensorFlow/"><span class="tag">TensorFlow</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Tensorflow/"><span class="tag">Tensorflow</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/ai-challenger/"><span class="tag">ai challenger</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/capsules/"><span class="tag">capsules</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/contrastive-learning/"><span class="tag">contrastive learning</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/cs224d/"><span class="tag">cs224d</span><span class="tag">10</span></a></div><div class="control"><a class="tags has-addons" href="/tags/data-augmentation/"><span class="tag">data augmentation</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/interview/"><span class="tag">interview</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/language-model/"><span class="tag">language model</span><span class="tag">6</span></a></div><div class="control"><a class="tags has-addons" href="/tags/machine-translation/"><span class="tag">machine translation</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/open-set-recognition/"><span class="tag">open set recognition</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/python/"><span class="tag">python</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/pytorch/"><span class="tag">pytorch</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/reinforcement-learning/"><span class="tag">reinforcement learning</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/sentence-embedding/"><span class="tag">sentence embedding</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/sentiment-classification/"><span class="tag">sentiment classification</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/sign-language-recognition/"><span class="tag">sign language recognition</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/text-matching/"><span class="tag">text matching</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/transfer-learning/"><span class="tag">transfer learning</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/vision-transformer/"><span class="tag">vision transformer</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"><span class="tag">数据结构与算法</span><span class="tag">6</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB/"><span class="tag">文本分类</span><span class="tag">8</span></a></div></div></div></div></div><div class="card widget" data-type="subscribe-email"><div class="card-content"><div class="menu"><h3 class="menu-label">Abonnieren Sie Updates</h3><form action="https://feedburner.google.com/fb/a/mailverify" method="post" target="popupwindow" onsubmit="window.open(&#039;https://feedburner.google.com/fb/a/mailverify?uri=&#039;,&#039;popupwindow&#039;,&#039;scrollbars=yes,width=550,height=520&#039;);return true"><input type="hidden" value="" name="uri"><input type="hidden" name="loc" value="en_US"><div class="field has-addons"><div class="control has-icons-left is-expanded"><input class="input" name="email" type="email" placeholder="Email"><span class="icon is-small is-left"><i class="fas fa-envelope"></i></span></div><div class="control"><input class="button" type="submit" value="Abonnieren"></div></div></form></div></div></div></div><!--!--></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/logo.svg" alt="潘小榭" height="28"></a><p class="is-size-7"><span>&copy; 2021 Xie Pan</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("default");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="Zurück nach oben" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "Diese Website verwendet Cookies, um Ihre Erfahrung zu verbessern.",
          dismiss: "Verstanden!",
          allow: "Cookies zulassen",
          deny: "Ablehnen",
          link: "Mehr erfahren",
          policy: "Cookie-Richtlinie",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.5/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Tippen Sie etwas..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"Tippen Sie etwas...","untitled":"(Ohne Titel)","posts":"Seiten","pages":"Pages","categories":"Kategorien","tags":"Tags"});
        });</script></body></html>