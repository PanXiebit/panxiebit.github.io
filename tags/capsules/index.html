<!doctype html>
<html lang="zh"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>标签: capsules - 潘小榭</title><link rel="manifest" href="/manifest.json"><meta name="theme-color" content="black"><meta name="application-name" content="panxiaoxie"><meta name="msapplication-TileImage" content="/img/avatar.png"><meta name="msapplication-TileColor" content="black"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="panxiaoxie"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta property="og:type" content="blog"><meta property="og:title" content="panxiaoxie"><meta property="og:url" content="https://github.com/PanXiebit"><meta property="og:site_name" content="panxiaoxie"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://www.qt86.com/cache/1625298592_187938.png"><meta property="article:author" content="panxiaoxie"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="https://www.qt86.com/cache/1625298592_187938.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"http://www.panxiaoxie.cn"},"headline":"潘小榭","image":["http://www.panxiaoxie.cn/img/og_image.png"],"author":{"@type":"Person","name":"Xie Pan"},"publisher":{"@type":"Organization","name":"潘小榭","logo":{"@type":"ImageObject","url":"http://www.panxiaoxie.cn/img/panxiaoxie.png"}},"description":null}</script><link rel="icon" href="/img/avatar.png"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/css/justifiedGallery.min.css"><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script><!--!--><!--!--><meta name="generator" content="Hexo 5.4.0"></head><body class="is-2-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/panxiaoxie.png" alt="潘小榭" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">主页</a><a class="navbar-item" href="/archives">归档</a><a class="navbar-item" href="/categories">分类</a><a class="navbar-item" href="/tags">标签</a><a class="navbar-item" href="/about">关于我</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/PanXiebit"><i class="fab fa-github"></i></a><a class="navbar-item search" title="搜索" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-10-widescreen"><div class="card"><div class="card-content"><nav class="breadcrumb" aria-label="breadcrumbs"><ul><li><a href="/tags">标签</a></li><li class="is-active"><a href="#" aria-current="page">capsules</a></li></ul></nav></div></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2019-01-19T13:28:17.000Z" title="2019/1/19 下午9:28:17">2019-01-19</time>发表</span><span class="level-item"><time dateTime="2021-07-06T07:11:06.686Z" title="2021/7/6 下午3:11:06">2021-07-06</time>更新</span><span class="level-item"><a class="link-muted" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/">论文笔记</a><span> / </span><a class="link-muted" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/capsules/">capsules</a></span><span class="level-item">17 分钟读完 (大约2618个字)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2019/01/19/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-%E5%86%8D%E7%9C%8B-Capsules-%E4%BB%A5%E5%8F%8A-capsules-%E5%9C%A8%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E4%B8%8A%E7%9A%84%E5%BA%94%E7%94%A8/">论文笔记-再看 Capsules 以及 capsules 在文本分类上的应用</a></h1><div class="content"><p>参考：  </p>
<ul>
<li><p>blog: <a target="_blank" rel="noopener" href="https://spaces.ac.cn/archives/4819">苏剑林：揭开迷雾，来一顿美味的Capsule盛宴</a>  </p>
</li>
<li><p>paper：<a target="_blank" rel="noopener" href="https://www.paperweekly.site/papers/1811">Investigating Capsule Networks with Dynamic Routing for Text Classification</a></p>
</li>
</ul>
<h2 id="再看-Capsules"><a href="#再看-Capsules" class="headerlink" title="再看 Capsules"></a>再看 Capsules</h2><p>苏剑林同学在他的那篇博客中对 capsule 的理解很有道理，胶囊也就是用 “vector in vector out” 取代了 “scaler in scaler out”。</p>
<p>在我的上一篇 blog 中在 PrimaryCaps 模块中，将前一步通过卷积得到的输出是 [batch, 20, 20, 256]. 经过 PrimaryCaps 第一步 affine-transform 转换成 [batch, 6, 6, 32, 8]. 实际上就是在这一步将一个像素点的特征转换成了一个 8d-vector 的胶囊。</p>
<p>事实上，在 NLP 的任务中，这种用向量来表示一维特征的做法确实最基本的。比如 one-hot 向量，word2vec 将词转换成 dense vector.</p>
<p>在传统的神经网络中，从低层次的特征逐步抽象，归纳为高层次的特征，是通过权重加权求和得到的，比如卷积啊，全连接都是这样，然后通过梯度反向传播，更新这些权重参数。  </p>
<p>这个过程某种程度上模拟了人的层次分类做法，从而完成对最终目标的输出，并且具有比较好的泛化能力。的确，神经网络应该是这样做的，然而它并不能告诉我们它确确实实是这样做的，这就是神经网络的难解释性，也就是很多人会将深度学习视为黑箱的原因之一。</p>
<p>而 Hiton 提出了 Capsule 就具有很好的可解释性，那么其中的 “抛弃梯度下降” 又是怎么一回事呢？苏神在 blog 中给了很好的解释。</p>
<h3 id="胶囊的计算"><a href="#胶囊的计算" class="headerlink" title="胶囊的计算"></a>胶囊的计算</h3><p>在前面的 blog 中我们已经理解了什么是“胶囊”。神经元是标量，胶囊就是向量！Hinton的理解是：每一个胶囊表示一个属性，而胶囊的向量则表示这个属性的“标架”。也就是说，我们以前只是用一个标量表示有没有这个特征（比如有没有羽毛），现在我们用一个向量来表示，不仅仅表示有没有，还表示“有什么样的”（比如有什么颜色、什么纹理的羽毛），如果这样理解，就是说在对单个特征的表达上更丰富了。不仅如此，上一篇 blog 中有提到的 CNN 中的不足，主要在于两点，一是 max pooling 丢失了部分信息（这在低层次的layer中可能影响不大，但是在高层次的layer就会有比较大的影响），二是 CNN 不能提取低维特征与高维特征之间在空间中的相对位置信息。而胶囊的方向能表示这一部分信息。比如下面这张图就很明显的表示出来了。</p>
<p><img src="/2019/01/19/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-%E5%86%8D%E7%9C%8B-Capsules-%E4%BB%A5%E5%8F%8A-capsules-%E5%9C%A8%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E4%B8%8A%E7%9A%84%E5%BA%94%E7%94%A8/09.png"></p>
<p>从低层次胶囊到高层次胶囊的计算细节，主要分为 3 个步骤：  </p>
<ul>
<li><p>affine transform  </p>
</li>
<li><p>weighting and sum  </p>
</li>
<li><p>squash</p>
</li>
</ul>
<p><img src="/2019/01/19/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-%E5%86%8D%E7%9C%8B-Capsules-%E4%BB%A5%E5%8F%8A-capsules-%E5%9C%A8%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E4%B8%8A%E7%9A%84%E5%BA%94%E7%94%A8/02.png"></p>
<p><img src="/2019/01/19/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-%E5%86%8D%E7%9C%8B-Capsules-%E4%BB%A5%E5%8F%8A-capsules-%E5%9C%A8%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E4%B8%8A%E7%9A%84%E5%BA%94%E7%94%A8/03.png"></p>
<p>如果考虑更多的胶囊，可以抽象到下面这张图。</p>
<p><img src="/2019/01/19/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-%E5%86%8D%E7%9C%8B-Capsules-%E4%BB%A5%E5%8F%8A-capsules-%E5%9C%A8%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E4%B8%8A%E7%9A%84%E5%BA%94%E7%94%A8/01.png"></p>
<p>我们只关注其中的某一部分就是：</p>
<p><img src="/2019/01/19/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-%E5%86%8D%E7%9C%8B-Capsules-%E4%BB%A5%E5%8F%8A-capsules-%E5%9C%A8%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E4%B8%8A%E7%9A%84%E5%BA%94%E7%94%A8/04.png"></p>
<p>关于从低层次特征如何整合到高层次特征以及这样做的原因是啥，苏同学这里说的是相同透彻了。</p>
<p><img src="/2019/01/19/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-%E5%86%8D%E7%9C%8B-Capsules-%E4%BB%A5%E5%8F%8A-capsules-%E5%9C%A8%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E4%B8%8A%E7%9A%84%E5%BA%94%E7%94%A8/05.png"></p>
<h3 id="动态路由"><a href="#动态路由" class="headerlink" title="动态路由"></a>动态路由</h3><p>在前面的blog中我们差不多能理解：动态路由实际上就是 低层次的胶囊将部分的自己交付给高层次的胶囊，而这个部分的权重却又取决于 低层次胶囊和高层次胶囊的相关性。</p>
<p>我们原本也是可以通过反向传播来解决这个问题的（不显示的计算出相关性，而是直接用神经网络来代替，不知是否可用梯度下降来处理胶囊？），而 Hinton 使用的动态路由算法可解释更强。</p>
<p>动态路由算法就是来解决这个权重分配的问题。</p>
<p><img src="/2019/01/19/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-%E5%86%8D%E7%9C%8B-Capsules-%E4%BB%A5%E5%8F%8A-capsules-%E5%9C%A8%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E4%B8%8A%E7%9A%84%E5%BA%94%E7%94%A8/06.png"></p>
<p>对于动态路由的理解，苏同学给上了两道小菜。总的理解就是，高层胶囊在启动阶段，我们并不知道它是多少，那么前面的相似度也就没法计算。于是，我们只能初始化一个值，也就是取低层次胶囊的均值。如同上图中第二步将 $b_ij$ 设置成 0，那么低层次胶囊分配给高层次胶囊的权重 $c_{ij}$ 就都是相等的。</p>
<p>$$c_{ij}=\dfrac{exp(b_{ij})}{\sum_k exp(b_ik)}$$</p>
<p>然后反复迭代。说白了，输出是输入的聚类结果，而聚类通常都需要迭代算法，这个迭代算法就称为“动态路由”。至于这个动态路由的细节，其实是不固定的，取决于聚类的算法，比如关于Capsule的新文章《MATRIX CAPSULES WITH EM ROUTING》就使用了Gaussian Mixture Model来聚类。</p>
<h3 id="共享版-or-全连接版"><a href="#共享版-or-全连接版" class="headerlink" title="共享版 or 全连接版"></a>共享版 or 全连接版</h3><h4 id="全连接版"><a href="#全连接版" class="headerlink" title="全连接版"></a>全连接版</h4><p>在 Capsule 中，低层次特征是通过普通的卷积神经网络提取，然后通过一个矩阵变换得到的。其中的 $W$ 是需要学习的参数。$v_j$ 是作为输入 $u_i$ 的某种聚类中心出现的，而从不同角度看输入，得到的聚类结果显然是不一样的。那么为了实现“多角度看特征”，于是可以在每个胶囊传入下一个胶囊之前，都要先乘上一个矩阵做变换.</p>
<p>$$v_j = \text{squash}\sum_i\dfrac{e^{&lt;\hat u_{j|i}, v_j&gt;}}{\sum_k e^{&lt;\hat u_{k|i}, v_k&gt;}}\hat u_{j|i}, \hat u_{j|i}=W_{ij}u_i$$</p>
<p><img src="/2019/01/19/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-%E5%86%8D%E7%9C%8B-Capsules-%E4%BB%A5%E5%8F%8A-capsules-%E5%9C%A8%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E4%B8%8A%E7%9A%84%E5%BA%94%E7%94%A8/07.png"></p>
<h4 id="共享版"><a href="#共享版" class="headerlink" title="共享版"></a>共享版</h4><p>全连接层只能处理定长输入，全连接版的Capsule也不例外。而CNN处理的图像大小通常是不定的，提取的特征数目就不定了，这种情形下，全连接层的Capsule就不适用了。因为在前一图就可以看到，参数矩阵的个数等于输入胶囊数目乘以输出胶囊数目，既然输入数目不固定，那么就不能用全连接了。</p>
<p>所以跟CNN的权值共享一样，我们也需要一个权值共享版的Capsule。所谓共享版，是指对于固定的上层胶囊j，它与所有的底层胶囊的连接的变换矩阵是共用的，即 $W_{ji}≡W_j$.</p>
<p><img src="/2019/01/19/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-%E5%86%8D%E7%9C%8B-Capsules-%E4%BB%A5%E5%8F%8A-capsules-%E5%9C%A8%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E4%B8%8A%E7%9A%84%E5%BA%94%E7%94%A8/08.png"></p>
<p>采用 Hiton 论文中的参数来计算就是：  </p>
<ul>
<li><p>输入 [batch, 6, 6, 32, 8]=[batch, 1152, 8], 输入有 6x6x32=1152 个 capsules.  </p>
</li>
<li><p>输出 [batch, 16, 10]， 输出有 10 个 capsules.  </p>
</li>
</ul>
<p>对于全连接版，权重参数是 $1152\times 8\times 16\times N + 1152\times N + 1152\times N$. N 表示 low-level capsules 的数目。  </p>
<p>对于共享版， 权重参数是 $8\times 16\times 1152 + 1152 + 1152$.</p>
<h3 id="反向传播"><a href="#反向传播" class="headerlink" title="反向传播"></a>反向传播</h3><p>现在又有了 $W_{ji}$，那么这些参数怎么训练呢？答案是反向传播。读者也许比较晕的是：现在既有动态路由，又有反向传播了，究竟两者怎么配合？其实这个真的就最简单不过了。从形式上来看，就是往模型中添加了三层罢了，剩下的该做什么还是什么，最后构建一个loss来反向传播。</p>
<p>这样看来，Capsule里边不仅有反向传播，而且只有反向传播，因为动态路由已经作为了模型的一部分，都不算在迭代算法里边了。</p>
<h2 id="capsules-在文本分类上的应用"><a href="#capsules-在文本分类上的应用" class="headerlink" title="capsules 在文本分类上的应用"></a>capsules 在文本分类上的应用</h2><p><a target="_blank" rel="noopener" href="https://www.paperweekly.site/papers/1811">Investigating Capsule Networks with Dynamic Routing for Text Classification</a>  </p>
<h3 id="Model-Architecture"><a href="#Model-Architecture" class="headerlink" title="Model Architecture"></a>Model Architecture</h3><p><img src="/2019/01/19/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-%E5%86%8D%E7%9C%8B-Capsules-%E4%BB%A5%E5%8F%8A-capsules-%E5%9C%A8%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E4%B8%8A%E7%9A%84%E5%BA%94%E7%94%A8/10.png"></p>
<h4 id="N-gram-Convolutional-Layer"><a href="#N-gram-Convolutional-Layer" class="headerlink" title="N-gram Convolutional Layer"></a>N-gram Convolutional Layer</h4><p>普通的卷积操作。  </p>
<p>输入：[batch, L, embed_size, 1]  </p>
<p>输出：[batch, L-k1+1, 1, B]  </p>
<p>其中：  </p>
<ul>
<li><p>kernel: [k1, embed_size, 1, B]</p>
</li>
<li><p>B 表示卷积核的个数  </p>
</li>
<li><p>k1 是sentence 长度维度上的 sliding-window 尺寸</p>
</li>
</ul>
<h4 id="Primary-Capsule-Layer"><a href="#Primary-Capsule-Layer" class="headerlink" title="Primary Capsule Layer"></a>Primary Capsule Layer</h4><p>初始化成 capsules, 但依然只是简单的卷积操作。  </p>
<p>输入：[batch, L-k1+1, 1, B]  </p>
<p>输出：[batch, L-k1+1, 1, C, d]</p>
<p>其中：  </p>
<ul>
<li><p>d 表示 capsule 的维度</p>
</li>
<li><p>实际上依然是普通的卷积操作，不同的是，原本是从 channels B 到 channels C.现在每个 channels C 对应的有 d 个。也就是初始化的 capsules.  </p>
</li>
<li><p>kernel: [1, 1, B, C<em>d], 实现时先生成 C</em>d channels, 然后 split.  </p>
</li>
</ul>
<h4 id="Convolutional-Capsule-Layer"><a href="#Convolutional-Capsule-Layer" class="headerlink" title="Convolutional Capsule Layer"></a>Convolutional Capsule Layer</h4><p>从低层次 feature 到高层次 feature, 在 Hinton 中是capsules版的全连接，在这里是 capsules 版的卷积操作，其中涉及到动态路由算法。</p>
<p>输入：[batch, L-k1+1, 1, C, d]  </p>
<p>输出：[batch, L-k1-k2+2, 1, D, d]  </p>
<p>其中：  </p>
<ul>
<li><p>输出的 capsules 维度依旧是 d  </p>
</li>
<li><p>但是 capsules 的个数发生了变化，在 Hinton 论文中是通过全连接维度的变换，这里是通过卷积的操作来实现 capsules 个数的变换的。  </p>
</li>
</ul>
<p>与 Hinton 的论文类似，第一步是 affine transform 矩阵变换操作，在这篇 paper 中，作者提出了两种方式，实际上就是苏同学博客中的全连接版和共享版（低层次的 capsules 是否共享同样的矩阵变换参数）。  </p>
<ul>
<li><p>shared: $W\in R^{N\times d\times d}$. N 是 capsules 的个数  </p>
</li>
<li><p>no-shared: $W\in R^{H\times N\times d\times d}$.H 是低维的 capsules 的个数。</p>
</li>
</ul>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2019-01-17T14:01:22.000Z" title="2019/1/17 下午10:01:22">2019-01-17</time>发表</span><span class="level-item"><time dateTime="2021-07-06T03:15:36.753Z" title="2021/7/6 上午11:15:36">2021-07-06</time>更新</span><span class="level-item"><a class="link-muted" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/">论文笔记</a><span> / </span><a class="link-muted" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/capsules/">capsules</a></span><span class="level-item">35 分钟读完 (大约5258个字)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2019/01/17/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-Capsules-Network/">Dynamic Routing Between Capsules</a></h1><div class="content"><ul>
<li><p>paper: <a target="_blank" rel="noopener" href="http://papers.nips.cc/paper/6975-dynamic-routing-between-capsules">Dynamic Routing Between Capsules</a>  </p>
</li>
<li><p>blog: <a target="_blank" rel="noopener" href="https://medium.com/ai%C2%B3-theory-practice-business/understanding-hintons-capsule-networks-part-i-intuition-b4b559d1159b">Understanding Hinton’s Capsule Networks.</a>  </p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://www.zhihu.com/search?type=content&q=capsules%20%E8%AF%A6%E8%A7%A3">浅析第一篇Capsule：Dynamic Routing Between Capsules</a></p>
</li>
</ul>
<h2 id="Part-1-Intution"><a href="#Part-1-Intution" class="headerlink" title="Part 1, Intution"></a>Part 1, Intution</h2><h3 id="CNN-是如何工作的？"><a href="#CNN-是如何工作的？" class="headerlink" title="CNN 是如何工作的？"></a>CNN 是如何工作的？</h3><ul>
<li><p>浅层的卷积层会检测一些简单的特征，例如边缘和颜色渐变。  </p>
</li>
<li><p>更高层的 layer 使用卷积操作将简单的特征加权合并到更复杂的特征中。   </p>
</li>
<li><p>最后，网络顶部的网络层会结合这些非常高级的特征去做分类预测。</p>
</li>
</ul>
<p>在第二步中，需要理解的是，CNN 是通过加权求和的方式将低层次的特征组合到高层次的特征的(weighted, added, nonlinear)。在这个过程中，简单的特征在组合成更复杂的特征之前，他们之间是存在位置关系的(pose translation and ratational)。</p>
<p>对于这个位置关系的问题，CNN 是通过 max pooling/successive convolution layer 来解决这个问题的。通过减小图像的尺寸，增加高层神经元的感受野（field of view），这使得他们能在更大的区域内检测出更高阶的特征。</p>
<h3 id="CNN-存在的问题"><a href="#CNN-存在的问题" class="headerlink" title="CNN 存在的问题"></a>CNN 存在的问题</h3><p>但是不要被 CNN 的表现好所迷惑，尽管 CNN 的表现优于其他模型。Hinton认为：max pooling工作得这么好其实是一个大灾难。</p>
<blockquote>
<p>Hinton: “The pooling operation used in convolutional neural networks is a big mistake and the fact that it works so well is a disaster.”</p>
</blockquote>
<p>就算你不使用max pooling，传统CNN依然存在这样的关键问题，学习不到简单与复杂对象之间的重要的空间层次特征。</p>
<blockquote>
<p>Internal data representation of a convolutional neural network does not take into account important spatial hierarchies between simple and complex objects.</p>
</blockquote>
<ul>
<li>CNN只关注要检测的目标是否存在，而不关注这些组件之间的位置和相对的空间关系。如下例，CNN判断人脸只需要检测出它是否存在两个眼睛，两个眉毛，一个鼻子和一个嘴唇，现在我们把右眼和嘴巴换个位置，CNN依然认为这是个人。</li>
</ul>
<p><img src="/2019/01/17/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-Capsules-Network/01.png"></p>
<blockquote>
<p>个人理解：神经网络能否具备模糊识别的能力？比如仅仅是鼻子和眼睛调换了位置，但是大致看起来依然是一张人脸。神经网络能否像我们人类一样，知道这张图片想去表达一张人脸，只不过有些地方除了问题，那么它是否知道问题出在哪儿了呢？而不仅仅是识别的问题对吧？  </p>
</blockquote>
<p>再比如在文本领域，一两个字颠倒顺序并不影响我们人类阅读，神经网络也能理解它的意思，但是能否准确的知道这两个字顺序是颠倒的呢？  </p>
<p>这能否作为一个课题。。神经网络纠错。。当然，如果给出了错误的数据集，那也就是监督学习以及分类的问题，能不能在没有给出这个有部分错误的数据情况下，依旧识别出来呢？</p>
<ul>
<li>CNN 对旋转不具备不变性，学不到 3D 空间信息。例如下面的自由女神，我们只看自由女神的一张照片，我们可能没有看过其它角度的照片，还是能分辨出这些旋转后的照片都是自由女神，也就是说，图像的内部表征不取决于我们的视角。但是CNN做这个事情很困难，因为它无法理解3D空间。</li>
</ul>
<p><img src="/2019/01/17/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-Capsules-Network/02.png"></p>
<ul>
<li>另外，神经网络一般需要学习成千上万个例子。人类学习数字，可能只需要看几十个个例子，最多几百个，就能区别数字。但是CNN需要成千上万个例子才能达到比较好的效果，强制去学习。并且关于前面的旋转不变性，CNN可以通过增强数据的手段去改善，但是这也就需要用到大量的数据集。</li>
</ul>
<h3 id="Hardcoding-3D-World-into-a-Neural-Net-Inverse-Graphics-Approach"><a href="#Hardcoding-3D-World-into-a-Neural-Net-Inverse-Graphics-Approach" class="headerlink" title="Hardcoding 3D World into a Neural Net: Inverse Graphics Approach"></a>Hardcoding 3D World into a Neural Net: Inverse Graphics Approach</h3><p>Capsules 就是为了解决这些问题。其灵感来源于计算机图形学中的渲染技术。</p>
<blockquote>
<p>Computer graphics deals with constructing a visual image from some internal hierarchical representation of geometric data.  </p>
</blockquote>
<p>在计算机图形领域，是通过几何数据的内部层次表示来重构一个视觉图像的。这项技术叫 “渲染 (rendering)”.</p>
<blockquote>
<p>Inspired by this idea, Hinton argues that brains, in fact, do the opposite of rendering. He calls it inverse graphics: from visual information received by eyes, they deconstruct a hierarchical representation of the world around us and try to match it with already learned patterns and relationships stored in the brain. This is how recognition happens. And the key idea is that representation of objects in the brain does not depend on view angle.  </p>
</blockquote>
<p>Hiton 认为大脑是反向渲染的一个过程。接受视觉信息，然后对这样一个具有层次的信息表示进行解构，并与我们已知的模式进行匹配。这里的关键是对象信息的表示在大脑中是不依赖于某一个视角的。</p>
<blockquote>
<p>So at this point the question is: how do we model these hierarchical relationships inside of a neural network?  </p>
</blockquote>
<p>那么我们如何通过神经网络对一个层次信息进行建模呢？</p>
<h3 id="Capsules"><a href="#Capsules" class="headerlink" title="Capsules"></a>Capsules</h3><blockquote>
<p>Capsules introduce a new building block that can be used in deep learning to better model hierarchical relationships inside of internal knowledge representation of a neural network.</p>
</blockquote>
<p><img src="/2019/01/17/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-Capsules-Network/04.png"></p>
<ul>
<li><p>Capsule可以学习到物体之间的位置关系，例如它可以学习到眉毛下面是眼睛，鼻子下面是嘴唇，可以减轻前面的目标组件乱序问题。  </p>
</li>
<li><p>Capsule可以对3D空间的关系进行明确建模，capsule可以学习到上面和下面的图片是同一个类别，只是视图的角度不一样。Capsule可以更好地在神经网络的内部知识表达中建立层次关系  </p>
</li>
<li><p>Capsule只使用CNN数据集的一小部分，就能达到很好的结果，更加接近人脑的思考方式，高效学习，并且能学到更好的物体表征。</p>
</li>
</ul>
<p>小结：这一节引用了capsule的概念，可以用于深度学习，更好地在神经网络的内部知识表达中建立层次关系，并用不同的方法去训练这样一个神经网络。</p>
<h2 id="Part2-How-Capsules-Work"><a href="#Part2-How-Capsules-Work" class="headerlink" title="Part2, How Capsules Work"></a>Part2, How Capsules Work</h2><h3 id="What-is-a-Capsule"><a href="#What-is-a-Capsule" class="headerlink" title="What is a Capsule?"></a>What is a Capsule?</h3><p>CNN 在解决视角的不变性时是通过 max pooling 解决的。选择一块区域的最大值，这样我们就能得到激活的不变性(invariance of activities). 不变性意味着，稍微改变输入的一小部分，输出依旧不变。并且，在图像中移动我们识别的目标，我们依然能检测出这个目标来。</p>
<p>但是 max pooling 会丢失很多信息，并且 CNN 不能编码特征之间的相对空间关系。所以采用 capsules.</p>
<blockquote>
<p>Capsules encapsulate all important information about the state of the feature they are detecting in vector form.</p>
</blockquote>
<ul>
<li><p>Capsule 是一个神经元向量（activity vector）  </p>
</li>
<li><p>这个向量的模长表示某个entity存在的概率，entity可以理解为比如鼻子，眼睛，或者某个类别，因为用vector的模长去表示概率，所以我们要对vector进行压缩，把vector的模长压缩到小于1，并且不改变orientation，保证属性不变化。  </p>
</li>
<li><p>这个向量的方向表示entiry的属性（orientation），或者理解为这个vector除了长度以外的不同形态的instantiation parameter，比如位置，大小，角度，形态，速度，反光度，颜色，表面的质感等等。  </p>
</li>
</ul>
<h3 id="How-does-a-capsule-work"><a href="#How-does-a-capsule-work" class="headerlink" title="How does a capsule work?"></a>How does a capsule work?</h3><p><img src="/2019/01/17/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-Capsules-Network/06.png"></p>
<p>传统神经元是一个 scaler, 神经元与神经元之间通过加权求和的方式连接。其计算方式：  </p>
<ul>
<li><p>计算输入标量 $x_i$ 的权重 $w_i$  </p>
</li>
<li><p>对输入标量 $x_i$ 进行加权求和  </p>
</li>
<li><p>通过非线性激活函数，进行标量与标量之间的变换，得到新标量 $h_j$</p>
</li>
</ul>
<p><img src="/2019/01/17/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-Capsules-Network/07.png"></p>
<p>capsule 的前向转换的计算方式：</p>
<p><img src="/2019/01/17/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-Capsules-Network/08.png"></p>
<ul>
<li><p>matrix multiplication of input vectors（输入向量 $u_i$ 的矩阵 W 乘法）  </p>
</li>
<li><p>scalar weighting of input vectors（输入向量 $\hat u_i$ 的标量加权 $c_i$）   </p>
</li>
<li><p>sum of weighted input vectors（输入向量的加权求和）  </p>
</li>
<li><p>vector-to-vector nonlinearity（向量到向量的非线性变换）  </p>
</li>
</ul>
<h4 id="输入向量-u-i-的矩阵-W-乘法"><a href="#输入向量-u-i-的矩阵-W-乘法" class="headerlink" title="输入向量 $u_i$ 的矩阵 W 乘法"></a>输入向量 $u_i$ 的矩阵 W 乘法</h4><p>Affine transform:　</p>
<p>$$\hat u_{j|i}=W_{ij}u_i$$</p>
<ul>
<li><p>向量的长度表示低维的胶囊能检测出对应实体的概率。向量的方向则编码了检测对象的中间状态表示。我们可以假设低维胶囊 $u_i$ 分别表示眼睛，嘴巴，鼻子这三个低层次的特征，高维胶囊 $u_j$ 检测脸部高层次特征。  </p>
</li>
<li><p>矩阵 W 编码了低层次特征之间或低层次特征与高层次特征之间的重要的空间或其他关系。  </p>
</li>
<li><p>$u_i$ 乘以相应的权重矩阵 W 得到prediction vector（注意这个图里只画了一个 prediction vector，也就是 $\hat u_i$，因为这里只对应了一个 capsule 输出，如果下一层有 j 个 capusles，$u_i$ 就会生成 j 个 prediction vectors）</p>
</li>
</ul>
<p>例如，矩阵 $W_{2j}$ 可以对鼻子和面部的关系进行编码:面部以鼻子为中心，其大小是鼻子的10倍，而在空间上的方向与鼻子的方向一致。矩阵 $W_{1j}$ 和 $W_{3j}$ 也是类似的。经过矩阵相乘之后，我们可以得到更高层次特征的预测位置。比如，$\hat u_1$ 根据眼睛预测人脸位置，$\hat u_2$ 根据嘴巴预测人脸位置，$\hat u_3$ 根据鼻子预测人脸位置。最后如果这3个低层次特征的预测指向面部的同一个位置和状态，那么我们判断这是一张脸</p>
<p><img src="/2019/01/17/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-Capsules-Network/09.png"></p>
<h4 id="输入向量-hat-u-i-的标量加权-c-i"><a href="#输入向量-hat-u-i-的标量加权-c-i" class="headerlink" title="输入向量 $\hat u_i$ 的标量加权 $c_i$"></a>输入向量 $\hat u_i$ 的标量加权 $c_i$</h4><p>weighting:</p>
<p>$$s_{j|i} = c_{ij}\hat u_{j|i}$$</p>
<p>$$s_{k|i} = c_{ik}\hat u_{k|i}$$</p>
<p>前面提到的传统神经元在这一步对输入进行加权，这些权重是在反向传播过程中得到的，但 Capsule 是通过 dynamic routing 的方式进行交流的。在这一步，低层次 capsule 需要决定怎么把自己的输出分配给高层次capsule。</p>
<p><img src="/2019/01/17/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-Capsules-Network/10.png"></p>
<p>$c_{ij}$ 是耦合系数 (coupling coefficients), 通过迭代动态路由过程来决定。比如上图中的，高层次有两个胶囊 capsule J 和 capsule K. 那么对于 capsule i 通过上一步的矩阵 W 就可以得到 $\hat u_{j|i}, \hat u_{k|i}$, 他们对应的权重分别是 $c_{ij}, c_{ik}$, 并且有 $c_{ij} + c_{ik} = 1$.</p>
<p>在动态路由的过程中是如何确定权重的呢，Routing by agreement：  </p>
<ul>
<li><p>在这张图片中，我们现在有一个低层次的已经被激活的capsule，它对下层每个capsule会生成一个prediction vector，所以这个低层次capsule现在有两个prediction vector，对这两个prediction vectors分配权重分别输入到高层次capsule J和K中。  </p>
</li>
<li><p>现在，更高层次的capsule已经从其他低层次的capsule中获得了许多输入向量，也就是图片中的点，标红的部分是聚集的点，当这些聚集点意味着较低层次的capsule的预测是相互接近的。  </p>
</li>
<li><p>低层次capsule希望找到高一层中合适的capsule，把自己更多的vector托付给它。低层次capsule通过dynamic routing的方式去调整权重c。</p>
</li>
</ul>
<p>例如，如果低层次capsule的prediction vector远离capsule J中“correct”预测的红色集群，并且接近capsule K 中的“true”预测的红色集群，那么低层次capsule就会调高capsule K对应的权重，降低capsule J对应的权重。最后，如果高层次capsule接收到的这些prediction都agree这个capsule，那么这个capsule就会被激活，处于active状态，这就叫Routing by agreement。</p>
<h4 id="加权输入向量的总和"><a href="#加权输入向量的总和" class="headerlink" title="加权输入向量的总和"></a>加权输入向量的总和</h4><p>sum:  </p>
<p>$$s_j = \sum_i c_{ij}\hat u_{j|i}$$</p>
<p>高层次capsule根据前面计算的权重c，对所有低层次capsule的prediction vectors进行加权，得到一个向量。</p>
<h4 id="向量到向量的非线性变换"><a href="#向量到向量的非线性变换" class="headerlink" title="向量到向量的非线性变换"></a>向量到向量的非线性变换</h4><p>Squashing是一种新的激活函数，我们对前面计算得到的向量施加这个激活函数，把这个向量的模长压缩到1以下，同时不改变向量方向，这样我们就可以利用模长去预测概率，并且保证属性不变化。</p>
<p><img src="/2019/01/17/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-Capsules-Network/11.png"></p>
<p>这个公式的左边是变换尺度，右边是单位向量。</p>
<p>小结：这一节介绍了capsule的基本概念，capsule把单个神经元扩展到神经元向量，有更强大的特征表征能力，并且引入矩阵权重来对不同layer特性之间的重要层次关系进行编码，结果说明了以下两种性质：</p>
<ul>
<li><p>Invariance 不变性：物体表示不随变换变化，例如空间的 Invariance，是对物体平移之类不敏感（物体不同的位置不影响它的识别)   </p>
</li>
<li><p>Equivariance同变性：用变换矩阵进行转换后，物体表示依旧不变，这是对物体内容的一种变换</p>
</li>
</ul>
<h2 id="Part-3-Dynamic-Routing-Between-Capsules"><a href="#Part-3-Dynamic-Routing-Between-Capsules" class="headerlink" title="Part 3, Dynamic Routing Between Capsules"></a>Part 3, Dynamic Routing Between Capsules</h2><p>算法的核心思想：  </p>
<blockquote>
<p>Lower level capsule will send its input to the higher level capsule that “agrees” with its input. This is the essence of the dynamic routing algorithm.</p>
</blockquote>
<p>动态路由算法的设计是为了动态调整 $c_{ij}$ 的值：   </p>
<ul>
<li><p>$c_{ij}$ 为非负 scalar  </p>
</li>
<li><p>对于每一个的 low level capsule i，所有的权重之和 $c_{ij}$ 为 1，j 表示 high-level capsule j.  </p>
</li>
<li><p>对于每一个 low-level capsule, 对应的权重数量等于 high-level 的数量  </p>
</li>
<li><p>权重由动态路由算法确定  </p>
</li>
</ul>
<p><img src="/2019/01/17/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-Capsules-Network/12.png"></p>
<p>下面我们逐行解释伪代码：  </p>
<ol>
<li><p>这个过程的输入是 第 $l$ 层的 capsule 经过矩阵变换之后的 prediction vector $\hat u$. 迭代步数 r  </p>
</li>
<li><p>初始化 $b_{ij}$ 为 0， $b_{ij}$ 是用来计算 $c_{ij}$ 的  </p>
</li>
<li><p>对接下来4-6行代码迭代r次，计算第 $l+1$ 层 capsule j 的 output  </p>
</li>
<li><p>在第 $l$ 层，每个 capsule i 对 $b_{ij}$ 做 softmax 得到 $c_{ij}$，$c_{ij}$ 是第 $l$ 层 capsule i 给第 $l+1$ 层 capsule j 分配的权重。在第一次迭代的时候，所有的 $b_{ij}$ 都初始化为 0，所以这里得到的 $c_{ij}$ 都是相等的概率，当然后面迭代多次后，$c_{ij}$ 的值会有更新。  </p>
</li>
<li><p>在第 $l+1$ 层，每个 capsule j 利用 $c_ij$ 对 $\hat u_j|i$ 进行加权求和，得到输出向量 $s_j$  </p>
</li>
<li><p>在第 $l+1$ 层，使用squash激活函数对 $s_j$ 做尺度的变换，压缩其模长不大于1  </p>
</li>
<li><p>我们在这一步更新参数，对所有的 $l$ 层 capsule i和 $l+1$ 层 capsule j，迭代更新 $b_{ij}$，更新 $b_{ij}$ 为旧 $b_{ij}$ + capsule j 的输入和输出的点乘，这个点乘是为了衡量这个 capsule 的输入和输出的相似度，低层 capsule 会把自己的输出分给跟它相似的高层 capsule。  </p>
</li>
</ol>
<p>经过r次循环，高层capsule可以确定低层分配的权重以及计算其输出，前向传播可以继续连接到下一个网络层。这个r一般推荐设置为3，次数太多了可能会过拟合。</p>
<p>susht 大佬画的图，不过没有把 $b_{ij}$ 表示出来。 $b_{ij}$ 的参数量和 $c_{ij}$ 以及 $u_{ij}$ 的个数是一致的。</p>
<p><img src="/2019/01/17/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-Capsules-Network/13.png"></p>
<p><img src="/2019/01/17/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-Capsules-Network/14.png"></p>
<ul>
<li><p>假设有两个高层capsule，紫色向量v1和v2分别是这两个capsule的输出，橙色向量是来自低层中某个capsule的输入，黑色向量是低层其它capsule的输入。  </p>
</li>
<li><p>左边的capsule，橙色u_hat跟v1方向相反，也就是这两个向量不相似，它们的点乘就会为负，更新的时候会减小对应的c_11数值。右边的capsule，橙色u_hat跟v2方向相近，更新的时候就会增大对应的c_12数值。  </p>
</li>
<li><p>那么经过多次迭代更新，所有的routing权重c都会更新到这样一种程度：对低层capsule的输出与高层capsule的输出都进行了最佳匹配。</p>
</li>
</ul>
<p>小结：这节介绍了 dynamic routing algorithm by agreement 的方式去训练 capsNet，主要 idea 是通过点乘去衡量两个 capsule 输出的相似度，并且更新routing的权重参数。</p>
<h2 id="CapsNet-Architecture"><a href="#CapsNet-Architecture" class="headerlink" title="CapsNet Architecture"></a>CapsNet Architecture</h2><p>论文给出了一个简单的CapsNet模型，第一层是个普通的conv层，第两层也结合了conv操作去构建初始的capsule，再通过routing的方式和第三层的DigitCaps交流，最后利用DigitCaps的capsule去做分类。</p>
<p><img src="/2019/01/17/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-Capsules-Network/15.png"></p>
<ul>
<li>ReLU Conv1: 这是一个普通的卷积层，参数量是 $9\times 9\times 256$, 假设输入是 $28\times 28\times 1$, 得到的输出是 $20\times 20\times 256$.</li>
</ul>
<ul>
<li>PrimaryCaps: 这里构建了 32 个 channels 的 capsules, 每个 capsule 的向量维度是 8. 依旧是采用卷积的方法，每一个 channels 使用 8 个卷积核 $9\times 9$. 所以总的参数量是 $9\times 9\times 256 \times 32\times 8 + 32 \times 8= 5308672$。 一个 channels 对应一个 feature map，在这里是 $6\times 6$ 个 8 维的 capsules.  所以最后是 $6\times 6\times 32=1152$ 个 capsules。</li>
</ul>
<ul>
<li>DigitCaps: 对前面1152个capules进行传播与routing更新，输入是1152个capsules，输出是10个capules，每个 capsule 的维度由 8 变成了 16，表示10个数字类别，最后我们用这10个capules去做分类. 总的参数量是 $1152\times 8\times 16+1152+1152=149760$. 后面两个 1152 分别表示 $b_{ij}, c_{ij}$.</li>
</ul>
<h3 id="loss-function"><a href="#loss-function" class="headerlink" title="loss function"></a>loss function</h3><p>在 dynamic routing 过程中我们更新了 $c_{ij}$ 参数，其余参数是通过反向传播进行更新，这里对于每一个capsule k我们都计算它的 Margin loss损失函数 $L_k$</p>
<p><img src="/2019/01/17/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-Capsules-Network/16.png"></p>
<p>跟 SVM 的 loss function 非常类似。  </p>
<p>$$L_i = \sum_{j\neq y_i} \max(0, s_j - s_{y_i} + \Delta)$$</p>
<ul>
<li><p>不同的是，这里设定了 正类的概率 越小于 $m^+=0.9$ 其贡献的 loss 越小，负类的概率越大于 $m^-=0.1$ 其贡献的 loss 越大。</p>
</li>
<li><p>$\lambda$ 参数设置为0.5，这是为了防止负例减小了所有capsule向量的模长。</p>
</li>
</ul>
<p><img src="/2019/01/17/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-Capsules-Network/17.png"></p>
<h3 id="Decoder-reconstruction-as-a-regularization-method"><a href="#Decoder-reconstruction-as-a-regularization-method" class="headerlink" title="Decoder: reconstruction as a regularization method"></a>Decoder: reconstruction as a regularization method</h3><p><img src="/2019/01/17/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-Capsules-Network/18.png"></p>
<p>这里会mask掉一些capsule，用有代表性的capsule去重构图像，通过几层全连接层得到784维的输出，也就是原始图像的像素点个数，以这个输出跟原始像素点的欧几里得距离作为重构损失函数。</p>
<p><img src="/2019/01/17/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-Capsules-Network/19.png"></p>
<h2 id="CapsNet与CNN的联系"><a href="#CapsNet与CNN的联系" class="headerlink" title="CapsNet与CNN的联系"></a>CapsNet与CNN的联系</h2><p>相同之处：CNN可以上下左右平移在图像上进行扫描，也就是它在这个地方学到的东西可以用到下一个地方，可以有效识别图片的内容，所以capsule也采用了convolution的特点，最后一层只用capsule.</p>
<p>不同之处：capsule不采用max pooling的做法，因为Max pooling只保留了区域内最好的特征，而忽视了其它的特征，routing并不会丢失这些信息，它可以高效处理高度层叠的例子。浅层capsule会把位置信息通过place-coded的方式记录在激活的capsule中，高层的capsule会通过rate-coded的方式记录在capsule vector的值当中。</p>
<p>Capsules做分类的优点</p>
<p>适合输出有多个类别的多分类问题，softmax只适合只有一个输出的多分类问题，因为softmax会提高某一类的概率，而压低其余所有类别的概率。  </p>
<p>另外，我们也可以用k sigmoid去代替softmax，把多分类任务转换成K个二分类任务.</p>
</div></article></div></div><!--!--><div class="column column-right is-4-tablet is-4-desktop is-4-widescreen  order-3"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar" src="/img/avatar.png" alt="panxiaoxie"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">panxiaoxie</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Beijing, China</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">文章</p><a href="/archives"><p class="title">116</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">分类</p><a href="/categories"><p class="title">38</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">标签</p><a href="/tags"><p class="title">35</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/PanXiebit" target="_blank" rel="noopener">关注我</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/PanXiebit"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Email" href="/ftdpanxie@gmail.com"><i class="fa fa-envelope"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="RSS" href="/"><i class="fas fa-rss"></i></a></div></div></div><!--!--><div class="card widget" data-type="links"><div class="card-content"><div class="menu"><h3 class="menu-label">链接</h3><ul class="menu-list"><li><a class="level is-mobile" href="https://github.com/PanXiebit" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">github</span></span><span class="level-right"><span class="level-item tag">github.com</span></span></a></li><li><a class="level is-mobile" href="ftdpanxie@gmail.com" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">email</span></span><span class="level-right"><span class="level-item tag">ftdpanxie@gmail.com</span></span></a></li></ul></div></div></div><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">分类</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/C/"><span class="level-start"><span class="level-item">C++</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/CSAPP/"><span class="level-start"><span class="level-item">CSAPP</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/DRL/"><span class="level-start"><span class="level-item">DRL</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/GAN/"><span class="level-start"><span class="level-item">GAN</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li><li><a class="level is-mobile" href="/categories/GAN-RL/"><span class="level-start"><span class="level-item">GAN, RL</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/ML/"><span class="level-start"><span class="level-item">ML</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/NLP/"><span class="level-start"><span class="level-item">NLP</span></span><span class="level-end"><span class="level-item tag">14</span></span></a></li><li><a class="level is-mobile" href="/categories/TensorFlow/"><span class="level-start"><span class="level-item">TensorFlow</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/cs224d/"><span class="level-start"><span class="level-item">cs224d</span></span><span class="level-end"><span class="level-item tag">10</span></span></a></li><li><a class="level is-mobile" href="/categories/generation/"><span class="level-start"><span class="level-item">generation</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/interview/"><span class="level-start"><span class="level-item">interview</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/machine-translation/"><span class="level-start"><span class="level-item">machine translation</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/python/"><span class="level-start"><span class="level-item">python</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/pytorch/"><span class="level-start"><span class="level-item">pytorch</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/reinforcement-learning/"><span class="level-start"><span class="level-item">reinforcement learning</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/sign-language-recognition/"><span class="level-start"><span class="level-item">sign language recognition</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/transfer-learning/"><span class="level-start"><span class="level-item">transfer learning</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"><span class="level-start"><span class="level-item">数据结构与算法</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile" href="/categories/%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB/"><span class="level-start"><span class="level-item">文本分类</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"><span class="level-start"><span class="level-item">论文笔记</span></span><span class="level-end"><span class="level-item tag">40</span></span></a><ul><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/DL/"><span class="level-start"><span class="level-item">DL</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/ESA/"><span class="level-start"><span class="level-item">ESA</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/GAN/"><span class="level-start"><span class="level-item">GAN</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/MRC-and-QA/"><span class="level-start"><span class="level-item">MRC and QA</span></span><span class="level-end"><span class="level-item tag">7</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/Machine-Translation/"><span class="level-start"><span class="level-item">Machine Translation</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/NLP/"><span class="level-start"><span class="level-item">NLP</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/Transformer/"><span class="level-start"><span class="level-item">Transformer</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/capsules/"><span class="level-start"><span class="level-item">capsules</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/computer-vision/"><span class="level-start"><span class="level-item">computer vision</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/constrast-learning/"><span class="level-start"><span class="level-item">constrast learning</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/data-augmentation/"><span class="level-start"><span class="level-item">data augmentation</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/dialogue-system/"><span class="level-start"><span class="level-item">dialogue system</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/language-model/"><span class="level-start"><span class="level-item">language model</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/machine-translation/"><span class="level-start"><span class="level-item">machine translation</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/open-set-recognition/"><span class="level-start"><span class="level-item">open set recognition</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/sentence-embedding/"><span class="level-start"><span class="level-item">sentence embedding</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/text-matching/"><span class="level-start"><span class="level-item">text matching</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/vision-language/"><span class="level-start"><span class="level-item">vision-language</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li></ul></div></div></div></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/panxiaoxie.png" alt="潘小榭" height="28"></a><p class="is-size-7"><span>&copy; 2021 Xie Pan</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("zh-CN");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="回到顶端" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "此网站使用Cookie来改善您的体验。",
          dismiss: "知道了！",
          allow: "允许使用Cookie",
          deny: "拒绝",
          link: "了解更多",
          policy: "Cookie政策",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.5/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="想要查找什么..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"想要查找什么...","untitled":"(无标题)","posts":"文章","pages":"页面","categories":"分类","tags":"标签"});
        });</script></body></html>