<!doctype html>
<html lang="zh"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>潘小榭</title><link rel="manifest" href="/manifest.json"><meta name="theme-color" content="black"><meta name="application-name" content="panxiaoxie"><meta name="msapplication-TileImage" content="/img/avatar.png"><meta name="msapplication-TileColor" content="black"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="panxiaoxie"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta property="og:type" content="blog"><meta property="og:title" content="panxiaoxie"><meta property="og:url" content="https://github.com/PanXiebit"><meta property="og:site_name" content="panxiaoxie"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://www.qt86.com/cache/1625298592_187938.png"><meta property="article:author" content="panxiaoxie"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="https://www.qt86.com/cache/1625298592_187938.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"http://www.panxiaoxie.cn"},"headline":"潘小榭","image":["http://www.panxiaoxie.cn/img/og_image.png"],"author":{"@type":"Person","name":"Xie Pan"},"publisher":{"@type":"Organization","name":"潘小榭","logo":{"@type":"ImageObject","url":"http://www.panxiaoxie.cn/img/panxiaoxie.png"}},"description":null}</script><link rel="icon" href="/img/avatar.png"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/css/justifiedGallery.min.css"><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script><!--!--><!--!--><meta name="generator" content="Hexo 5.4.0"></head><body class="is-2-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/panxiaoxie.png" alt="潘小榭" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">主页</a><a class="navbar-item" href="/archives">归档</a><a class="navbar-item" href="/categories">分类</a><a class="navbar-item" href="/tags">标签</a><a class="navbar-item" href="/about">关于我</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/PanXiebit"><i class="fab fa-github"></i></a><a class="navbar-item search" title="搜索" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-10-widescreen"><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2018-12-19T00:35:58.000Z" title="2018/12/19 上午8:35:58">2018-12-19</time>发表</span><span class="level-item"><time dateTime="2021-06-29T08:12:08.539Z" title="2021/6/29 下午4:12:08">2021-06-29</time>更新</span><span class="level-item"><a class="link-muted" href="/categories/NLP/">NLP</a></span><span class="level-item">8 分钟读完 (大约1186个字)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2018/12/19/AI-challenger-%E5%8F%82%E4%BC%9A%E8%AE%B0%E5%BD%95/">AI challenger 参会记录</a></h1><div class="content"><p>答辩听了观点型阅读理解和细粒度情感分类两个，相对来说后者更加干货满满，大佬云集的，基本上代表了国内 NLP 的四座大山，清/北/中科院/哈工大。造成前者干货较少的主要原因作为主持人的搜狗大佬也说了， BERT 的提出在阅读理解这样更加需要上下文理解任务的提升实在太多，使得选手的其它工作都黯然失色，导致大家的模型都趋向同一化。而 BERT 对于分类任务的提升就相对较少了，所以下午的答辩显得更加丰富，各种操作和 trick. 但也有选手说 BERT 作为单模型对这个分类任务依然能取得很不错的效果，所以 BERT 是真强啊</p>
<p>因为答辩的屏幕是真小，根本看不清楚。。所以记录会很零散，也许只是些关键词，后续还需要自行 google.</p>
<h2 id="观点型阅读理解"><a href="#观点型阅读理解" class="headerlink" title="观点型阅读理解"></a>观点型阅读理解</h2><p><img src="/2018/12/19/AI-challenger-%E5%8F%82%E4%BC%9A%E8%AE%B0%E5%BD%95/01.png"></p>
<p>取得好成绩的主要操作： 通过简单的正则匹配将三个观点转化为作为 “正/负/无法确定” 的三分类问题。训练集中 95% 的数据可以很准确的转化为这种形式，还有 5% 的是实体类问题，比如 “韩国/美国/无法确定”，有选手的做法是将 query 中对两个实体进行排序，比如韩国在前，美国在后。同样对应的 answer 就是 “韩国/美国/无法确定”. 将文本理解的问题，转换为分类问题之后，对整个模型的复杂度需求就降低太多了。但事实上，这是数据 bug …</p>
<p>模型关键词：  </p>
<ul>
<li>BERT  </li>
</ul>
<ul>
<li>multiway attention + R-Net</li>
</ul>
<ul>
<li>RCZoo  </li>
</ul>
<ul>
<li>浙大大佬的：多层 LSTM 模型，浅层+主要+深层 三个 loss 优化。具体忘了拍照，以及真的看不清楚。。  </li>
</ul>
<ul>
<li>基于 query 的 attention 还是基于 passage 的 attention 作为最终的 answer selection/matching.</li>
</ul>
<p>说句不马后炮的话，这里面大部分我也都想到了啊，只是做与没做，以及用与没用 BERT 。。。</p>
<h2 id="细粒度用户评论情感分析"><a href="#细粒度用户评论情感分析" class="headerlink" title="细粒度用户评论情感分析"></a>细粒度用户评论情感分析</h2><p><img src="/2018/12/19/AI-challenger-%E5%8F%82%E4%BC%9A%E8%AE%B0%E5%BD%95/02.png"></p>
<p><img src="/2018/12/19/AI-challenger-%E5%8F%82%E4%BC%9A%E8%AE%B0%E5%BD%95/03.png"></p>
<h3 id="seq2seq"><a href="#seq2seq" class="headerlink" title="seq2seq"></a>seq2seq</h3><p><img src="/2018/12/19/AI-challenger-%E5%8F%82%E4%BC%9A%E8%AE%B0%E5%BD%95/05.jpeg"></p>
<p>选手这么做的原因是 他觉得各个 粒度 之间存在一定的关联，所以采用 decoder 的形式能有效的利用这些信息。很神奇的操作，是否真的有效朱小燕老师有问到，好像作者并没有做对照实验。</p>
<p><img src="/2018/12/19/AI-challenger-%E5%8F%82%E4%BC%9A%E8%AE%B0%E5%BD%95/06.jpeg"></p>
<ul>
<li>ELMo 提升最多  </li>
</ul>
<ul>
<li>改进的注意力机制，其实就是 multi-head attention  </li>
</ul>
<ul>
<li><strong>PRAUC 损失函数，</strong> 这个我好像在哪儿见过，我不记得了  </li>
</ul>
<p><img src="/2018/12/19/AI-challenger-%E5%8F%82%E4%BC%9A%E8%AE%B0%E5%BD%95/07.jpeg">  </p>
<p>大佬感觉可以发 paper 了。。</p>
<h3 id="others"><a href="#others" class="headerlink" title="others"></a>others</h3><p>其他的也很强，但没有 seq2seq 这么具有特殊性，所以可以一起说。  </p>
<p><img src="/2018/12/19/AI-challenger-%E5%8F%82%E4%BC%9A%E8%AE%B0%E5%BD%95/08.jpeg"></p>
<p>词嵌入部分微调，没太懂？ 哪一部分微调，以及非监督的情况下，如何保证微调的程度</p>
<p><img src="/2018/12/19/AI-challenger-%E5%8F%82%E4%BC%9A%E8%AE%B0%E5%BD%95/09.jpeg"></p>
<p>F1 指标的优化，这个对于 unbalanced 数据看起来比 过/欠 采样有效。以及刘洋老师提到的可以基于 rainforce 对 F1 进行优化</p>
<p>附上刘洋老师照片一张，侧脸看起来真像李健啊，都是清华男神吧～</p>
<p><img src="/2018/12/19/AI-challenger-%E5%8F%82%E4%BC%9A%E8%AE%B0%E5%BD%95/10.jpeg"></p>
<p><img src="/2018/12/19/AI-challenger-%E5%8F%82%E4%BC%9A%E8%AE%B0%E5%BD%95/11.jpeg"></p>
<p>伪朴素贝叶斯特征，PPT 里面说的很清楚～每次输入几个样本其提取的是局部特征，而伪朴素贝叶斯特征能体现一个词的全局特征。感觉很棒啊</p>
<p><img src="/2018/12/19/AI-challenger-%E5%8F%82%E4%BC%9A%E8%AE%B0%E5%BD%95/12.jpeg"></p>
<p>数据增强方式：  </p>
<ul>
<li>drop words 随机 mask  </li>
</ul>
<ul>
<li>shuffle words  打乱词序  </li>
</ul>
<ul>
<li>组合增强策略  </li>
</ul>
<ul>
<li>对抗训练  </li>
</ul>
<p><img src="/2018/12/19/AI-challenger-%E5%8F%82%E4%BC%9A%E8%AE%B0%E5%BD%95/13.jpeg"></p>
<p>模型集成：</p>
<ul>
<li>贪婪式模型选择  </li>
</ul>
<ul>
<li>简单概率平均，最后采取了这种。。。anyway</li>
</ul>
<p><img src="/2018/12/19/AI-challenger-%E5%8F%82%E4%BC%9A%E8%AE%B0%E5%BD%95/15.jpeg"></p>
<p>根据验证集调整分类阈值，对当前的验证集当然会有较大提升。但是对于 测试集 可能出现过拟合，引入正则化和 Ensamble 策略。</p>
<p>$$b_i^j=\text{argmax}_b[\text{marco-}F_1(S^j[:,i]+b)-C|b]$$</p>
<p>第 j 个情感要素第 i 类别上的偏置， C&gt;0 为正则系数。</p>
<p>还有些关键词，有些来不及拍照。。  </p>
<ul>
<li>BiSRU  </li>
</ul>
<ul>
<li>未完待续。。</li>
</ul>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2018-12-17T06:50:31.000Z" title="2018/12/17 下午2:50:31">2018-12-17</time>发表</span><span class="level-item"><time dateTime="2021-06-29T08:12:09.158Z" title="2021/6/29 下午4:12:09">2021-06-29</time>更新</span><span class="level-item"><a class="link-muted" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/">论文笔记</a><span> / </span><a class="link-muted" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/language-model/">language model</a></span><span class="level-item">21 分钟读完 (大约3119个字)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2018/12/17/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/">论文笔记-BERT</a></h1><div class="content"><h2 id="BERT-Bidirectional-Encoder-Representations-from-Transformers"><a href="#BERT-Bidirectional-Encoder-Representations-from-Transformers" class="headerlink" title="BERT(Bidirectional Encoder Representations from Transformers.)"></a>BERT(Bidirectional Encoder Representations from Transformers.)</h2><p>对于 BERT 重点在于理解 Bidirectional 和 masked language model.</p>
<h3 id="Why-Bidirectional"><a href="#Why-Bidirectional" class="headerlink" title="Why Bidirectional?"></a>Why Bidirectional?</h3><p>对于预训练的表示，单向语言模型因为无法融合下文的信息，其能力是非常有限的，尤其是对类似于 SQuAD 这样需要结合上下文信息的任务。</p>
<p>对比 OpenAI GPT 和 BERT. 为什么 OpenAI GPT 不能采用双向 self-attention 呢？</p>
<p>传统的语言模型的定义，计算句子的概率：</p>
<p>$$P(S)=p(w_1,w_2, …, w_n)=p(w1)p(w_2|w_1)…p(w_n|w_1…w_{n-1})=\prod_{i=1}^m p(w_i|w_1…w_{i-1})$$</p>
<p>前向 RNN 语言模型：</p>
<p>$$P(S)=\prod_{i=1}^m p(w_i|w_1…w_{i-1})$$</p>
<p>也就是当前词的概率只依赖前面出现词的概率。</p>
<p>后向 RNN 语言模型  </p>
<p>$$P(S)=\prod_{i=1}^m p(w_i|w_{i+1}…w_{m})$$</p>
<p>也就是当前词的概率只依赖后面出现的词的概率。</p>
<p>ELMo 就是这样的双向语言模型(BiLM)</p>
<p><img src="/2018/12/17/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/02.jpg"></p>
<p>但是 RNN 相比 self-attention 对上下文信息 (contextual information)的利用相对有限，而且 ELMo 只能是一层双向，并不能使用多层。其原因和 GPT 无法使用 双向 编码的原因一样。</p>
<p>对于 GPT 如果它使用双向，那么模型就能准确的学到到句子中的下一个词是什么，并能 100% 的预测出下一个词。比如 “I love to work on NLP.” 在预测 love 的下一个词时，模型能看到 to，所以能很快的通过迭代学习到 “to” 100% 就是 love 的下一个词。所以，这导致模型并不能学到想要的东西（句法、语义信息）。</p>
<p><img src="/2018/12/17/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/03.png"> <img src="/2018/12/17/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/04.png"></p>
<p>那么 BERT 是怎么处理双向这个问题的呢？ 它改变了训练语言模型的任务形式。提出了两种方式 “masked language model” and “next sentence generation”. 再介绍这两种训练方式之前，先说明下输入形式。</p>
<h3 id="Input-representation"><a href="#Input-representation" class="headerlink" title="Input representation"></a>Input representation</h3><p><img src="/2018/12/17/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/05.png"></p>
<ul>
<li><p>position embedding: 跟 Transformer 类似    </p>
</li>
<li><p>sentence embedding, 同一个句子的词的表示一样，都是 $E_A$ 或 $E_B$. 用来表示不同的句子具有不同的含义  </p>
</li>
<li><p>对于 [Question, Answer] 这样的 sentence-pairs 的任务，在句子末尾加上 [SEP].  </p>
</li>
<li><p>对于文本分类这样的 single-sentence 的任务，只需要加上 [CLS], 并且 sentence embedding 只有 $E_A$.</p>
</li>
</ul>
<h3 id="masked-language-model"><a href="#masked-language-model" class="headerlink" title="masked language model"></a>masked language model</h3><p>何为 “masked LM”? idea 来源于 closed tasked. 原本的语言模型是预测所有语料中的下一个词，而 MLM 是在所有的 tokens 中随机选取 15% 的进行 mask，然后只需要预测被 mask 的词。这样以来，就能训练双向语言模型了。</p>
<p>但是存在一个问题，这样 pre-training 训练出来的语言模型并不能拿去做 fine-tune. 原因是在 fine-token 中从来没有见过 &lt;MASK&gt; 这个词。作者采用这样的策略：  </p>
<p>具体的操作，以 “My dog is hairy” 为例，mask “hairy” 这个词：</p>
<ul>
<li><p>“My dog is &lt;MASK&gt;“. 80% 被 <MASK> 代替  </MASK></p>
</li>
<li><p>“My dog is apple”.  10% 被一个随机的 token 代替  </p>
</li>
<li><p>“My dog is hairy”.  10% 保持原来的样子  </p>
</li>
</ul>
<h4 id="为什么不用-lt-MASK-gt-代替所有的-token？"><a href="#为什么不用-lt-MASK-gt-代替所有的-token？" class="headerlink" title="为什么不用 &lt;MASK&gt; 代替所有的 token？"></a>为什么不用 &lt;MASK&gt; 代替所有的 token？</h4><blockquote>
<p>If the model had been trained on only predicting ‘&lt;MASK&gt;’ tokens and then never saw this token during fine-tuning, it would have thought that there was no need to predict anything and this would have hampered performance. Furthermore, the model would have only learned a contextual representation of the ‘&lt;MASK&gt;’ token and this would have made it learn slowly (since only 15% of the input tokens are masked). By sometimes asking it to predict a word in a position that did not have a ‘&lt;MASK&gt;’ token, the model needed to learn a contextual representation of all the words in the input sentence, just in case it was asked to predict them afterwards.  </p>
</blockquote>
<p>如果模型在预训练的时候仅仅只预测 &lt;MASK&gt;, 然后在 fine-tune 的时候从未见过 &lt;MASK&gt; 这个词，那么模型就不需要预测任何词，在 fine-tune 时会影响性能。  </p>
<p>更严重的是，如果仅仅预测 &lt;MASK&gt;, 那么模型只需要学习 &lt;MASK&gt; 的上下文表示，这会导致它学习的很慢。  </p>
<p>如果让模型在某个位置去预测一个不是 &lt;MASK&gt; 的词，那么模型就需要学习所有 tokens 的上下文表示，因为万一需要预测这个词呢。</p>
<h4 id="只需要-random-tokens-足够吗？为什么还需要-10-的完整的-sentence"><a href="#只需要-random-tokens-足够吗？为什么还需要-10-的完整的-sentence" class="headerlink" title="只需要 random tokens 足够吗？为什么还需要 10% 的完整的 sentence?"></a>只需要 random tokens 足够吗？为什么还需要 10% 的完整的 sentence?</h4><blockquote>
<p>Well, ideally we want the model’s representation of the masked token to be better than random. By sometimes keeping the sentence intact (while still asking the model to predict the chosen token) the authors biased the model to learn a meaningful representation of the masked tokens.  </p>
</blockquote>
<p>使得模型具有偏置，更倾向于获得有意义的 masked token.</p>
<p>在知乎上问了这个问题，大佬的回复跟这篇 blog 有点差异，但实际上意思是一样的：  </p>
<p><img src="/2018/12/17/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/11.png"></p>
<p><img src="/2018/12/17/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/10.png"></p>
<p>总结下：  </p>
<p>为什么不能完全只有 &lt;MASK&gt; ?  如果只有 &lt;MASK&gt;, 那么这个预训练模型是有偏置的，也就是学到一种方式，用上下文去预测一个词。这导致在 fine-tune 时，会丢一部分信息，也就是知乎大佬第一部分所说的。</p>
<p>所以加上 random 和 ture token 是让模型知道，每个词都是有意义的，除了上下文信息，还要用到它本身的信息，即使是 &lt;MASK&gt;. 也就是知乎上说的，提取这两方面的信息。</p>
<p>再回过头，从语言模型的角度来看，依然是需要预测每一个词，但是绝大多数词它的 cross entropy loss 会很小，而主要去优化得到 &lt;MASK&gt; 对应的词。而 random/true token 告诉模型，你需要提防每一个词，他们也需要好好预测，因为他们不一定就是对的。</p>
<p>感谢知乎大佬！</p>
<h4 id="random-tokens-会-confuse-模型吗？"><a href="#random-tokens-会-confuse-模型吗？" class="headerlink" title="random tokens 会 confuse 模型吗？"></a>random tokens 会 confuse 模型吗？</h4><p>不会， random tokens 只占 15% * 10% = 1.5%. 这不会影响模型的性能。</p>
<p>还有一个问题， &lt;MASK&gt; 所占的比例很小，主要优化对象迭代一次对整个模型影响会很小，因而需要更多次迭代.</p>
<h3 id="next-sentence-generation"><a href="#next-sentence-generation" class="headerlink" title="next sentence generation"></a>next sentence generation</h3><p>对于下游是 Question Answering(QA), Natural Language Inference(NLI) 这样需要理解句子之间的相关性的任务，仅仅通过语言模型并不能获得这方面的信息。为了让模型能够理解句子之间的关系，作者提出了一个 binarized next sentence prediction.</p>
<p>具体方式是：  </p>
<p><img src="/2018/12/17/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/06.png"></p>
<p>50% 是正确的相邻的句子。 50% 是随机选取的一个句子。这个任务在预训练中能达到 97%-98% 的准确率，并且能很显著的提高 QA NLI 的任务。</p>
<h3 id="pre-training-procudure"><a href="#pre-training-procudure" class="headerlink" title="pre-training procudure"></a>pre-training procudure</h3><p>作者预训练使用的语料：BooksCorpus (800M words)，English Wikipedia (2,500M words)。 使用文档级别的语料很关键，而不是 shffule 的句子级别的语料，这样可以获得更长的 sentence.</p>
<p>获得训练样本：从预料库中抽取句子对，其中 50% 的两个句子之间是确实相邻的，50% 的第二个句子是随机抽取的。具体操作看代码吧</p>
<ul>
<li><p>batch_size 256.  </p>
</li>
<li><p>每一个 sentences 对： 512 tokens  </p>
</li>
<li><p>40 epochs  </p>
</li>
<li><p>Adam lr=1e-4, $\beta_1=0.9$, $\beta_2=0.999$, L2 weight decay 0.01  </p>
</li>
<li><p>learning rate warmup 10000 steps  </p>
</li>
<li><p>0.1 dropout  </p>
</li>
<li><p>gelu instead of relu  </p>
</li>
</ul>
<h3 id="Fine-tune-procedure"><a href="#Fine-tune-procedure" class="headerlink" title="Fine-tune procedure"></a>Fine-tune procedure</h3><h4 id="sequence-level-tasks"><a href="#sequence-level-tasks" class="headerlink" title="sequence-level tasks"></a>sequence-level tasks</h4><ul>
<li><p>比如 sentences pairs 的 Quora Question Pairs(QQP) 预测两个句子之间语义是否相同。如下图中（a）.  </p>
</li>
<li><p>如果是 single sentence classification 比如 Stanford Sentiment Treebank（SST-2）和 Corpus of Linguistic Acceptability（CoLA）这种分类问题。如下图（b）  </p>
</li>
</ul>
<p><img src="/2018/12/17/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/07.png"></p>
<p>只需要输出 Transformer 最后一层的隐藏状态中的第一个 token，也就是 [CLS]. 然后接上一个全链接映射到相应的 label 空间即可。</p>
<p>fine-tune 时的超参数跟 pre-training 时的参数大致相同。但是训练速度会很快</p>
<ul>
<li><p>Batch size: 16, 32  </p>
</li>
<li><p>Learning rate (Adam): 5e-5, 3e-5, 2e-5  </p>
</li>
<li><p>Number of epochs: 3, 4  </p>
</li>
</ul>
<p>语料库越大，对参数的敏感度越小。  </p>
<h4 id="token-level-tasks"><a href="#token-level-tasks" class="headerlink" title="token-level tasks."></a>token-level tasks.</h4><p><img src="/2018/12/17/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/09.png"></p>
<p>对于token-level classification(例如NER)，取所有token的最后层transformer输出，喂给softmax层做分类。</p>
<h2 id="如何使用-BERT"><a href="#如何使用-BERT" class="headerlink" title="如何使用 BERT"></a>如何使用 BERT</h2><h3 id="文本分类"><a href="#文本分类" class="headerlink" title="文本分类"></a>文本分类</h3><p><a target="_blank" rel="noopener" href="https://github.com/huggingface/pytorch-pretrained-BERT/blob/master/examples/run_classifier.py">https://github.com/huggingface/pytorch-pretrained-BERT/blob/master/examples/run_classifier.py</a></p>
<p>主要涉及到两个 类:  </p>
<ul>
<li><p>数据预处理   </p>
</li>
<li><p>预训练模型加载  </p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">from</span> pytorch_pretrained_bert <span class="keyword">import</span> BertTokenizer, BertForSequenceClassification, BertConfig, BertAdam， PYTORCH_PRETRAINED_BERT_CACHE</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">tokenizer = BertTokenizer.from_pretrained(args.bert_model, do_lower_case=args.do_lower_case)</span><br><span class="line"></span><br><span class="line">tokenizer = BertTokenizer.from_pretrained(<span class="string">&quot;./pre_trained_models/bert-base-uncased-vocab.txt&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">model = BertForSequenceClassification.from_pretrained(<span class="string">&#x27;bert-base-uncased&#x27;</span>,</span><br><span class="line"></span><br><span class="line">          cache_dir=PYTORCH_PRETRAINED_BERT_CACHE / <span class="string">&#x27;distributed_&#123;&#125;&#x27;</span>.<span class="built_in">format</span>(args.local_rank),</span><br><span class="line"></span><br><span class="line">          num_labels = num_labels)</span><br><span class="line"></span><br><span class="line">model = BertForSequenceClassification.from_pretrained(<span class="string">&quot;pre_trained_models/bert-base-uncased.tar.gz&quot;</span>, num_labels=<span class="number">2</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>其中 <code>bert-base-uncased</code> 可以分别用具体的 词表文件 和 模型文件 代替。从源代码中提供的链接下载即可。</p>
<h4 id="数据处理"><a href="#数据处理" class="headerlink" title="数据处理"></a>数据处理</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">from</span> pytorch_pretrained_bert <span class="keyword">import</span> BertTokenizer, BertForSequenceClassification, BertConfig, BertAdam， PYTORCH_PRETRAINED_BERT_CACHE</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">tokenizer = BertTokenizer.from_pretrained(args.bert_model, do_lower_case=args.do_lower_case)</span><br><span class="line"></span><br><span class="line">tokenizer = BertTokenizer.from_pretrained(<span class="string">&quot;./pre_trained_models/bert-base-uncased-vocab.txt&quot;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>前一种方式是根据代码中提供的 url 去下载词表文件，然后缓存在默认文件夹下 <code>/home/panxie/.pytorch_pretrained_bert</code> 。后者是直接下载词表文件后，放在本地。相对来说，后者更方便。</p>
<p>这部分代码相对比较简单，根据自己的任务，继承 <code>DataProcessor</code> 这个类即可。</p>
<p>作为模型的输入，features 主要包括三个部分：  </p>
<ul>
<li><p>input_ids 是通过词典映射来的  </p>
</li>
<li><p>input_mask 在 fine-tune 阶段，所有的词都是 1, padding 的是 0  </p>
</li>
<li><p>segment_ids 在 text_a 中是 0, 在 text_b 中是 1, padding 的是 0  </p>
</li>
</ul>
<p>这里对应了前面所说的，input_idx 就是 token embedding, segment_ids 就是 Sentence Embedding. 而 input_mask 则表示哪些位置被 mask 了，在 fine-tune 阶段都是 1.</p>
<h4 id="加载预训练模型"><a href="#加载预训练模型" class="headerlink" title="加载预训练模型"></a>加载预训练模型</h4><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">!tar -tf pre_trained_models/bert-base-uncased.tar.gz</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">./pytorch_model.bin</span><br><span class="line"></span><br><span class="line">./bert_config.json</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>下载好的文件包中含有两个文件，分别是 config 信息，以及模型参数。</p>
<p>如果不用具体的文件，则需要从代码中提供的 url 下载，并缓存在默认文件夹 <code>PYTORCH_PRETRAINED_BERT_CACHE = /home/panxie/.pytorch_pretrained_bert</code></p>
<p>作为分类任务， num_labels 参数默认为 2.</p>
<p>运行时会发现提取预训练模型会输出如下信息：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="number">12</span>/<span class="number">26</span>/<span class="number">2018</span> <span class="number">17</span>:<span class="number">00</span>:<span class="number">41</span> - INFO - pytorch_pretrained_bert.modeling -   </span><br><span class="line"></span><br><span class="line">loading archive file pre_trained_models/bert-base-uncased.tar.gz</span><br><span class="line"></span><br><span class="line"><span class="number">12</span>/<span class="number">26</span>/<span class="number">2018</span> <span class="number">17</span>:<span class="number">00</span>:<span class="number">41</span> - INFO - pytorch_pretrained_bert.modeling -   </span><br><span class="line"></span><br><span class="line">extracting archive file pre_trained_models/bert-base-uncased.tar.gz to temp <span class="built_in">dir</span> /tmp/tmpgm506dcx</span><br><span class="line"></span><br><span class="line"><span class="number">12</span>/<span class="number">26</span>/<span class="number">2018</span> <span class="number">17</span>:<span class="number">00</span>:<span class="number">44</span> - INFO - pytorch_pretrained_bert.modeling -   </span><br><span class="line"></span><br><span class="line">Model config &#123;</span><br><span class="line"></span><br><span class="line">  <span class="string">&quot;attention_probs_dropout_prob&quot;</span>: <span class="number">0.1</span>,</span><br><span class="line"></span><br><span class="line">  <span class="string">&quot;hidden_act&quot;</span>: <span class="string">&quot;gelu&quot;</span>,</span><br><span class="line"></span><br><span class="line">  <span class="string">&quot;hidden_dropout_prob&quot;</span>: <span class="number">0.1</span>,</span><br><span class="line"></span><br><span class="line">  <span class="string">&quot;hidden_size&quot;</span>: <span class="number">768</span>,</span><br><span class="line"></span><br><span class="line">  <span class="string">&quot;initializer_range&quot;</span>: <span class="number">0.02</span>,</span><br><span class="line"></span><br><span class="line">  <span class="string">&quot;intermediate_size&quot;</span>: <span class="number">3072</span>,</span><br><span class="line"></span><br><span class="line">  <span class="string">&quot;max_position_embeddings&quot;</span>: <span class="number">512</span>,</span><br><span class="line"></span><br><span class="line">  <span class="string">&quot;num_attention_heads&quot;</span>: <span class="number">12</span>,</span><br><span class="line"></span><br><span class="line">  <span class="string">&quot;num_hidden_layers&quot;</span>: <span class="number">12</span>,</span><br><span class="line"></span><br><span class="line">  <span class="string">&quot;type_vocab_size&quot;</span>: <span class="number">2</span>,</span><br><span class="line"></span><br><span class="line">  <span class="string">&quot;vocab_size&quot;</span>: <span class="number">30522</span></span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="number">12</span>/<span class="number">26</span>/<span class="number">2018</span> <span class="number">17</span>:<span class="number">00</span>:<span class="number">45</span> - INFO - pytorch_pretrained_bert.modeling -   </span><br><span class="line"></span><br><span class="line">Weights of BertForSequenceClassification <span class="keyword">not</span> initialized <span class="keyword">from</span> pretrained model:</span><br><span class="line"></span><br><span class="line">[<span class="string">&#x27;classifier.weight&#x27;</span>, <span class="string">&#x27;classifier.bias&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="number">12</span>/<span class="number">26</span>/<span class="number">2018</span> <span class="number">17</span>:<span class="number">00</span>:<span class="number">45</span> - INFO - pytorch_pretrained_bert.modeling -   </span><br><span class="line"></span><br><span class="line">Weights <span class="keyword">from</span> pretrained model <span class="keyword">not</span> used <span class="keyword">in</span> BertForSequenceClassification:</span><br><span class="line"></span><br><span class="line">[<span class="string">&#x27;cls.predictions.bias&#x27;</span>, <span class="string">&#x27;cls.predictions.transform.dense.weight&#x27;</span>,</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;cls.predictions.transform.dense.bias&#x27;</span>, <span class="string">&#x27;cls.predictions.decoder.weight&#x27;</span>,</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;cls.seq_relationship.weight&#x27;</span>, <span class="string">&#x27;cls.seq_relationship.bias&#x27;</span>,</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;cls.predictions.transform.LayerNorm.weight&#x27;</span>, <span class="string">&#x27;cls.predictions.transform.LayerNorm.bias&#x27;</span>]</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<p>不得不去观察 <code>from_pretrained</code> 的源码：<a target="_blank" rel="noopener" href="https://github.com/huggingface/pytorch-pretrained-BERT/blob/8da280ebbeca5ebd7561fd05af78c65df9161f92/pytorch_pretrained_bert/modeling.py#L448">https://github.com/huggingface/pytorch-pretrained-BERT/blob/8da280ebbeca5ebd7561fd05af78c65df9161f92/pytorch_pretrained_bert/modeling.py#L448</a></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">missing_keys = []</span><br><span class="line"></span><br><span class="line">unexpected_keys = []</span><br><span class="line"></span><br><span class="line">error_msgs = []</span><br><span class="line"></span><br><span class="line"><span class="comment"># copy state_dict so _load_from_state_dict can modify it</span></span><br><span class="line"></span><br><span class="line">metadata = <span class="built_in">getattr</span>(state_dict, <span class="string">&#x27;_metadata&#x27;</span>, <span class="literal">None</span>)</span><br><span class="line"></span><br><span class="line">state_dict = state_dict.copy()</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> metadata <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line"></span><br><span class="line">    state_dict._metadata = metadata</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load</span>(<span class="params">module, prefix=<span class="string">&#x27;&#x27;</span></span>):</span></span><br><span class="line"></span><br><span class="line">    local_metadata = &#123;&#125; <span class="keyword">if</span> metadata <span class="keyword">is</span> <span class="literal">None</span> <span class="keyword">else</span> metadata.get(prefix[:-<span class="number">1</span>], &#123;&#125;)</span><br><span class="line"></span><br><span class="line">    module._load_from_state_dict(</span><br><span class="line"></span><br><span class="line">        state_dict, prefix, local_metadata, <span class="literal">True</span>, missing_keys, unexpected_keys, error_msgs)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> name, child <span class="keyword">in</span> module._modules.items():</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> child <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line"></span><br><span class="line">            load(child, prefix + name + <span class="string">&#x27;.&#x27;</span>)</span><br><span class="line"></span><br><span class="line">load(model, prefix=<span class="string">&#x27;&#x27;</span> <span class="keyword">if</span> <span class="built_in">hasattr</span>(model, <span class="string">&#x27;bert&#x27;</span>) <span class="keyword">else</span> <span class="string">&#x27;bert.&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> <span class="built_in">len</span>(missing_keys) &gt; <span class="number">0</span>:</span><br><span class="line"></span><br><span class="line">    logger.info(<span class="string">&quot;Weights of &#123;&#125; not initialized from pretrained model: &#123;&#125;&quot;</span>.<span class="built_in">format</span>(</span><br><span class="line"></span><br><span class="line">        model.__class__.__name__, missing_keys))</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> <span class="built_in">len</span>(unexpected_keys) &gt; <span class="number">0</span>:</span><br><span class="line"></span><br><span class="line">    logger.info(<span class="string">&quot;Weights from pretrained model not used in &#123;&#125;: &#123;&#125;&quot;</span>.<span class="built_in">format</span>(</span><br><span class="line"></span><br><span class="line">        model.__class__.__name__, unexpected_keys))</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> tempdir:</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Clean up temp dir</span></span><br><span class="line"></span><br><span class="line">    shutil.rmtree(tempdir)</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> model</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>这部分内容解释了如何提取模型的部分参数.  </p>
<p> <code>missing_keys</code> 这里是没有从预训练模型提取参数的部分，也就是 <code>classifier</code> <code>[&#39;classifier.weight&#39;, &#39;classifier.bias&#39;]</code>层，因为这一层是分类任务独有的。  </p>
<p> <code>unexpected_keys</code> 则是对于分类任务不需要的，但是在预训练的语言模型中是存在的。查看 <code>BertForMaskedLM</code> 的模型就能看到，<code>cls</code> 层，是专属于语言模型的，在下游任务中都需要去掉。</p>
<p> 所以这部分代码实际上学到了如何选择预训练模型的部分参数～～棒啊！</p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2018-12-12T05:34:38.000Z" title="2018/12/12 下午1:34:38">2018-12-12</time>发表</span><span class="level-item"><time dateTime="2021-06-29T05:19:29.419Z" title="2021/6/29 下午1:19:29">2021-06-29</time>更新</span><span class="level-item"><a class="link-muted" href="/categories/C/">C++</a></span><span class="level-item">16 分钟读完 (大约2395个字)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2018/12/12/Cplusplus-prime/">C plus plus prime-类</a></h1><div class="content"><h2 id="类定义"><a href="#类定义" class="headerlink" title="类定义"></a>类定义</h2><p>类头、类体、类域</p>
<h3 id="数据成员"><a href="#数据成员" class="headerlink" title="数据成员"></a>数据成员</h3><p>数据成员声明在类体中，可以是任何类型，eg. 指针，类</p>
<p>分为：非静态（nonstatic），静态（static）.</p>
<h3 id="成员函数"><a href="#成员函数" class="headerlink" title="成员函数"></a>成员函数</h3><p>成员函数在类域之外是不可见的。通过 “.” 或 “-&gt;” 来引用。</p>
<p>注意区分全局域/全局函数，类域/成员函数。</p>
<h3 id="成员访问"><a href="#成员访问" class="headerlink" title="成员访问"></a>成员访问</h3><p>信息隐藏（information hiding）：类成员的访问限制，通过访问限定符来实现的。</p>
<ul>
<li><p>public 公有成员，提供给用户使用的</p>
</li>
<li><p>private 只能被成员函数和友元访问  </p>
</li>
<li><p>protected 对派生类表现的像 public, 对其他程序表现的像 private.</p>
</li>
</ul>
<h3 id="友元"><a href="#友元" class="headerlink" title="友元"></a>友元</h3><p>关键字 find， 友元可以是一个名字空间函数、一个前面定义的类的一个成员函数、也可以是一个完整的类。</p>
<p>允许一个类授权其他的函数访问他的非公有成员，通常声明放在类头之后。</p>
<h3 id="类声明和定义"><a href="#类声明和定义" class="headerlink" title="类声明和定义"></a>类声明和定义</h3><p>类声明，是只有类头，没有类体。无法确定类类型的大小，类成员也是未知的。但是可以声明指向该类类型的指针或引用。</p>
<p>类定义，是具有完整的类体。</p>
<p><strong>什么时候用类声明？什么时候用类定义？</strong></p>
<h2 id="类对象"><a href="#类对象" class="headerlink" title="类对象"></a>类对象</h2><p>类定义不会分配存储区，只有定义了一个类的对象，才会分配。</p>
<p>类类型，即定义的一个类。通过它定义的对象是有生命期的，生命期根据它在哪个域中被声明的。</p>
<p>类对象可以被另一个对象初始化或赋值，拷贝一个类对象与拷贝它的成员函数等价。</p>
<p>当一个类对象被指定为函数实参或函数返回值时，它就被按值传递。我们可以把一个函数参数或返回值声明为一个类类型的指针或引用。（7.3节，7.4节）</p>
<p><strong>回顾下指针：</strong>  </p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">int</span> i = <span class="number">100</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">int</span> *p;</span><br><span class="line"></span><br><span class="line"><span class="keyword">int</span>* p = &amp;i;</span><br><span class="line"></span><br><span class="line"><span class="keyword">int</span> *p = &amp;i;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>p 是指针变量，用来存储地址。注意数组名是 const 地址常量，代表第一个元素的地址。</p>
<p><strong>指针和引用的区别：</strong>  </p>
<p>指针：指针是一个变量，只不过这个变量存储的是一个地址，指向内存的一个存储单元；而引用跟原来的变量实质上是同一个东西，只不过是原变量的一个别名而已。如：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">int</span> a=<span class="number">1</span>; <span class="keyword">int</span> *p=&amp;a;</span><br><span class="line"></span><br><span class="line"><span class="keyword">int</span> a=<span class="number">1</span>; <span class="keyword">int</span> &amp;b=a;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>上面定义了一个整形变量和一个指针变量p，该指针变量指向a的存储单元，即p的值是a存储单元的地址.  </p>
<p>而下面2句定义了一个整形变量a和这个整形a的引用b，事实上a和b是同一个东西，在内存占有同一个存储单元。</p>
<ul>
<li><p>“sizeof引用”得到的是所指向的变量(对象)的大小，而”sizeof指针”得到的是指针本身的大小；  </p>
</li>
<li><p>可以有const指针，但是没有const引用；</p>
</li>
<li><p>指针的值可以为空，但是引用的值不能为NULL，并且引用在定义的时候必须初始化；  </p>
</li>
<li><p>指针的值在初始化后可以改变，即指向其它的存储单元，而引用在进行初始化后就不会再改变了</p>
</li>
</ul>
<p>继续回到类对象作为函数参数时，用成员访问操作符来访问类对象的数据成员或成员函数。点操作符与类对象或引用连用; 箭头访问操作符与类对象的指针连用。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="meta"># <span class="meta-keyword">include</span> <span class="meta-string">&quot;Screen.h&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">bool</span> <span class="title">isEqual</span><span class="params">(Screen&amp; s1, Screen *s2)</span></span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"></span><br><span class="line">  ...</span><br><span class="line"></span><br><span class="line">  s1.height ...</span><br><span class="line"></span><br><span class="line">  s2-&gt;height ...</span><br><span class="line"></span><br><span class="line">  ...</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<p>isEqual 是非成员函数，如果要直接引用 s1, s2 中的数据成员 height 是不可以的。所以必须借助于 Screen 中的公有成员函数。  </p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">s2-&gt;height 等价于 (*s2).height</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h2 id="类成员函数"><a href="#类成员函数" class="headerlink" title="类成员函数"></a>类成员函数</h2><p>一组操作的集合。</p>
<h3 id="inline-和-非-inline-成员函数"><a href="#inline-和-非-inline-成员函数" class="headerlink" title="inline 和 非 inline 成员函数"></a>inline 和 非 inline 成员函数</h3><p>内联函数的作用：如果在程序中调用某个函数，不但要拷贝实参，保存机器的寄存器，程序还必须转向一个新的位置，这样会降低效率。  </p>
<p>而内联函数就是解决这个问题的，在程序的调用节点上，“内联”的展开函数的操作，从而额外的执行开销被消除了。</p>
<p>类体内定义的成员函数自动的作为内联函数处理。  </p>
<p>类体内声明，类体外定的函数，需要显示的加上关键字 inline. 同时类体外的定义需要用类名限定修饰(限定修饰符 :: )</p>
<h3 id="访问类成员"><a href="#访问类成员" class="headerlink" title="访问类成员"></a>访问类成员</h3><p>成员函数的定义可以引用任何一个类成员，无论该成员是私有还是公有。  </p>
<p>成员函数可以直接访问它所属类的成员，无需访问操作符。这实际上是通过 this 指针实现的。</p>
<h3 id="私有与公有成员函数"><a href="#私有与公有成员函数" class="headerlink" title="私有与公有成员函数"></a>私有与公有成员函数</h3><p>公有函数集定义了类的接口。私有成员函数为其他成员函数提供支持。</p>
<h3 id="特殊的成员函数"><a href="#特殊的成员函数" class="headerlink" title="特殊的成员函数"></a>特殊的成员函数</h3><p>构造函数：管理类对象并处理初始化、赋值、内存管理、类型转换、析构等活动。每次定义一个类对象或 new 表达式分配一个类对象都会调用它。  </p>
<p>构造函数的名字必须与类名相同。</p>
<h3 id="const-和-volatile-成员函数"><a href="#const-和-volatile-成员函数" class="headerlink" title="const 和 volatile 成员函数"></a>const 和 volatile 成员函数</h3><p>只有被声明为 const 的成员函数才能被一个 const 对象调用。关键字 const 在函数体和参数表之间.</p>
<p>通常一个类如果想被广泛使用，其中不修改类数据成员的成员函数应该声明为 const 成员函数。</p>
<p>但是即使声明了，这个成员函数依然有可能修改数据成员，如果这个类含有指针。</p>
<p>比如：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">private:</span><br><span class="line"></span><br><span class="line">  char *_text;</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<p><code>_text</code> 不能被修改，但是它指向的字符却是可以被修改的。所以程序员这个时候就需要注意了。。</p>
<p>构造函数和析构函数即使不是 const 成员函数，也能被 const 对象调用。</p>
<p>volatile 跟 const 用法一样，它用来提示编译器该对象的值可能在编译器未被检测到的情况下被修改。因为，编译器不能武断的对引用这些对象的代码进行优化。</p>
<h3 id="mutable-数据成员"><a href="#mutable-数据成员" class="headerlink" title="mutable 数据成员"></a>mutable 数据成员</h3><p>一旦一个对象被声明为 const，它的内容就不能修改。但是其中某些数据成员，比如索引，被修改之后并没有修改对象本身，这个时候就可以将该数据成员（也就是索引）声明为 mutable.</p>
<p>那样，即使 const 对象， const 成员函数修改了该数据成员，也不会有编译错误。</p>
<h2 id="隐含的指针-this"><a href="#隐含的指针-this" class="headerlink" title="隐含的指针 this"></a>隐含的指针 this</h2><p>每个类成员函数都含有一个指向被调用对象的指针。但是一般不需要显示的写出来，如果写出来也是可以的。</p>
<h3 id="何时使用指针呢？"><a href="#何时使用指针呢？" class="headerlink" title="何时使用指针呢？"></a>何时使用指针呢？</h3><p>当连续使用成员函数时，比如 <code>myVector.find().sort().insert()</code> 时，对应的成员函数返回的值应该是被调用对象本身，也就是 <code>*this</code>.</p>
<p>还有一种情况， copy 函数：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">Screen::copy</span><span class="params">(<span class="keyword">const</span> Screen&amp; sobj)</span></span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (<span class="keyword">this</span> != &amp;sobj)</span><br><span class="line"></span><br><span class="line">  &#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 把 sobj 的值拷贝到 * this 中</span></span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>这里的 this 指针含有被调用对象的地址。如果 sobj 的地址 &amp;sobj 与 this 相同，那就不需要拷贝了。</p>
<p>注意这里 &amp; 用法：引用和取地址。</p>
<h2 id="静态类成员"><a href="#静态类成员" class="headerlink" title="静态类成员"></a>静态类成员</h2><h3 id="静态数据成员"><a href="#静态数据成员" class="headerlink" title="静态数据成员"></a>静态数据成员</h3><p>对于非静态成员，每个类都有一个自己的拷贝。而静态成员对每个类类型只有一个拷贝。静态数据成员只有一份，由该类类型的所有对象共同访问。</p>
<p>不同于全局对象，它可以隐藏，并且不会与其他全局名字冲突。</p>
<p>关键字 static. 注意与 const 的区别，没有加 const 意味着是可以更新的。只需要更新一次，所有的类对象对应的值都会更新。</p>
<p>静态类成员的显示初始化，在类定义之外，用类名限定修饰。在静态数据成员的定义中也可以直接使用私有成员，这与在类成员函数中直接引用私有成员是一样的。</p>
<p>对于静态数据成员，除了通过类对象使用成员访问操作符访问之外，还可以直接使用类名加限定修饰符访问</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">Account::_intersetRate</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h3 id="静态成员函数"><a href="#静态成员函数" class="headerlink" title="静态成员函数"></a>静态成员函数</h3><p>静态成员函数，只访问静态数据成员，而不访问任何其他数据成员。所以它们与哪个对象来调用这个函数无关。</p>
<p>在类体中声明时需要加关键字 static, 类体外不能指定关键字。并且不能设定为 const 和 volatile.</p>
<h2 id="指向类成员的指针"><a href="#指向类成员的指针" class="headerlink" title="指向类成员的指针"></a>指向类成员的指针</h2><h3 id="普通函数指针-7-9节"><a href="#普通函数指针-7-9节" class="headerlink" title="普通函数指针 7.9节"></a>普通函数指针 7.9节</h3><h3 id="成员函数指针"><a href="#成员函数指针" class="headerlink" title="成员函数指针"></a>成员函数指针</h3></div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2018-12-11T06:22:13.000Z" title="2018/12/11 下午2:22:13">2018-12-11</time>发表</span><span class="level-item"><time dateTime="2021-06-29T08:12:08.539Z" title="2021/6/29 下午4:12:08">2021-06-29</time>更新</span><span class="level-item"><a class="link-muted" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/">论文笔记</a><span> / </span><a class="link-muted" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/open-set-recognition/">open set recognition</a></span><span class="level-item">6 分钟读完 (大约871个字)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2018/12/11/rejection%E7%B3%BB%E5%88%973-OpenMax/">rejection系列3 OpenMax</a></h1><div class="content"><p>paper: Towards Open Set Deep Networks. CVPR</p>
<h2 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h2><p>closed set recognition 天然的特性使得它必须选择一个类别作为预测对象。但是实际场景下， recognition system 必须学会 reject unknown/unseen classes 在 testing 阶段。</p>
<p>于是乎，作者提出了一个新的 model layer, <strong>OpenMax</strong>, 能够估计一个样本输入是来自于 unknown class 的概率。</p>
<p>A key element of estimating the unknown probability is adapting Meta-Recognition concepts to the activation patterns in the penultimate layer of the network.  </p>
<p>所以关键词是 <strong>meta-recohnition</strong>, <strong>activation pattern/vector</strong>.</p>
<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>很多工作是基于 threshold 来找出 unknown 的，他们认为 unknwon 通过 softmax 会得到 low probability/confidence. 但是实际上很多 “fooling” “rubbish” 也会拥有 high</p>
<p>probability/confidence scores. 比如通过对抗学习得到的 adversarial images. 作者在后面也提到了， threshold 实际上拒绝的不是 unknown, 而是 uncertain predictions.</p>
<blockquote>
<p>OpenMax incorporates <strong>likelihood of the recognition system failure</strong>. This likelihood is used to estimate the probability for a given input belonging to an unknown class. For this estimation, we adapt the concept of <strong>Meta-Recognition</strong>[22, 32, 9] to deep networks. We use the scores from the penultimate layer of deep networks (the fully connected layer before SoftMax, e.g., FC8) to estimate if the input is “far” from known training data. We call scores in that layer the <strong>activation vector(AV)</strong>.  </p>
</blockquote>
<p>关于 OpenMax 如果实现的简单总结，回过头在看。</p>
<blockquote>
<p>A key insight in our opening deep networks is noting that “open space risk” should be measured in feature space rather than in pixel space.  </p>
</blockquote>
<p>一个重要的观点是，在 open deep networks 里面， open space risk 应该是从特征空间 feature space 的角度出发的， 而不是 pixel space. 也就是神经网络判断是不是 unknown, 应该是从 feature 的角度来看的。</p>
<blockquote>
<p>We show that an extreme-value meta-recognition inspired distance normalization process on the overall activation patterns of the penultimate network layer provides a rejection probability for OpenMax normalization for unknown images, fooling images and even for many adversarial images.</p>
</blockquote>
<h2 id="Open-set-deep-networks"><a href="#Open-set-deep-networks" class="headerlink" title="Open set deep networks"></a>Open set deep networks</h2><blockquote>
<p>Building on the concepts of open space risk, we seek to choose a layer (feature space) in which we can build a <strong>compact abating probability model</strong> that can be thresholded to limit open space risk.  </p>
</blockquote>
<p>基于 open space risk 的概念，提出了 compact abating probability model 能限制 open space risk.</p>
<h3 id="multi-classes-meta-recognition"><a href="#multi-classes-meta-recognition" class="headerlink" title="multi-classes meta-recognition"></a>multi-classes meta-recognition</h3><p>作者先简单介绍了一下前人的工作:  </p>
<blockquote>
<p>. Prior work on meta-recognition used the final system scores, analyzed their distribution based on Extreme Value Theory (EVT) and found these distributions follow Weibull distribution.</p>
</blockquote>
<p>感觉看懂这部分先要理解极值理论(Extreme value theory).</p>
<blockquote>
<p>from wikipedia:</p>
</blockquote>
<p>It seeks to assess, from a given ordered sample of a given random variable, the probability of events that are more extreme than any previously observed.  </p>
<p>它试图从给定随机变量的给定有序样本中评估比先前观察到的任何事件更极端的事件的概率.</p>
<p><img src="/2018/12/11/rejection%E7%B3%BB%E5%88%973-OpenMax/01.png"></p>
<p>然后是 极值分布 的一种 Weibull distribution</p>
<p><img src="/2018/12/11/rejection%E7%B3%BB%E5%88%973-OpenMax/02.png"></p>
<p><img src="/2018/12/11/rejection%E7%B3%BB%E5%88%973-OpenMax/03.png"></p>
<p><img src="/2018/12/11/rejection%E7%B3%BB%E5%88%973-OpenMax/04.png"></p>
<p><img src="/2018/12/11/rejection%E7%B3%BB%E5%88%973-OpenMax/05.png"></p>
<p><img src="/2018/12/11/rejection%E7%B3%BB%E5%88%973-OpenMax/06.png"></p>
<p><img src="/2018/12/11/rejection%E7%B3%BB%E5%88%973-OpenMax/07.png"></p>
<p>所以 Weibull distribution 就是从整个分布中取最极端的例子 sampling top-n score，然后的到的分布。</p>
<p><img src="/2018/12/11/rejection%E7%B3%BB%E5%88%973-OpenMax/08.png"></p>
<p><img src="/2018/12/11/rejection%E7%B3%BB%E5%88%973-OpenMax/09.png"></p>
<p><img src="/2018/12/11/rejection%E7%B3%BB%E5%88%973-OpenMax/10.png"></p>
<p>将极值理论运用到视觉特征的提取中。具体的我也不太清楚了。。这也是前人的研究。作者也并没有采取这种方法。</p>
<blockquote>
<p>We take the approach that the network values from penultimate layer (hereafter the Activation Vector (AV)), are not an independent per-class score estimate, but rather they provide a distribution of what classes are “related.”  </p>
</blockquote>
<p>作者采用的方法是 倒数第二层，也就是 (Activation Vector) 提供不同 classes 之间的相关性分布，而不是每一个类对应的独立的分布。</p>
<h3 id="interpretation-of-activation-vector"><a href="#interpretation-of-activation-vector" class="headerlink" title="interpretation of activation vector"></a>interpretation of activation vector</h3><h3 id="OpenMax"><a href="#OpenMax" class="headerlink" title="OpenMax"></a>OpenMax</h3></div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2018-12-09T01:00:08.000Z" title="2018/12/9 上午9:00:08">2018-12-09</time>发表</span><span class="level-item"><time dateTime="2021-06-29T08:12:08.539Z" title="2021/6/29 下午4:12:08">2021-06-29</time>更新</span><span class="level-item"><a class="link-muted" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/">论文笔记</a><span> / </span><a class="link-muted" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/open-set-recognition/">open set recognition</a></span><span class="level-item">34 分钟读完 (大约5074个字)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2018/12/09/rejection%E7%B3%BB%E5%88%971-overview-1/">rejection系列1-overview</a></h1><div class="content"><p>关于 open set recognition 的一片综述。  </p>
<p>paper: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1811.08581">Recent Advances in Open Set Recognition: A Survey</a></p>
<h2 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h2><blockquote>
<p>In real-world recognition/classification tasks, limited by various objective factors, it is usually difficult to collect training samples to exhaust all classes when training a recognizer or classifier. A more realistic scenario is open set recognition (OSR), where incomplete knowledge of the world exists at training time, and unknown classes can be submitted to an algorithm during testing, requiring the classifiers not only to accurately classify the seen classes, but also to effectively deal with the unseen ones.  </p>
</blockquote>
<p>现实中对于分类任务，不可能在训练集中穷尽所有类别。更实际的情况是 open set recognition (OSR). 在训练阶段包含的是不完整的 knowledge of world. 在测试阶段会出现 unknown 类别。这需要分类器不仅能准确的识别在训练阶段已经见到过的类别，也能有效的处理没有见过的类别, 比如 rejection 或者归类为 unknown.</p>
<blockquote>
<p>This paper provides a comprehensive survey of existing open set recognition techniques covering various aspects ranging from related definitions, representations of models, datasets, experiment setup and evaluation metrics. Furthermore, we briefly analyze the relationships between OSR and its related tasks including zero-shot, one-shot (few-shot) recognition/learning techniques, classification with reject option, and so forth. Additionally, we also overview the open world recognition which can be seen as a natural extension of OSR. Importantly, we highlight the limitations of existing approaches and point out some promising subsequent research directions in this field.  </p>
</blockquote>
<p>这篇综述覆盖了相关的定义、模型、实验以及验证指标。更多地，还分析了 与OSR 相关的任务 zero-shot, one-shot 识别，以及 rejection. 额外地，还概述了 open world recognition 可以看作 OSR 的扩展。更重要的是，作者说明了当前一些方法的限制，并指出了未来研究的一些方向。</p>
<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><blockquote>
<p>a more realistic scenario is usually open and non-stationary such as driverless, fault/medical diagnosis, etc., where unseen situations can emerge unexpectedly, which drastically weakens the robustness of these existing methods.  </p>
</blockquote>
<p>更现实的场景是 <strong>开放的和非静态</strong> 的。</p>
<blockquote>
<p>To meet this challenge, several related research directions actually have been explored including lifelong learning [1], [2], transfer learning [3]–[5], domain adaptation [6], zero-shot [7]–[9], one-shot (few-shot) [10]–[16] recognition/learning and open set recognition/classification [17]–[19], and so forth.  </p>
</blockquote>
<p>涉及到的领域： lifelong learning, transfer learning, domain adaption, zero-shot, one-shot, open set recogntion.</p>
<p>recognition should consider four basic categories of classes as follows:  </p>
<p><img src="/2018/12/09/rejection%E7%B3%BB%E5%88%971-overview-1/01.png"></p>
<ul>
<li><p>known known: train/dev 中有标签的样本，包括正负类别，并且有相关的语义信息。  </p>
</li>
<li><p>known unknown: train/dev 中有标签的样本，负类，没有相关的语义信息。  </p>
</li>
<li><p>unknown known: test 中没有出现在 train 中的样本，但是有相关的语义信息。比如，train 中有猫，然后 test 中有另外一种猫科动物，那么动物这个样本是有意义的吧？？？  </p>
</li>
<li><p>unknown unknown: test 中没有出现在 train 中的样本，并且没有任何相关的语义信息。  </p>
</li>
</ul>
<blockquote>
<p>Unlike the traditional classification, zero-shot learning (ZSL) can identify unseen classes which have no available observations in training. However, the available semantic/attribute information shared among all classes including seen and unseen ones are needed.  </p>
</blockquote>
<p>zero-shot 是针对 unknown known, 也就是包含了语义信息。</p>
<blockquote>
<p>The ZSL mainly focuses on the recognition of the unknown known classes defined above. Actually, such a setting is rather restrictive and impractical, since we usually know nothing about the testing samples which may come from known known classes or not.  </p>
</blockquote>
<p>unknown known 这种设定很有限，并且不切实际。因为我们很难知道 test 中的样本是否是包含了语义信息，无法判断是 unknown known or unknown unknown.  </p>
<p><strong>comparision between open set recognition and traditional classification</strong></p>
<p><img src="/2018/12/09/rejection%E7%B3%BB%E5%88%971-overview-1/02.png"></p>
<p>Via these decision boundaries, samples from an unknown unknown class are labeled as ”unknown” or rejected rather than misclassified as known known classes.</p>
<h2 id="Basic-notation-and-related-definition"><a href="#Basic-notation-and-related-definition" class="headerlink" title="Basic notation and related definition"></a>Basic notation and related definition</h2><p>经验风险函数：  </p>
<p><img src="/2018/12/09/rejection%E7%B3%BB%E5%88%971-overview-1/03.png"></p>
<p>$L(x, y, f(x)) \ge 0$ 是 loss function. P(x,y) 是对应样本 (x, y) 的概率，通常这个联合分布的概率我们是不知道的，因为我们无法确定自然界中样本空间(label space)到底是个什么分布。</p>
<p><strong>[李航，机器学习] 中关于风险函数的定义：</strong>  </p>
<blockquote>
<p> 损失函数度量一次模型预测的好坏，风险函数度量平均意义下模型预测的好坏。  </p>
</blockquote>
<p><img src="/2018/12/09/rejection%E7%B3%BB%E5%88%971-overview-1/04.png"></p>
<p><img src="/2018/12/09/rejection%E7%B3%BB%E5%88%971-overview-1/05.png"></p>
<p><img src="/2018/12/09/rejection%E7%B3%BB%E5%88%971-overview-1/06.png"></p>
<p><img src="/2018/12/09/rejection%E7%B3%BB%E5%88%971-overview-1/07.png"></p>
<p>以前看不懂这一部分，现在只想说： <strong>Perfect!</strong></p>
<blockquote>
<p>Therefore, traditional recognition/classification approaches minimize the empirical risk instead of the ideal risk RI by using other knowledge, such as assuming that the label space is at least locally smooth and regularizing the empirical risk minimization.  </p>
</blockquote>
<p>传统的分类方法是根据其他的外部知识来最小化经验风险，比如 label space 是光滑的，然后使用正则化最小经验风险（也就是上面所说的结构风险函数）。</p>
<blockquote>
<p>Note that traditional recognition problem is usually performed under the closed set assumption. When the assumption switches to open environment/set scenario with the open space, other things should be added since intuitively there is some risk in labeling sample in the open space as any known known classes. This gives such an insight for OSR that <strong>we do know something else: we do know where known known classes exist, and we know that in open space we do not have a good basis for assigning labels for the unknown unknown classes.</strong>  </p>
</blockquote>
<p>传统的识别是假设在固定的样本空间下(known known). 当转换到开放式场景下，我们很敏感的意识到需要给 label space 加点 risk。。我们知道 known known classes 是存在的，我们也知道我们并没有这样一个 basis 去给 unknown unknown 打标签。</p>
<h3 id="open-space-risk"><a href="#open-space-risk" class="headerlink" title="open space risk"></a>open space risk</h3><p>这部分的内容主要引自这篇 paper: <a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/document/6365193/">17. Toward Open Set Recognition</a></p>
<p>这篇 paper 是把 class of interest 当作一个类，然后所有的 unknown/known 当作很多 classes, 也就是  1-vs-set.</p>
<p><img src="/2018/12/09/rejection%E7%B3%BB%E5%88%971-overview-1/08.png"></p>
<blockquote>
<p>To improve the overall open set recognition error, our 1-vs-set formulation balances the unknown classes by obtaining a core margin around the decision boundary A from the base SVM, specializing the resulting half-space by adding another plane $\Omega$ and then generalizing or specializing the two planes (shown in Fig. 2) to optimize empirical and open space risk. This process uses the open set training data and the risk model to define a new “open set margin.” The second plane $\Omega$ allows the 1-vs-set machine to avoid the overgeneralization that would misclassify the raccoon in Fig. 2. The overall optimization can also adjust the original margin with respect to A to reduce open space risk, which can avoid negatives such as the owl.  </p>
</blockquote>
<p>使用了两个超平面，去分隔 Negatives/positivecs/unknown.</p>
<blockquote>
<p>While we do not know the joint distribution $P(x, y)$ in, one way to look at the open space risk is as a weak assumption: Far from the known data the Principle of Indifference [8] suggests that if there is no known reason to assign a probability, alternatives should be given equal probability. In our case, this means that at all points in open space, all labels (both known and unknown) are equally</p>
</blockquote>
<p>likely, and risk should be computed accordingly. However, we cannot have constant value probabilities over infinite spaces—the distribution must be integrable and integrate to 1. We must formalize open space differently (e.g., by ensuring the problem is well posed and then assuming the probability is proportional to relative Lebesgue measure [9]). Thus, we can consider the measure of the open space to the full space, and define our risk penalty proportional to such a ratio.  </p>
<p>无法知道联合分布 $P(x, y)$, 作者假设所有的样本概率是相等的，但是向量空间中样本总数是不确定的，所以作者定义一个比例来描述 在 open space 中出现 unknown 的危险惩罚系数。</p>
<p><img src="/2018/12/09/rejection%E7%B3%BB%E5%88%971-overview-1/09.png"></p>
<blockquote>
<p>where open space risk is considered to be the fraction (in terms of Lebesgue measure) of positively labeled open space compared to the overall measure of positively labeled space (which includes the space near the positive examples).  </p>
</blockquote>
<p><strong>open space risk</strong> 是开放空间中 positive label 的总数与总体空间中 positive label 的总体度量。</p>
<p>不太懂。。问题还是不知道怎么度量？ unknown 的类别能确定？？？</p>
<h3 id="openness"><a href="#openness" class="headerlink" title="openness"></a>openness</h3><p>openness，用来表征数据集的开放程度：</p>
<p><img src="/2018/12/09/rejection%E7%B3%BB%E5%88%971-overview-1/11.png"></p>
<ul>
<li><p>$C_{TR}$ 是训练集中的类别数，越大，开放程度越小。   </p>
</li>
<li><p>$C_{TE}$ 测试集中的类别数。  </p>
</li>
</ul>
<h3 id="The-Open-Set-Recognition-Problem"><a href="#The-Open-Set-Recognition-Problem" class="headerlink" title="The Open Set Recognition Problem"></a>The Open Set Recognition Problem</h3><blockquote>
<p>our goal is to balance the risk of the unknown in open space with the empirical (known) risk. In this sense, we formally define the open set recognition problem as follows:  </p>
</blockquote>
<p>我们的目的是平衡 the risk of unknown 出现在基于 known classes 计算的到的 open space 的 empirical risk。  </p>
<p>怎么理解呢？就是传统的风险函数都是只考虑了经验风险，也就是完全基于训练数据的。但是在 open space 里面，我们还要测试时会出现的 unknown，所以在 风险函数的设置的同时，就要考虑到 unknown 的存在。也就是前面的 open space risk.</p>
<p><img src="/2018/12/09/rejection%E7%B3%BB%E5%88%971-overview-1/12.png"></p>
<h2 id="a-categorization-of-OSR-techniques"><a href="#a-categorization-of-OSR-techniques" class="headerlink" title="a categorization of OSR techniques"></a>a categorization of OSR techniques</h2><p>问题的关键在于如何将 公式（4）open space risk 合并到模型中去。然后大佬们提出各式各样的模型，主要分为 discriminative model and generative models.</p>
<p>更进一步，可以分为：five categories (Table II):   </p>
<ul>
<li><p>Traditional ML-based  </p>
</li>
<li><p>Deep Network-based  </p>
</li>
<li><p>Adversarial Learning-based  </p>
</li>
<li><p>EVT-based  </p>
</li>
<li><p>Dirichlet Process-based OSR models</p>
</li>
</ul>
<p><img src="/2018/12/09/rejection%E7%B3%BB%E5%88%971-overview-1/21.png"></p>
<h3 id="Deep-Neural-Network-based-OSR-Models"><a href="#Deep-Neural-Network-based-OSR-Models" class="headerlink" title="Deep Neural Network-based OSR Models"></a>Deep Neural Network-based OSR Models</h3><p>大佬们的杰作，感觉都挺新的，新坑？</p>
<p><img src="/2018/12/09/rejection%E7%B3%BB%E5%88%971-overview-1/15.png"></p>
<p><img src="/2018/12/09/rejection%E7%B3%BB%E5%88%971-overview-1/13.png"></p>
<p><img src="/2018/12/09/rejection%E7%B3%BB%E5%88%971-overview-1/14.png"></p>
<p><img src="/2018/12/09/rejection%E7%B3%BB%E5%88%971-overview-1/16.png"></p>
<p>提出了 OpenMax,使用 deep networks, 还是用 softmax 损失函数来最小化 交叉熵 cross entropy loss. 然后在网络的倒数第二层（softmax 的前一层？）得到每一个正分类的 <strong>mean activate vector(MAV)</strong>.  </p>
<p>然后是根据 Weibull districution 去 redistribution 以及重新分类等等接下来的操作还是看相应 的 paper 吧。</p>
<blockquote>
<p>the OpenMax effectively addressed the challenge of the recognition for fooling/rubbish and unrelated open set images. However, as discussed in [71], the OpenMax fails to recognize the adversarial images which are visually indistinguishable from training samples but are designed to make deep networks produce high confidence but incorrect answers [96], [98].  </p>
</blockquote>
<p>OpenMax 有效的解决了 不相关的 open set images 的问题，但是却无法有效区分对抗生成样本。</p>
<blockquote>
<p>Actually, the authors in [72] have indicated that the OpenMax is susceptible to the adversarial generation techniques directly working on deep representations. Therefore, the adversarial samples are still a serious challenge for open set recognition. Furthermore, using the distance from MAV, the cross entropy loss function in OpenMax does not directly incentivize projecting class samples around the MAV. In addition to that, the distance function used in testing is not used in training, possibly resulting in inaccurate measurement in that space [73]. To address this limitation, Hassen and Chan [73] learned a neural network based representation for open set recognition, which is similar in spirit to the Fisher Discriminant, where samples from the same class are closed to each other while the ones from different classes are further apart, leading to larger space among known known classes for unknown unknown classes’ samples to occupy.  </p>
</blockquote>
<p>交叉熵并不能有效的将类别映射到相应的 MAV 中，因为在测试集中的 distence function 跟在 training set 里面是不一样的，这会导致不准确的判别。基于此，[73]提出了 Fisher 判别，从同一个类别中采样，使得unknown unknown 和 known known 的间距很大。</p>
<p><img src="/2018/12/09/rejection%E7%B3%BB%E5%88%971-overview-1/17.png"></p>
<ul>
<li><p>OpenMax to text classification  </p>
</li>
<li><p>Deep Open classifier  </p>
</li>
<li><p>tWiSARD  </p>
</li>
<li><p>hidden unknown unknown classes  </p>
</li>
</ul>
<h3 id="Adversarial-Learning-based-OSR-Models"><a href="#Adversarial-Learning-based-OSR-Models" class="headerlink" title="Adversarial Learning-based OSR Models"></a>Adversarial Learning-based OSR Models</h3><p><img src="/2018/12/09/rejection%E7%B3%BB%E5%88%971-overview-1/18.png"></p>
<blockquote>
<p>Note that the main challenge for open set recognition is the incomplete class knowledge existing in training, leading to the open space risk when classifiers encounter unknown unknown classes during testing. Fortunately, the adversarial learning technique can account for open space to some extent by adversarially generating the unknown unknown class data according to the known known class knowledge, which undoubtedly provides another way to tackle the challenging multiclass OSR problem.  </p>
</blockquote>
<p>open set recognition 最大的挑战是 training 中不完整的 knowledge， 在 testing 中遇到 unknown unknown 导致 open space risk.  </p>
<p>而对抗训练网络在某种程度上根据 known known 生成 unknown unknown，提供了另外一种方式解决 OSR 问题。</p>
<h3 id="EVT-based-OSR-Models"><a href="#EVT-based-OSR-Models" class="headerlink" title="EVT-based OSR Models"></a>EVT-based OSR Models</h3><blockquote>
<p>As a powerful tool to increase the classification performance, the <strong>statistical Extreme Value Theory (EVT)</strong> has recently achieved great success due to the fact that EVT can effectively model the tails of the distribution of distances between training observations using the asymptotic theory[100].  </p>
</blockquote>
<p>不是很懂这个理论，给出几篇 paper 吧</p>
<p><img src="/2018/12/09/rejection%E7%B3%BB%E5%88%971-overview-1/19.png"></p>
<p><img src="/2018/12/09/rejection%E7%B3%BB%E5%88%971-overview-1/20.png"></p>
<p><strong>Remark:</strong> As mentioned above, almost all existing OSR methods adopt the threshold-based classification scheme, where recognizers in decision either reject or categorize the input samples to some known known class using <strong>empirically set threshold</strong>. Thus the threshold plays a key role. However, the selection for it usually depends on the knowledge of known known classes, inevitably incurring risks due to lacking available information from unknown unknown classes [57]. This indicates the threshold-based OSR methods still face serious challenges.  </p>
<p>基于 known known 得到的 threshold 因为缺乏 unknown unknown 的信息，不可避免的会造成 risk, 这也是基于 threshold 这类方法所面临的困难。</p>
<h3 id="Dirichlet-Process-based-OSR-Models-生成模型"><a href="#Dirichlet-Process-based-OSR-Models-生成模型" class="headerlink" title="Dirichlet Process-based OSR Models (生成模型)"></a>Dirichlet Process-based OSR Models (生成模型)</h3><blockquote>
<p>Dirichlet process (DP) [104]–[108] considered as a distribution over distributions is a stochastic process, which has been widely applied in clustering and density estimation problems as a nonparametric prior defined over the number of mixture components. Furthermore, this model does not overly depend on training samples and can achieve adaptive change as the data changes, making it naturally adapt to the open set recognition scenario. In fact, researchers have begun the related research  </p>
</blockquote>
<p>Dirichlet 过程作为一种基于混合模型的非参数方法广泛用于聚类，参数估计。这种模型不需要依赖于 training，可以随着 dataset 的变化而自适应的变化，这使得它能有效的适用于 open set 的场景。</p>
<p>对生成模型不是很熟。。</p>
<p><strong>Remark:</strong> Instead of addressing the OSR problem from the discriminative model perspective, CD-OSR actually reconsiders this problem from the generative model perspective due to the use of HDP, which provides another research direction for open set recognition. Furthermore, the collective decision strategy for OSR is also worth further exploring since <strong>it not only takes the correlations among the testing samples into account but also provides a possibility for new class discovery,</strong> whereas single-sample decision strategy2 adopted by other existing OSR methods can not do such a work since it can not directly tell whether the single rejected sample is an outlier or from new class.  </p>
<h2 id="Beyond-open-set-Recognition"><a href="#Beyond-open-set-Recognition" class="headerlink" title="Beyond open set Recognition"></a>Beyond open set Recognition</h2><p>关于 open set recognition 如果仅仅考虑静态的 set，意义不是很大。以及，只对 unknown unknown 进行 rejection 也是不够的。为此，有人提出 open world recognition.</p>
<p>open world recognition (OWR), where a recognition system should perform four tasks:  </p>
<ul>
<li><p>detecting unknown unknown classes  </p>
</li>
<li><p>choosing which samples to label for addition to the model  </p>
</li>
<li><p>labelling those samples  </p>
</li>
<li><p>updating the classifier</p>
</li>
</ul>
<p><strong>Remark:</strong> As a natural extension of OSR, the OWR faces more serious challenges which require it not only to have the ability to handle the OSR task, but also to have minimal</p>
<p>downtime, even to continuously learn, which seems to have the flavor of lifelong learning to some extent. Besides, although some progress regarding the OWR has been made, there is still a long way to go.  </p>
<p>终身学习。。666</p>
<h2 id="Dataset-and-evalution-metrics"><a href="#Dataset-and-evalution-metrics" class="headerlink" title="Dataset and evalution metrics"></a>Dataset and evalution metrics</h2><h3 id="dataset"><a href="#dataset" class="headerlink" title="dataset"></a>dataset</h3><ul>
<li><p><a target="_blank" rel="noopener" href="https://dx.doi.org/10.6084/m9.figshare.1097614">https://dx.doi.org/10.6084/m9.figshare.1097614</a>  </p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://www.csie.ntu.edu.tw/%E2%88%BCcjlin/libsvmtools/datasets/multi-class.html">https://www.csie.ntu.edu.tw/∼cjlin/libsvmtools/datasets/multi-class.html</a></p>
</li>
</ul>
<p><img src="/2018/12/09/rejection%E7%B3%BB%E5%88%971-overview-1/22.png"></p>
<blockquote>
<p> Experiment Setup: In open set recognition, most existing experiments are carried out on a variety of recastes multi-class benchmark datasets. Specifically, taking the Usps dataset as an example, when it is used for OSR problem, one can randomly choose S distinct labels as the known known classes, and vary openness by adding a subset of the remaining labels.  </p>
</blockquote>
<p>可以增加减少类别数来改变 openness.</p>
<h3 id="Evaluation-Metrics-for-Open-Set-Recognition"><a href="#Evaluation-Metrics-for-Open-Set-Recognition" class="headerlink" title="Evaluation Metrics for Open Set Recognition"></a>Evaluation Metrics for Open Set Recognition</h3><ul>
<li><p>TP： true positive  </p>
</li>
<li><p>FP: false positive</p>
</li>
<li><p>TN: true negative  </p>
</li>
<li><p>FN: false negative  </p>
</li>
<li><p>TU: true unknown  </p>
</li>
<li><p>FU: false unknown</p>
</li>
</ul>
<h4 id="accuracy"><a href="#accuracy" class="headerlink" title="accuracy"></a>accuracy</h4><p>对于 closed set :</p>
<p>$$\text{accuracy}=\dfrac{TP+TN}{TP+TN+FP+FN}$$</p>
<p>对于 open set:</p>
<p>$$\text{accuracy}_O=\dfrac{(TP+TN)+TU}{(TP+TN+FP+FN)+(TU+FU)}$$</p>
<p>对于不均衡情况，accuracy 并不能客观的评价模型好坏。比如在testing 中，unknown unknown 样本数量很多,那么如果分类器把所有的类别都判为 unknown unknown，它的准确率依旧很高。</p>
<p>于是，有人提出了 <strong>normalized accuracy(NA)</strong>.</p>
<p><img src="/2018/12/09/rejection%E7%B3%BB%E5%88%971-overview-1/23.png"></p>
<p>$0\le \lambda \le 1$ 是正则化常数。</p>
<h4 id="F-measure"><a href="#F-measure" class="headerlink" title="F-measure"></a>F-measure</h4><p>F1:  </p>
<p>$$F1=\dfrac{2<em>\text{precision}</em> \text{recall}}{\text{precision}+\text{recall}}$$</p>
<p>$$precision=\dfrac{TP}{TP+FP}$$</p>
<p>精度： 预测得到的 positive 中真正是 positive 的概率。</p>
<p>$$recall=\dfrac{TP}{TP+FN}$$</p>
<p>召回： 所有真正 positive 的样本被预测为 positive 的概率。</p>
<p>在 open set 场景下，F1 值无法考虑 unknown unknown.</p>
<blockquote>
<p>Instead, the computations of Precision and Recall in it are only for available known known classes. Additionally, the work [67] has indicated that although the computations of Precision and Recall are only for available known known classes, the FN and FP also consider the false unknown unknown classes and false known known classes by taking into account the false negative and the false positive, and we refer the reader to [67] for more details.  </p>
</blockquote>
<p>事实上，在 FP 和 FN 中可能也包括 false unknown unknown, 这就有问题了是吧。。</p>
<p>详细参考这篇 paper <a target="_blank" rel="noopener" href="https://link.springer.com/content/pdf/10.1007%2Fs10994-016-5610-8.pdf">Nearest neighbors distance ratio open-set classifier</a></p>
<blockquote>
<p>Note that the Precision</p>
</blockquote>
<p>contains the <strong>macro-Precision and micro-Precision</strong> while Recall includes the macro-Recall and micro-Recall, which leads to the corresponding <strong>macro-F-measure and micro-F-measure</strong>. Nevertheless, whether it is macro-F-measure or micro-F-measure, the higher their values, the better the performance of the corresponding OSR model.</p>
<h4 id="Youden’s-index-for-OSR"><a href="#Youden’s-index-for-OSR" class="headerlink" title="Youden’s index for OSR"></a>Youden’s index for OSR</h4><p>$$J= \text{Recall}+S-1$$</p>
<p>其中 S 是真负类率： $S=\dfrac{TN}{TN+FP}$</p>
<h2 id="future-research-directions"><a href="#future-research-directions" class="headerlink" title="future research directions"></a>future research directions</h2><h3 id="About-modeling"><a href="#About-modeling" class="headerlink" title="About modeling"></a>About modeling</h3><ul>
<li><p>大部分工作都是基于判别模型来做的，只有少部分是基于生成模型，也许生成模型会更有探索空间。</p>
</li>
<li><p>OSR 的主要挑战是传统的分类器是在 closed-set 场景下获得的，一旦 unknown unknown class 落入这个空间，将永远无法被正确的分类。</p>
</li>
</ul>
<h4 id="modeling-known-known-classes"><a href="#modeling-known-known-classes" class="headerlink" title="modeling known known classes"></a>modeling known known classes</h4><p>如果得到的 known known class 没有被过拟合，那么这样的分类器就能有效的区分出 unknown unknown. 所以聚类和分类算法的结合会是不错的方向。关于 clustering 和  classification 的 unified learning framework:</p>
<p><img src="/2018/12/09/rejection%E7%B3%BB%E5%88%971-overview-1/24.png"></p>
<p>这两篇 paper 依旧是在 closed-set 下做的，所以需要你去尝试。。。</p>
<h4 id="modeling-unknown-unknown-classes"><a href="#modeling-unknown-unknown-classes" class="headerlink" title="modeling unknown unknown classes"></a>modeling unknown unknown classes</h4><p>似乎在只有 known known classes 的情况下是很难去学习 unknown unknown 的类的性质的。但是可以通过对抗学习来生成 unknown unknown 也是不错的方向。</p>
<p>顺便作者还提了下 transductive leanring，以及基于 Dirichlet process 的自适应行，CD-OSR、Dirichlet processed-based OSR 也是值得探索的。</p>
<h3 id="About-rejecting"><a href="#About-rejecting" class="headerlink" title="About rejecting"></a>About rejecting</h3><p>大部分的工作都是 reject unknown unknown classes，而没有后续的工作了。只有少量的 [66][67]进行了后续的工作，比如 new classes discovery.</p>
<p><img src="/2018/12/09/rejection%E7%B3%BB%E5%88%971-overview-1/25.png"></p>
<h3 id="About-the-decision"><a href="#About-the-decision" class="headerlink" title="About the decision"></a>About the decision</h3><p>所有的 OSR 模型都是用来识别单个样本的，但是一个决策的决定并没有考虑样本之间的相关性。所以 <strong>collective decision</strong> 不仅在 testing 时考虑相关性，同时还能发现 new classes.</p>
<p><img src="/2018/12/09/rejection%E7%B3%BB%E5%88%971-overview-1/27.png"></p>
<p><img src="/2018/12/09/rejection%E7%B3%BB%E5%88%971-overview-1/28.png"></p>
<h3 id="Open-set-‘sth’"><a href="#Open-set-‘sth’" class="headerlink" title="Open set + ‘sth’"></a>Open set + ‘sth’</h3><p>As open set scenario is a more practical assumption for the real-world classification/recognition tasks, it can naturally be combined with various fields involving classification/recognition such as <strong>semi-supervised learning, domain adaptation, active learning, multi-task learning, multi-label learning, multi-view learning,</strong> and so forth. For example, [124]–[126] recently introduced this scenario into domain adaptation, while [127] explored the open set classification in active learning field. Therefore, many interesting works are worth looking forward to.  </p>
<p>看起来是个不错的方向。。</p>
<p><img src="/2018/12/09/rejection%E7%B3%BB%E5%88%971-overview-1/26.png"></p>
<h3 id="Generalized-Open-Set-Recognition"><a href="#Generalized-Open-Set-Recognition" class="headerlink" title="Generalized Open Set Recognition"></a>Generalized Open Set Recognition</h3><p>利用 side-information,比如 unknown unknwon 和 known known 会有共同的语义信息(semantic/attribute information).</p>
<h4 id="Appending-semantic-attribute-information"><a href="#Appending-semantic-attribute-information" class="headerlink" title="Appending semantic/attribute information"></a>Appending semantic/attribute information</h4><blockquote>
<p>In fact, a lot</p>
</blockquote>
<p>of semantic/attibute information is shared between the known known and the unknown unknown classes. Therefore, we can fully utilize this kind of information to ’cognize’ the unknown unknown classes, or at least to provide a rough semantic/attribute description for the corresponding unknown unknown classes instead of simply rejecting them.  </p>
<p>利用语义信息去意识到 unknown unknwon，而不是简单的 reject.</p>
<p>但是要注意区分 open set recognition 和 ZSL(zero-shot learning) 的区别：</p>
<p><img src="/2018/12/09/rejection%E7%B3%BB%E5%88%971-overview-1/29.png"></p>
<p>The $\text{side-information}^1$ in ZSL denotes the semantic/attribute information shared among all classes including known known and unknown known classes.</p>
<p>where the $\text{side-information}^4$ denotes the available semantic/attribute information only for known known classes</p>
<p>感觉这个 side-information 的界限很难确定啊？Generalized Open Set Recognition 的这个范围似乎很难实现， 怎么可能出现在 training 中的 semantice information 完全不出现在 unknown unknown 中呢。。</p>
<p><img src="/2018/12/09/rejection%E7%B3%BB%E5%88%971-overview-1/30.png"></p>
<p><img src="/2018/12/09/rejection%E7%B3%BB%E5%88%971-overview-1/31.png"></p>
<p><img src="/2018/12/09/rejection%E7%B3%BB%E5%88%971-overview-1/32.png"></p>
<p>还有一些相似的工作：</p>
<p><img src="/2018/12/09/rejection%E7%B3%BB%E5%88%971-overview-1/33.png"></p>
<h4 id="Using-other-available-side-information"><a href="#Using-other-available-side-information" class="headerlink" title="Using other available side-information"></a>Using other available side-information</h4><blockquote>
<p>**The main reason for open space risk is that the traditional classifiers trained under closed set scenario usually divide over-occupied space for known known classes, thus inevitably resulting in misclassifications once the unknown unknown class samples</p>
</blockquote>
<p>fall into the space divided for some known known class.** From this perspective, the open space risk will be reduced as the space divided for those known known classes decreases by</p>
<p>using other side-information like universum [135], [136] to shrink their regions as much as possible.  </p>
<p>虽然感觉很扯淡。。但是还是有人做啊，不过关于 open space risk 的定义可以在看一遍。。</p>
<h3 id="Relative-Open-Set-Recognition"><a href="#Relative-Open-Set-Recognition" class="headerlink" title="Relative Open Set Recognition"></a>Relative Open Set Recognition</h3><p>感觉这个还挺有意思的。疾病的诊断，所有的样本空间都可以区分为 sick or no sick, 所以仅仅是判断有没有病，那么这是个 closed set 问题。但是如果我们要进一步判断疾病的类型，那么有可能出现 unseen disease in training.</p>
<h3 id="Knowledge-Integration-for-Open-Set-Recognition"><a href="#Knowledge-Integration-for-Open-Set-Recognition" class="headerlink" title="Knowledge Integration for Open Set Recognition"></a>Knowledge Integration for Open Set Recognition</h3><blockquote>
<p>In fact, the incomplete knowledge of the world is universal, especially for the single individuals: something you know does not mean I also know.  </p>
</blockquote>
<blockquote>
<p>how to integrate the classifiers trained on each sub-knowledge set to further reduce the open space risk will be an interesting yet challenging topic in the future work, especially for such a situation: we can only obtain the classifiers trained on corresponding sub-knowledge sets, yet these sub-knowledge sets are not available due to the privacy protection of data.  </p>
</blockquote>
<p>利用知识库来减小 open space risk。</p>
<p>似乎这个看起来比较靠谱，因为 unknown 范围确实很难定义，如果给个外部知识库给你，把跟知识库相关的 unknown 识别出来，就很棒了吧</p>
<p><img src="/2018/12/09/rejection%E7%B3%BB%E5%88%971-overview-1/34.png"></p>
<p>相关的一些开源工具和代码：</p>
<p><img src="/2018/12/09/rejection%E7%B3%BB%E5%88%971-overview-1/35.png"></p>
</div></article></div><nav class="pagination" role="navigation" aria-label="pagination"><div class="pagination-previous"><a href="/page/11/">上一页</a></div><div class="pagination-next"><a href="/page/13/">下一页</a></div><ul class="pagination-list is-hidden-mobile"><li><a class="pagination-link" href="/">1</a></li><li><span class="pagination-ellipsis">&hellip;</span></li><li><a class="pagination-link" href="/page/11/">11</a></li><li><a class="pagination-link is-current" href="/page/12/">12</a></li><li><a class="pagination-link" href="/page/13/">13</a></li><li><span class="pagination-ellipsis">&hellip;</span></li><li><a class="pagination-link" href="/page/25/">25</a></li></ul></nav></div><!--!--><div class="column column-right is-4-tablet is-4-desktop is-4-widescreen  order-3"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar" src="/img/avatar.png" alt="panxiaoxie"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">panxiaoxie</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Beijing, China</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">文章</p><a href="/archives"><p class="title">121</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">分类</p><a href="/categories"><p class="title">40</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">标签</p><a href="/tags"><p class="title">38</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/PanXiebit" target="_blank" rel="noopener">关注我</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/PanXiebit"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Email" href="/ftdpanxie@gmail.com"><i class="fa fa-envelope"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="RSS" href="/"><i class="fas fa-rss"></i></a></div></div></div><!--!--><div class="card widget" data-type="links"><div class="card-content"><div class="menu"><h3 class="menu-label">链接</h3><ul class="menu-list"><li><a class="level is-mobile" href="https://github.com/PanXiebit" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">github</span></span><span class="level-right"><span class="level-item tag">github.com</span></span></a></li><li><a class="level is-mobile" href="ftdpanxie@gmail.com" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">email</span></span><span class="level-right"><span class="level-item tag">ftdpanxie@gmail.com</span></span></a></li></ul></div></div></div><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">分类</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/C/"><span class="level-start"><span class="level-item">C++</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/CSAPP/"><span class="level-start"><span class="level-item">CSAPP</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/DRL/"><span class="level-start"><span class="level-item">DRL</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/GAN/"><span class="level-start"><span class="level-item">GAN</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li><li><a class="level is-mobile" href="/categories/GAN-RL/"><span class="level-start"><span class="level-item">GAN, RL</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/ML/"><span class="level-start"><span class="level-item">ML</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/NLP/"><span class="level-start"><span class="level-item">NLP</span></span><span class="level-end"><span class="level-item tag">14</span></span></a></li><li><a class="level is-mobile" href="/categories/TensorFlow/"><span class="level-start"><span class="level-item">TensorFlow</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/cs224d/"><span class="level-start"><span class="level-item">cs224d</span></span><span class="level-end"><span class="level-item tag">10</span></span></a></li><li><a class="level is-mobile" href="/categories/generation/"><span class="level-start"><span class="level-item">generation</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/generative-models/"><span class="level-start"><span class="level-item">generative models</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/interview/"><span class="level-start"><span class="level-item">interview</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/machine-translation/"><span class="level-start"><span class="level-item">machine translation</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/python/"><span class="level-start"><span class="level-item">python</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/pytorch/"><span class="level-start"><span class="level-item">pytorch</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/reinforcement-learning/"><span class="level-start"><span class="level-item">reinforcement learning</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/sign-language-recognition/"><span class="level-start"><span class="level-item">sign language recognition</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/transfer-learning/"><span class="level-start"><span class="level-item">transfer learning</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/transformer/"><span class="level-start"><span class="level-item">transformer</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"><span class="level-start"><span class="level-item">数据结构与算法</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile" href="/categories/%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB/"><span class="level-start"><span class="level-item">文本分类</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"><span class="level-start"><span class="level-item">论文笔记</span></span><span class="level-end"><span class="level-item tag">40</span></span></a><ul><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/DL/"><span class="level-start"><span class="level-item">DL</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/ESA/"><span class="level-start"><span class="level-item">ESA</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/GAN/"><span class="level-start"><span class="level-item">GAN</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/MRC-and-QA/"><span class="level-start"><span class="level-item">MRC and QA</span></span><span class="level-end"><span class="level-item tag">7</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/Machine-Translation/"><span class="level-start"><span class="level-item">Machine Translation</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/NLP/"><span class="level-start"><span class="level-item">NLP</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/Transformer/"><span class="level-start"><span class="level-item">Transformer</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/capsules/"><span class="level-start"><span class="level-item">capsules</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/computer-vision/"><span class="level-start"><span class="level-item">computer vision</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/constrast-learning/"><span class="level-start"><span class="level-item">constrast learning</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/data-augmentation/"><span class="level-start"><span class="level-item">data augmentation</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/dialogue-system/"><span class="level-start"><span class="level-item">dialogue system</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/language-model/"><span class="level-start"><span class="level-item">language model</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/machine-translation/"><span class="level-start"><span class="level-item">machine translation</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/open-set-recognition/"><span class="level-start"><span class="level-item">open set recognition</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/sentence-embedding/"><span class="level-start"><span class="level-item">sentence embedding</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/text-matching/"><span class="level-start"><span class="level-item">text matching</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/vision-language/"><span class="level-start"><span class="level-item">vision-language</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li></ul></div></div></div></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/panxiaoxie.png" alt="潘小榭" height="28"></a><p class="is-size-7"><span>&copy; 2022 Xie Pan</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("zh-CN");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="回到顶端" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "此网站使用Cookie来改善您的体验。",
          dismiss: "知道了！",
          allow: "允许使用Cookie",
          deny: "拒绝",
          link: "了解更多",
          policy: "Cookie政策",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.5/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="想要查找什么..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"想要查找什么...","untitled":"(无标题)","posts":"文章","pages":"页面","categories":"分类","tags":"标签"});
        });</script></body></html>