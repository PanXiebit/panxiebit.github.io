<!doctype html>
<html lang="zh"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>潘小榭</title><link rel="manifest" href="/manifest.json"><meta name="theme-color" content="black"><meta name="application-name" content="潘晓榭"><meta name="msapplication-TileImage" content="/img/avatar.png"><meta name="msapplication-TileColor" content="black"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="潘晓榭"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta property="og:type" content="blog"><meta property="og:title" content="潘晓榭"><meta property="og:url" content="https://github.com/PanXiebit"><meta property="og:site_name" content="潘晓榭"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://www.qt86.com/cache/1625298592_187938.png"><meta property="article:author" content="潘晓榭"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="https://www.qt86.com/cache/1625298592_187938.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"http://www.panxiaoxie.cn"},"headline":"潘小榭","image":["http://www.panxiaoxie.cn/img/og_image.png"],"author":{"@type":"Person","name":"Xie Pan"},"publisher":{"@type":"Organization","name":"潘小榭","logo":{"@type":"ImageObject","url":"http://www.panxiaoxie.cn/img/panxiaoxie.png"}},"description":null}</script><link rel="icon" href="/img/avatar.png"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/css/justifiedGallery.min.css"><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script><!--!--><!--!--><meta name="generator" content="Hexo 5.4.0"></head><body class="is-2-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/panxiaoxie.png" alt="潘小榭" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">主页</a><a class="navbar-item" href="/archives">归档</a><a class="navbar-item" href="/categories">分类</a><a class="navbar-item" href="/tags">标签</a><a class="navbar-item" href="/about">关于我</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/PanXiebit"><i class="fab fa-github"></i></a><a class="navbar-item search" title="搜索" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-8-widescreen"><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2019-08-30T11:36:13.000Z" title="2019/8/30 下午7:36:13">2019-08-30</time>发表</span><span class="level-item"><time dateTime="2021-06-29T08:12:08.200Z" title="2021/6/29 下午4:12:08">2021-06-29</time>更新</span><span class="level-item"><a class="link-muted" href="/categories/GAN/">GAN</a></span><span class="level-item">10 分钟读完 (大约1448个字)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2019/08/30/%E4%BB%8E0%E5%BC%80%E5%A7%8BGAN-7-IRGAN/">从0开始GAN-7-IRGAN</a></h1><div class="content"><h3 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h3><p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1705.10513">IRGAN: A Minimax Game for Unifying Generative and Discriminative Information Retrieval Models</a>  </p>
<p>信息检索的方法主要分为两个流派，生成式检s索模型(generative retrieval model)和判别式检索模型(discriminative retrieval model)。</p>
<p>生成式检索模型 ($q \rightarrow d$)：认为query和检索所需要的document之间有一个潜在的随机生成的过程。也就是给定一个 query，然后生成相应的 document.  </p>
<p>判别式检索模型 ($q + d \rightarrow r$)：把query和document作为联合feature，计算其相关性relevancy. 然后基于 relevancy 对 document 进行排序。其中关于 ranking a list of documents 有三种范式：pointwise, pairwise, listwise.</p>
<p>作者将上述两种模型与GAN相结合，利用GAN的对抗性的思想去提升两类模型。   </p>
<p>判别式检索模型 $p_{\phi}(r|q,d)$ 作为判别器，maximize 来自真实 labeled 的数据。它提供信息来指导生成器的训练，这种信息不同于传统的 log-likelihood.  </p>
<p>判别式检索模型 $p_{\theta}(d|q,r)$ 是生成器，生成generated sample来迷惑判别器，minimize 对应的目标函数。</p>
<h3 id="Model-Architecture"><a href="#Model-Architecture" class="headerlink" title="Model Architecture"></a>Model Architecture</h3><h4 id="A-Minimax-Retrieval-Framework"><a href="#A-Minimax-Retrieval-Framework" class="headerlink" title="A Minimax Retrieval Framework"></a>A Minimax Retrieval Framework</h4><p>a set of queries ${q_1,…,q_N}$, a set of documents ${d_1,…,d_M}$. 其中 给定一个 query 都有对应的相关度较高的 document 也就是真实的数据 $true_{(q,d)}$，其数据量是远小于总的document数量 M 的.</p>
<blockquote>
<p>The underlying true relevance distribution can be expressed</p>
</blockquote>
<p>as conditional probability $p_{true} (d|q, r)$, which depicts the (user’s) relevance preference distribution over the candidate documents with respect to her submitted query.  </p>
<p>这样真实的相关性 (q,d) 存在潜在的相关性条件分布 $p_{true}(d|q,r)$.</p>
<p>Generative retrieval model $p_{\theta}(d|q,r)$: 生成器的目的就是去尽可能的模拟真实的相关性分布 $p_{ture}(d|q,r)$, 从而尽可能生成相似度高的 document.</p>
<p><img src="/2019/08/30/%E4%BB%8E0%E5%BC%80%E5%A7%8BGAN-7-IRGAN/generator_model.png"></p>
<p>Discriminative retrieval model $f_{\phi}(q,d)$：是一个二分类分类器。</p>
<p><img src="/2019/08/30/%E4%BB%8E0%E5%BC%80%E5%A7%8BGAN-7-IRGAN/discriminator_model.png">  </p>
<p>其中判别器具体的计算 $f_{\phi}(d,q)$ 与IR task有关。后续会详细介绍。</p>
<p>Overall Objective 目标函数：</p>
<p><img src="/2019/08/30/%E4%BB%8E0%E5%BC%80%E5%A7%8BGAN-7-IRGAN/object_func.png">  </p>
<p>最小化来自生成器 $p_{\theta}$ 的 sample 的概率，最大化来自true data $p_{true}$ 的 sample 的概率.  </p>
<h4 id="Optimising-Discriminative-Retrieval"><a href="#Optimising-Discriminative-Retrieval" class="headerlink" title="Optimising Discriminative Retrieval"></a>Optimising Discriminative Retrieval</h4><p>优化判别器：  </p>
<p><img src="/2019/08/30/%E4%BB%8E0%E5%BC%80%E5%A7%8BGAN-7-IRGAN/train_dis_model.png">  </p>
<h4 id="Optimising-Generative-Retrieval"><a href="#Optimising-Generative-Retrieval" class="headerlink" title="Optimising Generative Retrieval"></a>Optimising Generative Retrieval</h4><p>这篇paper中生成器不是token by token的生成新的ducoment，而是从given documents中选择最相关的document.  </p>
<p>对于生成器的优化，最小化目标函数（1）：  </p>
<p><img src="/2019/08/30/%E4%BB%8E0%E5%BC%80%E5%A7%8BGAN-7-IRGAN/train_gen_model.png"></p>
<p>上述公式从第一步到第二步有点小变化，简单推导下即可。</p>
<p>这里sample得到d的过程是离散的。怎么理解呢，可以类比文本的生成（尽管此表的分布是连续的，但是从中选一个token，然后作为判别器的输入，这个过程是不可导的）。同样，这里是从一系列documents中sample一个作为判别器的输入，这个过程是离散的，且不可导。所以作者采用了policy gradient的方法来解决这个问题。</p>
<p>公式(4)中对生成器的优化可以看作是 maximize $J^G(q_n)$. 使用policy gradient优化的推导如下：</p>
<p><img src="/2019/08/30/%E4%BB%8E0%E5%BC%80%E5%A7%8BGAN-7-IRGAN/pg_train.png">  </p>
<p>这里的policy是 $p_{\theta}(d|q_n,r)$ 就是我们需要优化的生成式检索模型，对应的action是给定environment q的情况下sample得到 document. 判别器得到的log-prob就是reward.</p>
<p>为了减小REINFORCE方法中variance，作者采用了advantage-function，也就是减去baseline，其中baseline是均值：</p>
<p><img src="/2019/08/30/%E4%BB%8E0%E5%BC%80%E5%A7%8BGAN-7-IRGAN/advantage_func.png"></p>
<p>整个IRGAN的训练过程的伪代码：</p>
<p><img src="/2019/08/30/%E4%BB%8E0%E5%BC%80%E5%A7%8BGAN-7-IRGAN/algorithm.png"></p>
<p>上图中的公式(22)就是公式(5). 整个过程理解起来还是蛮简单的。</p>
<p>还有个问题为解决的是，前面提到对于不同的 IR 任务，判别器 $f_{\phi}(q,d)$ 的方式是不一样的。</p>
<h4 id="pairwise-case"><a href="#pairwise-case" class="headerlink" title="pairwise case"></a>pairwise case</h4><blockquote>
<p>Furthermore, ifwe use graded relevance scales (indicating a varying degree of match between each document and the corresponding query) rather than binary relevance, the training data could also be represented naturally as ordered document pairs.   </p>
</blockquote>
<p>此外，如果我们使用分级相关性比例（指示每个文档与相应查询之间的不同匹配程度）而不是二元相关性，则训练数据也可以自然地表示为有序文档对.</p>
<p>也就是不仅仅根据query和document之间是否相似这样的二元文档对，而是利用有序文档对（这在IR中其实更为常见），作为判别器的输入，这样能获取更多的信息。</p>
<p>这个时候的labeled document是 $R_n={&lt;d_i,d_j&gt;|d_i &gt; d_j}$, 其中 $d_i &gt; d_j$ 意味着 $d_i$ 比 $d_j$ 的相关性更高。</p>
<p><img src="/2019/08/30/%E4%BB%8E0%E5%BC%80%E5%A7%8BGAN-7-IRGAN/pairwise_func.png"></p>
<p>使用pairwise discriminator对应的目标函数：  </p>
<p><img src="/2019/08/30/%E4%BB%8E0%E5%BC%80%E5%A7%8BGAN-7-IRGAN/pairwise_train.png"></p>
<p>其中 $o = &lt;d_u,d_v&gt;, o’=&lt;d_u’,d_v’&gt;$. 在实际的操作中，选择一对document $&lt;d_i,d_j&gt;$. 然后选择相似度较低的 $d_j$ 与生成器得到的 $d_k$ 组成新的pairs $&lt;d_k, d_j&gt;$，作为判别器的输入。这样的目的就是认为 $d_k$ 的相似度高于 $d_j$ 的情况下，让 $d_k$ 尽可能的去与 $d_i$ 相似。</p>
<p>在前面介绍了生成器 $p_{\theta}(d|q,r)$ 实际上就是 softmax，看公式(2).</p>
<p>对于pairwise的形式,$d_j$ 也作为生成器的输入之一，对应的生成器是另一种 softmax:</p>
<p><img src="/2019/08/30/%E4%BB%8E0%E5%BC%80%E5%A7%8BGAN-7-IRGAN/pairwise_gen.png">  </p>
<p>其中 $g_{\theta}(q,d)$ is a task-specific real-valued function reflecting the chance of d being generated from q.  </p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2019-08-12T12:41:48.000Z" title="2019/8/12 下午8:41:48">2019-08-12</time>发表</span><span class="level-item"><time dateTime="2021-01-27T08:44:33.173Z" title="2021/1/27 下午4:44:33">2021-01-27</time>更新</span><span class="level-item"><a class="link-muted" href="/categories/reinforcement-learning/">reinforcement learning</a></span><span class="level-item">几秒读完 (大约2个字)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2019/08/12/UCB-cs294-policy-gradient/">UCB-cs294-policy gradient</a></h1><div class="content"><h3 id="Policy-Gradient"><a href="#Policy-Gradient" class="headerlink" title="Policy Gradient"></a>Policy Gradient</h3></div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2019-06-30T07:43:31.000Z" title="2019/6/30 下午3:43:31">2019-06-30</time>发表</span><span class="level-item"><time dateTime="2021-06-29T08:12:08.539Z" title="2021/6/29 下午4:12:08">2021-06-29</time>更新</span><span class="level-item"><a class="link-muted" href="/categories/GAN/">GAN</a></span><span class="level-item">10 分钟读完 (大约1521个字)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2019/06/30/%E4%BB%8E0%E5%BC%80%E5%A7%8BGAN-6-pretraining-for-NLG/">从0开始GAN-6-pretraining for NLG</a></h1><div class="content"><h3 id="related-papers"><a href="#related-papers" class="headerlink" title="related papers"></a>related papers</h3><ul>
<li><p><a href>BERT</a>   </p>
</li>
<li><p><a href>BERT has a Mouth, and It Must Speak: BERT as a Markov Random Field Language Model</a>    </p>
</li>
<li><p><a href>GPT/GPT-2.0</a>  </p>
</li>
<li><p><a href>MASS: Masked Sequence to Sequence Pre-training for Language Generation</a>   </p>
</li>
<li><p><a href>Unified Language Model Pre-training for Natural Language Understanding and Generation</a>      </p>
</li>
<li><p><a href>Pretraining for Conditional Generation with Pseudo Self Attention</a>    </p>
</li>
<li><p><a href>Transformer-XL</a>       </p>
</li>
<li><p><a href>XLNet</a>     </p>
</li>
<li><p><a href>Defending Against Neural Fake News</a></p>
</li>
<li><p><a href>ERNIE</a>  </p>
</li>
<li><p><a href>WWM</a>  </p>
</li>
<li><p><a href>SpanBERT</a></p>
</li>
</ul>
<h3 id><a href="#" class="headerlink" title></a></h3><h3 id="cross-lingual-word-embedding"><a href="#cross-lingual-word-embedding" class="headerlink" title="cross-lingual word embedding"></a>cross-lingual word embedding</h3><p><a href>A survey of cross-lingual word embedding models, Ruder et al.2017</a>  </p>
<p><a href>Word translation without parallel data. Conneau et al.2017</a>  </p>
<p><a href>Massively multilingual sentence embeddings for zero-shot cross-lingual transfer and beyond. Artetxe et al.2018</a>  </p>
<h3 id="contextual-word-embedding"><a href="#contextual-word-embedding" class="headerlink" title="contextual word embedding"></a>contextual word embedding</h3><p><a href>ELMo</a>  </p>
<p><a href>Word2vec</a>  </p>
<p><a href>Glove</a>  </p>
<p><a href>GPT</a>  </p>
<p><a href>ULMFT: Universal language model fine-tuning for text classificatio</a>  </p>
<p><a href>Cross-lingual language model pretraining</a>  </p>
<p><a href>Polyglot contextual representations im- prove crosslingual transfer</a>  </p>
<h3 id="pre-trained-for-NMT"><a href="#pre-trained-for-NMT" class="headerlink" title="pre-trained for NMT"></a>pre-trained for NMT</h3><p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1908.05672">Towards Making the Most of BERT in Neural Machine Translation</a></p>
<p><a href>Unsupervised Pretraining for Sequence to Sequence Learning</a></p>
<p><a href>When and Why are Pre-trained Word Embeddings Useful for Neural Machine Translation?</a></p>
<p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1901.07291">Cross-lingual Language Model Pretraining</a>  </p>
<h1 id="XLM"><a href="#XLM" class="headerlink" title="XLM"></a>XLM</h1><p>paper: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1901.07291">Cross-lingual Language Model Pretraining</a>  </p>
<p>作者提出了两种方法来学习 cross-lingual 语言模型。其中一种是仅基于 monolingual data, 另一种是基于平行语料。在 cross-lingal 相关的任务上都有很大的提升。比如 XNLI，unsupervised machine translation, 以及 supervised machine tranlsation.</p>
<p>现有的在NLP领域的发展主要是围绕英文进行的，一些start-of-the-art或者NLP任务的benchmarks都是以英文为基础的。其他的一些语言受限于语料的问题，发展相对缓慢。近期随着cross-lingual sentence representation的发展，消除English-centric bias,并且构建一个通用的cross-lingual encoder来讲任何语言的sentence编码到共享的embedding空间成为可能。</p>
<p><strong>Shared sub-word vocabulary</strong></p>
<p>使用 bpe,并且不同的language共享词表.</p>
<blockquote>
<p>this greatly improves the alignment of embedding spaces across languages that share either the same alphabet or anchor tokens such as digits (Smith et al., 2017) or proper nouns.  </p>
</blockquote>
<p>共享词表能显著提升那些具有相同字母表或者anchor token(数字或专有名词)的语言之间的向量空间的对齐。</p>
<p>作者先从不同语言的monolingual data中筛选出部分data，然后学习bpe splits.</p>
<blockquote>
<p>Sentences are sampled according to a multinomial distribution with probabilities ${q_i}_{i=1…N}$, where:</p>
</blockquote>
<p><img src="/2019/06/30/%E4%BB%8E0%E5%BC%80%E5%A7%8BGAN-6-pretraining-for-NLG/sample_data.png"></p>
<p>其中 $n_i$ 表示第 i 中语言中sentence的总数。 $\sum_{k=1}^nn_k$ 表示N种语言所有的sentence的总数。$p_i$ 则表示第 i 中语言sample的概率。设定 $\alpha=0.5$，这样能增加 low-resource 的比例，从而减轻 bias to high-resource language.</p>
<p>作者总共提出了三种 language model. 接下来一一介绍：</p>
<p><strong>Causal Language Modeling (CLM)</strong>  </p>
<p>$p(w_t|w_1,…,w_{t-1},\theta)$</p>
<p>也就是普通的 aotu-regressive 语言模型。</p>
<p><a target="_blank" rel="noopener" href="https://www.aaai.org/ojs/index.php/AAAI/article/view/4182">Character-Level Language Modeling with Deeper Self-Attention</a> 这篇paper使用的self-attention, 我们知道self-attention 不像rnn那样具有hidden state的概率，这篇paper把上一个batch作为下一个batch的context，有点类似于 transformer-XL,但是这对于cross-lingual不太适合，所以这里的 CLM 与传统的language model完全一致。</p>
<p><strong>Masked Language Modeling (MLM)</strong></p>
<p><img src="/2019/06/30/%E4%BB%8E0%E5%BC%80%E5%A7%8BGAN-6-pretraining-for-NLG/mlm.png"></p>
<p>与 BERT 中MLM的区别：  </p>
<blockquote>
<p>Differences between our approach and the MLM of Devlin et al. (2018) include the use of text streams of an arbitrary number of sentences (truncated at 256 tokens) instead of pairs of sentences.  </p>
</blockquote>
<p>文本 stream 是任意数量的sentences，而不是pairs.（这里的pairs in BERT应该指的是 next sentence prediction.）</p>
<p>在筛选用来mask的词时，为了处理 rare word 和 frequent word(punctuation or stop words) 的不均衡问题:    </p>
<blockquote>
<p>tokens in a text stream are sampled according to a multinomial distribution, whose weights are proportional to the square root of their invert frequencies.</p>
</blockquote>
<p><strong>Translation Language Modeling (TLM)</strong></p>
<p><img src="/2019/06/30/%E4%BB%8E0%E5%BC%80%E5%A7%8BGAN-6-pretraining-for-NLG/tlm.png"></p>
<p>在预测一个 masked english word 的同时，不仅可以attend english context，也可以 attend franch translation.</p>
<p><strong>Cross-lingual Language Models</strong></p>
<p>如何使用这三种语言模型，CLM 和 MLM 在单语上进行训练。 TLM 在平行语料上训练。TLM 在使用时是联合 MLM 一起训练的，迭代优化两个目标函数。</p>
<blockquote>
<p>In this work, we consider cross-lingual language model pretraining with either CLM, MLM, or MLM used in combination with TLM. For the CLM and MLM objectives, we train the model with batches of 64 streams of continuous sentences composed of 256 tokens. At each iteration, a batch is composed of sentences coming from the same language, which is sampled from the distribution ${q_i}_{i=1…N}$ above, with α = 0.7. When TLM is used in combination with MLM, we alternate between these two objectives, and sample the language pairs with a similar approach.</p>
</blockquote>
<h1 id="CTNMT"><a href="#CTNMT" class="headerlink" title="CTNMT"></a>CTNMT</h1><p>paper: [Towards Making the Most of BERT in Neural Machine Translation</p>
<p>Jiacheng](<a target="_blank" rel="noopener" href="https://arxiv.org/abs/1908.05672">https://arxiv.org/abs/1908.05672</a>)</p>
<p>ByteDance 的一篇paper.</p>
<p>前人的研究中我们发现，BERT pretrian 对NMT几乎没有提升。作者认为其原因是，NMT 相对其他linguistic的任务，训练的steps会多很多，比如NMT一般是10万step，而 POS tagging只需要几百步。这使得在训练过程中，参数的更新太多导致 catastrophic forgetting problem. 也就是 BERT 训练得到的knowledge并不能给NMT代来提升。</p>
<p>于是乎，作者认为只是大家没有好好利用BERT而已，像我们这样搞, BERT还是能对NMT有提升的。然后提出了三种techniques:</p>
<p><strong>Asymptotic Distillation</strong>  </p>
<p><img src="/2019/06/30/%E4%BB%8E0%E5%BC%80%E5%A7%8BGAN-6-pretraining-for-NLG/asymptotic_distill.png"></p>
<p>渐近蒸馏，主要是用来解决 catastrophic forgetting 这一问题的，和这篇paper “<a href>Overcoming Catastrophic Forgetting During Domain Adaptation of Neural Machine Translation</a>“ 相似，也是采用的 Elastic Weight Consolidation(EWC) 的方法，对weight采用MSE的约束。</p>
<p>$$L_{kd}=-||\hat h^{lm}-h_l||^2_2$$</p>
<p>$$L=\alpha\cdot L_{nmt}+(1-\alpha)\cdot L_{kd}$$</p>
<p>其中 $L_{kd}$ 是正则化项，$\hat h^{lm}$ 是经过BERT编码之后的 sentence embedding. $h_l$ 则是NMT的encoded之后的 sentence embedding. 作者都使用的最后一层的表示。在后续实验中，作者也测试了不同层的表示进行约束。</p>
<p><strong>Dynamic Switch</strong></p>
<p>动态开关。</p>
<p><img src="/2019/06/30/%E4%BB%8E0%E5%BC%80%E5%A7%8BGAN-6-pretraining-for-NLG/switch.png"></p>
<p>就是GRU中的gate机制。</p>
<p>$$g = \sigma(Wh^{lm} + Uh^{nmt} + b)$$</p>
<p>$$h=g\odot h^{lm}+(1-g)\odot h^{nmt}$$</p>
<p><strong>Rate-scheduled learning</strong></p>
<p>slanted triangular learning, 斜三角学习率。最开始提出是在 <a href>ULMFT: Universal language model fine-tuning for text classificatio</a> 这篇论文中。</p>
<p>$$\theta_t=\theta_{t-1}-\eta\nabla_{\theta}L(\theta)$$</p>
<p>对 NMT 和 LM 对应的参数使用不同的学习率，但是都采用这种scheduled学习率.</p>
<p><strong>Result</strong></p>
<p><img src="/2019/06/30/%E4%BB%8E0%E5%BC%80%E5%A7%8BGAN-6-pretraining-for-NLG/result.png"></p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2019-06-29T01:48:44.000Z" title="2019/6/29 上午9:48:44">2019-06-29</time>发表</span><span class="level-item"><time dateTime="2021-06-29T08:12:08.539Z" title="2021/6/29 下午4:12:08">2021-06-29</time>更新</span><span class="level-item"><a class="link-muted" href="/categories/GAN/">GAN</a></span><span class="level-item">8 分钟读完 (大约1173个字)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2019/06/29/%E4%BB%8E0%E5%BC%80%E5%A7%8BGAN-5-decoding/">从0开始GAN-5-NAT Decoding</a></h1><div class="content"><p>non-autoregressive decode 相关的paper：</p>
<ul>
<li><p><a href>Non-autoregressive neural machine translation. Gu et al. 2018 ICLR</a></p>
</li>
<li><p><a href>End-to-End Non-Autoregressive Neural Machine Translation with Connectionist Temporal Classification</a>  </p>
</li>
<li><p><a href>Deterministic Non-Autoregressive Neural Sequence Modeling by Iterative Refinemen</a>  </p>
</li>
</ul>
<h2 id="paper1"><a href="#paper1" class="headerlink" title="paper1"></a>paper1</h2><p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1904.09324">Constant-Time Machine Translation with Conditional Masked Language Models</a></p>
<h3 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h3><p>把auto-regressive转换成non-autoregressive. 其做法是先确定一个target sentece的长度，然后可以看作是每一个time-step的分类任务了。这样decoder就是可并行的了。</p>
<h3 id="architecture"><a href="#architecture" class="headerlink" title="architecture"></a>architecture</h3><p>模型架构采用transformer的架构。  </p>
<p>原生的 Transformer:  </p>
<ul>
<li><p>source-language encoder: self-attention, 包括padding mask.  </p>
</li>
<li><p>translation model decoder  </p>
<ul>
<li><p>self-attention, 包括padding mask和 look ahead mask，用以mask掉future information.</p>
</li>
<li><p>interaction attention with enc_out, 包括 padding mask.</p>
</li>
</ul>
</li>
</ul>
<p>这篇paper中的 conditional mask language model(CMLM) 与transormer的区别在于 decoder 部分的self-attention去掉了 look ahead mask. 所以可以类似于 BERT 那样基于上下文来预测被 mask 的词，decoder 是 bi-directional.</p>
<h3 id="Decoding-with-Mask-Predict"><a href="#Decoding-with-Mask-Predict" class="headerlink" title="Decoding with Mask-Predict"></a>Decoding with Mask-Predict</h3><p>decoder 的具体操作是一个迭代的过程。</p>
<p>| src | Der Abzug der franzsischen Kampftruppen wurde am 20. November abgeschlossen .    |</p>
<p>| :—– | :—————————————————- |</p>
<p>|t=0|<strong>The withdrawal of French combat troops was completed on November 20th .</strong>|</p>
<p>|t=1|The <strong>departure of the French combat completed completed on</strong> 20 November .|</p>
<p>|t=2|The <strong>departure</strong> of the French combat completed <strong>completed</strong> on <strong>20 November</strong> .|</p>
<p>表中加粗的部分是被 mask 的。可以看到随着迭代进行，mask的词越来越少。</p>
<p>如何选择mask的词：  </p>
<ol>
<li><p>mask词的数量n: 基于一个递减的公式, $n=N\dfrac{T-t}{T}$. t 是迭代次数。  </p>
</li>
<li><p>mask哪些词呢：$Y^{(t)}_{mask}=argmin_i(p_i,n)$ $p_i$ 表示上一次prediction得到的每一个词的置信度，选择概率最低的 n 个词。</p>
</li>
</ol>
<p>基于 encoder_src, $Y_{obs}$ 对 mask token 进行预测:</p>
<p><img src="/2019/06/29/%E4%BB%8E0%E5%BC%80%E5%A7%8BGAN-5-decoding/prediction.png"></p>
<h3 id="target-sequence-length"><a href="#target-sequence-length" class="headerlink" title="target sequence length"></a>target sequence length</h3><p>这中 non-Autoregressive 存在的一个大问题就是如何确定target sentence 的长度。在 auto-egressive 里面是根据 ${<eos>}$ 来确定句子长度的。</eos></p>
<p>针对这个问题，作者采用了类似于 BERT 中 CLS 的做法。使用了 $LENGTH$ 来预测sentence的长度，也是一个分类任务，这个 LENGTH 对应的词表应该就是长度~</p>
<p>作者选取 top b length，类似于 beam search. 然后选择 candidated b sentence 中概率最大的.</p>
<p>$$\dfrac{1}{N}\sum logp_i^{(T)}$$</p>
<h3 id="code-reading"><a href="#code-reading" class="headerlink" title="code reading"></a>code reading</h3><h2 id="paper2"><a href="#paper2" class="headerlink" title="paper2"></a>paper2</h2><p>Non-Autoregressive Neural Machine Translation</p>
<h3 id="Motivation-1"><a href="#Motivation-1" class="headerlink" title="Motivation:"></a>Motivation:</h3><p>现有的机器翻译模型在inference时，需要在生成前一个单词的基础上继续生成下一个单词，这种自回归的特性严重影响了推理的速度。</p>
<p>并且与训练阶段的不一致导致存在exposure bias。作者提出一个非自回归的方法，在infer阶段并行输出。</p>
<p>Exposure bias:</p>
<ul>
<li><p>training 阶段上一个token是ground truth</p>
</li>
<li><p>infer 阶段上一个token是生成得到的，这样自回归生成整个句子存在误差累积</p>
</li>
<li><p>两个阶段生成target的方式不一样，也就是 exposure bias.</p>
</li>
</ul>
<h3 id="Model-Architecture"><a href="#Model-Architecture" class="headerlink" title="Model Architecture:"></a>Model Architecture:</h3><ul>
<li><p>前一项表示基于监督学习来预测targets 句子的长度。在本文中作者使用了这个词 fertilities(生育能力) 来表示通过source句子通过encode之后所包含的知识.</p>
</li>
<li><p>后一项依旧是极大似然估计，也就是 independent cross-entropy losses on each output distribution。 但不同的是，在inference阶段也是可以并行的。</p>
</li>
</ul>
<p>这里有个疑问，在训练阶段会预测得到一个长度T，但是训练阶段时groud truth长度的，这个怎么解决？</p>
<p>这里在训练阶段显然需要长度与 ground truth 的target sentence长度一致，才能计算 word-wise corss entropy loss.</p>
<h3 id="Decoder-Stack"><a href="#Decoder-Stack" class="headerlink" title="Decoder Stack"></a>Decoder Stack</h3><p>1.decoder input</p>
<p>首先关于 decoder 的初始输入，在已有的模型中，训练阶段 decoder 的输入是 time-shifted target outputs，推理阶段是前面时间步预测的输出。</p>
<p>对于NAT模型，需要提前确定 target output 的长度，作者提出了两种方法：</p>
<ul>
<li><p>Copy source inputs uniformly</p>
</li>
<li><p>Copy source inputs using fertilities， 如上图中输入的每个时间步都有其对应的 fertility. 然后把source input按照其对应的次数copy到decoder的输入。</p>
</li>
</ul>
<p>2.Non-causal self-attention</p>
<p>因为不是自回归，也就是下一个词的生成并不依赖于previous的tokens，所以可以去掉transformer中decoder部分的cause-mask,也就是可以结合上下文的词，而不仅仅只是上文。</p>
<p>3.position attention</p>
<p>We also include an additional positional attention module in each decoder layer, which is a multi-head attention module with the same general attention mechanism used in other parts of the Transformer network. 为了强调位置信息。</p>
<p>Modeling fertility to tackle the multimodality problem</p>
<p>$P_F(f_{t’}|x_{1:T’}; \theta)$ 表示 fertility 在 t’ 时间步的概率分布，其是通过encoder顶层的 mlp + softmax 得到的。</p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2019-06-22T08:47:50.000Z" title="2019/6/22 下午4:47:50">2019-06-22</time>发表</span><span class="level-item"><time dateTime="2021-06-29T08:12:08.200Z" title="2021/6/29 下午4:12:08">2021-06-29</time>更新</span><span class="level-item"><a class="link-muted" href="/categories/DRL/">DRL</a></span><span class="level-item">8 分钟读完 (大约1208个字)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2019/06/22/UCL-DRL-04-policy-gradient-and-Actor-Critic-Methods/">UCL-DRL-04-policy gradient and Actor Critic Methods </a></h1><div class="content"><h2 id="policy-gradient"><a href="#policy-gradient" class="headerlink" title="policy gradient"></a>policy gradient</h2><h3 id="basic"><a href="#basic" class="headerlink" title="basic"></a>basic</h3><p><a target="_blank" rel="noopener" href="https://medium.com/@thechrisyoon/deriving-policy-gradients-and-implementing-reinforce-f887949bd63">Deriving Policy Gradients and Implementing REINFORCE</a> 这篇博客详细推导了 policy gradients 的过程，虽然公式很多，但其实还算简单。</p>
<p>最终的结论就是，从公式(1)推导为公式(2):</p>
<p>$$J(\theta)=\mathbb{E}[\sum_{t=0}^{T-1}r_{t+1}|\pi_{\theta}]=\sum_{t=1}^{T-1}P(s_t, a_t|\tau)r_{t+1}\quad(1)$$</p>
<p>$$\nabla_{\theta}J(\theta)=\sum_{t=0}^{T-1}\nabla_{\theta}log\pi_{\theta}(a_t|s_t)(\sum_{t’=t+1}^T\gamma^{t’-t-1}\gamma_{t’})\quad(2)$$</p>
<p>其中 $Gt=\sum_{t’=t+1}^T\gamma^{t’-t-1}\gamma_{t’}$</p>
<p>公式(2)可简化为:  </p>
<p>$$\nabla_{\theta}J(\theta)=\sum_{t=0}^{T-1}\nabla_{\theta}log\pi_{\theta}(a_t|s_t)G_t$$</p>
<p>之后就是针对 policy gradient 的各种改进。接下来的公式参数是根据李宏毅老师课程来的。所以符号与上面的有差异。</p>
<h3 id="add-baseline"><a href="#add-baseline" class="headerlink" title="add baseline"></a>add baseline</h3><p>$$\nabla{\overline R}<em>{\theta}=\dfrac{1}{N}\sum</em>{n=1}^N\sum_{t=1}^{T_n}(R(\tau^n)-b)\nabla logp_{\theta}(a_t^n|s_t^n)$$</p>
<h3 id="assign-suitable-credit"><a href="#assign-suitable-credit" class="headerlink" title="assign suitable credit"></a>assign suitable credit</h3><p>$$\nabla{\overline R}<em>{\theta}=\dfrac{1}{N}\sum</em>{n=1}^N\sum_{t=1}^{T_n}(\sum_{t’=t}^{T_n}r_{t’}^n-b)\nabla logp_{\theta}(a_t^n|s_t^n)$$</p>
<h3 id="add-discount-factor"><a href="#add-discount-factor" class="headerlink" title="add discount factor"></a>add discount factor</h3><p><img src="/2019/06/22/UCL-DRL-04-policy-gradient-and-Actor-Critic-Methods/policy_gradient.png"></p>
<h3 id="advantage-function"><a href="#advantage-function" class="headerlink" title="advantage function"></a>advantage function</h3><p>action $a_t$ 的好是相对的，而不是绝对的。它可以是 state-dependent.</p>
<p><img src="/2019/06/22/UCL-DRL-04-policy-gradient-and-Actor-Critic-Methods/actor_critic.png"></p>
<h2 id="on-policy-and-off-policy"><a href="#on-policy-and-off-policy" class="headerlink" title="on-policy and off-policy"></a>on-policy and off-policy</h2><h3 id="importance-sampling"><a href="#importance-sampling" class="headerlink" title="importance sampling"></a>importance sampling</h3><p><img src="/2019/06/22/UCL-DRL-04-policy-gradient-and-Actor-Critic-Methods/importance_sampling.png"></p>
<p>issue of importance sampling:</p>
<p><img src="/2019/06/22/UCL-DRL-04-policy-gradient-and-Actor-Critic-Methods/issue_IS.png"></p>
<p>采用 importance sampling，会导致sample 得到的action的分布方差发生变化。因此要保证action的分布尽可能与</p>
<h3 id="on-policy-to-off-policy"><a href="#on-policy-to-off-policy" class="headerlink" title="on-policy to off-policy"></a>on-policy to off-policy</h3><p><img src="/2019/06/22/UCL-DRL-04-policy-gradient-and-Actor-Critic-Methods/off_policy.png"></p>
<h3 id="PPO-proximal-policy-optimization"><a href="#PPO-proximal-policy-optimization" class="headerlink" title="PPO(proximal policy optimization)"></a>PPO(proximal policy optimization)</h3><p><strong>add constraint:</strong></p>
<p><img src="/2019/06/22/UCL-DRL-04-policy-gradient-and-Actor-Critic-Methods/ppo.png"></p>
<p>$\theta, \theta’$ 并不是distribution，而是参数。那么这里的 $kl(\theta, \theta’)$ 到底是什么？</p>
<p>这里的kl divergence 实际上是行为上的差距，也就是 action 分布的距离。那这个意思就是我们还是得用 $\theta$ 去求出 action 的 distribution，但是我们不用去sample出样本了。可以继续需要用 $\theta’$ sample出来的样本，但是需要给reward乘以系数 $\dfrac{p_{\theta}(a_t|s_t)}{p_{\theta’}(a_t|s_t)}$.</p>
<p><img src="/2019/06/22/UCL-DRL-04-policy-gradient-and-Actor-Critic-Methods/ppo_algorithm.png"></p>
<h3 id="PPO2"><a href="#PPO2" class="headerlink" title="PPO2"></a>PPO2</h3><p><img src="/2019/06/22/UCL-DRL-04-policy-gradient-and-Actor-Critic-Methods/ppo2.png"></p>
<p>因为 $kl(\theta, \theta’)$ 的计算还是蛮复杂的，所以用ppo2来代替。方法也是很直接，用clip的方式代替原来的正则项。</p>
<p>总结一下ppo：  </p>
<ol>
<li><p>首先它是off-policy的，为什么将on-policy转换成off-policy呢，因为on-policy速度太慢了。在policy iteration的时候先sample尽可能多的(state, action)pairs，然后计算对应的reward，再基于policy gradient来更新policy的参数 $\theta$.这是一次迭代。再然后基于updated policy生成新的(state, action) pairs或者新的example吧，依次迭代。。。这个过程中，得到action的分布，然后sample得到尽可能多的actions，这一步是非常耗时的，而且每次迭代都需要重新生成样本。  </p>
</li>
<li><p>off-policy改进的就是搞一个近似于当前policy $\theta$ 的 $\theta’$. 用这个 $\theta’$ 去采样 $(state, action)$ 样本，这个 $\theta’$ 并不是随着 policy $\theta$ 的更新而更新的，所以它sample出来的样本可以用很久。  </p>
</li>
<li><p>但是policy $\theta$ 更新之后，其对应的 action 的分布也是变换的，这也是我们想要的。所以怎么减小 $\theta’$ 和 $\theta$ 对应的action分布的差异，就有了ppo公式的第一项，也就是 importance sampling.  </p>
</li>
</ol>
<p><img src="/2019/06/22/UCL-DRL-04-policy-gradient-and-Actor-Critic-Methods/im_policy.png"></p>
<ol start="4">
<li>但是importance sampling得到的action的分布存在偏差（方差不一致)，所以需要尽可能保证 $\theta, \theta’$ 采样得到的action分布尽可能接近。于是有了ppo,ppo2的方法。</li>
</ol>
<h2 id="Critic"><a href="#Critic" class="headerlink" title="Critic"></a>Critic</h2><h3 id="state-value-function"><a href="#state-value-function" class="headerlink" title="state-value function"></a>state-value function</h3><p>$V_{\pi}(s)$ 表示的是当到达某个状态 s 之后，如果接下来一直按着策略 $\pi$ 来行动，能够获得的期望收益.</p>
<h3 id="action-value-function"><a href="#action-value-function" class="headerlink" title="action value function"></a>action value function</h3><p>$Q_{\pi}(s,a)$ 表示的是当达到某个状态 s 之后，如果强制采取行动 a ，接下来再按照策略 $\pi$ 来行动，能获得的期望收益。</p>
<p><img src="/2019/06/22/UCL-DRL-04-policy-gradient-and-Actor-Critic-Methods/calue_funvtion.svg"></p>
<p><img src="/2019/06/22/UCL-DRL-04-policy-gradient-and-Actor-Critic-Methods/action_value.svg"></p>
<p>显然地，状态价值函数和行动价值函数之间有关系:</p>
<p>$$V_{\pi}(s)=\sum_a\pi(a|s)Q_{\pi}(s,a)$$</p>
<h3 id="MC-v-s-TD"><a href="#MC-v-s-TD" class="headerlink" title="MC v.s. TD"></a>MC v.s. TD</h3><p><img src="/2019/06/22/UCL-DRL-04-policy-gradient-and-Actor-Critic-Methods/mvcstd.png"></p>
<p>sample同样的结果，采用 MC 和 TD最终计算的结果也是不一样的。</p>
<p>MC考虑的是，当前state $s_a$ 对未来的 state $s_b$ 可能也是有影响的. 所以MC实际上是要计算到整个游戏（episode）结束。</p>
</div></article></div><nav class="pagination" role="navigation" aria-label="pagination"><div class="pagination-previous"><a href="/page/2/">上一页</a></div><div class="pagination-next"><a href="/page/4/">下一页</a></div><ul class="pagination-list is-hidden-mobile"><li><a class="pagination-link" href="/">1</a></li><li><a class="pagination-link" href="/page/2/">2</a></li><li><a class="pagination-link is-current" href="/page/3/">3</a></li><li><a class="pagination-link" href="/page/4/">4</a></li><li><span class="pagination-ellipsis">&hellip;</span></li><li><a class="pagination-link" href="/page/23/">23</a></li></ul></nav></div><div class="column column-left is-4-tablet is-4-desktop is-4-widescreen  order-1"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar" src="/img/avatar.png" alt="潘晓榭"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">潘晓榭</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Beijing, China</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">文章</p><a href="/archives"><p class="title">112</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">分类</p><a href="/categories"><p class="title">33</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">标签</p><a href="/tags"><p class="title">32</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/PanXiebit" target="_blank" rel="noopener">关注我</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/PanXiebit"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Email" href="/ftdpanxie@gmail.com"><i class="fa fa-envelope"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="RSS" href="/"><i class="fas fa-rss"></i></a></div></div></div><!--!--><div class="card widget" data-type="links"><div class="card-content"><div class="menu"><h3 class="menu-label">链接</h3><ul class="menu-list"><li><a class="level is-mobile" href="https://github.com/PanXiebit" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">github</span></span><span class="level-right"><span class="level-item tag">github.com</span></span></a></li><li><a class="level is-mobile" href="ftdpanxie@gmail.com" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">email</span></span><span class="level-right"><span class="level-item tag">ftdpanxie@gmail.com</span></span></a></li></ul></div></div></div><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">分类</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/C/"><span class="level-start"><span class="level-item">C++</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/CSAPP/"><span class="level-start"><span class="level-item">CSAPP</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/DRL/"><span class="level-start"><span class="level-item">DRL</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/GAN/"><span class="level-start"><span class="level-item">GAN</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li><li><a class="level is-mobile" href="/categories/GAN-RL/"><span class="level-start"><span class="level-item">GAN, RL</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/ML/"><span class="level-start"><span class="level-item">ML</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/NLP/"><span class="level-start"><span class="level-item">NLP</span></span><span class="level-end"><span class="level-item tag">14</span></span></a></li><li><a class="level is-mobile" href="/categories/TensorFlow/"><span class="level-start"><span class="level-item">TensorFlow</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/cs224d/"><span class="level-start"><span class="level-item">cs224d</span></span><span class="level-end"><span class="level-item tag">10</span></span></a></li><li><a class="level is-mobile" href="/categories/interview/"><span class="level-start"><span class="level-item">interview</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/machine-translation/"><span class="level-start"><span class="level-item">machine translation</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/python/"><span class="level-start"><span class="level-item">python</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/pytorch/"><span class="level-start"><span class="level-item">pytorch</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/reinforcement-learning/"><span class="level-start"><span class="level-item">reinforcement learning</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/sign-language-recognition/"><span class="level-start"><span class="level-item">sign language recognition</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/transfer-learning/"><span class="level-start"><span class="level-item">transfer learning</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"><span class="level-start"><span class="level-item">数据结构与算法</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile" href="/categories/%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB/"><span class="level-start"><span class="level-item">文本分类</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"><span class="level-start"><span class="level-item">论文笔记</span></span><span class="level-end"><span class="level-item tag">34</span></span></a><ul><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/DL/"><span class="level-start"><span class="level-item">DL</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/ESA/"><span class="level-start"><span class="level-item">ESA</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/GAN/"><span class="level-start"><span class="level-item">GAN</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/MRC-and-QA/"><span class="level-start"><span class="level-item">MRC and QA</span></span><span class="level-end"><span class="level-item tag">7</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/Machine-Translation/"><span class="level-start"><span class="level-item">Machine Translation</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/NLP/"><span class="level-start"><span class="level-item">NLP</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/capsules/"><span class="level-start"><span class="level-item">capsules</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/data-augmentation/"><span class="level-start"><span class="level-item">data augmentation</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/dialogue-system/"><span class="level-start"><span class="level-item">dialogue system</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/language-model/"><span class="level-start"><span class="level-item">language model</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/machine-translation/"><span class="level-start"><span class="level-item">machine translation</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/open-set-recognition/"><span class="level-start"><span class="level-item">open set recognition</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/sentence-embedding/"><span class="level-start"><span class="level-item">sentence embedding</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/text-matching/"><span class="level-start"><span class="level-item">text matching</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li></ul></div></div></div><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">最新文章</h3><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-07-02T04:37:58.000Z">2021-07-02</time></p><p class="title"><a href="/2021/07/02/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-constrast-learning-in-NLP/">论文笔记-constrast learning in NLP</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-05-05T02:03:16.000Z">2021-05-05</time></p><p class="title"><a href="/2021/05/05/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-contrastive-learning/">论文笔记-image-based contrastive learning</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-04-29T01:07:08.000Z">2021-04-29</time></p><p class="title"><a href="/2021/04/29/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-video-transformer/">论文笔记-video transformer</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-04-29T01:05:10.000Z">2021-04-29</time></p><p class="title"><a href="/2021/04/29/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-dynamic-convolution-and-involution/">论文笔记-dynamic convolution and involution</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-04-16T07:48:48.000Z">2021-04-16</time></p><p class="title"><a href="/2021/04/16/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-unlikelihood-training/">论文笔记-unlikelihood training</a></p></div></article></div></div><div class="card widget" data-type="archives"><div class="card-content"><div class="menu"><h3 class="menu-label">归档</h3><ul class="menu-list"><li><a class="level is-mobile" href="/archives/2021/07/"><span class="level-start"><span class="level-item">七月 2021</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2021/05/"><span class="level-start"><span class="level-item">五月 2021</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2021/04/"><span class="level-start"><span class="level-item">四月 2021</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/archives/2020/09/"><span class="level-start"><span class="level-item">九月 2020</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2019/11/"><span class="level-start"><span class="level-item">十一月 2019</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2019/10/"><span class="level-start"><span class="level-item">十月 2019</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2019/08/"><span class="level-start"><span class="level-item">八月 2019</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2019/06/"><span class="level-start"><span class="level-item">六月 2019</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/archives/2019/05/"><span class="level-start"><span class="level-item">五月 2019</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2019/04/"><span class="level-start"><span class="level-item">四月 2019</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2019/03/"><span class="level-start"><span class="level-item">三月 2019</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile" href="/archives/2019/02/"><span class="level-start"><span class="level-item">二月 2019</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/archives/2019/01/"><span class="level-start"><span class="level-item">一月 2019</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li><li><a class="level is-mobile" href="/archives/2018/12/"><span class="level-start"><span class="level-item">十二月 2018</span></span><span class="level-end"><span class="level-item tag">16</span></span></a></li><li><a class="level is-mobile" href="/archives/2018/11/"><span class="level-start"><span class="level-item">十一月 2018</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2018/10/"><span class="level-start"><span class="level-item">十月 2018</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2018/09/"><span class="level-start"><span class="level-item">九月 2018</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/archives/2018/08/"><span class="level-start"><span class="level-item">八月 2018</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile" href="/archives/2018/07/"><span class="level-start"><span class="level-item">七月 2018</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/archives/2018/06/"><span class="level-start"><span class="level-item">六月 2018</span></span><span class="level-end"><span class="level-item tag">10</span></span></a></li><li><a class="level is-mobile" href="/archives/2018/05/"><span class="level-start"><span class="level-item">五月 2018</span></span><span class="level-end"><span class="level-item tag">11</span></span></a></li><li><a class="level is-mobile" href="/archives/2018/04/"><span class="level-start"><span class="level-item">四月 2018</span></span><span class="level-end"><span class="level-item tag">16</span></span></a></li><li><a class="level is-mobile" href="/archives/2018/03/"><span class="level-start"><span class="level-item">三月 2018</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li></ul></div></div></div><div class="card widget" data-type="tags"><div class="card-content"><div class="menu"><h3 class="menu-label">标签</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/C/"><span class="tag">C++</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/CSAPP/"><span class="tag">CSAPP</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/DL/"><span class="tag">DL</span><span class="tag">8</span></a></div><div class="control"><a class="tags has-addons" href="/tags/ESA/"><span class="tag">ESA</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/GAN/"><span class="tag">GAN</span><span class="tag">9</span></a></div><div class="control"><a class="tags has-addons" href="/tags/GAN%EF%BC%8CRL/"><span class="tag">GAN，RL</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/ML/"><span class="tag">ML</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/MRC-and-QA/"><span class="tag">MRC and QA</span><span class="tag">7</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Machine-Translation/"><span class="tag">Machine Translation</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/NLP/"><span class="tag">NLP</span><span class="tag">14</span></a></div><div class="control"><a class="tags has-addons" href="/tags/TensorFlow/"><span class="tag">TensorFlow</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Tensorflow/"><span class="tag">Tensorflow</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/ai-challenger/"><span class="tag">ai challenger</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/capsules/"><span class="tag">capsules</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/contrastive-learning/"><span class="tag">contrastive learning</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/cs224d/"><span class="tag">cs224d</span><span class="tag">10</span></a></div><div class="control"><a class="tags has-addons" href="/tags/data-augmentation/"><span class="tag">data augmentation</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/interview/"><span class="tag">interview</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/language-model/"><span class="tag">language model</span><span class="tag">6</span></a></div><div class="control"><a class="tags has-addons" href="/tags/machine-translation/"><span class="tag">machine translation</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/open-set-recognition/"><span class="tag">open set recognition</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/python/"><span class="tag">python</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/pytorch/"><span class="tag">pytorch</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/reinforcement-learning/"><span class="tag">reinforcement learning</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/sentence-embedding/"><span class="tag">sentence embedding</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/sentiment-classification/"><span class="tag">sentiment classification</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/sign-language-recognition/"><span class="tag">sign language recognition</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/text-matching/"><span class="tag">text matching</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/transfer-learning/"><span class="tag">transfer learning</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/vision-transformer/"><span class="tag">vision transformer</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"><span class="tag">数据结构与算法</span><span class="tag">6</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB/"><span class="tag">文本分类</span><span class="tag">8</span></a></div></div></div></div></div><div class="card widget" data-type="subscribe-email"><div class="card-content"><div class="menu"><h3 class="menu-label">订阅更新</h3><form action="https://feedburner.google.com/fb/a/mailverify" method="post" target="popupwindow" onsubmit="window.open(&#039;https://feedburner.google.com/fb/a/mailverify?uri=&#039;,&#039;popupwindow&#039;,&#039;scrollbars=yes,width=550,height=520&#039;);return true"><input type="hidden" value="" name="uri"><input type="hidden" name="loc" value="en_US"><div class="field has-addons"><div class="control has-icons-left is-expanded"><input class="input" name="email" type="email" placeholder="Email"><span class="icon is-small is-left"><i class="fas fa-envelope"></i></span></div><div class="control"><input class="button" type="submit" value="订阅"></div></div></form></div></div></div></div><!--!--></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/panxiaoxie.png" alt="潘小榭" height="28"></a><p class="is-size-7"><span>&copy; 2021 Xie Pan</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("zh-CN");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="回到顶端" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "此网站使用Cookie来改善您的体验。",
          dismiss: "知道了！",
          allow: "允许使用Cookie",
          deny: "拒绝",
          link: "了解更多",
          policy: "Cookie政策",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.5/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="想要查找什么..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"想要查找什么...","untitled":"(无标题)","posts":"文章","pages":"页面","categories":"分类","tags":"标签"});
        });</script></body></html>