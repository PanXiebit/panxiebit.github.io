<!doctype html>
<html lang="zh"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>潘小榭</title><link rel="manifest" href="/manifest.json"><meta name="theme-color" content="black"><meta name="application-name" content="panxiaoxie"><meta name="msapplication-TileImage" content="/img/avatar.png"><meta name="msapplication-TileColor" content="black"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="panxiaoxie"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta property="og:type" content="blog"><meta property="og:title" content="panxiaoxie"><meta property="og:url" content="https://github.com/PanXiebit"><meta property="og:site_name" content="panxiaoxie"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://www.qt86.com/cache/1625298592_187938.png"><meta property="article:author" content="panxiaoxie"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="https://www.qt86.com/cache/1625298592_187938.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"http://www.panxiaoxie.cn"},"headline":"潘小榭","image":["http://www.panxiaoxie.cn/img/og_image.png"],"author":{"@type":"Person","name":"Xie Pan"},"publisher":{"@type":"Organization","name":"潘小榭","logo":{"@type":"ImageObject","url":"http://www.panxiaoxie.cn/img/panxiaoxie.png"}},"description":null}</script><link rel="icon" href="/img/avatar.png"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/css/justifiedGallery.min.css"><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script><!--!--><!--!--><meta name="generator" content="Hexo 5.4.0"></head><body class="is-2-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/panxiaoxie.png" alt="潘小榭" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">主页</a><a class="navbar-item" href="/archives">归档</a><a class="navbar-item" href="/categories">分类</a><a class="navbar-item" href="/tags">标签</a><a class="navbar-item" href="/about">关于我</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/PanXiebit"><i class="fab fa-github"></i></a><a class="navbar-item search" title="搜索" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-10-widescreen"><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2019-11-21T02:10:37.000Z" title="2019/11/21 上午10:10:37">2019-11-21</time>发表</span><span class="level-item"><time dateTime="2021-06-29T08:12:08.539Z" title="2021/6/29 下午4:12:08">2021-06-29</time>更新</span><span class="level-item"><a class="link-muted" href="/categories/machine-translation/">machine translation</a></span><span class="level-item">6 分钟读完 (大约934个字)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2019/11/21/FAIR-%E6%97%A0%E7%9B%91%E7%9D%A3%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91/">FAIR-无监督机器翻译</a></h1><div class="content"><p>无监督机器翻译的几篇paper:</p>
<ul>
<li><p><a href>Word Translation without Parallel Data - ICLR’18</a>  </p>
</li>
<li><p><a href>Unsupervised machine translation using monolingual corpora only, Lample, et al. ICLR 2018a</a>    </p>
</li>
<li><p><a href>Unsupervised neural machine translation, ICLR 2018</a>    </p>
</li>
<li><p><a href>Phrase-based &amp; neural unsupervised machine translation. emnlp 2018b</a>  </p>
</li>
<li><p><a href>Cross-lingual Language Model Pretraining</a>  </p>
</li>
</ul>
<ul>
<li><a target="_blank" rel="noopener" href="https://papers.nips.cc/paper/5477-neural-word-embedding-as-implicit-matrix-factorization.pdf">Neural word embedding as implicit matrix factorization</a>  </li>
</ul>
<h2 id="Phrase-Based-amp-Neural-Unsupervised-Machine-Translation"><a href="#Phrase-Based-amp-Neural-Unsupervised-Machine-Translation" class="headerlink" title="Phrase-Based &amp; Neural Unsupervised Machine Translation"></a>Phrase-Based &amp; Neural Unsupervised Machine Translation</h2><p>对前两篇无监督机器翻译进行了一个总结：  </p>
<ul>
<li><ol>
<li>carefully initialize the MT system with an inferred bilingual dictionary. 通过双语字典对MT模型进行初始化。  </li>
</ol>
</li>
<li><ol start="2">
<li>leverage strong language models, via training the sequence-to-sequence system as a denoising autoencoder. 通过训练seq2eq模型来利用强大的语言模型作为降噪自编码。     </li>
</ol>
</li>
<li><ol start="3">
<li>turn the unsupervised problem into a supervised one by automatic generation of sentence pairs via back-translation.把无监督问题转换为有监督的问题，也就是通过back-translation自动生成语言对。  </li>
</ol>
</li>
</ul>
<p>这篇论文的作者将上述方法做了个整合，得到的NMT 系统在无监督翻译上能达到 +10 BLEU, 并且应用到phrase-based MT上，达到了 +12 BLEU.</p>
<p><img src="/2019/11/21/FAIR-%E6%97%A0%E7%9B%91%E7%9D%A3%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91/unsupervised.png"></p>
<p>作者将无监督机器翻译抽象成上述过程。  </p>
<ul>
<li><p>B. 初始化</p>
</li>
<li><p>C. 语言模型  </p>
</li>
<li><p>D. 迭代反向翻译。</p>
</li>
</ul>
<h3 id="Initialization"><a href="#Initialization" class="headerlink" title="Initialization"></a>Initialization</h3><p>前人的初始化方法：</p>
<ul>
<li><p>利用意思相近的词、短语或是 subword   </p>
</li>
<li><p>bilingual dictionary  </p>
</li>
<li><p>dictionaries inferred in an unsupervised way. <a href>Lample et al. (2018) and Artetxe et al. (2018)</a></p>
</li>
</ul>
<p>这种初始化的方式对于距离相距较远的语言可能效果不太好。比如中英？</p>
<p><strong>作者的初始化方法：</strong>    </p>
<p>先对source和target language进行bpe处理(bpe的优势：减小词表大小，消除unknow word)，然后联合起来（而不是分开）训练word embedding.  </p>
<ul>
<li><p>join the monolingual corpora  </p>
</li>
<li><p>apply BPE tokenization on the resulting corpus  </p>
</li>
<li><p>learn token embeddings (Mikolov et al., 2013) on the same corpus</p>
</li>
</ul>
<h3 id="Language-Modeling"><a href="#Language-Modeling" class="headerlink" title="Language Modeling"></a>Language Modeling</h3><p>基于单语训练得到的语言模型，主要是通过 local substitutions and word reorderings 来提升翻译的质量（也就是 contextual information）。</p>
<p><strong>作者的 language model training 基于 denosing autoencoder.</strong></p>
<p><img src="/2019/11/21/FAIR-%E6%97%A0%E7%9B%91%E7%9D%A3%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91/dae.png"></p>
<p>C is a noise model with some words dropped and swapped. $P_{s→s}$ and $P_{t→t}$ are the composition of encoder and decoder both operating on the source and target sides, respectively. Back-translation:</p>
<h3 id="Iterative-Back-translation"><a href="#Iterative-Back-translation" class="headerlink" title="Iterative Back-translation"></a>Iterative Back-translation</h3><p><a target="_blank" rel="noopener" href="http://papers.nips.cc/paper/6469-dual-learning-for-machine-translation.pdf">Dual Learning for Machine Translation</a></p>
<p>$fr \rightarrow \hat{en} \rightarrow fr$ fr 是 target language. en 是 source language.   </p>
<p>先利用反向模型翻译得到 pesudo en sentence $\hat{en}$. 然后将 $(\hat{en}, fr)$ 作为翻译对进行有监督的学习。尽管 $\hat{en}$ 会非常 noisy，但保证了target端是pure sentence，效果确实不错吧。</p>
<p><strong>作者的 iteration BT</strong> 与上述方法一致：</p>
<p>$u^{* }(y)=argmaxP_{t→s}(u|y)$, $u^{* }(y)$ 是 pesudo source sentence.</p>
<p>$v^{* }(x)=argmaxP_{s→t}(v|x)$, $v^{* }(x)$ 是 pesudo target sentence.</p>
<p><img src="/2019/11/21/FAIR-%E6%97%A0%E7%9B%91%E7%9D%A3%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91/bt.png"></p>
<p>作者在实验时，并没有对 $u\rightarrow u^{* }, v\rightarrow v^{* }$ 这个过程进行优化，因为这在实验中并没有提升。同时在训练时，作者是简单的将 $L^{back}$ 和 $L^{lm}$ 加起来进行优化。</p>
<p>为了避免模型混淆两个语言的向量空间，作者提供了一个解决方法，<strong>Sharing Latent Representations</strong>. 也就是  denosing aotoencoder 和 back-translation 可以用同一个 encoder-decoder 模型，不同语言之间共享 encoder 和 decoder.</p>
<blockquote>
<p>While sharing the encoder is critical to get the model to work, shar- ing the decoder simply induces useful regularization.  </p>
</blockquote>
<p>共享 encoder 对于无监督模型非常关键，而 decoder 的共享则主要是提供有效的正则化。这与 GNMT 模型不一样，不需要加上 tag 来指定翻译方向。</p>
<h3 id="Result"><a href="#Result" class="headerlink" title="Result"></a>Result</h3><p><img src="/2019/11/21/FAIR-%E6%97%A0%E7%9B%91%E7%9D%A3%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91/result.png"></p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2019-10-31T02:46:20.000Z" title="2019/10/31 上午10:46:20">2019-10-31</time>发表</span><span class="level-item"><time dateTime="2021-06-29T08:12:08.540Z" title="2021/6/29 下午4:12:08">2021-06-29</time>更新</span><span class="level-item"><a class="link-muted" href="/categories/GAN/">GAN</a></span><span class="level-item">6 分钟读完 (大约942个字)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2019/10/31/%E4%BB%8E0%E5%BC%80%E5%A7%8BGAN-9-metric-for-NLG/">从0开始GAN-9-metric for NLG</a></h1><div class="content"><p>related papers:  </p>
<ul>
<li><p><a href>MoverScore: Text Generation Evaluating with Contextualized Embeddings and Earth Mover Distance</a>  </p>
</li>
<li><p><a href>Why We Need New Evaluation Metrics for NLG</a>      </p>
</li>
<li><p><a href>Beyond BLEU: Training Neural Machine Translation with Semantic Similarity</a>    </p>
</li>
<li><p><a href>Better Rewards Yield Better Summaries: Learning to Summarise Without References</a>    </p>
</li>
<li><p><a href>RUSE: Regressor Using Sentence Embeddings for Automatic Machine Translation Evaluation</a>     </p>
</li>
<li><p><a href>ROUGE: A Package for Automatic Evaluation of Summaries Chin-Yew</a>  </p>
</li>
</ul>
<h2 id="MoverScore"><a href="#MoverScore" class="headerlink" title="MoverScore"></a>MoverScore</h2><h3 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h3><p>评价指标对于模型的训练或选择至关重要，现阶段对于文本生成的模型（机器翻译，摘要生产，图像标题生成）大都采用的hard match的方式，比如 BLEU, ROUGE. 这些都是简单的基于共现词的统计，这种metric仅仅只考虑了表面的形式，无法覆盖同意却不同词的表达，所以他们并不太好（over correction），不具备评价文本相似性的能力。</p>
<h3 id="MoverScore-1"><a href="#MoverScore-1" class="headerlink" title="MoverScore"></a>MoverScore</h3><blockquote>
<p>It is particularly important for a metric to not only capture the amount of shared content between two texts, i.e., intersect(A,B), as is the case with many semantic textual similarity measures  </p>
</blockquote>
<p>根据语义相似度来计算距离。</p>
<p>计算 MoverScore 的一些符号：  </p>
<ul>
<li><p>sentence：$x=(x_1,x_2,…,x_m)$  </p>
</li>
<li><p>$x^n$ 表示 x 中的 n-gram.</p>
</li>
<li><p>$f_{x^n}$ 表示x中每一个 n-gram 的权重。如果 n=(size of sentence), 那么 $f_{x^n}=1$  </p>
</li>
</ul>
<p>n-gram 之间的距离：  </p>
<p>$$C_{ij}=d(x_i^n,y_j^n)$$</p>
<p>表示 x 中第 $i^{th}$ 个 n-gram 与 y 中第 $j^{th}$ 个 n-gram 的距离。</p>
<p>那么两个句子中所有 n-gram 的距离 Word Mover’s Distance (WMD)：</p>
<p>$$WMD(x^n,y^n):=min_{F\in R^{|x^n|\times |y^n|}}&lt;C,F&gt;$$</p>
<p>$&lt;&gt;$ 表示加权求和。计算出两个 n-gram 序列的推土机距离与传统的推土机距离不太一样的地方是，这里每个 n-gram 还有权重。</p>
<p>那么如何计算两个 n-gram 的距离 $d(x_i^n,y_j^n)$ 呢, 作者采用的是 Euclidean distance：</p>
<p>$$d(x_i^n,y_j^n)=||E(x_i^n)-E(y^n_j)||_ {2}$$</p>
<p>$E$ 是n-gram 的向量表示，比如 $x_i^n=(x_i,..,x_{i+n-1})$ 是 x 中第 i 个 n-gram.</p>
<p>$$E{(x_i^n)}=\sum_{k=i}^{i+n-1}idf{(x_k)}\cdot E{(x_k)}$$</p>
<p>n-gram 的权重计算：</p>
<p>$$f_{x_i^n}=\dfrac{1}{Z}\sum_{k=i}^{i+n-1}idf{(x_k)}$$</p>
<p>Z 是归一化常数，也就是总和吧。</p>
<p>当 n&gt;(size of sentence) 时，$WMD(x^n,y^n)$ 变成计算两个完整的句子的距离：  </p>
<p>$$SMD(x^n,y^n)=||E(x_1^{l_x})-E(y_1^{l_y})||$$</p>
<p>其中 $l_x,l_y$ 表示两个sentence 的长度。</p>
<h3 id="Contextualized-Representations"><a href="#Contextualized-Representations" class="headerlink" title="Contextualized Representations"></a>Contextualized Representations</h3><p>如何得到一个 word/n-gram 的向量表示，基于预训练的模型来得到 contextualized 表示是一个开放性的问题，Elmo和BERT都是多层结构，不同的layer包含了不同的含义。作者这里提到了两种方法，并最终采用了前者：    </p>
<ul>
<li><p>the concatenation of power means  </p>
</li>
<li><p>a routing mechanism for aggregation</p>
</li>
</ul>
<p><strong>power means:</strong></p>
<p>$$h_i(p)=(\dfrac{z_{i,1}^p+…+z_{i,L}^p}{L})^{1/p}$$</p>
<p>L 表示预训练模型的层数，p=1是数值平均，p=0时是调和平均。</p>
<p>$$E(x_i)=h_i^{p_1}\oplus …. \oplus h_i^{p_k}$$</p>
<p>$\oplus$ 表示 concatenation. 作者设置 p=1,K=3. 也就是一个词的向量表示由三个向量表示 $h$ 拼接而成,而每个h又是不同层的数值平均。</p>
<h3 id="result"><a href="#result" class="headerlink" title="result"></a>result</h3><p>对于这种提出新指标的问题，一直很疑惑怎么去 evaluation。好像只能通过人工去评价了对吧？</p>
<p><img src="/2019/10/31/%E4%BB%8E0%E5%BC%80%E5%A7%8BGAN-9-metric-for-NLG/mt.png"></p>
<p>这是机器翻译的结果。</p>
<p>WMD-1/2+BERT+MNLI+PMeans：表示 1-gram 的word mover distences + 在NMLI语料上训练的BERT + PMeans 的融合方式。</p>
<p>根据 NMT system 得到 translations，然后与 references 计算对应的指标。然后根据指标与human evalation相似度进行对比，越接近人类评价的，这个指标就越好。</p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2019-10-11T07:21:16.000Z" title="2019/10/11 下午3:21:16">2019-10-11</time>发表</span><span class="level-item"><time dateTime="2021-01-27T08:44:33.417Z" title="2021/1/27 下午4:44:33">2021-01-27</time>更新</span><span class="level-item"><a class="link-muted" href="/categories/GAN-RL/">GAN, RL</a></span><span class="level-item">1 分钟读完 (大约179个字)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2019/10/11/%E4%BB%8E0%E5%BC%80%E5%A7%8BGAN-8-RL-in-NMT/">从0开始GAN-8-RL in NMT</a></h1><div class="content"><p>related papers:</p>
<ul>
<li><p><a href>A Study of Reinforcement Learning for Neural Machine Translation</a>  </p>
</li>
<li><p><a href>Bilingual-GAN: A Step Towards Parallel Text Generation</a>  </p>
</li>
<li><p>[On the Weaknesses of Reinforcement Learning</p>
</li>
</ul>
<p>for Neural Machine Translation](<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1907.01752.pdf">https://arxiv.org/pdf/1907.01752.pdf</a>)  </p>
<p>暂时有个idea，根据那篇paper, beyond bleu 提出的metric来作为优化指标。好处是，对于每一个token生成的时候，不需要接着生成完整的句子就能得到有效的reward（这点需要用实验来验证）。这样对于每个句子中的token都会有对应的rewards,最好可以给每个rewards一个折扣因子，越靠前的系数越小，越靠后的系数越大。</p>
<h1 id="RL-in-NMT"><a href="#RL-in-NMT" class="headerlink" title="RL in NMT"></a>RL in NMT</h1><p>paper: [On the Weaknesses of Reinforcement Learning</p>
<p>for Neural Machine Translation](<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1907.01752.pdf">https://arxiv.org/pdf/1907.01752.pdf</a>)</p>
<h2 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h2></div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2019-08-30T11:36:13.000Z" title="2019/8/30 下午7:36:13">2019-08-30</time>发表</span><span class="level-item"><time dateTime="2021-06-29T08:12:08.200Z" title="2021/6/29 下午4:12:08">2021-06-29</time>更新</span><span class="level-item"><a class="link-muted" href="/categories/GAN/">GAN</a></span><span class="level-item">10 分钟读完 (大约1448个字)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2019/08/30/%E4%BB%8E0%E5%BC%80%E5%A7%8BGAN-7-IRGAN/">从0开始GAN-7-IRGAN</a></h1><div class="content"><h3 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h3><p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1705.10513">IRGAN: A Minimax Game for Unifying Generative and Discriminative Information Retrieval Models</a>  </p>
<p>信息检索的方法主要分为两个流派，生成式检s索模型(generative retrieval model)和判别式检索模型(discriminative retrieval model)。</p>
<p>生成式检索模型 ($q \rightarrow d$)：认为query和检索所需要的document之间有一个潜在的随机生成的过程。也就是给定一个 query，然后生成相应的 document.  </p>
<p>判别式检索模型 ($q + d \rightarrow r$)：把query和document作为联合feature，计算其相关性relevancy. 然后基于 relevancy 对 document 进行排序。其中关于 ranking a list of documents 有三种范式：pointwise, pairwise, listwise.</p>
<p>作者将上述两种模型与GAN相结合，利用GAN的对抗性的思想去提升两类模型。   </p>
<p>判别式检索模型 $p_{\phi}(r|q,d)$ 作为判别器，maximize 来自真实 labeled 的数据。它提供信息来指导生成器的训练，这种信息不同于传统的 log-likelihood.  </p>
<p>判别式检索模型 $p_{\theta}(d|q,r)$ 是生成器，生成generated sample来迷惑判别器，minimize 对应的目标函数。</p>
<h3 id="Model-Architecture"><a href="#Model-Architecture" class="headerlink" title="Model Architecture"></a>Model Architecture</h3><h4 id="A-Minimax-Retrieval-Framework"><a href="#A-Minimax-Retrieval-Framework" class="headerlink" title="A Minimax Retrieval Framework"></a>A Minimax Retrieval Framework</h4><p>a set of queries ${q_1,…,q_N}$, a set of documents ${d_1,…,d_M}$. 其中 给定一个 query 都有对应的相关度较高的 document 也就是真实的数据 $true_{(q,d)}$，其数据量是远小于总的document数量 M 的.</p>
<blockquote>
<p>The underlying true relevance distribution can be expressed</p>
</blockquote>
<p>as conditional probability $p_{true} (d|q, r)$, which depicts the (user’s) relevance preference distribution over the candidate documents with respect to her submitted query.  </p>
<p>这样真实的相关性 (q,d) 存在潜在的相关性条件分布 $p_{true}(d|q,r)$.</p>
<p>Generative retrieval model $p_{\theta}(d|q,r)$: 生成器的目的就是去尽可能的模拟真实的相关性分布 $p_{ture}(d|q,r)$, 从而尽可能生成相似度高的 document.</p>
<p><img src="/2019/08/30/%E4%BB%8E0%E5%BC%80%E5%A7%8BGAN-7-IRGAN/generator_model.png"></p>
<p>Discriminative retrieval model $f_{\phi}(q,d)$：是一个二分类分类器。</p>
<p><img src="/2019/08/30/%E4%BB%8E0%E5%BC%80%E5%A7%8BGAN-7-IRGAN/discriminator_model.png">  </p>
<p>其中判别器具体的计算 $f_{\phi}(d,q)$ 与IR task有关。后续会详细介绍。</p>
<p>Overall Objective 目标函数：</p>
<p><img src="/2019/08/30/%E4%BB%8E0%E5%BC%80%E5%A7%8BGAN-7-IRGAN/object_func.png">  </p>
<p>最小化来自生成器 $p_{\theta}$ 的 sample 的概率，最大化来自true data $p_{true}$ 的 sample 的概率.  </p>
<h4 id="Optimising-Discriminative-Retrieval"><a href="#Optimising-Discriminative-Retrieval" class="headerlink" title="Optimising Discriminative Retrieval"></a>Optimising Discriminative Retrieval</h4><p>优化判别器：  </p>
<p><img src="/2019/08/30/%E4%BB%8E0%E5%BC%80%E5%A7%8BGAN-7-IRGAN/train_dis_model.png">  </p>
<h4 id="Optimising-Generative-Retrieval"><a href="#Optimising-Generative-Retrieval" class="headerlink" title="Optimising Generative Retrieval"></a>Optimising Generative Retrieval</h4><p>这篇paper中生成器不是token by token的生成新的ducoment，而是从given documents中选择最相关的document.  </p>
<p>对于生成器的优化，最小化目标函数（1）：  </p>
<p><img src="/2019/08/30/%E4%BB%8E0%E5%BC%80%E5%A7%8BGAN-7-IRGAN/train_gen_model.png"></p>
<p>上述公式从第一步到第二步有点小变化，简单推导下即可。</p>
<p>这里sample得到d的过程是离散的。怎么理解呢，可以类比文本的生成（尽管此表的分布是连续的，但是从中选一个token，然后作为判别器的输入，这个过程是不可导的）。同样，这里是从一系列documents中sample一个作为判别器的输入，这个过程是离散的，且不可导。所以作者采用了policy gradient的方法来解决这个问题。</p>
<p>公式(4)中对生成器的优化可以看作是 maximize $J^G(q_n)$. 使用policy gradient优化的推导如下：</p>
<p><img src="/2019/08/30/%E4%BB%8E0%E5%BC%80%E5%A7%8BGAN-7-IRGAN/pg_train.png">  </p>
<p>这里的policy是 $p_{\theta}(d|q_n,r)$ 就是我们需要优化的生成式检索模型，对应的action是给定environment q的情况下sample得到 document. 判别器得到的log-prob就是reward.</p>
<p>为了减小REINFORCE方法中variance，作者采用了advantage-function，也就是减去baseline，其中baseline是均值：</p>
<p><img src="/2019/08/30/%E4%BB%8E0%E5%BC%80%E5%A7%8BGAN-7-IRGAN/advantage_func.png"></p>
<p>整个IRGAN的训练过程的伪代码：</p>
<p><img src="/2019/08/30/%E4%BB%8E0%E5%BC%80%E5%A7%8BGAN-7-IRGAN/algorithm.png"></p>
<p>上图中的公式(22)就是公式(5). 整个过程理解起来还是蛮简单的。</p>
<p>还有个问题为解决的是，前面提到对于不同的 IR 任务，判别器 $f_{\phi}(q,d)$ 的方式是不一样的。</p>
<h4 id="pairwise-case"><a href="#pairwise-case" class="headerlink" title="pairwise case"></a>pairwise case</h4><blockquote>
<p>Furthermore, ifwe use graded relevance scales (indicating a varying degree of match between each document and the corresponding query) rather than binary relevance, the training data could also be represented naturally as ordered document pairs.   </p>
</blockquote>
<p>此外，如果我们使用分级相关性比例（指示每个文档与相应查询之间的不同匹配程度）而不是二元相关性，则训练数据也可以自然地表示为有序文档对.</p>
<p>也就是不仅仅根据query和document之间是否相似这样的二元文档对，而是利用有序文档对（这在IR中其实更为常见），作为判别器的输入，这样能获取更多的信息。</p>
<p>这个时候的labeled document是 $R_n={&lt;d_i,d_j&gt;|d_i &gt; d_j}$, 其中 $d_i &gt; d_j$ 意味着 $d_i$ 比 $d_j$ 的相关性更高。</p>
<p><img src="/2019/08/30/%E4%BB%8E0%E5%BC%80%E5%A7%8BGAN-7-IRGAN/pairwise_func.png"></p>
<p>使用pairwise discriminator对应的目标函数：  </p>
<p><img src="/2019/08/30/%E4%BB%8E0%E5%BC%80%E5%A7%8BGAN-7-IRGAN/pairwise_train.png"></p>
<p>其中 $o = &lt;d_u,d_v&gt;, o’=&lt;d_u’,d_v’&gt;$. 在实际的操作中，选择一对document $&lt;d_i,d_j&gt;$. 然后选择相似度较低的 $d_j$ 与生成器得到的 $d_k$ 组成新的pairs $&lt;d_k, d_j&gt;$，作为判别器的输入。这样的目的就是认为 $d_k$ 的相似度高于 $d_j$ 的情况下，让 $d_k$ 尽可能的去与 $d_i$ 相似。</p>
<p>在前面介绍了生成器 $p_{\theta}(d|q,r)$ 实际上就是 softmax，看公式(2).</p>
<p>对于pairwise的形式,$d_j$ 也作为生成器的输入之一，对应的生成器是另一种 softmax:</p>
<p><img src="/2019/08/30/%E4%BB%8E0%E5%BC%80%E5%A7%8BGAN-7-IRGAN/pairwise_gen.png">  </p>
<p>其中 $g_{\theta}(q,d)$ is a task-specific real-valued function reflecting the chance of d being generated from q.  </p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2019-08-12T12:41:48.000Z" title="2019/8/12 下午8:41:48">2019-08-12</time>发表</span><span class="level-item"><time dateTime="2021-01-27T08:44:33.173Z" title="2021/1/27 下午4:44:33">2021-01-27</time>更新</span><span class="level-item"><a class="link-muted" href="/categories/reinforcement-learning/">reinforcement learning</a></span><span class="level-item">几秒读完 (大约2个字)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2019/08/12/UCB-cs294-policy-gradient/">UCB-cs294-policy gradient</a></h1><div class="content"><h3 id="Policy-Gradient"><a href="#Policy-Gradient" class="headerlink" title="Policy Gradient"></a>Policy Gradient</h3></div></article></div><nav class="pagination" role="navigation" aria-label="pagination"><div class="pagination-previous"><a href="/page/3/">上一页</a></div><div class="pagination-next"><a href="/page/5/">下一页</a></div><ul class="pagination-list is-hidden-mobile"><li><a class="pagination-link" href="/">1</a></li><li><a class="pagination-link" href="/page/2/">2</a></li><li><a class="pagination-link" href="/page/3/">3</a></li><li><a class="pagination-link is-current" href="/page/4/">4</a></li><li><a class="pagination-link" href="/page/5/">5</a></li><li><span class="pagination-ellipsis">&hellip;</span></li><li><a class="pagination-link" href="/page/24/">24</a></li></ul></nav></div><!--!--><div class="column column-right is-4-tablet is-4-desktop is-4-widescreen  order-3"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar" src="/img/avatar.png" alt="panxiaoxie"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">panxiaoxie</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Beijing, China</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">文章</p><a href="/archives"><p class="title">120</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">分类</p><a href="/categories"><p class="title">40</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">标签</p><a href="/tags"><p class="title">37</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/PanXiebit" target="_blank" rel="noopener">关注我</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/PanXiebit"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Email" href="/ftdpanxie@gmail.com"><i class="fa fa-envelope"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="RSS" href="/"><i class="fas fa-rss"></i></a></div></div></div><!--!--><div class="card widget" data-type="links"><div class="card-content"><div class="menu"><h3 class="menu-label">链接</h3><ul class="menu-list"><li><a class="level is-mobile" href="https://github.com/PanXiebit" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">github</span></span><span class="level-right"><span class="level-item tag">github.com</span></span></a></li><li><a class="level is-mobile" href="ftdpanxie@gmail.com" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">email</span></span><span class="level-right"><span class="level-item tag">ftdpanxie@gmail.com</span></span></a></li></ul></div></div></div><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">分类</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/C/"><span class="level-start"><span class="level-item">C++</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/CSAPP/"><span class="level-start"><span class="level-item">CSAPP</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/DRL/"><span class="level-start"><span class="level-item">DRL</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/GAN/"><span class="level-start"><span class="level-item">GAN</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li><li><a class="level is-mobile" href="/categories/GAN-RL/"><span class="level-start"><span class="level-item">GAN, RL</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/ML/"><span class="level-start"><span class="level-item">ML</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/NLP/"><span class="level-start"><span class="level-item">NLP</span></span><span class="level-end"><span class="level-item tag">14</span></span></a></li><li><a class="level is-mobile" href="/categories/TensorFlow/"><span class="level-start"><span class="level-item">TensorFlow</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/cs224d/"><span class="level-start"><span class="level-item">cs224d</span></span><span class="level-end"><span class="level-item tag">10</span></span></a></li><li><a class="level is-mobile" href="/categories/generation/"><span class="level-start"><span class="level-item">generation</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/generative-models/"><span class="level-start"><span class="level-item">generative models</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/interview/"><span class="level-start"><span class="level-item">interview</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/machine-translation/"><span class="level-start"><span class="level-item">machine translation</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/python/"><span class="level-start"><span class="level-item">python</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/pytorch/"><span class="level-start"><span class="level-item">pytorch</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/reinforcement-learning/"><span class="level-start"><span class="level-item">reinforcement learning</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/sign-language-recognition/"><span class="level-start"><span class="level-item">sign language recognition</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/transfer-learning/"><span class="level-start"><span class="level-item">transfer learning</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/transformer/"><span class="level-start"><span class="level-item">transformer</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"><span class="level-start"><span class="level-item">数据结构与算法</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile" href="/categories/%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB/"><span class="level-start"><span class="level-item">文本分类</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"><span class="level-start"><span class="level-item">论文笔记</span></span><span class="level-end"><span class="level-item tag">40</span></span></a><ul><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/DL/"><span class="level-start"><span class="level-item">DL</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/ESA/"><span class="level-start"><span class="level-item">ESA</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/GAN/"><span class="level-start"><span class="level-item">GAN</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/MRC-and-QA/"><span class="level-start"><span class="level-item">MRC and QA</span></span><span class="level-end"><span class="level-item tag">7</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/Machine-Translation/"><span class="level-start"><span class="level-item">Machine Translation</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/NLP/"><span class="level-start"><span class="level-item">NLP</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/Transformer/"><span class="level-start"><span class="level-item">Transformer</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/capsules/"><span class="level-start"><span class="level-item">capsules</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/computer-vision/"><span class="level-start"><span class="level-item">computer vision</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/constrast-learning/"><span class="level-start"><span class="level-item">constrast learning</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/data-augmentation/"><span class="level-start"><span class="level-item">data augmentation</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/dialogue-system/"><span class="level-start"><span class="level-item">dialogue system</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/language-model/"><span class="level-start"><span class="level-item">language model</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/machine-translation/"><span class="level-start"><span class="level-item">machine translation</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/open-set-recognition/"><span class="level-start"><span class="level-item">open set recognition</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/sentence-embedding/"><span class="level-start"><span class="level-item">sentence embedding</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/text-matching/"><span class="level-start"><span class="level-item">text matching</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/vision-language/"><span class="level-start"><span class="level-item">vision-language</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li></ul></div></div></div></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/panxiaoxie.png" alt="潘小榭" height="28"></a><p class="is-size-7"><span>&copy; 2022 Xie Pan</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("zh-CN");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="回到顶端" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "此网站使用Cookie来改善您的体验。",
          dismiss: "知道了！",
          allow: "允许使用Cookie",
          deny: "拒绝",
          link: "了解更多",
          policy: "Cookie政策",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.5/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="想要查找什么..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"想要查找什么...","untitled":"(无标题)","posts":"文章","pages":"页面","categories":"分类","tags":"标签"});
        });</script></body></html>