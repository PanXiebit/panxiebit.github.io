<!doctype html>
<html lang="zh"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>潘小榭</title><link rel="manifest" href="/manifest.json"><meta name="theme-color" content="black"><meta name="application-name" content="panxiaoxie"><meta name="msapplication-TileImage" content="/img/avatar.png"><meta name="msapplication-TileColor" content="black"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="panxiaoxie"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta property="og:type" content="blog"><meta property="og:title" content="panxiaoxie"><meta property="og:url" content="https://github.com/PanXiebit"><meta property="og:site_name" content="panxiaoxie"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://www.qt86.com/cache/1625298592_187938.png"><meta property="article:author" content="panxiaoxie"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="https://www.qt86.com/cache/1625298592_187938.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"http://www.panxiaoxie.cn"},"headline":"潘小榭","image":["http://www.panxiaoxie.cn/img/og_image.png"],"author":{"@type":"Person","name":"Xie Pan"},"publisher":{"@type":"Organization","name":"潘小榭","logo":{"@type":"ImageObject","url":"http://www.panxiaoxie.cn/img/panxiaoxie.png"}},"description":null}</script><link rel="icon" href="/img/avatar.png"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/css/justifiedGallery.min.css"><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script><!--!--><!--!--><meta name="generator" content="Hexo 5.4.0"></head><body class="is-2-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/panxiaoxie.png" alt="潘小榭" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">主页</a><a class="navbar-item" href="/archives">归档</a><a class="navbar-item" href="/categories">分类</a><a class="navbar-item" href="/tags">标签</a><a class="navbar-item" href="/about">关于我</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/PanXiebit"><i class="fab fa-github"></i></a><a class="navbar-item search" title="搜索" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-10-widescreen"><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2019-03-19T01:25:22.000Z" title="2019/3/19 上午9:25:22">2019-03-19</time>发表</span><span class="level-item"><time dateTime="2021-06-29T08:12:08.200Z" title="2021/6/29 下午4:12:08">2021-06-29</time>更新</span><span class="level-item"><a class="link-muted" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/">论文笔记</a><span> / </span><a class="link-muted" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/machine-translation/">machine translation</a></span><span class="level-item">6 分钟读完 (大约881个字)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2019/03/19/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-Using-monoligual-data-in-machine-transaltion/">论文笔记-Using monoligual data in machine transaltion</a></h1><div class="content"><h2 id="Monolingual-Data-in-NMT"><a href="#Monolingual-Data-in-NMT" class="headerlink" title="Monolingual Data in NMT"></a>Monolingual Data in NMT</h2><p><img src="/2019/03/19/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-Using-monoligual-data-in-machine-transaltion/01.png"></p>
<h2 id="Why-Monolingual-data-enhancement"><a href="#Why-Monolingual-data-enhancement" class="headerlink" title="Why Monolingual data enhancement"></a>Why Monolingual data enhancement</h2><ul>
<li>Large scale source-side data:  </li>
</ul>
<p>enhancing encoder network to obtain high quality context vector</p>
<p>representation of source sentence.</p>
<ul>
<li>Large scale target-side data:  </li>
</ul>
<p>boosting fluency for machine translation when decoding.</p>
<h2 id="The-methods-of-using-monolingual-data"><a href="#The-methods-of-using-monolingual-data" class="headerlink" title="The methods of using monolingual data"></a>The methods of using monolingual data</h2><p><img src="/2019/03/19/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-Using-monoligual-data-in-machine-transaltion/02.png"></p>
<h3 id="Multi-task-learning"><a href="#Multi-task-learning" class="headerlink" title="Multi-task learning"></a>Multi-task learning</h3><p>Target-side language model:  Integrating Language Model into the Decoder</p>
<p><strong>shallow fusion</strong></p>
<p><img src="/2019/03/19/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-Using-monoligual-data-in-machine-transaltion/05.png"></p>
<p><img src="/2019/03/19/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-Using-monoligual-data-in-machine-transaltion/06.png"></p>
<p>both an NMT model (on parallel corpora) as well as a recurrent neural network language model (RNNLM, on larger monolingual corpora) have been pre-trained separately before being integrated.</p>
<p>Shallow fusion: rescore the probability of the candidate words.</p>
<p><strong>deep fusion</strong></p>
<p><img src="/2019/03/19/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-Using-monoligual-data-in-machine-transaltion/03.png"></p>
<p><img src="/2019/03/19/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-Using-monoligual-data-in-machine-transaltion/04.png"></p>
<p><strong>multi-task learning</strong></p>
<p><img src="/2019/03/19/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-Using-monoligual-data-in-machine-transaltion/07.png"></p>
<p><img src="/2019/03/19/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-Using-monoligual-data-in-machine-transaltion/08.png"></p>
<p>Using Target-side Monolingual Data for Neural Machine Translation through Multi-task Learning, EMNLP, 2017</p>
<p>利用 target-side 的单语多了一个训练语言模型的任务。事实上（b）就是上一张 PPT 中的方法，这篇paper在这个基础上增加了语言模型的 loss。</p>
<p>$\sigma$ 参数在两个任务训练时都会更新。而 $\theta$ 参数仅仅在训练翻译模型时才会更新参数。</p>
<h3 id="auto-encoder"><a href="#auto-encoder" class="headerlink" title="auto-encoder"></a>auto-encoder</h3><p><img src="/2019/03/19/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-Using-monoligual-data-in-machine-transaltion/10.png"></p>
<p><img src="/2019/03/19/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-Using-monoligual-data-in-machine-transaltion/11.png"></p>
<p>通过 自编码 的形式，重构对应的 mono-data，作为辅助任务，与 NMT 模型共享 encoder 参数。</p>
<p>Semi-Supervised Learning for Neural Machine Translation, ACL, 2016</p>
<h3 id="Back-translation"><a href="#Back-translation" class="headerlink" title="Back-translation"></a>Back-translation</h3><h4 id="What-is-back-translation"><a href="#What-is-back-translation" class="headerlink" title="What is back-translation?"></a>What is back-translation?</h4><p>Synthetic pseudo parallel data from target-side monolingual data using a reverse translation model.</p>
<h4 id="why-back-translation-and-motivation"><a href="#why-back-translation-and-motivation" class="headerlink" title="why back-translation and motivation?"></a>why back-translation and motivation?</h4><p>It mitigates the problem of overfitting and fluency by exploiting additional data in the target language.</p>
<p>目标语言必须始终是真实句子才能让翻译模型翻译的结果更流畅、更准确，而源语言即便有少量用词不当、语序不对、语法错误，只要不影响理解就无所谓。其实人做翻译的时候也是一样的：翻译质量取决于一个人译出语言的水平，而不是源语言的水平（源语言的水平只要足够看懂句子即可）</p>
<p>Different aspects of the BT which influence the performance of translation:  </p>
<ul>
<li><p>Size of the Synthetic Data  </p>
</li>
<li><p>Direction of Back-Translation  </p>
</li>
<li><p>Quality of the Synthetic Data  </p>
</li>
</ul>
<h4 id="Size-of-the-Synthetic-Data"><a href="#Size-of-the-Synthetic-Data" class="headerlink" title="Size of the Synthetic Data"></a>Size of the Synthetic Data</h4><p><img src="/2019/03/19/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-Using-monoligual-data-in-machine-transaltion/12.png"></p>
<h4 id="Direction-of-Back-Translation"><a href="#Direction-of-Back-Translation" class="headerlink" title="Direction of Back-Translation"></a>Direction of Back-Translation</h4><p><img src="/2019/03/19/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-Using-monoligual-data-in-machine-transaltion/13.png"></p>
<h4 id="Quality-of-the-Synthetic-Data"><a href="#Quality-of-the-Synthetic-Data" class="headerlink" title="Quality of the Synthetic Data"></a>Quality of the Synthetic Data</h4><p><img src="/2019/03/19/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-Using-monoligual-data-in-machine-transaltion/14.png"></p>
<h3 id="copy-mechanism"><a href="#copy-mechanism" class="headerlink" title="copy mechanism"></a>copy mechanism</h3><p><img src="/2019/03/19/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-Using-monoligual-data-in-machine-transaltion/15.png"></p>
<p>作者的实验设置：用 target-side mono-data 来构建伪平行语料，一部分是直接 copy，另一部分是通过 back-translate 得到的。也就是 mono-data 出现了两次。</p>
<p>总觉得哪里不对。。。</p>
<h3 id="Dummy-source-sentence"><a href="#Dummy-source-sentence" class="headerlink" title="Dummy source sentence"></a>Dummy source sentence</h3><p>Pseudo parallel data:</p>
<p><null> +  target-side mono-data</null></p>
<p>The downside:</p>
<p>the network  ‘unlearns’  its conditioning on the source context if the ratio of monolingual training instances is too high.</p>
<p>Improving Neural Machine Translation Models with Monolingual Data, Sennrich et al, ACL 2016</p>
<h3 id="Self-learning"><a href="#Self-learning" class="headerlink" title="Self-learning"></a>Self-learning</h3><p>Synthetic target sentences from source-side mono-data:</p>
<ul>
<li><p>Build a baseline machine translation (MT) system on parallel data  </p>
</li>
<li><p>Translate source-side mono-data into target sentences  </p>
</li>
<li><p>Real parallel data + pseudo parallel data</p>
</li>
</ul>
<h2 id="reference"><a href="#reference" class="headerlink" title="reference"></a>reference</h2><ol>
<li><p>Improving Neural Machine Translation Models with Monolingual Data, Sennrich et al, ACL 2016  </p>
</li>
<li><p>Using Monolingual Data in Neural Machine Translation: a Systematic Study, Burlot et al. ACL 2018  </p>
</li>
<li><p>Copied Monolingual Data Improves Low-Resource Neural Machine Translation, Currey et al. 2017 In Proceedings of the Second Conference on Machine Translation  </p>
</li>
<li><p>Semi-Supervised Learning for Neural Machine Translation, Cheng et al. ACL 2016  </p>
</li>
<li><p>Exploiting Source-side Monolingual Data in Neural Machine Translation, Zhang et al. EMNLP 2016  </p>
</li>
<li><p>Using Target-side Monolingual Data for Neural Machine Translation through Multi-task Learning, Domhan et al. EMNLP 2018</p>
</li>
</ol>
<p>On Using Monolingual Corpora in Neural Machine Translation, Gulcehre, 2015  </p>
<ol start="7">
<li><p>Back-Translation Sampling by Targeting Difficult Words in Neural Machine Translation, EMNLP 2018  </p>
</li>
<li><p>Understanding Back-Translation at Scale, Edunov et al. EMNLP 2018  </p>
</li>
</ol>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2019-03-08T07:43:02.000Z" title="2019/3/8 下午3:43:02">2019-03-08</time>发表</span><span class="level-item"><time dateTime="2021-06-29T08:12:08.200Z" title="2021/6/29 下午4:12:08">2021-06-29</time>更新</span><span class="level-item"><a class="link-muted" href="/categories/transfer-learning/">transfer learning</a></span><span class="level-item">10 分钟读完 (大约1516个字)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2019/03/08/%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%E7%B3%BB%E5%88%97-3-%E7%8E%8B%E6%99%8B%E4%B8%9C%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%E6%89%8B%E5%86%8C%E9%98%85%E8%AF%BB/">迁移学习系列-3-王晋东迁移学习手册阅读</a></h1><div class="content"><h3 id="迁移学习的定义"><a href="#迁移学习的定义" class="headerlink" title="迁移学习的定义"></a>迁移学习的定义</h3><p>迁移学习，是指利用数据、任务、或模型之间的相似性，将在旧领域学习过的模型，应用于新领域的一种学习过程。</p>
<p>综述文章：</p>
<p>A survey on transfer learning [Pan and Yang, 2010]</p>
<h3 id="为什么要学习迁移学习？"><a href="#为什么要学习迁移学习？" class="headerlink" title="为什么要学习迁移学习？"></a>为什么要学习迁移学习？</h3><ol>
<li><p>缺少数据标注</p>
</li>
<li><p>缺少足够算力</p>
</li>
<li><p>普适化模型与个性化需求之间的矛盾</p>
</li>
<li><p>特定应用需求</p>
</li>
</ol>
<p>迁移学习如何解决这些问题：</p>
<ol>
<li><p>大数据与少标注：迁移数据标注</p>
</li>
<li><p>大数据与弱计算：模型迁移</p>
</li>
<li><p>普适化模型与个性化需求：自适应学习</p>
</li>
<li><p>特定应用的需求：相似领域知识迁移（比如cross-lingual）</p>
</li>
</ol>
<p><img src="/2019/03/08/%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%E7%B3%BB%E5%88%97-3-%E7%8E%8B%E6%99%8B%E4%B8%9C%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%E6%89%8B%E5%86%8C%E9%98%85%E8%AF%BB/01.png"></p>
<p>迁移学习与传统机器学习的区别：</p>
<p><img src="/2019/03/08/%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%E7%B3%BB%E5%88%97-3-%E7%8E%8B%E6%99%8B%E4%B8%9C%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%E6%89%8B%E5%86%8C%E9%98%85%E8%AF%BB/02.png"></p>
<p>迁移学习与领域自适应的区别：  </p>
<p>领域自适应问题是迁移学习的研究内容之一，它侧重于解决特征空间一致、类别空间一致，仅特征分布不一致的问题。而迁移学习也可以解决上述内容不一致的情况。</p>
<h3 id="迁移学习的常用分类"><a href="#迁移学习的常用分类" class="headerlink" title="迁移学习的常用分类"></a>迁移学习的常用分类</h3><p><img src="/2019/03/08/%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%E7%B3%BB%E5%88%97-3-%E7%8E%8B%E6%99%8B%E4%B8%9C%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%E6%89%8B%E5%86%8C%E9%98%85%E8%AF%BB/04.png"></p>
<h4 id="按照目标域标签分类"><a href="#按照目标域标签分类" class="headerlink" title="按照目标域标签分类"></a>按照目标域标签分类</h4><ol>
<li><p>监督迁移学习 (Supervised Transfer Learning)   </p>
</li>
<li><p>半监督迁移学习 (Semi-Supervised Transfer Learning)   </p>
</li>
<li><p>无监督迁移学习 (Unsupervised Transfer Learning)</p>
</li>
</ol>
<h4 id="按照学习方法分类"><a href="#按照学习方法分类" class="headerlink" title="按照学习方法分类"></a>按照学习方法分类</h4><ul>
<li><p>基于实例的迁移学习方法 (Instance based Transfer Learning)：</p>
</li>
<li><p>基于特征的迁移学习方法 (Feature based Transfer Learning)  </p>
</li>
<li><p>基于模型的迁移学习方法 (Model based Transfer Learning)  </p>
</li>
<li><p>基于关系的迁移学习方法 (Relation based Transfer Learning)</p>
</li>
</ul>
<p>基于实例的迁移，简单来说就是通过权重重用，对源域和目标域的样例进行迁移。就是说直接对不同的样本赋予不同权重，比如说相似的样本，我就给它高权重，这样我就完成了 迁移，非常简单非常非常直接。</p>
<p>基于特征的迁移，就是更进一步对特征进行变换。意思是说，假设源域和目标域的特征 原来不在一个空间，或者说它们在原来那个空间上不相似，那我们就想办法把它们变换到一个空间里面，那这些特征不就相似了？这个思路也非常直接。这个方法是用得非常多的，一 直在研究，目前是感觉是研究最热的。</p>
<p>基于模型的迁移，就是说构建参数共享的模型。这个主要就是在神经网络里面用的特别多，因为神经网络的结构可以直接进行迁移。比如说神经网络最经典的 <strong>finetune</strong> 就是模型参数迁移的很好的体现。</p>
<p>基于关系的迁移，这个方法用的比较少，这个主要就是说挖掘和利用关系进行类比迁移。比如老师上课、学生听课就可以类比为公司开会的场景。这个就是一种关系的迁移。</p>
<h4 id="按照特征分类"><a href="#按照特征分类" class="headerlink" title="按照特征分类"></a>按照特征分类</h4><ul>
<li><p>同构迁移学习 (Homogeneous Transfer Learning)  </p>
</li>
<li><p>异构迁移学习 (Heterogeneous Transfer Learning)  </p>
</li>
</ul>
<p>这也是一种很直观的方式：如果特征语义和维度都相同，那么就是同构；反之，如果特征完全不相同，那么就是异构。举个例子来说，不同图片的迁移，就可以认为是同构；而图片到文本的迁移，则是异构的。</p>
<h4 id="按离线与在线形式分"><a href="#按离线与在线形式分" class="headerlink" title="按离线与在线形式分"></a>按离线与在线形式分</h4><ul>
<li><p>离线迁移学习 (Offline Transfer Learning)  </p>
</li>
<li><p>在线迁移学习 (Online Transfer Learning)</p>
</li>
</ul>
<h3 id="迁移学习的应用"><a href="#迁移学习的应用" class="headerlink" title="迁移学习的应用"></a>迁移学习的应用</h3><p><img src="/2019/03/08/%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%E7%B3%BB%E5%88%97-3-%E7%8E%8B%E6%99%8B%E4%B8%9C%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%E6%89%8B%E5%86%8C%E9%98%85%E8%AF%BB/05.png"></p>
<h4 id="计算机视觉"><a href="#计算机视觉" class="headerlink" title="计算机视觉"></a>计算机视觉</h4><p>在 CV 领域，迁移学习主要是方法是领域自适应 domain adaption. 侧重于解决特征空间一致、类别空间一致，仅特征分布不一致的问题。</p>
<p><img src="/2019/03/08/%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%E7%B3%BB%E5%88%97-3-%E7%8E%8B%E6%99%8B%E4%B8%9C%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%E6%89%8B%E5%86%8C%E9%98%85%E8%AF%BB/06.png"></p>
<p>个人理解：在图像上，即使类别差别很大，但是在特征空间上仍然是一致的，或者说有很多相似之处。比如人和狗，从轮廓、颜色、五官等等特征都是具有可迁移性的。再比如人和桌子，也是具有相似特征的。</p>
<p>那么问题是，特征空间完全一致吗？不一致的部分呢？</p>
<h4 id="文本分类"><a href="#文本分类" class="headerlink" title="文本分类"></a>文本分类</h4><p>由于文本数据有其领域特殊性，因此，在一个领域上训练的分类器，不能直接拿来作用到另一个领域上。这就需要用到迁移学习。例如，在电影评论文本数据集上训练好的分类器，不能直接用于图书评论的预测。这就需要进行迁移学习。图 11是一个由电子产品评论 迁移到 DVD 评论的迁移学习任务。</p>
<p><img src="/2019/03/08/%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%E7%B3%BB%E5%88%97-3-%E7%8E%8B%E6%99%8B%E4%B8%9C%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%E6%89%8B%E5%86%8C%E9%98%85%E8%AF%BB/07.png"></p>
<p>那么问题来了，这种从一个domain 迁移到另一个 domain，到底改变了什么？比如同样一个词，在 电子产品中对应的 vector 经过迁移后（finetune?），发生了怎样的变化，这个可以可视化嘛？</p>
<h4 id="时间序列"><a href="#时间序列" class="headerlink" title="时间序列"></a>时间序列</h4><ul>
<li><p>行为识别(Activity Recognition)  </p>
</li>
<li><p>室内定位 (Indoor Location)  </p>
</li>
</ul>
<h4 id="医疗健康"><a href="#医疗健康" class="headerlink" title="医疗健康"></a>医疗健康</h4><p>不同于其他领域，医疗领域研究的难点问题是，无法获取足够有效的医疗数据。在这一领域，迁移学习同样也变得越来越重要。</p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2019-03-06T08:44:52.000Z" title="2019/3/6 下午4:44:52">2019-03-06</time>发表</span><span class="level-item"><time dateTime="2021-06-29T08:12:08.522Z" title="2021/6/29 下午4:12:08">2021-06-29</time>更新</span><span class="level-item"><a class="link-muted" href="/categories/DRL/">DRL</a></span><span class="level-item">5 分钟读完 (大约739个字)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2019/03/06/UCL-DRL-03-planning-by-DP/">UCL-DRL-03-planning by DP</a></h1><div class="content"><h1 id="Planning-by-Dynamic-Programming"><a href="#Planning-by-Dynamic-Programming" class="headerlink" title="Planning by Dynamic Programming"></a>Planning by Dynamic Programming</h1><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>what is dynamic programming?</p>
<p><img src="/2019/03/06/UCL-DRL-03-planning-by-DP/01.png"></p>
<p>动态规划是一种方法/思想，将复杂问题分解成子问题，并解决子问题。</p>
<p><img src="/2019/03/06/UCL-DRL-03-planning-by-DP/02.png"></p>
<p>DP 是具有以下两种特质的问题常用的解决方法：  </p>
<ul>
<li><p>具有可优化的子结构</p>
<ul>
<li>优化问题可以分解成子问题  </li>
</ul>
</li>
<li><p>重叠子问题</p>
<ul>
<li><p>子问题重复出现很多次  </p>
</li>
<li><p>子问题的solution可以被缓存和reuse</p>
</li>
</ul>
</li>
</ul>
<p>马尔可夫决策过程就具有这两种特质：  </p>
<ul>
<li><p>Bellman 公式给出了迭代分解的方式  </p>
</li>
<li><p>value funvtion 用来存储和再利用子solutions</p>
</li>
</ul>
<p>Bellman 公式的含义分为两部分，第一部分是目前的一步是最优的行为，第二部分是余下来的其他步骤也是最优的行为。</p>
<p><img src="/2019/03/06/UCL-DRL-03-planning-by-DP/03.png"></p>
<p>动态规划需要的输入：  </p>
<ul>
<li><p>MDP $&lt;S,A,P,R,\gamma&gt;$ and policy $\pi$  </p>
</li>
<li><p>or MDP $&lt;S,P^{\pi},R^{\pi},\gamma&gt;$</p>
</li>
</ul>
<p>输出： value function $v_{\pi}$</p>
<p><img src="/2019/03/06/UCL-DRL-03-planning-by-DP/04.png"></p>
<p>DP 适用的一些场景。比较熟悉的 sequence alignment, shortest path algorithms, viterbi algorithm.  </p>
<h2 id="Policy-evaluation"><a href="#Policy-evaluation" class="headerlink" title="Policy evaluation"></a>Policy evaluation</h2><h3 id="Iterative-policy-evaluation"><a href="#Iterative-policy-evaluation" class="headerlink" title="Iterative policy evaluation"></a>Iterative policy evaluation</h3><p><img src="/2019/03/06/UCL-DRL-03-planning-by-DP/05.png"></p>
<p><img src="/2019/03/06/UCL-DRL-03-planning-by-DP/06.png"></p>
<p>$v_{k+1}(s)=\sum_{a\in A}\pi(a|s)(R_s^a+\gamma\sum_{s’\in S}P^a_{ss’}v_k(s’))$</p>
<h3 id="example"><a href="#example" class="headerlink" title="example"></a>example</h3><p><img src="/2019/03/06/UCL-DRL-03-planning-by-DP/07.png"></p>
<ul>
<li><p>方块中任意一个状态到另一个状态的 reward 是 -1.  </p>
</li>
<li><p>每迭代一步有 north, east, south, weat 4种选择。</p>
</li>
</ul>
<p><img src="/2019/03/06/UCL-DRL-03-planning-by-DP/08.png"></p>
<p><img src="/2019/03/06/UCL-DRL-03-planning-by-DP/09.png"></p>
<ul>
<li>k=0. 初始状态下，所有的方块累计的 reward 都是 0. 所以在这个状态下是 random policy.</li>
</ul>
<ul>
<li>k=1, 迭代一步之后，除了 terminal squares, 其他的 reward 都是 1. 如果采用 greedy policy，就能确定部分路径了。</li>
</ul>
<ul>
<li>k=2, 在 random policy 策略下，我们来看下 1.75 怎么得到的：</li>
</ul>
<p>$$1+(1+1+1)/4=1.75$$</p>
<ul>
<li>k=3, 在 random policy 策略下，我们来看 2.4, 2.9 怎么得到的：</li>
</ul>
<p>$$(1+2.7+3+3)/4=2.425$$</p>
<p>$$(2.7+3+3+3)/4=2.925$$</p>
<p>这里的 k 是迭代的次数，并不是时间.</p>
<h3 id="policy-iteration"><a href="#policy-iteration" class="headerlink" title="policy iteration"></a>policy iteration</h3><p><img src="/2019/03/06/UCL-DRL-03-planning-by-DP/10.png"></p>
<p><img src="/2019/03/06/UCL-DRL-03-planning-by-DP/11.png"></p>
<p>迭代方式：  </p>
<ul>
<li><p>policy evaluation  </p>
</li>
<li><p>policy improvement: greedy</p>
</li>
</ul>
<h3 id="policy-improvement"><a href="#policy-improvement" class="headerlink" title="policy improvement"></a>policy improvement</h3><p><img src="/2019/03/06/UCL-DRL-03-planning-by-DP/12.png"></p>
<p>$$v_{\pi}(s)=E[R_{t+1}+\gamma R_{t+2}+….|S_t=s]$$</p>
<p>improve the policy by acting greedily.</p>
<p>当前最优 policy:</p>
<p> $${\pi}^{‘}(s)=greedy(v_{\pi})=argmax_{a\in A}q_{\pi}(s,a)$$</p>
<p>$q_{\pi}(s,a)$ 是 action-value function.</p>
<p>这页ppt中最后的公式实际证明了：采用 greedy policy 至少能保证 $v_{\pi^{‘}}\ge v_{\pi}(s)$.</p>
<p><img src="/2019/03/06/UCL-DRL-03-planning-by-DP/13.png"></p>
<h3 id="modified-policy-iteration"><a href="#modified-policy-iteration" class="headerlink" title="modified policy iteration"></a>modified policy iteration</h3><p><img src="/2019/03/06/UCL-DRL-03-planning-by-DP/14.png"></p>
<p><img src="/2019/03/06/UCL-DRL-03-planning-by-DP/15.png"></p>
<h2 id="value-iteration"><a href="#value-iteration" class="headerlink" title="value iteration"></a>value iteration</h2><p><img src="/2019/03/06/UCL-DRL-03-planning-by-DP/16.png"></p>
<p>优化的定理：  </p>
<p>任何优化策略都可以分解成两部分：  </p>
<ul>
<li><p>最优化的 action A  </p>
</li>
<li><p>后继状态 S’ 下的最优化策略 policy  </p>
</li>
</ul>
<p><img src="/2019/03/06/UCL-DRL-03-planning-by-DP/17.png"></p>
<p>example:</p>
<p><img src="/2019/03/06/UCL-DRL-03-planning-by-DP/18.png"></p>
<p><img src="/2019/03/06/UCL-DRL-03-planning-by-DP/19.png"></p>
<p><img src="/2019/03/06/UCL-DRL-03-planning-by-DP/20.png"></p>
<h2 id="summary-of-DP-algorithms"><a href="#summary-of-DP-algorithms" class="headerlink" title="summary of DP algorithms"></a>summary of DP algorithms</h2><p><img src="/2019/03/06/UCL-DRL-03-planning-by-DP/21.png"></p>
<p><img src="/2019/03/06/UCL-DRL-03-planning-by-DP/22.png"></p>
<p><img src="/2019/03/06/UCL-DRL-03-planning-by-DP/23.png"></p>
<h3 id="In-Place-Dynamic-Programming"><a href="#In-Place-Dynamic-Programming" class="headerlink" title="In-Place Dynamic Programming"></a>In-Place Dynamic Programming</h3><p><img src="/2019/03/06/UCL-DRL-03-planning-by-DP/25.png"></p>
<h3 id="Prioritised-Sweeping"><a href="#Prioritised-Sweeping" class="headerlink" title="Prioritised Sweeping"></a>Prioritised Sweeping</h3><p><img src="/2019/03/06/UCL-DRL-03-planning-by-DP/26.png"></p>
<h3 id="Real-Time-Dynamic-Programming"><a href="#Real-Time-Dynamic-Programming" class="headerlink" title="Real-Time Dynamic Programming"></a>Real-Time Dynamic Programming</h3><p><img src="/2019/03/06/UCL-DRL-03-planning-by-DP/27.png"></p>
<h2 id="Extensions-to-dynamic-programming"><a href="#Extensions-to-dynamic-programming" class="headerlink" title="Extensions to dynamic programming"></a>Extensions to dynamic programming</h2><p><img src="/2019/03/06/UCL-DRL-03-planning-by-DP/24.png"></p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2019-03-06T07:37:28.000Z" title="2019/3/6 下午3:37:28">2019-03-06</time>发表</span><span class="level-item"><time dateTime="2021-06-29T08:12:08.522Z" title="2021/6/29 下午4:12:08">2021-06-29</time>更新</span><span class="level-item"><a class="link-muted" href="/categories/transfer-learning/">transfer learning</a></span><span class="level-item">4 分钟读完 (大约584个字)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2019/03/06/%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%E7%B3%BB%E5%88%97-2-Combining-semi-supervised-learning-with-transfer-learning/">迁移学习系列-2-Combining semi-supervised learning with transfer learning</a></h1><div class="content"><h2 id="paper"><a href="#paper" class="headerlink" title="paper"></a>paper</h2><p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1804.09530">Strong Baselines for Neural Semi-Supervised Learning under Domain Shift</a></p>
<h3 id="motivation"><a href="#motivation" class="headerlink" title="motivation"></a>motivation</h3><p>这篇paper的工作就是提出了一个经典方法实现的strong baseline.他的motivation就是前面很多研究比如基于deep learning的，对比的经典算法都很weak，或者是在专有的数据集上跑（容易过拟合）。</p>
<p>对比的三种传统方法， self-traning, tritraining, tri-training with disagreement</p>
<h3 id="self-training"><a href="#self-training" class="headerlink" title="self-training:"></a>self-training:</h3><ol>
<li><p>使用有标签的数据，训练一个模型  </p>
</li>
<li><p>用这个模型去预测无标签的数据，得到对应样本属于某一类别的概率  </p>
</li>
<li><p>选择一个阈值，大于这个阈值的样本，可以打上伪标签。但是通常来说，阈值不太好确定，所以可以使用相对阈值，也就是选取概率相对较高的 top N.  </p>
</li>
</ol>
<p>模型的缺点在于：如果预测错了某些样本，那么错误会累积并放大。  </p>
<p><img src="/2019/03/06/%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%E7%B3%BB%E5%88%97-2-Combining-semi-supervised-learning-with-transfer-learning/01.png"></p>
<h3 id="tri-training"><a href="#tri-training" class="headerlink" title="tri-training:"></a>tri-training:</h3><ol>
<li><p>使用有标签的数据，训练三个模型 m1, m2, m3  </p>
</li>
<li><p>使用 bootstrapping 的方法，sample部分无标签的数据，然后使用三个模型进行预测，当 m1 预测样本属于某一类的概率低时，而 m2, m3 预测样本属于这一类的概率高时，将这个样本打上伪标签，加入到 m1 的训练集中去  </p>
</li>
<li><p>迭代这个过程，直到分类器不在变化，可以同时更新三个分类器？  </p>
</li>
</ol>
<p>motivation：模型应该增强它相对较弱的地方。其实也就是 ensamble 的 sense.  </p>
<p>缺点：计算量太大， 耗费时间和空间  </p>
<p><img src="/2019/03/06/%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%E7%B3%BB%E5%88%97-2-Combining-semi-supervised-learning-with-transfer-learning/02.png"></p>
<h3 id="multi-task-tritraining"><a href="#multi-task-tritraining" class="headerlink" title="multi-task tritraining:"></a>multi-task tritraining:</h3><ol>
<li><p>多任务训练，这里的任务其实可以看作是一致的，底层 encoder 层参数共享，softmax层，也就是 decoder 层参数不一致。  </p>
</li>
<li><p>要尽可能让 m1, m2 具有差异性 diversity，加上了正则化项  </p>
</li>
<li><p>模型 m3 只在伪标签数据上进行训练。其目的是让模型在 domain shift 情况下鲁棒性更强。  </p>
</li>
</ol>
<p><img src="/2019/03/06/%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%E7%B3%BB%E5%88%97-2-Combining-semi-supervised-learning-with-transfer-learning/03.png"></p>
<h2 id="paper2"><a href="#paper2" class="headerlink" title="paper2"></a>paper2</h2><p><a target="_blank" rel="noopener" href="http://aclweb.org/anthology/D18-1217">Semi-Supervised Sequence Modeling with Cross-View Training (EMNLP 2018)</a></p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2019-03-04T01:09:08.000Z" title="2019/3/4 上午9:09:08">2019-03-04</time>发表</span><span class="level-item"><time dateTime="2021-06-29T08:12:08.504Z" title="2021/6/29 下午4:12:08">2021-06-29</time>更新</span><span class="level-item"><a class="link-muted" href="/categories/transfer-learning/">transfer learning</a></span><span class="level-item">10 分钟读完 (大约1552个字)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2019/03/04/%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%E7%B3%BB%E5%88%97-1-Neural-Transfer-Learning-for-NLP/">迁移学习系列 1-Neural Transfer Learning for NLP</a></h1><div class="content"><h2 id="迁移学习与监督学习的区别"><a href="#迁移学习与监督学习的区别" class="headerlink" title="迁移学习与监督学习的区别"></a>迁移学习与监督学习的区别</h2><p><img src="/2019/03/04/%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%E7%B3%BB%E5%88%97-1-Neural-Transfer-Learning-for-NLP/01.png"></p>
<p>training domain 和 target domain 不一致时，需要知识迁移。  </p>
<p>那么暂时的问题来了？  </p>
<ul>
<li><p>1.如何界定 domain 的范围，尤其是NLP领域。从医学文本能迁移到科幻小说吗，感觉不可以。。  </p>
</li>
<li><p>2.从 big domain 到 small domain 的迁移也是属于迁移学习的范畴吧？比如像 BERT 这样在超大的训练集上进行 training，然后在小的子集上 fine-tune，都能表现的很好是吗？  </p>
</li>
</ul>
<h2 id="Why-transfer-learning"><a href="#Why-transfer-learning" class="headerlink" title="Why transfer learning"></a>Why transfer learning</h2><p><img src="/2019/03/04/%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%E7%B3%BB%E5%88%97-1-Neural-Transfer-Learning-for-NLP/02.png"></p>
<p>目前的监督模型依旧非常脆弱，<a target="_blank" rel="noopener" href="https://arxiv.org/abs/1707.07328">Jia and Liang, EMNLP 2017</a> 这篇 paper 证明了目前的 SOTA 的模型对对抗样本非常敏感。</p>
<p>迁移学习能解决这个问题吗，疑惑？？</p>
<blockquote>
<p><strong>Abstract：</strong>    </p>
</blockquote>
<p>Standard accuracy metrics indicate that reading comprehension systems are making rapid progress, but the extent to which these systems truly understand language remains unclear. To reward systems with real language understanding abilities, we propose an adversarial evaluation scheme for the Stanford Question Answering Dataset (SQuAD). Our method tests whether systems can answer questions about paragraphs that contain adversarially inserted sentences, which are automatically generated to distract computer systems without changing the correct answer or misleading humans. In this adversarial setting, the accuracy of sixteen published models drops from an average of 75% F1 score to 36%; when the adversary is allowed to add ungrammatical sequences of words, average accuracy on four models decreases further to 7%. We hope our insights will motivate the development of new models that understand language more precisely.</p>
<p><img src="/2019/03/04/%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%E7%B3%BB%E5%88%97-1-Neural-Transfer-Learning-for-NLP/03.png"></p>
<p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1711.02173">Synthetic and Natural Noise Both Break Neural Machine Translation, Belinkov and Bisk (ICLR 2018)</a> 这篇 paper 中提到基于字符级别的翻译模型能有效解决 OOV 等问题，但是却使得模型对 noise 非常敏感且脆弱。如果出现 phonetic 拼写错误，omission 省略， key swap 关键字母交换，都会导致 BLEU 值严重下降。</p>
<blockquote>
<p><strong>Abstract</strong>   </p>
</blockquote>
<p>Character-based neural machine translation (NMT) models alleviate out-of-vocabulary issues, learn morphology, and move us closer to completely end-to-end translation systems. Unfortunately, they are also very brittle and easily falter when presented with noisy data. In this paper, we confront NMT models with synthetic and natural sources of noise. We find that state-of-the-art models fail to translate even moderately noisy texts that humans have no trouble comprehending. We explore two approaches to increase model robustness: structure-invariant word representations and robust training on noisy texts. We find that a model based on a character convolutional neural network is able to simultaneously learn representations robust to multiple kinds of noise.</p>
<p><img src="/2019/03/04/%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%E7%B3%BB%E5%88%97-1-Neural-Transfer-Learning-for-NLP/04.png"></p>
<p><a target="_blank" rel="noopener" href="http://aclweb.org/anthology/N18-1170">Iyyer et al. (NAACL 2018)</a> 这篇 paper 提出了一个句法规则控制下的释义生成模型，syntactically controlled paraphrase networks (SCPNs). 然后发现这样的对抗样本很容易愚弄训练好的监督模型。</p>
<blockquote>
<p><strong>Abstract：</strong>     </p>
</blockquote>
<p>We propose syntactically controlled paraphrase networks (SCPNs) and use them to generate adversarial examples. Given a sentence and a target syntactic form (e.g., a constituency parse), SCPNs are trained to produce a paraphrase of the sentence with the desired syntax. We show it is possible to create training data for this task by first doing backtranslation at a very large scale, and then using a parser to label the syntactic transformations that naturally occur during this process. Such data allows us to train a neural encoderdecoder model with extra inputs to specify the target syntax. A combination of automated and human evaluations show that SCPNs generate paraphrases that follow their target specifications without decreasing paraphrase quality when compared to baseline (uncontrolled)paraphrase systems. Furthermore, they are more capable of generating syntactically adversarial examples that both (1) “fool” pretrained models and (2) improve the robustness of these models to syntactic variation when used to augment their training data</p>
<p><img src="/2019/03/04/%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%E7%B3%BB%E5%88%97-1-Neural-Transfer-Learning-for-NLP/05.png"></p>
<p>人工标注所有 domain 或者任何语言的数据是不可理的，因此需要 transfering knowledge from a related setting to the target setting.</p>
<p><img src="/2019/03/04/%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%E7%B3%BB%E5%88%97-1-Neural-Transfer-Learning-for-NLP/06.png"></p>
<p>NLP 很多重大的基础性的研究都可以看作是迁移学习的一种形式。  </p>
<ul>
<li><p>LSA  </p>
</li>
<li><p>Brown clusters  </p>
</li>
<li><p>word embedding  </p>
</li>
</ul>
<p><img src="/2019/03/04/%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%E7%B3%BB%E5%88%97-1-Neural-Transfer-Learning-for-NLP/07.png"></p>
<p>已有工作的局限性：  </p>
<ul>
<li><p>限制度太高：预设定好的相似度指标，hard 参数共享  </p>
</li>
<li><p>条件设定太过于具体：单一的 task  </p>
</li>
<li><p>baseline 太弱：缺少与传统方法的对比  </p>
</li>
<li><p>模型脆弱：在 out-of-domain 不work，依赖于相似的语言/任务  </p>
</li>
<li><p>效率低：需要大量参数，时间和样本  </p>
</li>
</ul>
<h2 id="研究目标"><a href="#研究目标" class="headerlink" title="研究目标"></a>研究目标</h2><p><img src="/2019/03/04/%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%E7%B3%BB%E5%88%97-1-Neural-Transfer-Learning-for-NLP/08.png"></p>
<p><img src="/2019/03/04/%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%E7%B3%BB%E5%88%97-1-Neural-Transfer-Learning-for-NLP/09.png"></p>
<ul>
<li><p>迁移学习</p>
<ul>
<li><p>传导式迁移学习（相同的任务，只有sourced domain有label）  </p>
<ul>
<li><p>领域自适应（不同的 domain）  </p>
</li>
<li><p>跨语言学习（不同的 language）  </p>
</li>
</ul>
</li>
<li><p>归纳式迁移学习（不同的任务， target domain 也有标签）  </p>
<ul>
<li><p>多任务学习  </p>
</li>
<li><p>序列迁移学习  </p>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>大佬太强了。。。。强到爆炸啊</p>
<h2 id="domain-adaptation"><a href="#domain-adaptation" class="headerlink" title="domain adaptation"></a>domain adaptation</h2><p>Propose two novel methods that bridge the domain discrepancy by selecting relevant and informative data for unsupervised domain adaptation.  </p>
<p>提出两方法，替无监督的域适应选择相关的，具有信息量的数据来弥合域之间的差异。</p>
<h3 id="Based-on-Bayesian-Optimisation"><a href="#Based-on-Bayesian-Optimisation" class="headerlink" title="Based on Bayesian Optimisation"></a>Based on Bayesian Optimisation</h3><p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1707.05246">Learning to select data for transfer learning with Bayesian Optimization, EMNLP2017</a></p>
<p><img src="/2019/03/04/%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%E7%B3%BB%E5%88%97-1-Neural-Transfer-Learning-for-NLP/10.png"></p>
<p>还不太懂 bayesian optimisation:  </p>
<ul>
<li><p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/29779000">https://zhuanlan.zhihu.com/p/29779000</a>  </p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://www.jiqizhixin.com/articles/2017-08-18-5">https://www.jiqizhixin.com/articles/2017-08-18-5</a>  </p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1807.02811">A Tutorial on Bayesian Optimization</a></p>
</li>
</ul>
<p><img src="/2019/03/04/%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%E7%B3%BB%E5%88%97-1-Neural-Transfer-Learning-for-NLP/11.png"></p>
<h3 id="Using-semi-supervised-learning-and-multi-task-learning"><a href="#Using-semi-supervised-learning-and-multi-task-learning" class="headerlink" title="Using semi-supervised learning and multi-task learning"></a>Using semi-supervised learning and multi-task learning</h3><p><a target="_blank" rel="noopener" href="https://acl2018.org/paper/168/">Strong Baselines for Neural Semi-supervised Learning under Domain Shift, Ruder &amp; Plank, ACL 2018</a>  </p>
<blockquote>
<p>Novel neural models have been proposed in recent years for learning under domain shift. Most models, however, only evaluate on a single task, on proprietary datasets, or compare to weak baselines, which makes comparison of models difficult. In this paper, we re-evaluate classic general-purpose bootstrapping approaches in the context of neural networks under domain shifts vs. recent neural approaches and propose a novel multi-task tri-training method that reduces the time and space complexity of classic tri-training. Extensive experiments on two benchmarks for part-of-speech tagging and sentiment analysis are negative: while our novel method establishes a new state-of-the-art for sentiment analysis, it does not fare consistently the best. More importantly, we arrive at the somewhat surprising conclusion that classic tri-training, with some additions, outperforms the state-of-the-art for NLP. Hence classic approaches constitute an important and strong baseline.</p>
</blockquote>
<p>大佬的论文真的难。。太 hardcore 了。。</p>
<h2 id="cross-lingual-Learning"><a href="#cross-lingual-Learning" class="headerlink" title="cross-lingual Learning"></a>cross-lingual Learning</h2><p><img src="/2019/03/04/%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%E7%B3%BB%E5%88%97-1-Neural-Transfer-Learning-for-NLP/12.png"></p>
<p><img src="/2019/03/04/%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%E7%B3%BB%E5%88%97-1-Neural-Transfer-Learning-for-NLP/14.png"></p>
<p><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1805.03620.pdf">On the Limitations of Unsupervised Bilingual Dictionary Induction</a>  </p>
<p><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1808.09334.pdf">A Discriminative Latent-Variable Model for Bilingual Lexicon Induction</a>  </p>
<p><img src="/2019/03/04/%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%E7%B3%BB%E5%88%97-1-Neural-Transfer-Learning-for-NLP/16.png"></p>
<h2 id="multi-task-learning"><a href="#multi-task-learning" class="headerlink" title="multi-task learning"></a>multi-task learning</h2><p><img src="/2019/03/04/%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%E7%B3%BB%E5%88%97-1-Neural-Transfer-Learning-for-NLP/17.png"></p>
<h2 id="sequential-transfer-learning"><a href="#sequential-transfer-learning" class="headerlink" title="sequential transfer learning"></a>sequential transfer learning</h2><p><img src="/2019/03/04/%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%E7%B3%BB%E5%88%97-1-Neural-Transfer-Learning-for-NLP/18.png"></p>
</div></article></div><nav class="pagination" role="navigation" aria-label="pagination"><div class="pagination-previous"><a href="/page/5/">上一页</a></div><div class="pagination-next"><a href="/page/7/">下一页</a></div><ul class="pagination-list is-hidden-mobile"><li><a class="pagination-link" href="/">1</a></li><li><span class="pagination-ellipsis">&hellip;</span></li><li><a class="pagination-link" href="/page/5/">5</a></li><li><a class="pagination-link is-current" href="/page/6/">6</a></li><li><a class="pagination-link" href="/page/7/">7</a></li><li><span class="pagination-ellipsis">&hellip;</span></li><li><a class="pagination-link" href="/page/24/">24</a></li></ul></nav></div><!--!--><div class="column column-right is-4-tablet is-4-desktop is-4-widescreen  order-3"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar" src="/img/avatar.png" alt="panxiaoxie"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">panxiaoxie</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Beijing, China</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">文章</p><a href="/archives"><p class="title">116</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">分类</p><a href="/categories"><p class="title">39</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">标签</p><a href="/tags"><p class="title">36</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/PanXiebit" target="_blank" rel="noopener">关注我</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/PanXiebit"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Email" href="/ftdpanxie@gmail.com"><i class="fa fa-envelope"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="RSS" href="/"><i class="fas fa-rss"></i></a></div></div></div><!--!--><div class="card widget" data-type="links"><div class="card-content"><div class="menu"><h3 class="menu-label">链接</h3><ul class="menu-list"><li><a class="level is-mobile" href="https://github.com/PanXiebit" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">github</span></span><span class="level-right"><span class="level-item tag">github.com</span></span></a></li><li><a class="level is-mobile" href="ftdpanxie@gmail.com" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">email</span></span><span class="level-right"><span class="level-item tag">ftdpanxie@gmail.com</span></span></a></li></ul></div></div></div><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">分类</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/C/"><span class="level-start"><span class="level-item">C++</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/CSAPP/"><span class="level-start"><span class="level-item">CSAPP</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/DRL/"><span class="level-start"><span class="level-item">DRL</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/GAN/"><span class="level-start"><span class="level-item">GAN</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li><li><a class="level is-mobile" href="/categories/GAN-RL/"><span class="level-start"><span class="level-item">GAN, RL</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/ML/"><span class="level-start"><span class="level-item">ML</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/NLP/"><span class="level-start"><span class="level-item">NLP</span></span><span class="level-end"><span class="level-item tag">14</span></span></a></li><li><a class="level is-mobile" href="/categories/TensorFlow/"><span class="level-start"><span class="level-item">TensorFlow</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/cs224d/"><span class="level-start"><span class="level-item">cs224d</span></span><span class="level-end"><span class="level-item tag">10</span></span></a></li><li><a class="level is-mobile" href="/categories/generation/"><span class="level-start"><span class="level-item">generation</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/interview/"><span class="level-start"><span class="level-item">interview</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/leetcode/"><span class="level-start"><span class="level-item">leetcode</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/machine-translation/"><span class="level-start"><span class="level-item">machine translation</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/python/"><span class="level-start"><span class="level-item">python</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/pytorch/"><span class="level-start"><span class="level-item">pytorch</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/reinforcement-learning/"><span class="level-start"><span class="level-item">reinforcement learning</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/sign-language-recognition/"><span class="level-start"><span class="level-item">sign language recognition</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/transfer-learning/"><span class="level-start"><span class="level-item">transfer learning</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"><span class="level-start"><span class="level-item">数据结构与算法</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile" href="/categories/%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB/"><span class="level-start"><span class="level-item">文本分类</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"><span class="level-start"><span class="level-item">论文笔记</span></span><span class="level-end"><span class="level-item tag">40</span></span></a><ul><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/DL/"><span class="level-start"><span class="level-item">DL</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/ESA/"><span class="level-start"><span class="level-item">ESA</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/GAN/"><span class="level-start"><span class="level-item">GAN</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/MRC-and-QA/"><span class="level-start"><span class="level-item">MRC and QA</span></span><span class="level-end"><span class="level-item tag">7</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/Machine-Translation/"><span class="level-start"><span class="level-item">Machine Translation</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/NLP/"><span class="level-start"><span class="level-item">NLP</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/Transformer/"><span class="level-start"><span class="level-item">Transformer</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/capsules/"><span class="level-start"><span class="level-item">capsules</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/computer-vision/"><span class="level-start"><span class="level-item">computer vision</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/constrast-learning/"><span class="level-start"><span class="level-item">constrast learning</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/data-augmentation/"><span class="level-start"><span class="level-item">data augmentation</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/dialogue-system/"><span class="level-start"><span class="level-item">dialogue system</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/language-model/"><span class="level-start"><span class="level-item">language model</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/machine-translation/"><span class="level-start"><span class="level-item">machine translation</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/open-set-recognition/"><span class="level-start"><span class="level-item">open set recognition</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/sentence-embedding/"><span class="level-start"><span class="level-item">sentence embedding</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/text-matching/"><span class="level-start"><span class="level-item">text matching</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/vision-language/"><span class="level-start"><span class="level-item">vision-language</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li></ul></div></div></div></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/panxiaoxie.png" alt="潘小榭" height="28"></a><p class="is-size-7"><span>&copy; 2021 Xie Pan</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("zh-CN");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="回到顶端" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "此网站使用Cookie来改善您的体验。",
          dismiss: "知道了！",
          allow: "允许使用Cookie",
          deny: "拒绝",
          link: "了解更多",
          policy: "Cookie政策",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.5/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="想要查找什么..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"想要查找什么...","untitled":"(无标题)","posts":"文章","pages":"页面","categories":"分类","tags":"标签"});
        });</script></body></html>