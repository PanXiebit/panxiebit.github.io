<!doctype html>
<html lang="zh"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>潘小榭</title><link rel="manifest" href="/manifest.json"><meta name="theme-color" content="black"><meta name="application-name" content="panxiaoxie"><meta name="msapplication-TileImage" content="/img/avatar.png"><meta name="msapplication-TileColor" content="black"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="panxiaoxie"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta property="og:type" content="blog"><meta property="og:title" content="panxiaoxie"><meta property="og:url" content="https://github.com/PanXiebit"><meta property="og:site_name" content="panxiaoxie"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://www.qt86.com/cache/1625298592_187938.png"><meta property="article:author" content="panxiaoxie"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="https://www.qt86.com/cache/1625298592_187938.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"http://www.panxiaoxie.cn"},"headline":"潘小榭","image":["http://www.panxiaoxie.cn/img/og_image.png"],"author":{"@type":"Person","name":"Xie Pan"},"publisher":{"@type":"Organization","name":"潘小榭","logo":{"@type":"ImageObject","url":"http://www.panxiaoxie.cn/img/panxiaoxie.png"}},"description":null}</script><link rel="icon" href="/img/avatar.png"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/css/justifiedGallery.min.css"><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script><!--!--><!--!--><meta name="generator" content="Hexo 5.4.0"></head><body class="is-2-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/panxiaoxie.png" alt="潘小榭" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">主页</a><a class="navbar-item" href="/archives">归档</a><a class="navbar-item" href="/categories">分类</a><a class="navbar-item" href="/tags">标签</a><a class="navbar-item" href="/about">关于我</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/PanXiebit"><i class="fab fa-github"></i></a><a class="navbar-item search" title="搜索" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-10-widescreen"><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2018-12-19T01:22:32.000Z" title="2018/12/19 上午9:22:32">2018-12-19</time>发表</span><span class="level-item"><time dateTime="2021-06-29T08:12:08.539Z" title="2021/6/29 下午4:12:08">2021-06-29</time>更新</span><span class="level-item"><a class="link-muted" href="/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/">数据结构与算法</a></span><span class="level-item">17 分钟读完 (大约2496个字)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2018/12/19/%E9%82%93%E5%85%AC%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%951-%E7%AE%97%E6%B3%95%E5%88%86%E6%9E%90/">邓公数据结构与算法1-算法分析</a></h1><div class="content"><ul>
<li><p>算法分析  </p>
</li>
<li><p>迭代、递归  </p>
</li>
<li><p>动态规划</p>
</li>
</ul>
<h2 id="算法分析"><a href="#算法分析" class="headerlink" title="算法分析"></a>算法分析</h2><ul>
<li><p>级数的大 O 分析  </p>
</li>
<li><p>循环 vs 级数</p>
</li>
</ul>
<h3 id="非极端元素-冒泡排序"><a href="#非极端元素-冒泡排序" class="headerlink" title="非极端元素+冒泡排序"></a>非极端元素+冒泡排序</h3><p><img src="/2018/12/19/%E9%82%93%E5%85%AC%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%951-%E7%AE%97%E6%B3%95%E5%88%86%E6%9E%90/05.png"></p>
<p>算法分析：</p>
<p><img src="/2018/12/19/%E9%82%93%E5%85%AC%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%951-%E7%AE%97%E6%B3%95%E5%88%86%E6%9E%90/06.png"></p>
<p>通过挖掘算法中的不变性、单调性，进而证明正确性是算法分析的重要技巧。</p>
<h2 id="迭代与递归"><a href="#迭代与递归" class="headerlink" title="迭代与递归"></a>迭代与递归</h2><h3 id="减而治之-decrease-and-conquer"><a href="#减而治之-decrease-and-conquer" class="headerlink" title="减而治之 (decrease and conquer)"></a>减而治之 (decrease and conquer)</h3><p>求解一个大规模问题，可以将其划分为两个子问题，一个 naive，一个规模缩减。</p>
<p>算法分析：线性递归，使用递归跟踪，仅使用于简明的递归</p>
<h4 id="example-颠倒数组"><a href="#example-颠倒数组" class="headerlink" title="example: 颠倒数组"></a>example: 颠倒数组</h4><p>任意给定数组 A[0, n), 将其中的子区间 A[lo, hi] 颠倒</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">reverse</span> <span class="params">(<span class="keyword">int</span>* A, <span class="keyword">int</span> lo, <span class="keyword">int</span> hi)</span></span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (lo &lt; hi)</span><br><span class="line"></span><br><span class="line">  &#123;</span><br><span class="line"></span><br><span class="line">    swap (A[lo], A[hi]);</span><br><span class="line"></span><br><span class="line">    reverse (A, lo++, hi--)</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>迭代：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">reverse</span> <span class="params">(<span class="keyword">int</span>* A, <span class="keyword">int</span> lo, <span class="keyword">int</span> hi)</span></span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">while</span>(lo &lt; hi)</span><br><span class="line"></span><br><span class="line">  &#123;</span><br><span class="line"></span><br><span class="line">    swap(A[lo--], A[hi++])</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h3 id="分而治之-divide-and-conquer"><a href="#分而治之-divide-and-conquer" class="headerlink" title="分而治之 (divide and conquer)"></a>分而治之 (divide and conquer)</h3><p>求解一个大规模问题，可以将其划分为两个子问题，规模大体相当。  </p>
<p>分别求解子问题  </p>
<p>由子问题的解，得到原问题的解。</p>
<h4 id="Example：-MAX2，二分递归"><a href="#Example：-MAX2，二分递归" class="headerlink" title="Example： MAX2，二分递归"></a>Example： MAX2，二分递归</h4><p>从数组区间 A[lo,hi] 中找出最大的两个整数。</p>
<p><strong>迭代解法</strong>  </p>
<p>遍历整个数组，分别与 x1, x2 比较。</p>
<p><img src="/2018/12/19/%E9%82%93%E5%85%AC%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%951-%E7%AE%97%E6%B3%95%E5%88%86%E6%9E%90/10.png"></p>
<p>每迭代一次，比较 1/2 次。O(2n-3).</p>
<p><strong>递归+分治解法</strong>  </p>
<p>分而治之：  </p>
<p><img src="/2018/12/19/%E9%82%93%E5%85%AC%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%951-%E7%AE%97%E6%B3%95%E5%88%86%E6%9E%90/15.png"></p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">max2</span><span class="params">(<span class="keyword">int</span> A[], <span class="keyword">int</span> lo, <span class="keyword">int</span> hi, <span class="keyword">int</span> x1, <span class="keyword">int</span> x2)</span></span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 递归基, 总共只有 3个/4个 元素</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (lo + <span class="number">2</span> == hi) &#123;* ... * ; <span class="keyword">return</span>;&#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (lo + <span class="number">3</span> == hi) &#123;* ... * ; <span class="keyword">return</span>;&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  <span class="comment">// 递归过程，分为两组，两边至少2个元素  </span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">int</span> mi = (lo + hi)/<span class="number">2</span>;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  <span class="comment">// 递归</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">int</span> x1L, x2L;</span><br><span class="line"></span><br><span class="line">  max2(A, lo, mi, x1L, x2L);</span><br><span class="line"></span><br><span class="line">  <span class="keyword">int</span> x1R, x2R;</span><br><span class="line"></span><br><span class="line">  max2(A, mi, hi, x1R, x2R);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  <span class="comment">// 每个递归实例所需操作</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (A[x1L] &gt; A[x1R])</span><br><span class="line"></span><br><span class="line">  &#123;</span><br><span class="line"></span><br><span class="line">    x1 = x1L;</span><br><span class="line"></span><br><span class="line">    x2 = (A[x2L] &gt; A[x1R]) ? x2L : x1R;</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">else</span></span><br><span class="line"></span><br><span class="line">  &#123;</span><br><span class="line"></span><br><span class="line">    x1 = x1R;</span><br><span class="line"></span><br><span class="line">    x2 = (A[x1L] &gt; A[x2R]) ? x1L : x2R;</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="动态规划"><a href="#动态规划" class="headerlink" title="动态规划"></a>动态规划</h2><h3 id="记忆法：example-Fabonacci"><a href="#记忆法：example-Fabonacci" class="headerlink" title="记忆法：example Fabonacci"></a>记忆法：example Fabonacci</h3><p>$$fib(n)=fib(n-1)+fib(n-2)$$</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">fib</span><span class="params">(n)</span></span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> (<span class="number">2</span> &gt; n) ? n : fib(n<span class="number">-1</span>) + fib(n<span class="number">-2</span>);</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<p>速度很慢很慢！ 因为大量的递归实例被重复的调用。</p>
<p><img src="/2018/12/19/%E9%82%93%E5%85%AC%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%951-%E7%AE%97%E6%B3%95%E5%88%86%E6%9E%90/11.png"></p>
<p>解决方法：  </p>
<ul>
<li><p>记忆，通过制表，避免重复调用  </p>
</li>
<li><p>动态规划：颠倒计算方向，自顶而下递归，转换为自底而上迭代</p>
</li>
</ul>
<p>这个可以类比上台阶，每一步可以是 1 或 2 级台阶。  </p>
<p>那么走到第 n 级台阶的方式是 第 n-1 阶 和 第n-2 阶的方式之和。  </p>
<p><img src="/2018/12/19/%E9%82%93%E5%85%AC%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%951-%E7%AE%97%E6%B3%95%E5%88%86%E6%9E%90/12.png"></p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">f = <span class="number">1</span>; g = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span>( <span class="number">0</span> &lt; n-- )</span><br><span class="line"></span><br><span class="line">&#123;</span><br><span class="line"></span><br><span class="line">  g = g + f;</span><br><span class="line"></span><br><span class="line">  f = g - f;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> g;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>不断的从下而上的更新 g, f.</p>
<h3 id="example-LCS-longest-common-sequence"><a href="#example-LCS-longest-common-sequence" class="headerlink" title="example: LCS (longest common sequence)"></a>example: LCS (longest common sequence)</h3><p>题目详情（子序列不同于子串，子序列可以是不连续的）：  </p>
<p><img src="/2018/12/19/%E9%82%93%E5%85%AC%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%951-%E7%AE%97%E6%B3%95%E5%88%86%E6%9E%90/13.png"></p>
<p>思考：从递归的角度去想，缩小规模无非是 分而治之 和 减而治之。</p>
<p>将规模缩小，A[0, n], B[0, m], LCS[A, B] 只有三种情况：  </p>
<ul>
<li><p>n=-1 或 m=-1, 则为空  </p>
</li>
<li><p>A[n] = B[m] = “X”, 减而治之，同时缩小两个字串 LCS(A[0, n-1], B[0, m-1]) + “X”  </p>
</li>
<li><p>$A[n] \ne B[m]$, 分而治之，LCS(A[0, n-1], B[0,m]) 和 LCS(A[0, n],B[0, m-1]) 中的较大值。</p>
</li>
</ul>
<p><img src="/2018/12/19/%E9%82%93%E5%85%AC%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%951-%E7%AE%97%E6%B3%95%E5%88%86%E6%9E%90/14.png"></p>
<p><img src="/2018/12/19/%E9%82%93%E5%85%AC%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%951-%E7%AE%97%E6%B3%95%E5%88%86%E6%9E%90/16.png"></p>
<p>分析算法的可行性：  </p>
<p><img src="/2018/12/19/%E9%82%93%E5%85%AC%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%951-%E7%AE%97%E6%B3%95%E5%88%86%E6%9E%90/18.png"></p>
<p>解决这种递归实例反复调用的方法：  </p>
<ul>
<li><p>将所有子问题列成一张表  </p>
</li>
<li><p>颠倒计算方向，从 LCS(A[0], B[0]) 依次计算所有项。</p>
</li>
</ul>
<p>从上图可以很清楚的明白制表的过程，每一个递归实例都可能被反复的经过。  </p>
<p>比如： $A[n] \ne B[m]$. 那么分为两条路径： LCS(A[0, n-1], B[0,m]) 和 LCS(A[0, n],B[0, m-1]). 这两个的计算都需要计算 LCS(A[0, n-1], B[0,m-1]), 所以会造成重复计算。</p>
<p><strong>所以如何制表呢？</strong>  </p>
<p>递归公式， 用 $C[i,j]$ 来表示表格中 $[A_i, B_j]$ 处的长度。</p>
<p><img src="/2018/12/19/%E9%82%93%E5%85%AC%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%951-%E7%AE%97%E6%B3%95%E5%88%86%E6%9E%90/20.png"></p>
<p>具体填表的过程参考： <a target="_blank" rel="noopener" href="https://blog.csdn.net/hrn1216/article/details/51534607">https://blog.csdn.net/hrn1216/article/details/51534607</a></p>
<p>想清楚表格的物理意义： 可以看作某一个序列固定（列），然后逐渐增加另一个序列的长度（行），也就是逐渐填入行。  </p>
<p>初始的情况也要想清楚，某一个序列长度为 0 时，公共序列肯定也为 0。</p>
<p>$m\times n$ 的表格  </p>
<p><img src="/2018/12/19/%E9%82%93%E5%85%AC%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%951-%E7%AE%97%E6%B3%95%E5%88%86%E6%9E%90/21.jpeg"></p>
<p>初始化， i=0 或 j=0</p>
<p><img src="/2018/12/19/%E9%82%93%E5%85%AC%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%951-%E7%AE%97%E6%B3%95%E5%88%86%E6%9E%90/22.jpeg"></p>
<ul>
<li><p>先填入第一行，一个字符为 “3”，没有与之相同的字符，所有这一行都为 0.  </p>
</li>
<li><p>再填入第二行，填 [2,1] 处，都为3，C[2,1]=C[1,1]+1，然后按照递归公式走下去。</p>
</li>
</ul>
<p><img src="/2018/12/19/%E9%82%93%E5%85%AC%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%951-%E7%AE%97%E6%B3%95%E5%88%86%E6%9E%90/23.jpeg"></p>
<p>第二行其他空格 $A[i]\ne B[j]$，C[i,j]=max(C[i-1,j], C[i, j-1])  </p>
<p><img src="/2018/12/19/%E9%82%93%E5%85%AC%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%951-%E7%AE%97%E6%B3%95%E5%88%86%E6%9E%90/24.jpeg"></p>
<p><img src="/2018/12/19/%E9%82%93%E5%85%AC%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%951-%E7%AE%97%E6%B3%95%E5%88%86%E6%9E%90/25.jpeg"></p>
<p><img src="/2018/12/19/%E9%82%93%E5%85%AC%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%951-%E7%AE%97%E6%B3%95%E5%88%86%E6%9E%90/26.jpeg"></p>
<p><img src="/2018/12/19/%E9%82%93%E5%85%AC%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%951-%E7%AE%97%E6%B3%95%E5%88%86%E6%9E%90/27.jpeg"></p>
<p><strong>回溯构造 LCS</strong>  </p>
<p>我们根据递归公式构建了上表，我们将从最后一个元素c[8][9]倒推出S1和S2的LCS。</p>
<ul>
<li><p>C[8, 9] = 5，且$S_1[8] \ne S_2[9]$，所以倒推回去，C[8,9]的值来源于 C[8,8]的值(因为C[8,8] &gt; c[7,9])  </p>
</li>
<li><p>C[8, 8] = 5,  且 $S_1[8] = S_2[8]$, 所以倒推回去，C[8,8]的值来源于 C[7, 7]。  </p>
</li>
<li><p>可能会出现分歧的情况，$S_1[i] \ne S_2[j]$, 且 C[i-1,j]=C[i, j-1]. 这个时候选择一个方向。</p>
</li>
</ul>
<p>两种结果：</p>
<p><img src="/2018/12/19/%E9%82%93%E5%85%AC%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%951-%E7%AE%97%E6%B3%95%E5%88%86%E6%9E%90/28.jpeg"></p>
<p>分歧处选择另一个方向。  </p>
<p><img src="/2018/12/19/%E9%82%93%E5%85%AC%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%951-%E7%AE%97%E6%B3%95%E5%88%86%E6%9E%90/29.jpeg"></p>
<p><strong>时间复杂度分析</strong>： 构建表格需要 O(mn), 回溯输出一个 LCS 需要 O(m+n)</p>
<h2 id="leetcode-300-Longest-increasing-sequence"><a href="#leetcode-300-Longest-increasing-sequence" class="headerlink" title="leetcode 300. Longest increasing sequence"></a>leetcode 300. Longest increasing sequence</h2><p>Given an unsorted array of integers, find the length of longest increasing subsequence.</p>
<p>Example:</p>
<p>Input: [10,9,2,5,3,7,101,18]</p>
<p>Output: 4</p>
<p>Explanation: The longest increasing subsequence is [2,3,7,101], therefore the length is 4.</p>
<p>Note:</p>
<p>There may be more than one LIS combination, it is only necessary for you to return the length.</p>
<p>Your algorithm should run in O(n2) complexity.</p>
<p>Follow up: Could you improve it to O(n log n) time complexity?</p>
<h3 id="Brute-Force-Time-Limit-Exceeded-recursive"><a href="#Brute-Force-Time-Limit-Exceeded-recursive" class="headerlink" title="Brute Force [Time Limit Exceeded]: recursive"></a>Brute Force [Time Limit Exceeded]: recursive</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">lenofLIS</span><span class="params">(vector&lt;<span class="keyword">int</span>&gt; &amp;nums, <span class="keyword">int</span> prev, <span class="keyword">int</span> curpos)</span></span>;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">lengthOfLIS</span><span class="params">(vector&lt;<span class="keyword">int</span>&gt;&amp; nums)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">lenofLIS</span>(nums, INT_MIN, <span class="number">0</span>);</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">lenofLIS</span><span class="params">(vector&lt;<span class="keyword">int</span>&gt; &amp;nums, <span class="keyword">int</span> prev, <span class="keyword">int</span> curpos)</span></span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (curpos == nums.<span class="built_in">size</span>())</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">int</span> taken = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (nums[curpos] &gt; prev)</span><br><span class="line"></span><br><span class="line">        taken = <span class="number">1</span> + <span class="built_in">lenofLIS</span>(nums, nums[curpos], curpos+<span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">int</span> notaken = <span class="built_in">lenofLIS</span>(nums, prev, curpos+<span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">max</span>(taken, notaken);</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<p>时间复杂度分析：  </p>
<p>数组中每一个位置都可能出现或者不出现在 LIS 中，也就是说每一个递归实例的操作是 2，所以最终时间复杂度是 $O(2^n)$</p>
<p>空间复杂度分析：$O(n^2)$</p>
<h3 id="Recursion-with-memorization-Memory-Limit-Exceeded"><a href="#Recursion-with-memorization-Memory-Limit-Exceeded" class="headerlink" title="Recursion with memorization [Memory Limit Exceeded]"></a>Recursion with memorization [Memory Limit Exceeded]</h3><p>解决上面这种递归实例反复调用的问题，通常有两种方法，在上面学习中也说到了。这里先采用记忆法，将所有子问题列成一张表。</p>
<h3 id="Dynamic-Programming-Accepted"><a href="#Dynamic-Programming-Accepted" class="headerlink" title="Dynamic Programming [Accepted]"></a>Dynamic Programming [Accepted]</h3><p>参考： <a target="_blank" rel="noopener" href="https://www.geeksforgeeks.org/longest-increasing-subsequence-dp-3/">https://www.geeksforgeeks.org/longest-increasing-subsequence-dp-3/</a></p>
<p>Optimal Substructure:</p>
<p>Let arr[0..n-1] be the input array and L(i) be the length of the LIS ending at index i such that arr[i] is the last element of the LIS.  </p>
<p>Then, L(i) can be recursively written as:</p>
<p>L(i) = 1 + max( L(j) ) where 0 &lt; j &lt; i and arr[j] &lt; arr[i]; or</p>
<p>L(i) = 1, if no such j exists.</p>
<p>To find the LIS for a given array, we need to return max(L(i)) where 0 &lt; i &lt; n.</p>
<p>Thus, we see the LIS problem satisfies the optimal substructure property as the main problem can be solved using solutions to subproblems.</p>
<p>Following is a simple recursive implementation of the LIS problem. It follows the recursive structure discussed above.</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">lenofLIS</span><span class="params">(vector&lt;<span class="keyword">int</span>&gt; &amp;nums, <span class="keyword">int</span> prev, <span class="keyword">int</span> curpos)</span></span>;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">lengthOfLIS</span><span class="params">(vector&lt;<span class="keyword">int</span>&gt;&amp; nums)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (nums.<span class="built_in">size</span>() == <span class="number">0</span>) <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">int</span> dp[nums.<span class="built_in">size</span>()];</span><br><span class="line"></span><br><span class="line">        dp[<span class="number">0</span>] = <span class="number">1</span>;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i=<span class="number">1</span>; i&lt; nums.<span class="built_in">size</span>(); i++)&#123;</span><br><span class="line"></span><br><span class="line">            dp[i] = <span class="number">1</span>;</span><br><span class="line"></span><br><span class="line">            <span class="keyword">for</span> (<span class="keyword">int</span> j=<span class="number">0</span>; j &lt; i; j++)&#123;</span><br><span class="line"></span><br><span class="line">                <span class="keyword">if</span> (nums[i] &gt; nums[j] &amp;&amp; dp[i] &lt; dp[j]+<span class="number">1</span>)&#123;</span><br><span class="line"></span><br><span class="line">                    dp[i] = dp[j] + <span class="number">1</span>;</span><br><span class="line"></span><br><span class="line">                &#125;</span><br><span class="line"></span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> *<span class="built_in">max_element</span>(dp, dp+nums.<span class="built_in">size</span>());</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>复杂度分析：  </p>
<p>Time complexity: $O(n^2)$  Two loops of n.</p>
<p>Space complexity: $O(n)$ dp array size n is used.</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>再回过头思考下动态规划的含义：</p>
<p>动态规划常常适用于有重叠子问题[1]和最优子结构性质的问题，动态规划方法所耗时间往往远少于朴素解法。</p>
<p>动态规划背后的基本思想非常简单。大致上，若要解一个给定问题，我们需要解其不同部分（即子问题），再根据子问题的解以得出原问题的解。</p>
<p>通常许多子问题非常相似，为此动态规划法试图仅仅解决每个子问题一次，从而减少计算量：一旦某个给定子问题的解已经算出，则将其记忆化存储，以便下次需要同一个子问题解之时直接查表。这种做法在重复子问题的数目关于输入的规模呈指数增长时特别有用。</p>
<p>对于 longest increasing subsequence 里面就存在最有子问题。对于一个序列，每增加一个元素，都可以看作一个子问题。</p>
<p>子问题的解是固定的，但是子问题与当前步的结合又是动态变化的。比如这里，当前 i 位置的值大于 j 的值和小于 j 的值的处理方式就不太一样。我们要做的就是找出这个规律 <strong>（递推公式）</strong>，然后根据填写好的子问题的解的表格，进一步扩大问题规模。</p>
<p>所以如前面所说，动态规划：自顶而下递归，自底而上迭代。</p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2018-12-19T00:35:58.000Z" title="2018/12/19 上午8:35:58">2018-12-19</time>发表</span><span class="level-item"><time dateTime="2021-06-29T08:12:08.539Z" title="2021/6/29 下午4:12:08">2021-06-29</time>更新</span><span class="level-item"><a class="link-muted" href="/categories/NLP/">NLP</a></span><span class="level-item">8 分钟读完 (大约1186个字)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2018/12/19/AI-challenger-%E5%8F%82%E4%BC%9A%E8%AE%B0%E5%BD%95/">AI challenger 参会记录</a></h1><div class="content"><p>答辩听了观点型阅读理解和细粒度情感分类两个，相对来说后者更加干货满满，大佬云集的，基本上代表了国内 NLP 的四座大山，清/北/中科院/哈工大。造成前者干货较少的主要原因作为主持人的搜狗大佬也说了， BERT 的提出在阅读理解这样更加需要上下文理解任务的提升实在太多，使得选手的其它工作都黯然失色，导致大家的模型都趋向同一化。而 BERT 对于分类任务的提升就相对较少了，所以下午的答辩显得更加丰富，各种操作和 trick. 但也有选手说 BERT 作为单模型对这个分类任务依然能取得很不错的效果，所以 BERT 是真强啊</p>
<p>因为答辩的屏幕是真小，根本看不清楚。。所以记录会很零散，也许只是些关键词，后续还需要自行 google.</p>
<h2 id="观点型阅读理解"><a href="#观点型阅读理解" class="headerlink" title="观点型阅读理解"></a>观点型阅读理解</h2><p><img src="/2018/12/19/AI-challenger-%E5%8F%82%E4%BC%9A%E8%AE%B0%E5%BD%95/01.png"></p>
<p>取得好成绩的主要操作： 通过简单的正则匹配将三个观点转化为作为 “正/负/无法确定” 的三分类问题。训练集中 95% 的数据可以很准确的转化为这种形式，还有 5% 的是实体类问题，比如 “韩国/美国/无法确定”，有选手的做法是将 query 中对两个实体进行排序，比如韩国在前，美国在后。同样对应的 answer 就是 “韩国/美国/无法确定”. 将文本理解的问题，转换为分类问题之后，对整个模型的复杂度需求就降低太多了。但事实上，这是数据 bug …</p>
<p>模型关键词：  </p>
<ul>
<li>BERT  </li>
</ul>
<ul>
<li>multiway attention + R-Net</li>
</ul>
<ul>
<li>RCZoo  </li>
</ul>
<ul>
<li>浙大大佬的：多层 LSTM 模型，浅层+主要+深层 三个 loss 优化。具体忘了拍照，以及真的看不清楚。。  </li>
</ul>
<ul>
<li>基于 query 的 attention 还是基于 passage 的 attention 作为最终的 answer selection/matching.</li>
</ul>
<p>说句不马后炮的话，这里面大部分我也都想到了啊，只是做与没做，以及用与没用 BERT 。。。</p>
<h2 id="细粒度用户评论情感分析"><a href="#细粒度用户评论情感分析" class="headerlink" title="细粒度用户评论情感分析"></a>细粒度用户评论情感分析</h2><p><img src="/2018/12/19/AI-challenger-%E5%8F%82%E4%BC%9A%E8%AE%B0%E5%BD%95/02.png"></p>
<p><img src="/2018/12/19/AI-challenger-%E5%8F%82%E4%BC%9A%E8%AE%B0%E5%BD%95/03.png"></p>
<h3 id="seq2seq"><a href="#seq2seq" class="headerlink" title="seq2seq"></a>seq2seq</h3><p><img src="/2018/12/19/AI-challenger-%E5%8F%82%E4%BC%9A%E8%AE%B0%E5%BD%95/05.jpeg"></p>
<p>选手这么做的原因是 他觉得各个 粒度 之间存在一定的关联，所以采用 decoder 的形式能有效的利用这些信息。很神奇的操作，是否真的有效朱小燕老师有问到，好像作者并没有做对照实验。</p>
<p><img src="/2018/12/19/AI-challenger-%E5%8F%82%E4%BC%9A%E8%AE%B0%E5%BD%95/06.jpeg"></p>
<ul>
<li>ELMo 提升最多  </li>
</ul>
<ul>
<li>改进的注意力机制，其实就是 multi-head attention  </li>
</ul>
<ul>
<li><strong>PRAUC 损失函数，</strong> 这个我好像在哪儿见过，我不记得了  </li>
</ul>
<p><img src="/2018/12/19/AI-challenger-%E5%8F%82%E4%BC%9A%E8%AE%B0%E5%BD%95/07.jpeg">  </p>
<p>大佬感觉可以发 paper 了。。</p>
<h3 id="others"><a href="#others" class="headerlink" title="others"></a>others</h3><p>其他的也很强，但没有 seq2seq 这么具有特殊性，所以可以一起说。  </p>
<p><img src="/2018/12/19/AI-challenger-%E5%8F%82%E4%BC%9A%E8%AE%B0%E5%BD%95/08.jpeg"></p>
<p>词嵌入部分微调，没太懂？ 哪一部分微调，以及非监督的情况下，如何保证微调的程度</p>
<p><img src="/2018/12/19/AI-challenger-%E5%8F%82%E4%BC%9A%E8%AE%B0%E5%BD%95/09.jpeg"></p>
<p>F1 指标的优化，这个对于 unbalanced 数据看起来比 过/欠 采样有效。以及刘洋老师提到的可以基于 rainforce 对 F1 进行优化</p>
<p>附上刘洋老师照片一张，侧脸看起来真像李健啊，都是清华男神吧～</p>
<p><img src="/2018/12/19/AI-challenger-%E5%8F%82%E4%BC%9A%E8%AE%B0%E5%BD%95/10.jpeg"></p>
<p><img src="/2018/12/19/AI-challenger-%E5%8F%82%E4%BC%9A%E8%AE%B0%E5%BD%95/11.jpeg"></p>
<p>伪朴素贝叶斯特征，PPT 里面说的很清楚～每次输入几个样本其提取的是局部特征，而伪朴素贝叶斯特征能体现一个词的全局特征。感觉很棒啊</p>
<p><img src="/2018/12/19/AI-challenger-%E5%8F%82%E4%BC%9A%E8%AE%B0%E5%BD%95/12.jpeg"></p>
<p>数据增强方式：  </p>
<ul>
<li>drop words 随机 mask  </li>
</ul>
<ul>
<li>shuffle words  打乱词序  </li>
</ul>
<ul>
<li>组合增强策略  </li>
</ul>
<ul>
<li>对抗训练  </li>
</ul>
<p><img src="/2018/12/19/AI-challenger-%E5%8F%82%E4%BC%9A%E8%AE%B0%E5%BD%95/13.jpeg"></p>
<p>模型集成：</p>
<ul>
<li>贪婪式模型选择  </li>
</ul>
<ul>
<li>简单概率平均，最后采取了这种。。。anyway</li>
</ul>
<p><img src="/2018/12/19/AI-challenger-%E5%8F%82%E4%BC%9A%E8%AE%B0%E5%BD%95/15.jpeg"></p>
<p>根据验证集调整分类阈值，对当前的验证集当然会有较大提升。但是对于 测试集 可能出现过拟合，引入正则化和 Ensamble 策略。</p>
<p>$$b_i^j=\text{argmax}_b[\text{marco-}F_1(S^j[:,i]+b)-C|b]$$</p>
<p>第 j 个情感要素第 i 类别上的偏置， C&gt;0 为正则系数。</p>
<p>还有些关键词，有些来不及拍照。。  </p>
<ul>
<li>BiSRU  </li>
</ul>
<ul>
<li>未完待续。。</li>
</ul>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2018-12-17T06:50:31.000Z" title="2018/12/17 下午2:50:31">2018-12-17</time>发表</span><span class="level-item"><time dateTime="2021-06-29T08:12:09.158Z" title="2021/6/29 下午4:12:09">2021-06-29</time>更新</span><span class="level-item"><a class="link-muted" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/">论文笔记</a><span> / </span><a class="link-muted" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/language-model/">language model</a></span><span class="level-item">21 分钟读完 (大约3119个字)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2018/12/17/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/">论文笔记-BERT</a></h1><div class="content"><h2 id="BERT-Bidirectional-Encoder-Representations-from-Transformers"><a href="#BERT-Bidirectional-Encoder-Representations-from-Transformers" class="headerlink" title="BERT(Bidirectional Encoder Representations from Transformers.)"></a>BERT(Bidirectional Encoder Representations from Transformers.)</h2><p>对于 BERT 重点在于理解 Bidirectional 和 masked language model.</p>
<h3 id="Why-Bidirectional"><a href="#Why-Bidirectional" class="headerlink" title="Why Bidirectional?"></a>Why Bidirectional?</h3><p>对于预训练的表示，单向语言模型因为无法融合下文的信息，其能力是非常有限的，尤其是对类似于 SQuAD 这样需要结合上下文信息的任务。</p>
<p>对比 OpenAI GPT 和 BERT. 为什么 OpenAI GPT 不能采用双向 self-attention 呢？</p>
<p>传统的语言模型的定义，计算句子的概率：</p>
<p>$$P(S)=p(w_1,w_2, …, w_n)=p(w1)p(w_2|w_1)…p(w_n|w_1…w_{n-1})=\prod_{i=1}^m p(w_i|w_1…w_{i-1})$$</p>
<p>前向 RNN 语言模型：</p>
<p>$$P(S)=\prod_{i=1}^m p(w_i|w_1…w_{i-1})$$</p>
<p>也就是当前词的概率只依赖前面出现词的概率。</p>
<p>后向 RNN 语言模型  </p>
<p>$$P(S)=\prod_{i=1}^m p(w_i|w_{i+1}…w_{m})$$</p>
<p>也就是当前词的概率只依赖后面出现的词的概率。</p>
<p>ELMo 就是这样的双向语言模型(BiLM)</p>
<p><img src="/2018/12/17/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/02.jpg"></p>
<p>但是 RNN 相比 self-attention 对上下文信息 (contextual information)的利用相对有限，而且 ELMo 只能是一层双向，并不能使用多层。其原因和 GPT 无法使用 双向 编码的原因一样。</p>
<p>对于 GPT 如果它使用双向，那么模型就能准确的学到到句子中的下一个词是什么，并能 100% 的预测出下一个词。比如 “I love to work on NLP.” 在预测 love 的下一个词时，模型能看到 to，所以能很快的通过迭代学习到 “to” 100% 就是 love 的下一个词。所以，这导致模型并不能学到想要的东西（句法、语义信息）。</p>
<p><img src="/2018/12/17/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/03.png"> <img src="/2018/12/17/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/04.png"></p>
<p>那么 BERT 是怎么处理双向这个问题的呢？ 它改变了训练语言模型的任务形式。提出了两种方式 “masked language model” and “next sentence generation”. 再介绍这两种训练方式之前，先说明下输入形式。</p>
<h3 id="Input-representation"><a href="#Input-representation" class="headerlink" title="Input representation"></a>Input representation</h3><p><img src="/2018/12/17/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/05.png"></p>
<ul>
<li><p>position embedding: 跟 Transformer 类似    </p>
</li>
<li><p>sentence embedding, 同一个句子的词的表示一样，都是 $E_A$ 或 $E_B$. 用来表示不同的句子具有不同的含义  </p>
</li>
<li><p>对于 [Question, Answer] 这样的 sentence-pairs 的任务，在句子末尾加上 [SEP].  </p>
</li>
<li><p>对于文本分类这样的 single-sentence 的任务，只需要加上 [CLS], 并且 sentence embedding 只有 $E_A$.</p>
</li>
</ul>
<h3 id="masked-language-model"><a href="#masked-language-model" class="headerlink" title="masked language model"></a>masked language model</h3><p>何为 “masked LM”? idea 来源于 closed tasked. 原本的语言模型是预测所有语料中的下一个词，而 MLM 是在所有的 tokens 中随机选取 15% 的进行 mask，然后只需要预测被 mask 的词。这样以来，就能训练双向语言模型了。</p>
<p>但是存在一个问题，这样 pre-training 训练出来的语言模型并不能拿去做 fine-tune. 原因是在 fine-token 中从来没有见过 &lt;MASK&gt; 这个词。作者采用这样的策略：  </p>
<p>具体的操作，以 “My dog is hairy” 为例，mask “hairy” 这个词：</p>
<ul>
<li><p>“My dog is &lt;MASK&gt;“. 80% 被 <MASK> 代替  </MASK></p>
</li>
<li><p>“My dog is apple”.  10% 被一个随机的 token 代替  </p>
</li>
<li><p>“My dog is hairy”.  10% 保持原来的样子  </p>
</li>
</ul>
<h4 id="为什么不用-lt-MASK-gt-代替所有的-token？"><a href="#为什么不用-lt-MASK-gt-代替所有的-token？" class="headerlink" title="为什么不用 &lt;MASK&gt; 代替所有的 token？"></a>为什么不用 &lt;MASK&gt; 代替所有的 token？</h4><blockquote>
<p>If the model had been trained on only predicting ‘&lt;MASK&gt;’ tokens and then never saw this token during fine-tuning, it would have thought that there was no need to predict anything and this would have hampered performance. Furthermore, the model would have only learned a contextual representation of the ‘&lt;MASK&gt;’ token and this would have made it learn slowly (since only 15% of the input tokens are masked). By sometimes asking it to predict a word in a position that did not have a ‘&lt;MASK&gt;’ token, the model needed to learn a contextual representation of all the words in the input sentence, just in case it was asked to predict them afterwards.  </p>
</blockquote>
<p>如果模型在预训练的时候仅仅只预测 &lt;MASK&gt;, 然后在 fine-tune 的时候从未见过 &lt;MASK&gt; 这个词，那么模型就不需要预测任何词，在 fine-tune 时会影响性能。  </p>
<p>更严重的是，如果仅仅预测 &lt;MASK&gt;, 那么模型只需要学习 &lt;MASK&gt; 的上下文表示，这会导致它学习的很慢。  </p>
<p>如果让模型在某个位置去预测一个不是 &lt;MASK&gt; 的词，那么模型就需要学习所有 tokens 的上下文表示，因为万一需要预测这个词呢。</p>
<h4 id="只需要-random-tokens-足够吗？为什么还需要-10-的完整的-sentence"><a href="#只需要-random-tokens-足够吗？为什么还需要-10-的完整的-sentence" class="headerlink" title="只需要 random tokens 足够吗？为什么还需要 10% 的完整的 sentence?"></a>只需要 random tokens 足够吗？为什么还需要 10% 的完整的 sentence?</h4><blockquote>
<p>Well, ideally we want the model’s representation of the masked token to be better than random. By sometimes keeping the sentence intact (while still asking the model to predict the chosen token) the authors biased the model to learn a meaningful representation of the masked tokens.  </p>
</blockquote>
<p>使得模型具有偏置，更倾向于获得有意义的 masked token.</p>
<p>在知乎上问了这个问题，大佬的回复跟这篇 blog 有点差异，但实际上意思是一样的：  </p>
<p><img src="/2018/12/17/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/11.png"></p>
<p><img src="/2018/12/17/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/10.png"></p>
<p>总结下：  </p>
<p>为什么不能完全只有 &lt;MASK&gt; ?  如果只有 &lt;MASK&gt;, 那么这个预训练模型是有偏置的，也就是学到一种方式，用上下文去预测一个词。这导致在 fine-tune 时，会丢一部分信息，也就是知乎大佬第一部分所说的。</p>
<p>所以加上 random 和 ture token 是让模型知道，每个词都是有意义的，除了上下文信息，还要用到它本身的信息，即使是 &lt;MASK&gt;. 也就是知乎上说的，提取这两方面的信息。</p>
<p>再回过头，从语言模型的角度来看，依然是需要预测每一个词，但是绝大多数词它的 cross entropy loss 会很小，而主要去优化得到 &lt;MASK&gt; 对应的词。而 random/true token 告诉模型，你需要提防每一个词，他们也需要好好预测，因为他们不一定就是对的。</p>
<p>感谢知乎大佬！</p>
<h4 id="random-tokens-会-confuse-模型吗？"><a href="#random-tokens-会-confuse-模型吗？" class="headerlink" title="random tokens 会 confuse 模型吗？"></a>random tokens 会 confuse 模型吗？</h4><p>不会， random tokens 只占 15% * 10% = 1.5%. 这不会影响模型的性能。</p>
<p>还有一个问题， &lt;MASK&gt; 所占的比例很小，主要优化对象迭代一次对整个模型影响会很小，因而需要更多次迭代.</p>
<h3 id="next-sentence-generation"><a href="#next-sentence-generation" class="headerlink" title="next sentence generation"></a>next sentence generation</h3><p>对于下游是 Question Answering(QA), Natural Language Inference(NLI) 这样需要理解句子之间的相关性的任务，仅仅通过语言模型并不能获得这方面的信息。为了让模型能够理解句子之间的关系，作者提出了一个 binarized next sentence prediction.</p>
<p>具体方式是：  </p>
<p><img src="/2018/12/17/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/06.png"></p>
<p>50% 是正确的相邻的句子。 50% 是随机选取的一个句子。这个任务在预训练中能达到 97%-98% 的准确率，并且能很显著的提高 QA NLI 的任务。</p>
<h3 id="pre-training-procudure"><a href="#pre-training-procudure" class="headerlink" title="pre-training procudure"></a>pre-training procudure</h3><p>作者预训练使用的语料：BooksCorpus (800M words)，English Wikipedia (2,500M words)。 使用文档级别的语料很关键，而不是 shffule 的句子级别的语料，这样可以获得更长的 sentence.</p>
<p>获得训练样本：从预料库中抽取句子对，其中 50% 的两个句子之间是确实相邻的，50% 的第二个句子是随机抽取的。具体操作看代码吧</p>
<ul>
<li><p>batch_size 256.  </p>
</li>
<li><p>每一个 sentences 对： 512 tokens  </p>
</li>
<li><p>40 epochs  </p>
</li>
<li><p>Adam lr=1e-4, $\beta_1=0.9$, $\beta_2=0.999$, L2 weight decay 0.01  </p>
</li>
<li><p>learning rate warmup 10000 steps  </p>
</li>
<li><p>0.1 dropout  </p>
</li>
<li><p>gelu instead of relu  </p>
</li>
</ul>
<h3 id="Fine-tune-procedure"><a href="#Fine-tune-procedure" class="headerlink" title="Fine-tune procedure"></a>Fine-tune procedure</h3><h4 id="sequence-level-tasks"><a href="#sequence-level-tasks" class="headerlink" title="sequence-level tasks"></a>sequence-level tasks</h4><ul>
<li><p>比如 sentences pairs 的 Quora Question Pairs(QQP) 预测两个句子之间语义是否相同。如下图中（a）.  </p>
</li>
<li><p>如果是 single sentence classification 比如 Stanford Sentiment Treebank（SST-2）和 Corpus of Linguistic Acceptability（CoLA）这种分类问题。如下图（b）  </p>
</li>
</ul>
<p><img src="/2018/12/17/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/07.png"></p>
<p>只需要输出 Transformer 最后一层的隐藏状态中的第一个 token，也就是 [CLS]. 然后接上一个全链接映射到相应的 label 空间即可。</p>
<p>fine-tune 时的超参数跟 pre-training 时的参数大致相同。但是训练速度会很快</p>
<ul>
<li><p>Batch size: 16, 32  </p>
</li>
<li><p>Learning rate (Adam): 5e-5, 3e-5, 2e-5  </p>
</li>
<li><p>Number of epochs: 3, 4  </p>
</li>
</ul>
<p>语料库越大，对参数的敏感度越小。  </p>
<h4 id="token-level-tasks"><a href="#token-level-tasks" class="headerlink" title="token-level tasks."></a>token-level tasks.</h4><p><img src="/2018/12/17/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/09.png"></p>
<p>对于token-level classification(例如NER)，取所有token的最后层transformer输出，喂给softmax层做分类。</p>
<h2 id="如何使用-BERT"><a href="#如何使用-BERT" class="headerlink" title="如何使用 BERT"></a>如何使用 BERT</h2><h3 id="文本分类"><a href="#文本分类" class="headerlink" title="文本分类"></a>文本分类</h3><p><a target="_blank" rel="noopener" href="https://github.com/huggingface/pytorch-pretrained-BERT/blob/master/examples/run_classifier.py">https://github.com/huggingface/pytorch-pretrained-BERT/blob/master/examples/run_classifier.py</a></p>
<p>主要涉及到两个 类:  </p>
<ul>
<li><p>数据预处理   </p>
</li>
<li><p>预训练模型加载  </p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">from</span> pytorch_pretrained_bert <span class="keyword">import</span> BertTokenizer, BertForSequenceClassification, BertConfig, BertAdam， PYTORCH_PRETRAINED_BERT_CACHE</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">tokenizer = BertTokenizer.from_pretrained(args.bert_model, do_lower_case=args.do_lower_case)</span><br><span class="line"></span><br><span class="line">tokenizer = BertTokenizer.from_pretrained(<span class="string">&quot;./pre_trained_models/bert-base-uncased-vocab.txt&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">model = BertForSequenceClassification.from_pretrained(<span class="string">&#x27;bert-base-uncased&#x27;</span>,</span><br><span class="line"></span><br><span class="line">          cache_dir=PYTORCH_PRETRAINED_BERT_CACHE / <span class="string">&#x27;distributed_&#123;&#125;&#x27;</span>.<span class="built_in">format</span>(args.local_rank),</span><br><span class="line"></span><br><span class="line">          num_labels = num_labels)</span><br><span class="line"></span><br><span class="line">model = BertForSequenceClassification.from_pretrained(<span class="string">&quot;pre_trained_models/bert-base-uncased.tar.gz&quot;</span>, num_labels=<span class="number">2</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>其中 <code>bert-base-uncased</code> 可以分别用具体的 词表文件 和 模型文件 代替。从源代码中提供的链接下载即可。</p>
<h4 id="数据处理"><a href="#数据处理" class="headerlink" title="数据处理"></a>数据处理</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">from</span> pytorch_pretrained_bert <span class="keyword">import</span> BertTokenizer, BertForSequenceClassification, BertConfig, BertAdam， PYTORCH_PRETRAINED_BERT_CACHE</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">tokenizer = BertTokenizer.from_pretrained(args.bert_model, do_lower_case=args.do_lower_case)</span><br><span class="line"></span><br><span class="line">tokenizer = BertTokenizer.from_pretrained(<span class="string">&quot;./pre_trained_models/bert-base-uncased-vocab.txt&quot;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>前一种方式是根据代码中提供的 url 去下载词表文件，然后缓存在默认文件夹下 <code>/home/panxie/.pytorch_pretrained_bert</code> 。后者是直接下载词表文件后，放在本地。相对来说，后者更方便。</p>
<p>这部分代码相对比较简单，根据自己的任务，继承 <code>DataProcessor</code> 这个类即可。</p>
<p>作为模型的输入，features 主要包括三个部分：  </p>
<ul>
<li><p>input_ids 是通过词典映射来的  </p>
</li>
<li><p>input_mask 在 fine-tune 阶段，所有的词都是 1, padding 的是 0  </p>
</li>
<li><p>segment_ids 在 text_a 中是 0, 在 text_b 中是 1, padding 的是 0  </p>
</li>
</ul>
<p>这里对应了前面所说的，input_idx 就是 token embedding, segment_ids 就是 Sentence Embedding. 而 input_mask 则表示哪些位置被 mask 了，在 fine-tune 阶段都是 1.</p>
<h4 id="加载预训练模型"><a href="#加载预训练模型" class="headerlink" title="加载预训练模型"></a>加载预训练模型</h4><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">!tar -tf pre_trained_models/bert-base-uncased.tar.gz</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">./pytorch_model.bin</span><br><span class="line"></span><br><span class="line">./bert_config.json</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>下载好的文件包中含有两个文件，分别是 config 信息，以及模型参数。</p>
<p>如果不用具体的文件，则需要从代码中提供的 url 下载，并缓存在默认文件夹 <code>PYTORCH_PRETRAINED_BERT_CACHE = /home/panxie/.pytorch_pretrained_bert</code></p>
<p>作为分类任务， num_labels 参数默认为 2.</p>
<p>运行时会发现提取预训练模型会输出如下信息：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="number">12</span>/<span class="number">26</span>/<span class="number">2018</span> <span class="number">17</span>:<span class="number">00</span>:<span class="number">41</span> - INFO - pytorch_pretrained_bert.modeling -   </span><br><span class="line"></span><br><span class="line">loading archive file pre_trained_models/bert-base-uncased.tar.gz</span><br><span class="line"></span><br><span class="line"><span class="number">12</span>/<span class="number">26</span>/<span class="number">2018</span> <span class="number">17</span>:<span class="number">00</span>:<span class="number">41</span> - INFO - pytorch_pretrained_bert.modeling -   </span><br><span class="line"></span><br><span class="line">extracting archive file pre_trained_models/bert-base-uncased.tar.gz to temp <span class="built_in">dir</span> /tmp/tmpgm506dcx</span><br><span class="line"></span><br><span class="line"><span class="number">12</span>/<span class="number">26</span>/<span class="number">2018</span> <span class="number">17</span>:<span class="number">00</span>:<span class="number">44</span> - INFO - pytorch_pretrained_bert.modeling -   </span><br><span class="line"></span><br><span class="line">Model config &#123;</span><br><span class="line"></span><br><span class="line">  <span class="string">&quot;attention_probs_dropout_prob&quot;</span>: <span class="number">0.1</span>,</span><br><span class="line"></span><br><span class="line">  <span class="string">&quot;hidden_act&quot;</span>: <span class="string">&quot;gelu&quot;</span>,</span><br><span class="line"></span><br><span class="line">  <span class="string">&quot;hidden_dropout_prob&quot;</span>: <span class="number">0.1</span>,</span><br><span class="line"></span><br><span class="line">  <span class="string">&quot;hidden_size&quot;</span>: <span class="number">768</span>,</span><br><span class="line"></span><br><span class="line">  <span class="string">&quot;initializer_range&quot;</span>: <span class="number">0.02</span>,</span><br><span class="line"></span><br><span class="line">  <span class="string">&quot;intermediate_size&quot;</span>: <span class="number">3072</span>,</span><br><span class="line"></span><br><span class="line">  <span class="string">&quot;max_position_embeddings&quot;</span>: <span class="number">512</span>,</span><br><span class="line"></span><br><span class="line">  <span class="string">&quot;num_attention_heads&quot;</span>: <span class="number">12</span>,</span><br><span class="line"></span><br><span class="line">  <span class="string">&quot;num_hidden_layers&quot;</span>: <span class="number">12</span>,</span><br><span class="line"></span><br><span class="line">  <span class="string">&quot;type_vocab_size&quot;</span>: <span class="number">2</span>,</span><br><span class="line"></span><br><span class="line">  <span class="string">&quot;vocab_size&quot;</span>: <span class="number">30522</span></span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="number">12</span>/<span class="number">26</span>/<span class="number">2018</span> <span class="number">17</span>:<span class="number">00</span>:<span class="number">45</span> - INFO - pytorch_pretrained_bert.modeling -   </span><br><span class="line"></span><br><span class="line">Weights of BertForSequenceClassification <span class="keyword">not</span> initialized <span class="keyword">from</span> pretrained model:</span><br><span class="line"></span><br><span class="line">[<span class="string">&#x27;classifier.weight&#x27;</span>, <span class="string">&#x27;classifier.bias&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="number">12</span>/<span class="number">26</span>/<span class="number">2018</span> <span class="number">17</span>:<span class="number">00</span>:<span class="number">45</span> - INFO - pytorch_pretrained_bert.modeling -   </span><br><span class="line"></span><br><span class="line">Weights <span class="keyword">from</span> pretrained model <span class="keyword">not</span> used <span class="keyword">in</span> BertForSequenceClassification:</span><br><span class="line"></span><br><span class="line">[<span class="string">&#x27;cls.predictions.bias&#x27;</span>, <span class="string">&#x27;cls.predictions.transform.dense.weight&#x27;</span>,</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;cls.predictions.transform.dense.bias&#x27;</span>, <span class="string">&#x27;cls.predictions.decoder.weight&#x27;</span>,</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;cls.seq_relationship.weight&#x27;</span>, <span class="string">&#x27;cls.seq_relationship.bias&#x27;</span>,</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;cls.predictions.transform.LayerNorm.weight&#x27;</span>, <span class="string">&#x27;cls.predictions.transform.LayerNorm.bias&#x27;</span>]</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<p>不得不去观察 <code>from_pretrained</code> 的源码：<a target="_blank" rel="noopener" href="https://github.com/huggingface/pytorch-pretrained-BERT/blob/8da280ebbeca5ebd7561fd05af78c65df9161f92/pytorch_pretrained_bert/modeling.py#L448">https://github.com/huggingface/pytorch-pretrained-BERT/blob/8da280ebbeca5ebd7561fd05af78c65df9161f92/pytorch_pretrained_bert/modeling.py#L448</a></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">missing_keys = []</span><br><span class="line"></span><br><span class="line">unexpected_keys = []</span><br><span class="line"></span><br><span class="line">error_msgs = []</span><br><span class="line"></span><br><span class="line"><span class="comment"># copy state_dict so _load_from_state_dict can modify it</span></span><br><span class="line"></span><br><span class="line">metadata = <span class="built_in">getattr</span>(state_dict, <span class="string">&#x27;_metadata&#x27;</span>, <span class="literal">None</span>)</span><br><span class="line"></span><br><span class="line">state_dict = state_dict.copy()</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> metadata <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line"></span><br><span class="line">    state_dict._metadata = metadata</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load</span>(<span class="params">module, prefix=<span class="string">&#x27;&#x27;</span></span>):</span></span><br><span class="line"></span><br><span class="line">    local_metadata = &#123;&#125; <span class="keyword">if</span> metadata <span class="keyword">is</span> <span class="literal">None</span> <span class="keyword">else</span> metadata.get(prefix[:-<span class="number">1</span>], &#123;&#125;)</span><br><span class="line"></span><br><span class="line">    module._load_from_state_dict(</span><br><span class="line"></span><br><span class="line">        state_dict, prefix, local_metadata, <span class="literal">True</span>, missing_keys, unexpected_keys, error_msgs)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> name, child <span class="keyword">in</span> module._modules.items():</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> child <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line"></span><br><span class="line">            load(child, prefix + name + <span class="string">&#x27;.&#x27;</span>)</span><br><span class="line"></span><br><span class="line">load(model, prefix=<span class="string">&#x27;&#x27;</span> <span class="keyword">if</span> <span class="built_in">hasattr</span>(model, <span class="string">&#x27;bert&#x27;</span>) <span class="keyword">else</span> <span class="string">&#x27;bert.&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> <span class="built_in">len</span>(missing_keys) &gt; <span class="number">0</span>:</span><br><span class="line"></span><br><span class="line">    logger.info(<span class="string">&quot;Weights of &#123;&#125; not initialized from pretrained model: &#123;&#125;&quot;</span>.<span class="built_in">format</span>(</span><br><span class="line"></span><br><span class="line">        model.__class__.__name__, missing_keys))</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> <span class="built_in">len</span>(unexpected_keys) &gt; <span class="number">0</span>:</span><br><span class="line"></span><br><span class="line">    logger.info(<span class="string">&quot;Weights from pretrained model not used in &#123;&#125;: &#123;&#125;&quot;</span>.<span class="built_in">format</span>(</span><br><span class="line"></span><br><span class="line">        model.__class__.__name__, unexpected_keys))</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> tempdir:</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Clean up temp dir</span></span><br><span class="line"></span><br><span class="line">    shutil.rmtree(tempdir)</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> model</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>这部分内容解释了如何提取模型的部分参数.  </p>
<p> <code>missing_keys</code> 这里是没有从预训练模型提取参数的部分，也就是 <code>classifier</code> <code>[&#39;classifier.weight&#39;, &#39;classifier.bias&#39;]</code>层，因为这一层是分类任务独有的。  </p>
<p> <code>unexpected_keys</code> 则是对于分类任务不需要的，但是在预训练的语言模型中是存在的。查看 <code>BertForMaskedLM</code> 的模型就能看到，<code>cls</code> 层，是专属于语言模型的，在下游任务中都需要去掉。</p>
<p> 所以这部分代码实际上学到了如何选择预训练模型的部分参数～～棒啊！</p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2018-12-12T05:34:38.000Z" title="2018/12/12 下午1:34:38">2018-12-12</time>发表</span><span class="level-item"><time dateTime="2021-06-29T05:19:29.419Z" title="2021/6/29 下午1:19:29">2021-06-29</time>更新</span><span class="level-item"><a class="link-muted" href="/categories/C/">C++</a></span><span class="level-item">16 分钟读完 (大约2395个字)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2018/12/12/Cplusplus-prime/">C plus plus prime-类</a></h1><div class="content"><h2 id="类定义"><a href="#类定义" class="headerlink" title="类定义"></a>类定义</h2><p>类头、类体、类域</p>
<h3 id="数据成员"><a href="#数据成员" class="headerlink" title="数据成员"></a>数据成员</h3><p>数据成员声明在类体中，可以是任何类型，eg. 指针，类</p>
<p>分为：非静态（nonstatic），静态（static）.</p>
<h3 id="成员函数"><a href="#成员函数" class="headerlink" title="成员函数"></a>成员函数</h3><p>成员函数在类域之外是不可见的。通过 “.” 或 “-&gt;” 来引用。</p>
<p>注意区分全局域/全局函数，类域/成员函数。</p>
<h3 id="成员访问"><a href="#成员访问" class="headerlink" title="成员访问"></a>成员访问</h3><p>信息隐藏（information hiding）：类成员的访问限制，通过访问限定符来实现的。</p>
<ul>
<li><p>public 公有成员，提供给用户使用的</p>
</li>
<li><p>private 只能被成员函数和友元访问  </p>
</li>
<li><p>protected 对派生类表现的像 public, 对其他程序表现的像 private.</p>
</li>
</ul>
<h3 id="友元"><a href="#友元" class="headerlink" title="友元"></a>友元</h3><p>关键字 find， 友元可以是一个名字空间函数、一个前面定义的类的一个成员函数、也可以是一个完整的类。</p>
<p>允许一个类授权其他的函数访问他的非公有成员，通常声明放在类头之后。</p>
<h3 id="类声明和定义"><a href="#类声明和定义" class="headerlink" title="类声明和定义"></a>类声明和定义</h3><p>类声明，是只有类头，没有类体。无法确定类类型的大小，类成员也是未知的。但是可以声明指向该类类型的指针或引用。</p>
<p>类定义，是具有完整的类体。</p>
<p><strong>什么时候用类声明？什么时候用类定义？</strong></p>
<h2 id="类对象"><a href="#类对象" class="headerlink" title="类对象"></a>类对象</h2><p>类定义不会分配存储区，只有定义了一个类的对象，才会分配。</p>
<p>类类型，即定义的一个类。通过它定义的对象是有生命期的，生命期根据它在哪个域中被声明的。</p>
<p>类对象可以被另一个对象初始化或赋值，拷贝一个类对象与拷贝它的成员函数等价。</p>
<p>当一个类对象被指定为函数实参或函数返回值时，它就被按值传递。我们可以把一个函数参数或返回值声明为一个类类型的指针或引用。（7.3节，7.4节）</p>
<p><strong>回顾下指针：</strong>  </p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">int</span> i = <span class="number">100</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">int</span> *p;</span><br><span class="line"></span><br><span class="line"><span class="keyword">int</span>* p = &amp;i;</span><br><span class="line"></span><br><span class="line"><span class="keyword">int</span> *p = &amp;i;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>p 是指针变量，用来存储地址。注意数组名是 const 地址常量，代表第一个元素的地址。</p>
<p><strong>指针和引用的区别：</strong>  </p>
<p>指针：指针是一个变量，只不过这个变量存储的是一个地址，指向内存的一个存储单元；而引用跟原来的变量实质上是同一个东西，只不过是原变量的一个别名而已。如：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">int</span> a=<span class="number">1</span>; <span class="keyword">int</span> *p=&amp;a;</span><br><span class="line"></span><br><span class="line"><span class="keyword">int</span> a=<span class="number">1</span>; <span class="keyword">int</span> &amp;b=a;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>上面定义了一个整形变量和一个指针变量p，该指针变量指向a的存储单元，即p的值是a存储单元的地址.  </p>
<p>而下面2句定义了一个整形变量a和这个整形a的引用b，事实上a和b是同一个东西，在内存占有同一个存储单元。</p>
<ul>
<li><p>“sizeof引用”得到的是所指向的变量(对象)的大小，而”sizeof指针”得到的是指针本身的大小；  </p>
</li>
<li><p>可以有const指针，但是没有const引用；</p>
</li>
<li><p>指针的值可以为空，但是引用的值不能为NULL，并且引用在定义的时候必须初始化；  </p>
</li>
<li><p>指针的值在初始化后可以改变，即指向其它的存储单元，而引用在进行初始化后就不会再改变了</p>
</li>
</ul>
<p>继续回到类对象作为函数参数时，用成员访问操作符来访问类对象的数据成员或成员函数。点操作符与类对象或引用连用; 箭头访问操作符与类对象的指针连用。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="meta"># <span class="meta-keyword">include</span> <span class="meta-string">&quot;Screen.h&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">bool</span> <span class="title">isEqual</span><span class="params">(Screen&amp; s1, Screen *s2)</span></span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"></span><br><span class="line">  ...</span><br><span class="line"></span><br><span class="line">  s1.height ...</span><br><span class="line"></span><br><span class="line">  s2-&gt;height ...</span><br><span class="line"></span><br><span class="line">  ...</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<p>isEqual 是非成员函数，如果要直接引用 s1, s2 中的数据成员 height 是不可以的。所以必须借助于 Screen 中的公有成员函数。  </p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">s2-&gt;height 等价于 (*s2).height</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h2 id="类成员函数"><a href="#类成员函数" class="headerlink" title="类成员函数"></a>类成员函数</h2><p>一组操作的集合。</p>
<h3 id="inline-和-非-inline-成员函数"><a href="#inline-和-非-inline-成员函数" class="headerlink" title="inline 和 非 inline 成员函数"></a>inline 和 非 inline 成员函数</h3><p>内联函数的作用：如果在程序中调用某个函数，不但要拷贝实参，保存机器的寄存器，程序还必须转向一个新的位置，这样会降低效率。  </p>
<p>而内联函数就是解决这个问题的，在程序的调用节点上，“内联”的展开函数的操作，从而额外的执行开销被消除了。</p>
<p>类体内定义的成员函数自动的作为内联函数处理。  </p>
<p>类体内声明，类体外定的函数，需要显示的加上关键字 inline. 同时类体外的定义需要用类名限定修饰(限定修饰符 :: )</p>
<h3 id="访问类成员"><a href="#访问类成员" class="headerlink" title="访问类成员"></a>访问类成员</h3><p>成员函数的定义可以引用任何一个类成员，无论该成员是私有还是公有。  </p>
<p>成员函数可以直接访问它所属类的成员，无需访问操作符。这实际上是通过 this 指针实现的。</p>
<h3 id="私有与公有成员函数"><a href="#私有与公有成员函数" class="headerlink" title="私有与公有成员函数"></a>私有与公有成员函数</h3><p>公有函数集定义了类的接口。私有成员函数为其他成员函数提供支持。</p>
<h3 id="特殊的成员函数"><a href="#特殊的成员函数" class="headerlink" title="特殊的成员函数"></a>特殊的成员函数</h3><p>构造函数：管理类对象并处理初始化、赋值、内存管理、类型转换、析构等活动。每次定义一个类对象或 new 表达式分配一个类对象都会调用它。  </p>
<p>构造函数的名字必须与类名相同。</p>
<h3 id="const-和-volatile-成员函数"><a href="#const-和-volatile-成员函数" class="headerlink" title="const 和 volatile 成员函数"></a>const 和 volatile 成员函数</h3><p>只有被声明为 const 的成员函数才能被一个 const 对象调用。关键字 const 在函数体和参数表之间.</p>
<p>通常一个类如果想被广泛使用，其中不修改类数据成员的成员函数应该声明为 const 成员函数。</p>
<p>但是即使声明了，这个成员函数依然有可能修改数据成员，如果这个类含有指针。</p>
<p>比如：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">private:</span><br><span class="line"></span><br><span class="line">  char *_text;</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<p><code>_text</code> 不能被修改，但是它指向的字符却是可以被修改的。所以程序员这个时候就需要注意了。。</p>
<p>构造函数和析构函数即使不是 const 成员函数，也能被 const 对象调用。</p>
<p>volatile 跟 const 用法一样，它用来提示编译器该对象的值可能在编译器未被检测到的情况下被修改。因为，编译器不能武断的对引用这些对象的代码进行优化。</p>
<h3 id="mutable-数据成员"><a href="#mutable-数据成员" class="headerlink" title="mutable 数据成员"></a>mutable 数据成员</h3><p>一旦一个对象被声明为 const，它的内容就不能修改。但是其中某些数据成员，比如索引，被修改之后并没有修改对象本身，这个时候就可以将该数据成员（也就是索引）声明为 mutable.</p>
<p>那样，即使 const 对象， const 成员函数修改了该数据成员，也不会有编译错误。</p>
<h2 id="隐含的指针-this"><a href="#隐含的指针-this" class="headerlink" title="隐含的指针 this"></a>隐含的指针 this</h2><p>每个类成员函数都含有一个指向被调用对象的指针。但是一般不需要显示的写出来，如果写出来也是可以的。</p>
<h3 id="何时使用指针呢？"><a href="#何时使用指针呢？" class="headerlink" title="何时使用指针呢？"></a>何时使用指针呢？</h3><p>当连续使用成员函数时，比如 <code>myVector.find().sort().insert()</code> 时，对应的成员函数返回的值应该是被调用对象本身，也就是 <code>*this</code>.</p>
<p>还有一种情况， copy 函数：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">Screen::copy</span><span class="params">(<span class="keyword">const</span> Screen&amp; sobj)</span></span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (<span class="keyword">this</span> != &amp;sobj)</span><br><span class="line"></span><br><span class="line">  &#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 把 sobj 的值拷贝到 * this 中</span></span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>这里的 this 指针含有被调用对象的地址。如果 sobj 的地址 &amp;sobj 与 this 相同，那就不需要拷贝了。</p>
<p>注意这里 &amp; 用法：引用和取地址。</p>
<h2 id="静态类成员"><a href="#静态类成员" class="headerlink" title="静态类成员"></a>静态类成员</h2><h3 id="静态数据成员"><a href="#静态数据成员" class="headerlink" title="静态数据成员"></a>静态数据成员</h3><p>对于非静态成员，每个类都有一个自己的拷贝。而静态成员对每个类类型只有一个拷贝。静态数据成员只有一份，由该类类型的所有对象共同访问。</p>
<p>不同于全局对象，它可以隐藏，并且不会与其他全局名字冲突。</p>
<p>关键字 static. 注意与 const 的区别，没有加 const 意味着是可以更新的。只需要更新一次，所有的类对象对应的值都会更新。</p>
<p>静态类成员的显示初始化，在类定义之外，用类名限定修饰。在静态数据成员的定义中也可以直接使用私有成员，这与在类成员函数中直接引用私有成员是一样的。</p>
<p>对于静态数据成员，除了通过类对象使用成员访问操作符访问之外，还可以直接使用类名加限定修饰符访问</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">Account::_intersetRate</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h3 id="静态成员函数"><a href="#静态成员函数" class="headerlink" title="静态成员函数"></a>静态成员函数</h3><p>静态成员函数，只访问静态数据成员，而不访问任何其他数据成员。所以它们与哪个对象来调用这个函数无关。</p>
<p>在类体中声明时需要加关键字 static, 类体外不能指定关键字。并且不能设定为 const 和 volatile.</p>
<h2 id="指向类成员的指针"><a href="#指向类成员的指针" class="headerlink" title="指向类成员的指针"></a>指向类成员的指针</h2><h3 id="普通函数指针-7-9节"><a href="#普通函数指针-7-9节" class="headerlink" title="普通函数指针 7.9节"></a>普通函数指针 7.9节</h3><h3 id="成员函数指针"><a href="#成员函数指针" class="headerlink" title="成员函数指针"></a>成员函数指针</h3></div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2018-12-11T06:22:13.000Z" title="2018/12/11 下午2:22:13">2018-12-11</time>发表</span><span class="level-item"><time dateTime="2021-06-29T08:12:08.539Z" title="2021/6/29 下午4:12:08">2021-06-29</time>更新</span><span class="level-item"><a class="link-muted" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/">论文笔记</a><span> / </span><a class="link-muted" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/open-set-recognition/">open set recognition</a></span><span class="level-item">6 分钟读完 (大约871个字)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2018/12/11/rejection%E7%B3%BB%E5%88%973-OpenMax/">rejection系列3 OpenMax</a></h1><div class="content"><p>paper: Towards Open Set Deep Networks. CVPR</p>
<h2 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h2><p>closed set recognition 天然的特性使得它必须选择一个类别作为预测对象。但是实际场景下， recognition system 必须学会 reject unknown/unseen classes 在 testing 阶段。</p>
<p>于是乎，作者提出了一个新的 model layer, <strong>OpenMax</strong>, 能够估计一个样本输入是来自于 unknown class 的概率。</p>
<p>A key element of estimating the unknown probability is adapting Meta-Recognition concepts to the activation patterns in the penultimate layer of the network.  </p>
<p>所以关键词是 <strong>meta-recohnition</strong>, <strong>activation pattern/vector</strong>.</p>
<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>很多工作是基于 threshold 来找出 unknown 的，他们认为 unknwon 通过 softmax 会得到 low probability/confidence. 但是实际上很多 “fooling” “rubbish” 也会拥有 high</p>
<p>probability/confidence scores. 比如通过对抗学习得到的 adversarial images. 作者在后面也提到了， threshold 实际上拒绝的不是 unknown, 而是 uncertain predictions.</p>
<blockquote>
<p>OpenMax incorporates <strong>likelihood of the recognition system failure</strong>. This likelihood is used to estimate the probability for a given input belonging to an unknown class. For this estimation, we adapt the concept of <strong>Meta-Recognition</strong>[22, 32, 9] to deep networks. We use the scores from the penultimate layer of deep networks (the fully connected layer before SoftMax, e.g., FC8) to estimate if the input is “far” from known training data. We call scores in that layer the <strong>activation vector(AV)</strong>.  </p>
</blockquote>
<p>关于 OpenMax 如果实现的简单总结，回过头在看。</p>
<blockquote>
<p>A key insight in our opening deep networks is noting that “open space risk” should be measured in feature space rather than in pixel space.  </p>
</blockquote>
<p>一个重要的观点是，在 open deep networks 里面， open space risk 应该是从特征空间 feature space 的角度出发的， 而不是 pixel space. 也就是神经网络判断是不是 unknown, 应该是从 feature 的角度来看的。</p>
<blockquote>
<p>We show that an extreme-value meta-recognition inspired distance normalization process on the overall activation patterns of the penultimate network layer provides a rejection probability for OpenMax normalization for unknown images, fooling images and even for many adversarial images.</p>
</blockquote>
<h2 id="Open-set-deep-networks"><a href="#Open-set-deep-networks" class="headerlink" title="Open set deep networks"></a>Open set deep networks</h2><blockquote>
<p>Building on the concepts of open space risk, we seek to choose a layer (feature space) in which we can build a <strong>compact abating probability model</strong> that can be thresholded to limit open space risk.  </p>
</blockquote>
<p>基于 open space risk 的概念，提出了 compact abating probability model 能限制 open space risk.</p>
<h3 id="multi-classes-meta-recognition"><a href="#multi-classes-meta-recognition" class="headerlink" title="multi-classes meta-recognition"></a>multi-classes meta-recognition</h3><p>作者先简单介绍了一下前人的工作:  </p>
<blockquote>
<p>. Prior work on meta-recognition used the final system scores, analyzed their distribution based on Extreme Value Theory (EVT) and found these distributions follow Weibull distribution.</p>
</blockquote>
<p>感觉看懂这部分先要理解极值理论(Extreme value theory).</p>
<blockquote>
<p>from wikipedia:</p>
</blockquote>
<p>It seeks to assess, from a given ordered sample of a given random variable, the probability of events that are more extreme than any previously observed.  </p>
<p>它试图从给定随机变量的给定有序样本中评估比先前观察到的任何事件更极端的事件的概率.</p>
<p><img src="/2018/12/11/rejection%E7%B3%BB%E5%88%973-OpenMax/01.png"></p>
<p>然后是 极值分布 的一种 Weibull distribution</p>
<p><img src="/2018/12/11/rejection%E7%B3%BB%E5%88%973-OpenMax/02.png"></p>
<p><img src="/2018/12/11/rejection%E7%B3%BB%E5%88%973-OpenMax/03.png"></p>
<p><img src="/2018/12/11/rejection%E7%B3%BB%E5%88%973-OpenMax/04.png"></p>
<p><img src="/2018/12/11/rejection%E7%B3%BB%E5%88%973-OpenMax/05.png"></p>
<p><img src="/2018/12/11/rejection%E7%B3%BB%E5%88%973-OpenMax/06.png"></p>
<p><img src="/2018/12/11/rejection%E7%B3%BB%E5%88%973-OpenMax/07.png"></p>
<p>所以 Weibull distribution 就是从整个分布中取最极端的例子 sampling top-n score，然后的到的分布。</p>
<p><img src="/2018/12/11/rejection%E7%B3%BB%E5%88%973-OpenMax/08.png"></p>
<p><img src="/2018/12/11/rejection%E7%B3%BB%E5%88%973-OpenMax/09.png"></p>
<p><img src="/2018/12/11/rejection%E7%B3%BB%E5%88%973-OpenMax/10.png"></p>
<p>将极值理论运用到视觉特征的提取中。具体的我也不太清楚了。。这也是前人的研究。作者也并没有采取这种方法。</p>
<blockquote>
<p>We take the approach that the network values from penultimate layer (hereafter the Activation Vector (AV)), are not an independent per-class score estimate, but rather they provide a distribution of what classes are “related.”  </p>
</blockquote>
<p>作者采用的方法是 倒数第二层，也就是 (Activation Vector) 提供不同 classes 之间的相关性分布，而不是每一个类对应的独立的分布。</p>
<h3 id="interpretation-of-activation-vector"><a href="#interpretation-of-activation-vector" class="headerlink" title="interpretation of activation vector"></a>interpretation of activation vector</h3><h3 id="OpenMax"><a href="#OpenMax" class="headerlink" title="OpenMax"></a>OpenMax</h3></div></article></div><nav class="pagination" role="navigation" aria-label="pagination"><div class="pagination-previous"><a href="/page/10/">上一页</a></div><div class="pagination-next"><a href="/page/12/">下一页</a></div><ul class="pagination-list is-hidden-mobile"><li><a class="pagination-link" href="/">1</a></li><li><span class="pagination-ellipsis">&hellip;</span></li><li><a class="pagination-link" href="/page/10/">10</a></li><li><a class="pagination-link is-current" href="/page/11/">11</a></li><li><a class="pagination-link" href="/page/12/">12</a></li><li><span class="pagination-ellipsis">&hellip;</span></li><li><a class="pagination-link" href="/page/24/">24</a></li></ul></nav></div><!--!--><div class="column column-right is-4-tablet is-4-desktop is-4-widescreen  order-3"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar" src="/img/avatar.png" alt="panxiaoxie"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">panxiaoxie</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Beijing, China</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">文章</p><a href="/archives"><p class="title">117</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">分类</p><a href="/categories"><p class="title">39</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">标签</p><a href="/tags"><p class="title">36</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/PanXiebit" target="_blank" rel="noopener">关注我</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/PanXiebit"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Email" href="/ftdpanxie@gmail.com"><i class="fa fa-envelope"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="RSS" href="/"><i class="fas fa-rss"></i></a></div></div></div><!--!--><div class="card widget" data-type="links"><div class="card-content"><div class="menu"><h3 class="menu-label">链接</h3><ul class="menu-list"><li><a class="level is-mobile" href="https://github.com/PanXiebit" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">github</span></span><span class="level-right"><span class="level-item tag">github.com</span></span></a></li><li><a class="level is-mobile" href="ftdpanxie@gmail.com" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">email</span></span><span class="level-right"><span class="level-item tag">ftdpanxie@gmail.com</span></span></a></li></ul></div></div></div><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">分类</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/C/"><span class="level-start"><span class="level-item">C++</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/CSAPP/"><span class="level-start"><span class="level-item">CSAPP</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/DRL/"><span class="level-start"><span class="level-item">DRL</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/GAN/"><span class="level-start"><span class="level-item">GAN</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li><li><a class="level is-mobile" href="/categories/GAN-RL/"><span class="level-start"><span class="level-item">GAN, RL</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/ML/"><span class="level-start"><span class="level-item">ML</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/NLP/"><span class="level-start"><span class="level-item">NLP</span></span><span class="level-end"><span class="level-item tag">14</span></span></a></li><li><a class="level is-mobile" href="/categories/TensorFlow/"><span class="level-start"><span class="level-item">TensorFlow</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/cs224d/"><span class="level-start"><span class="level-item">cs224d</span></span><span class="level-end"><span class="level-item tag">10</span></span></a></li><li><a class="level is-mobile" href="/categories/generation/"><span class="level-start"><span class="level-item">generation</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/interview/"><span class="level-start"><span class="level-item">interview</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/leetcode/"><span class="level-start"><span class="level-item">leetcode</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/machine-translation/"><span class="level-start"><span class="level-item">machine translation</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/python/"><span class="level-start"><span class="level-item">python</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/pytorch/"><span class="level-start"><span class="level-item">pytorch</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/reinforcement-learning/"><span class="level-start"><span class="level-item">reinforcement learning</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/sign-language-recognition/"><span class="level-start"><span class="level-item">sign language recognition</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/transfer-learning/"><span class="level-start"><span class="level-item">transfer learning</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"><span class="level-start"><span class="level-item">数据结构与算法</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile" href="/categories/%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB/"><span class="level-start"><span class="level-item">文本分类</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"><span class="level-start"><span class="level-item">论文笔记</span></span><span class="level-end"><span class="level-item tag">40</span></span></a><ul><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/DL/"><span class="level-start"><span class="level-item">DL</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/ESA/"><span class="level-start"><span class="level-item">ESA</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/GAN/"><span class="level-start"><span class="level-item">GAN</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/MRC-and-QA/"><span class="level-start"><span class="level-item">MRC and QA</span></span><span class="level-end"><span class="level-item tag">7</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/Machine-Translation/"><span class="level-start"><span class="level-item">Machine Translation</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/NLP/"><span class="level-start"><span class="level-item">NLP</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/Transformer/"><span class="level-start"><span class="level-item">Transformer</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/capsules/"><span class="level-start"><span class="level-item">capsules</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/computer-vision/"><span class="level-start"><span class="level-item">computer vision</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/constrast-learning/"><span class="level-start"><span class="level-item">constrast learning</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/data-augmentation/"><span class="level-start"><span class="level-item">data augmentation</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/dialogue-system/"><span class="level-start"><span class="level-item">dialogue system</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/language-model/"><span class="level-start"><span class="level-item">language model</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/machine-translation/"><span class="level-start"><span class="level-item">machine translation</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/open-set-recognition/"><span class="level-start"><span class="level-item">open set recognition</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/sentence-embedding/"><span class="level-start"><span class="level-item">sentence embedding</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/text-matching/"><span class="level-start"><span class="level-item">text matching</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/vision-language/"><span class="level-start"><span class="level-item">vision-language</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li></ul></div></div></div></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/panxiaoxie.png" alt="潘小榭" height="28"></a><p class="is-size-7"><span>&copy; 2021 Xie Pan</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("zh-CN");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="回到顶端" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "此网站使用Cookie来改善您的体验。",
          dismiss: "知道了！",
          allow: "允许使用Cookie",
          deny: "拒绝",
          link: "了解更多",
          policy: "Cookie政策",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.5/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="想要查找什么..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"想要查找什么...","untitled":"(无标题)","posts":"文章","pages":"页面","categories":"分类","tags":"标签"});
        });</script></body></html>