<!doctype html>
<html lang="zh"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>分类: transfer learning - 潘小榭</title><link rel="manifest" href="/manifest.json"><meta name="theme-color" content="black"><meta name="application-name" content="panxiaoxie"><meta name="msapplication-TileImage" content="/img/avatar.png"><meta name="msapplication-TileColor" content="black"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="panxiaoxie"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta property="og:type" content="blog"><meta property="og:title" content="panxiaoxie"><meta property="og:url" content="https://github.com/PanXiebit"><meta property="og:site_name" content="panxiaoxie"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://www.qt86.com/cache/1625298592_187938.png"><meta property="article:author" content="panxiaoxie"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="https://www.qt86.com/cache/1625298592_187938.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"http://www.panxiaoxie.cn"},"headline":"潘小榭","image":["http://www.panxiaoxie.cn/img/og_image.png"],"author":{"@type":"Person","name":"Xie Pan"},"publisher":{"@type":"Organization","name":"潘小榭","logo":{"@type":"ImageObject","url":"http://www.panxiaoxie.cn/img/panxiaoxie.png"}},"description":null}</script><link rel="icon" href="/img/avatar.png"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/css/justifiedGallery.min.css"><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script><!--!--><!--!--><meta name="generator" content="Hexo 5.4.0"></head><body class="is-2-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/panxiaoxie.png" alt="潘小榭" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">主页</a><a class="navbar-item" href="/archives">归档</a><a class="navbar-item" href="/categories">分类</a><a class="navbar-item" href="/tags">标签</a><a class="navbar-item" href="/about">关于我</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/PanXiebit"><i class="fab fa-github"></i></a><a class="navbar-item search" title="搜索" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-10-widescreen"><div class="card"><div class="card-content"><nav class="breadcrumb" aria-label="breadcrumbs"><ul><li><a href="/categories">分类</a></li><li class="is-active"><a href="#" aria-current="page">transfer learning</a></li></ul></nav></div></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2019-03-08T07:43:02.000Z" title="2019/3/8 下午3:43:02">2019-03-08</time>发表</span><span class="level-item"><time dateTime="2021-06-29T08:12:08.200Z" title="2021/6/29 下午4:12:08">2021-06-29</time>更新</span><span class="level-item"><a class="link-muted" href="/categories/transfer-learning/">transfer learning</a></span><span class="level-item">10 分钟读完 (大约1516个字)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2019/03/08/%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%E7%B3%BB%E5%88%97-3-%E7%8E%8B%E6%99%8B%E4%B8%9C%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%E6%89%8B%E5%86%8C%E9%98%85%E8%AF%BB/">迁移学习系列-3-王晋东迁移学习手册阅读</a></h1><div class="content"><h3 id="迁移学习的定义"><a href="#迁移学习的定义" class="headerlink" title="迁移学习的定义"></a>迁移学习的定义</h3><p>迁移学习，是指利用数据、任务、或模型之间的相似性，将在旧领域学习过的模型，应用于新领域的一种学习过程。</p>
<p>综述文章：</p>
<p>A survey on transfer learning [Pan and Yang, 2010]</p>
<h3 id="为什么要学习迁移学习？"><a href="#为什么要学习迁移学习？" class="headerlink" title="为什么要学习迁移学习？"></a>为什么要学习迁移学习？</h3><ol>
<li><p>缺少数据标注</p>
</li>
<li><p>缺少足够算力</p>
</li>
<li><p>普适化模型与个性化需求之间的矛盾</p>
</li>
<li><p>特定应用需求</p>
</li>
</ol>
<p>迁移学习如何解决这些问题：</p>
<ol>
<li><p>大数据与少标注：迁移数据标注</p>
</li>
<li><p>大数据与弱计算：模型迁移</p>
</li>
<li><p>普适化模型与个性化需求：自适应学习</p>
</li>
<li><p>特定应用的需求：相似领域知识迁移（比如cross-lingual）</p>
</li>
</ol>
<p><img src="/2019/03/08/%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%E7%B3%BB%E5%88%97-3-%E7%8E%8B%E6%99%8B%E4%B8%9C%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%E6%89%8B%E5%86%8C%E9%98%85%E8%AF%BB/01.png"></p>
<p>迁移学习与传统机器学习的区别：</p>
<p><img src="/2019/03/08/%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%E7%B3%BB%E5%88%97-3-%E7%8E%8B%E6%99%8B%E4%B8%9C%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%E6%89%8B%E5%86%8C%E9%98%85%E8%AF%BB/02.png"></p>
<p>迁移学习与领域自适应的区别：  </p>
<p>领域自适应问题是迁移学习的研究内容之一，它侧重于解决特征空间一致、类别空间一致，仅特征分布不一致的问题。而迁移学习也可以解决上述内容不一致的情况。</p>
<h3 id="迁移学习的常用分类"><a href="#迁移学习的常用分类" class="headerlink" title="迁移学习的常用分类"></a>迁移学习的常用分类</h3><p><img src="/2019/03/08/%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%E7%B3%BB%E5%88%97-3-%E7%8E%8B%E6%99%8B%E4%B8%9C%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%E6%89%8B%E5%86%8C%E9%98%85%E8%AF%BB/04.png"></p>
<h4 id="按照目标域标签分类"><a href="#按照目标域标签分类" class="headerlink" title="按照目标域标签分类"></a>按照目标域标签分类</h4><ol>
<li><p>监督迁移学习 (Supervised Transfer Learning)   </p>
</li>
<li><p>半监督迁移学习 (Semi-Supervised Transfer Learning)   </p>
</li>
<li><p>无监督迁移学习 (Unsupervised Transfer Learning)</p>
</li>
</ol>
<h4 id="按照学习方法分类"><a href="#按照学习方法分类" class="headerlink" title="按照学习方法分类"></a>按照学习方法分类</h4><ul>
<li><p>基于实例的迁移学习方法 (Instance based Transfer Learning)：</p>
</li>
<li><p>基于特征的迁移学习方法 (Feature based Transfer Learning)  </p>
</li>
<li><p>基于模型的迁移学习方法 (Model based Transfer Learning)  </p>
</li>
<li><p>基于关系的迁移学习方法 (Relation based Transfer Learning)</p>
</li>
</ul>
<p>基于实例的迁移，简单来说就是通过权重重用，对源域和目标域的样例进行迁移。就是说直接对不同的样本赋予不同权重，比如说相似的样本，我就给它高权重，这样我就完成了 迁移，非常简单非常非常直接。</p>
<p>基于特征的迁移，就是更进一步对特征进行变换。意思是说，假设源域和目标域的特征 原来不在一个空间，或者说它们在原来那个空间上不相似，那我们就想办法把它们变换到一个空间里面，那这些特征不就相似了？这个思路也非常直接。这个方法是用得非常多的，一 直在研究，目前是感觉是研究最热的。</p>
<p>基于模型的迁移，就是说构建参数共享的模型。这个主要就是在神经网络里面用的特别多，因为神经网络的结构可以直接进行迁移。比如说神经网络最经典的 <strong>finetune</strong> 就是模型参数迁移的很好的体现。</p>
<p>基于关系的迁移，这个方法用的比较少，这个主要就是说挖掘和利用关系进行类比迁移。比如老师上课、学生听课就可以类比为公司开会的场景。这个就是一种关系的迁移。</p>
<h4 id="按照特征分类"><a href="#按照特征分类" class="headerlink" title="按照特征分类"></a>按照特征分类</h4><ul>
<li><p>同构迁移学习 (Homogeneous Transfer Learning)  </p>
</li>
<li><p>异构迁移学习 (Heterogeneous Transfer Learning)  </p>
</li>
</ul>
<p>这也是一种很直观的方式：如果特征语义和维度都相同，那么就是同构；反之，如果特征完全不相同，那么就是异构。举个例子来说，不同图片的迁移，就可以认为是同构；而图片到文本的迁移，则是异构的。</p>
<h4 id="按离线与在线形式分"><a href="#按离线与在线形式分" class="headerlink" title="按离线与在线形式分"></a>按离线与在线形式分</h4><ul>
<li><p>离线迁移学习 (Offline Transfer Learning)  </p>
</li>
<li><p>在线迁移学习 (Online Transfer Learning)</p>
</li>
</ul>
<h3 id="迁移学习的应用"><a href="#迁移学习的应用" class="headerlink" title="迁移学习的应用"></a>迁移学习的应用</h3><p><img src="/2019/03/08/%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%E7%B3%BB%E5%88%97-3-%E7%8E%8B%E6%99%8B%E4%B8%9C%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%E6%89%8B%E5%86%8C%E9%98%85%E8%AF%BB/05.png"></p>
<h4 id="计算机视觉"><a href="#计算机视觉" class="headerlink" title="计算机视觉"></a>计算机视觉</h4><p>在 CV 领域，迁移学习主要是方法是领域自适应 domain adaption. 侧重于解决特征空间一致、类别空间一致，仅特征分布不一致的问题。</p>
<p><img src="/2019/03/08/%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%E7%B3%BB%E5%88%97-3-%E7%8E%8B%E6%99%8B%E4%B8%9C%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%E6%89%8B%E5%86%8C%E9%98%85%E8%AF%BB/06.png"></p>
<p>个人理解：在图像上，即使类别差别很大，但是在特征空间上仍然是一致的，或者说有很多相似之处。比如人和狗，从轮廓、颜色、五官等等特征都是具有可迁移性的。再比如人和桌子，也是具有相似特征的。</p>
<p>那么问题是，特征空间完全一致吗？不一致的部分呢？</p>
<h4 id="文本分类"><a href="#文本分类" class="headerlink" title="文本分类"></a>文本分类</h4><p>由于文本数据有其领域特殊性，因此，在一个领域上训练的分类器，不能直接拿来作用到另一个领域上。这就需要用到迁移学习。例如，在电影评论文本数据集上训练好的分类器，不能直接用于图书评论的预测。这就需要进行迁移学习。图 11是一个由电子产品评论 迁移到 DVD 评论的迁移学习任务。</p>
<p><img src="/2019/03/08/%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%E7%B3%BB%E5%88%97-3-%E7%8E%8B%E6%99%8B%E4%B8%9C%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%E6%89%8B%E5%86%8C%E9%98%85%E8%AF%BB/07.png"></p>
<p>那么问题来了，这种从一个domain 迁移到另一个 domain，到底改变了什么？比如同样一个词，在 电子产品中对应的 vector 经过迁移后（finetune?），发生了怎样的变化，这个可以可视化嘛？</p>
<h4 id="时间序列"><a href="#时间序列" class="headerlink" title="时间序列"></a>时间序列</h4><ul>
<li><p>行为识别(Activity Recognition)  </p>
</li>
<li><p>室内定位 (Indoor Location)  </p>
</li>
</ul>
<h4 id="医疗健康"><a href="#医疗健康" class="headerlink" title="医疗健康"></a>医疗健康</h4><p>不同于其他领域，医疗领域研究的难点问题是，无法获取足够有效的医疗数据。在这一领域，迁移学习同样也变得越来越重要。</p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2019-03-06T07:37:28.000Z" title="2019/3/6 下午3:37:28">2019-03-06</time>发表</span><span class="level-item"><time dateTime="2021-06-29T08:12:08.522Z" title="2021/6/29 下午4:12:08">2021-06-29</time>更新</span><span class="level-item"><a class="link-muted" href="/categories/transfer-learning/">transfer learning</a></span><span class="level-item">4 分钟读完 (大约584个字)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2019/03/06/%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%E7%B3%BB%E5%88%97-2-Combining-semi-supervised-learning-with-transfer-learning/">迁移学习系列-2-Combining semi-supervised learning with transfer learning</a></h1><div class="content"><h2 id="paper"><a href="#paper" class="headerlink" title="paper"></a>paper</h2><p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1804.09530">Strong Baselines for Neural Semi-Supervised Learning under Domain Shift</a></p>
<h3 id="motivation"><a href="#motivation" class="headerlink" title="motivation"></a>motivation</h3><p>这篇paper的工作就是提出了一个经典方法实现的strong baseline.他的motivation就是前面很多研究比如基于deep learning的，对比的经典算法都很weak，或者是在专有的数据集上跑（容易过拟合）。</p>
<p>对比的三种传统方法， self-traning, tritraining, tri-training with disagreement</p>
<h3 id="self-training"><a href="#self-training" class="headerlink" title="self-training:"></a>self-training:</h3><ol>
<li><p>使用有标签的数据，训练一个模型  </p>
</li>
<li><p>用这个模型去预测无标签的数据，得到对应样本属于某一类别的概率  </p>
</li>
<li><p>选择一个阈值，大于这个阈值的样本，可以打上伪标签。但是通常来说，阈值不太好确定，所以可以使用相对阈值，也就是选取概率相对较高的 top N.  </p>
</li>
</ol>
<p>模型的缺点在于：如果预测错了某些样本，那么错误会累积并放大。  </p>
<p><img src="/2019/03/06/%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%E7%B3%BB%E5%88%97-2-Combining-semi-supervised-learning-with-transfer-learning/01.png"></p>
<h3 id="tri-training"><a href="#tri-training" class="headerlink" title="tri-training:"></a>tri-training:</h3><ol>
<li><p>使用有标签的数据，训练三个模型 m1, m2, m3  </p>
</li>
<li><p>使用 bootstrapping 的方法，sample部分无标签的数据，然后使用三个模型进行预测，当 m1 预测样本属于某一类的概率低时，而 m2, m3 预测样本属于这一类的概率高时，将这个样本打上伪标签，加入到 m1 的训练集中去  </p>
</li>
<li><p>迭代这个过程，直到分类器不在变化，可以同时更新三个分类器？  </p>
</li>
</ol>
<p>motivation：模型应该增强它相对较弱的地方。其实也就是 ensamble 的 sense.  </p>
<p>缺点：计算量太大， 耗费时间和空间  </p>
<p><img src="/2019/03/06/%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%E7%B3%BB%E5%88%97-2-Combining-semi-supervised-learning-with-transfer-learning/02.png"></p>
<h3 id="multi-task-tritraining"><a href="#multi-task-tritraining" class="headerlink" title="multi-task tritraining:"></a>multi-task tritraining:</h3><ol>
<li><p>多任务训练，这里的任务其实可以看作是一致的，底层 encoder 层参数共享，softmax层，也就是 decoder 层参数不一致。  </p>
</li>
<li><p>要尽可能让 m1, m2 具有差异性 diversity，加上了正则化项  </p>
</li>
<li><p>模型 m3 只在伪标签数据上进行训练。其目的是让模型在 domain shift 情况下鲁棒性更强。  </p>
</li>
</ol>
<p><img src="/2019/03/06/%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%E7%B3%BB%E5%88%97-2-Combining-semi-supervised-learning-with-transfer-learning/03.png"></p>
<h2 id="paper2"><a href="#paper2" class="headerlink" title="paper2"></a>paper2</h2><p><a target="_blank" rel="noopener" href="http://aclweb.org/anthology/D18-1217">Semi-Supervised Sequence Modeling with Cross-View Training (EMNLP 2018)</a></p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2019-03-04T01:09:08.000Z" title="2019/3/4 上午9:09:08">2019-03-04</time>发表</span><span class="level-item"><time dateTime="2021-06-29T08:12:08.504Z" title="2021/6/29 下午4:12:08">2021-06-29</time>更新</span><span class="level-item"><a class="link-muted" href="/categories/transfer-learning/">transfer learning</a></span><span class="level-item">10 分钟读完 (大约1552个字)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2019/03/04/%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%E7%B3%BB%E5%88%97-1-Neural-Transfer-Learning-for-NLP/">迁移学习系列 1-Neural Transfer Learning for NLP</a></h1><div class="content"><h2 id="迁移学习与监督学习的区别"><a href="#迁移学习与监督学习的区别" class="headerlink" title="迁移学习与监督学习的区别"></a>迁移学习与监督学习的区别</h2><p><img src="/2019/03/04/%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%E7%B3%BB%E5%88%97-1-Neural-Transfer-Learning-for-NLP/01.png"></p>
<p>training domain 和 target domain 不一致时，需要知识迁移。  </p>
<p>那么暂时的问题来了？  </p>
<ul>
<li><p>1.如何界定 domain 的范围，尤其是NLP领域。从医学文本能迁移到科幻小说吗，感觉不可以。。  </p>
</li>
<li><p>2.从 big domain 到 small domain 的迁移也是属于迁移学习的范畴吧？比如像 BERT 这样在超大的训练集上进行 training，然后在小的子集上 fine-tune，都能表现的很好是吗？  </p>
</li>
</ul>
<h2 id="Why-transfer-learning"><a href="#Why-transfer-learning" class="headerlink" title="Why transfer learning"></a>Why transfer learning</h2><p><img src="/2019/03/04/%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%E7%B3%BB%E5%88%97-1-Neural-Transfer-Learning-for-NLP/02.png"></p>
<p>目前的监督模型依旧非常脆弱，<a target="_blank" rel="noopener" href="https://arxiv.org/abs/1707.07328">Jia and Liang, EMNLP 2017</a> 这篇 paper 证明了目前的 SOTA 的模型对对抗样本非常敏感。</p>
<p>迁移学习能解决这个问题吗，疑惑？？</p>
<blockquote>
<p><strong>Abstract：</strong>    </p>
</blockquote>
<p>Standard accuracy metrics indicate that reading comprehension systems are making rapid progress, but the extent to which these systems truly understand language remains unclear. To reward systems with real language understanding abilities, we propose an adversarial evaluation scheme for the Stanford Question Answering Dataset (SQuAD). Our method tests whether systems can answer questions about paragraphs that contain adversarially inserted sentences, which are automatically generated to distract computer systems without changing the correct answer or misleading humans. In this adversarial setting, the accuracy of sixteen published models drops from an average of 75% F1 score to 36%; when the adversary is allowed to add ungrammatical sequences of words, average accuracy on four models decreases further to 7%. We hope our insights will motivate the development of new models that understand language more precisely.</p>
<p><img src="/2019/03/04/%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%E7%B3%BB%E5%88%97-1-Neural-Transfer-Learning-for-NLP/03.png"></p>
<p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1711.02173">Synthetic and Natural Noise Both Break Neural Machine Translation, Belinkov and Bisk (ICLR 2018)</a> 这篇 paper 中提到基于字符级别的翻译模型能有效解决 OOV 等问题，但是却使得模型对 noise 非常敏感且脆弱。如果出现 phonetic 拼写错误，omission 省略， key swap 关键字母交换，都会导致 BLEU 值严重下降。</p>
<blockquote>
<p><strong>Abstract</strong>   </p>
</blockquote>
<p>Character-based neural machine translation (NMT) models alleviate out-of-vocabulary issues, learn morphology, and move us closer to completely end-to-end translation systems. Unfortunately, they are also very brittle and easily falter when presented with noisy data. In this paper, we confront NMT models with synthetic and natural sources of noise. We find that state-of-the-art models fail to translate even moderately noisy texts that humans have no trouble comprehending. We explore two approaches to increase model robustness: structure-invariant word representations and robust training on noisy texts. We find that a model based on a character convolutional neural network is able to simultaneously learn representations robust to multiple kinds of noise.</p>
<p><img src="/2019/03/04/%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%E7%B3%BB%E5%88%97-1-Neural-Transfer-Learning-for-NLP/04.png"></p>
<p><a target="_blank" rel="noopener" href="http://aclweb.org/anthology/N18-1170">Iyyer et al. (NAACL 2018)</a> 这篇 paper 提出了一个句法规则控制下的释义生成模型，syntactically controlled paraphrase networks (SCPNs). 然后发现这样的对抗样本很容易愚弄训练好的监督模型。</p>
<blockquote>
<p><strong>Abstract：</strong>     </p>
</blockquote>
<p>We propose syntactically controlled paraphrase networks (SCPNs) and use them to generate adversarial examples. Given a sentence and a target syntactic form (e.g., a constituency parse), SCPNs are trained to produce a paraphrase of the sentence with the desired syntax. We show it is possible to create training data for this task by first doing backtranslation at a very large scale, and then using a parser to label the syntactic transformations that naturally occur during this process. Such data allows us to train a neural encoderdecoder model with extra inputs to specify the target syntax. A combination of automated and human evaluations show that SCPNs generate paraphrases that follow their target specifications without decreasing paraphrase quality when compared to baseline (uncontrolled)paraphrase systems. Furthermore, they are more capable of generating syntactically adversarial examples that both (1) “fool” pretrained models and (2) improve the robustness of these models to syntactic variation when used to augment their training data</p>
<p><img src="/2019/03/04/%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%E7%B3%BB%E5%88%97-1-Neural-Transfer-Learning-for-NLP/05.png"></p>
<p>人工标注所有 domain 或者任何语言的数据是不可理的，因此需要 transfering knowledge from a related setting to the target setting.</p>
<p><img src="/2019/03/04/%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%E7%B3%BB%E5%88%97-1-Neural-Transfer-Learning-for-NLP/06.png"></p>
<p>NLP 很多重大的基础性的研究都可以看作是迁移学习的一种形式。  </p>
<ul>
<li><p>LSA  </p>
</li>
<li><p>Brown clusters  </p>
</li>
<li><p>word embedding  </p>
</li>
</ul>
<p><img src="/2019/03/04/%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%E7%B3%BB%E5%88%97-1-Neural-Transfer-Learning-for-NLP/07.png"></p>
<p>已有工作的局限性：  </p>
<ul>
<li><p>限制度太高：预设定好的相似度指标，hard 参数共享  </p>
</li>
<li><p>条件设定太过于具体：单一的 task  </p>
</li>
<li><p>baseline 太弱：缺少与传统方法的对比  </p>
</li>
<li><p>模型脆弱：在 out-of-domain 不work，依赖于相似的语言/任务  </p>
</li>
<li><p>效率低：需要大量参数，时间和样本  </p>
</li>
</ul>
<h2 id="研究目标"><a href="#研究目标" class="headerlink" title="研究目标"></a>研究目标</h2><p><img src="/2019/03/04/%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%E7%B3%BB%E5%88%97-1-Neural-Transfer-Learning-for-NLP/08.png"></p>
<p><img src="/2019/03/04/%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%E7%B3%BB%E5%88%97-1-Neural-Transfer-Learning-for-NLP/09.png"></p>
<ul>
<li><p>迁移学习</p>
<ul>
<li><p>传导式迁移学习（相同的任务，只有sourced domain有label）  </p>
<ul>
<li><p>领域自适应（不同的 domain）  </p>
</li>
<li><p>跨语言学习（不同的 language）  </p>
</li>
</ul>
</li>
<li><p>归纳式迁移学习（不同的任务， target domain 也有标签）  </p>
<ul>
<li><p>多任务学习  </p>
</li>
<li><p>序列迁移学习  </p>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>大佬太强了。。。。强到爆炸啊</p>
<h2 id="domain-adaptation"><a href="#domain-adaptation" class="headerlink" title="domain adaptation"></a>domain adaptation</h2><p>Propose two novel methods that bridge the domain discrepancy by selecting relevant and informative data for unsupervised domain adaptation.  </p>
<p>提出两方法，替无监督的域适应选择相关的，具有信息量的数据来弥合域之间的差异。</p>
<h3 id="Based-on-Bayesian-Optimisation"><a href="#Based-on-Bayesian-Optimisation" class="headerlink" title="Based on Bayesian Optimisation"></a>Based on Bayesian Optimisation</h3><p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1707.05246">Learning to select data for transfer learning with Bayesian Optimization, EMNLP2017</a></p>
<p><img src="/2019/03/04/%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%E7%B3%BB%E5%88%97-1-Neural-Transfer-Learning-for-NLP/10.png"></p>
<p>还不太懂 bayesian optimisation:  </p>
<ul>
<li><p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/29779000">https://zhuanlan.zhihu.com/p/29779000</a>  </p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://www.jiqizhixin.com/articles/2017-08-18-5">https://www.jiqizhixin.com/articles/2017-08-18-5</a>  </p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1807.02811">A Tutorial on Bayesian Optimization</a></p>
</li>
</ul>
<p><img src="/2019/03/04/%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%E7%B3%BB%E5%88%97-1-Neural-Transfer-Learning-for-NLP/11.png"></p>
<h3 id="Using-semi-supervised-learning-and-multi-task-learning"><a href="#Using-semi-supervised-learning-and-multi-task-learning" class="headerlink" title="Using semi-supervised learning and multi-task learning"></a>Using semi-supervised learning and multi-task learning</h3><p><a target="_blank" rel="noopener" href="https://acl2018.org/paper/168/">Strong Baselines for Neural Semi-supervised Learning under Domain Shift, Ruder &amp; Plank, ACL 2018</a>  </p>
<blockquote>
<p>Novel neural models have been proposed in recent years for learning under domain shift. Most models, however, only evaluate on a single task, on proprietary datasets, or compare to weak baselines, which makes comparison of models difficult. In this paper, we re-evaluate classic general-purpose bootstrapping approaches in the context of neural networks under domain shifts vs. recent neural approaches and propose a novel multi-task tri-training method that reduces the time and space complexity of classic tri-training. Extensive experiments on two benchmarks for part-of-speech tagging and sentiment analysis are negative: while our novel method establishes a new state-of-the-art for sentiment analysis, it does not fare consistently the best. More importantly, we arrive at the somewhat surprising conclusion that classic tri-training, with some additions, outperforms the state-of-the-art for NLP. Hence classic approaches constitute an important and strong baseline.</p>
</blockquote>
<p>大佬的论文真的难。。太 hardcore 了。。</p>
<h2 id="cross-lingual-Learning"><a href="#cross-lingual-Learning" class="headerlink" title="cross-lingual Learning"></a>cross-lingual Learning</h2><p><img src="/2019/03/04/%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%E7%B3%BB%E5%88%97-1-Neural-Transfer-Learning-for-NLP/12.png"></p>
<p><img src="/2019/03/04/%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%E7%B3%BB%E5%88%97-1-Neural-Transfer-Learning-for-NLP/14.png"></p>
<p><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1805.03620.pdf">On the Limitations of Unsupervised Bilingual Dictionary Induction</a>  </p>
<p><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1808.09334.pdf">A Discriminative Latent-Variable Model for Bilingual Lexicon Induction</a>  </p>
<p><img src="/2019/03/04/%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%E7%B3%BB%E5%88%97-1-Neural-Transfer-Learning-for-NLP/16.png"></p>
<h2 id="multi-task-learning"><a href="#multi-task-learning" class="headerlink" title="multi-task learning"></a>multi-task learning</h2><p><img src="/2019/03/04/%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%E7%B3%BB%E5%88%97-1-Neural-Transfer-Learning-for-NLP/17.png"></p>
<h2 id="sequential-transfer-learning"><a href="#sequential-transfer-learning" class="headerlink" title="sequential transfer learning"></a>sequential transfer learning</h2><p><img src="/2019/03/04/%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%E7%B3%BB%E5%88%97-1-Neural-Transfer-Learning-for-NLP/18.png"></p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2019-02-28T03:00:35.000Z" title="2019/2/28 上午11:00:35">2019-02-28</time>发表</span><span class="level-item"><time dateTime="2021-06-29T08:12:09.141Z" title="2021/6/29 下午4:12:09">2021-06-29</time>更新</span><span class="level-item"><a class="link-muted" href="/categories/transfer-learning/">transfer learning</a></span><span class="level-item">23 分钟读完 (大约3449个字)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2019/02/28/%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%E7%B3%BB%E5%88%97-0-NLP%20classification%20with%20transfer%20learning%20and%20weak%20supervision/">迁移学习系列-0-NLP classification with transfer learning and weak supervision</a></h1><div class="content"><p>paper:  </p>
<ul>
<li><p>Building NLP Classifiers Cheaply With Transfer Learning and Weak Supervision  </p>
</li>
<li><p>A Brief Introduction to Weakly Supervised Learning</p>
</li>
</ul>
<h2 id="motivation"><a href="#motivation" class="headerlink" title="motivation"></a>motivation</h2><p>现在的 state-of-the-art 技术都严重依赖于大量的数据，可以说数据是 NLP 应用的瓶颈(bottleneck)。比如，标注医学领域的电子健康记录需要大量的医学专业知识。</p>
<p>随着 transfer learning, multi-task learning 以及 weak supervision 的发展，NLP 可以尝试着去解决这些问题。</p>
<p>这里将介绍如何在没有公开数据集的情况下，使用少量的数据，来构建一个 dectect anti-smitic tweets 分类器。分为以下 3 个步骤：  </p>
<ul>
<li><p>Collect a small number of labeled examples (~600)  </p>
</li>
<li><p>Use weak supervision to build a training set from many unlabeled examples using weak supervision  </p>
</li>
<li><p>Use a large pre-trained language model for transfer learning</p>
</li>
</ul>
<h2 id="Weak-Supervision"><a href="#Weak-Supervision" class="headerlink" title="Weak Supervision"></a>Weak Supervision</h2><p>何为弱监督学习？</p>
<p><a target="_blank" rel="noopener" href="https://academic.oup.com/nsr/article/5/1/44/4093912">paper: A Brief Introduction to Weakly Supervised Learning</a>  </p>
<p><a target="_blank" rel="noopener" href="http://www.zhuanzhi.ai/document/ef293016d9acc5fd8b6c96e0d3d9b122">翻译版</a></p>
<p>弱监督学习是一个总括性的术语，它涵盖了试图通过较弱的监督来构建预测模型的各种研究。弱监督通常分为三种类型。  </p>
<ul>
<li><p>不完全监督(Incomplete Supervision): 只有训练数据集的一个（通常很小的）子集有标签，其它数据则没有标签。  </p>
</li>
<li><p>不确切监督(inexact supervision): 只有粗粒度的标签。以图像分类任务为例。我们希望图片中的每个物体都被标注；然而我们只有图片级的标签而没有物体级的标签。  </p>
</li>
<li><p>不准确监督(inaccurate supervision)，即给定的标签并不总是真值。</p>
</li>
</ul>
<p><img src="/2019/02/28/%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%E7%B3%BB%E5%88%97-0-NLP%20classification%20with%20transfer%20learning%20and%20weak%20supervision/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-NLP-classification-with-transfer-learning-and-weak-supervision%5C01.png"></p>
<p>图1:三种弱监督学习的示意图。长方形表示特征向量；红色或蓝色表示标签；“？”表示标注可能是不准确的。中间的子图表示了几种弱监督的混合情形</p>
<h3 id="不完全监督"><a href="#不完全监督" class="headerlink" title="不完全监督"></a>不完全监督</h3><p>可以形式化为：$D={(x_1,y_1),…,(x_l,y_l),x_{l+1},…, x_m}$  即有 $l$ 个数据有标签（如 $y_i$ 所示），$u = m-l$ 个数据没有标签。</p>
<p>解决这类问题有两种技术：  </p>
<ul>
<li><p>主动学习(active learning), 也就是有个专家来标注 unlabeled 数据.</p>
</li>
<li><p>半监督学习(semi-supervision), 有一种特殊的半监督学习，叫 transductive learning(传导式学习)，它与（纯）半监督学习之间的差别在于，对测试数据（训练模型要预测的数据）的假设不同。传导式学习持有“封闭世界”的假设，即测试数据是事先给定的，且目标就是优化模型在测试数据上的性能；换句话说，未标注数据就是测试数据。纯半监督学习持有“开放世界”的假设，即测试数据是未知的，且未标注数据不一定是测试数据。实际中，绝大多数情况都是纯半监督学习。</p>
</li>
</ul>
<p><img src="/2019/02/28/%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%E7%B3%BB%E5%88%97-0-NLP%20classification%20with%20transfer%20learning%20and%20weak%20supervision/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-NLP-classification-with-transfer-learning-and-weak-supervision%5C02.png"></p>
<h4 id="有人为干预"><a href="#有人为干预" class="headerlink" title="有人为干预"></a>有人为干预</h4><p>主动学习 active learning.</p>
<h4 id="无人为干预"><a href="#无人为干预" class="headerlink" title="无人为干预"></a>无人为干预</h4><p>半监督学习[3-5]是指在不询问人类专家的条件下挖掘未标注数据。为什么未标注数据对于构建预测模型也会有用？做一个简单的解释[19]，假设数据来自一个由 n 个高斯分布混合的 <a target="_blank" rel="noopener" href="https://panxiaoxie.cn/2018/03/29/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B%E5%88%B0%E9%AB%98%E6%96%AF%E5%88%A4%E5%88%AB%E5%88%86%E6%9E%90%E5%86%8D%E5%88%B0GMM%E5%92%8CEM%E7%AE%97%E6%B3%95/">高斯混合模型(参考以前的笔记)</a>，也就是说：</p>
<p>$$f(x | \theta) = \sum_{j=1}^n \alpha_j f(x | \theta_j)\quad\text{(1)}$$</p>
<p>其中 $\alpha_j$ 为混合系数，$\sum_{j=1}^n \alpha_j = 1$ 并且 $\theta = {\theta_j}$ 是模型参数。在这种情况下，标签 $y_i$ 可以看作一个随机变量，其分布 $P(y_i | x_i, g_i)$ 由混合成分 $g_i$ 和特征向量 $x_i$ 决定。最大化后验概率有：</p>
<p>$$h(x) = {argmax}<em>c \sum</em>{j=1}^n P(y_i = c | g_i = j, x_i) \times P(g_i = j | x_i)\quad(2)$$</p>
<p>其中：$P(g_i = j | x_i) = \dfrac{\alpha_j f(x_i | \theta_j)}  {\sum_{k=1}^n \alpha_k f(x_i | \theta_k)}\quad(3)$</p>
<p>$h(x)$ 可以通过用训练数据估计 $P(y_i = c | g_i = j, x_i)$ 和 $P(g_i = j | x_i)$ 来求得。很明显只有第一项需要需要标签信息。因此，未标注数据可以用来估计提升对第二项的估计，从而提升学习模型的性能。</p>
<p><img src="/2019/02/28/%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%E7%B3%BB%E5%88%97-0-NLP%20classification%20with%20transfer%20learning%20and%20weak%20supervision/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-NLP-classification-with-transfer-learning-and-weak-supervision%5C03.png"></p>
<p>图中 $+,-$ 表示标注样本。而测试样本 $\bigcirc$ 正好在两者中间。</p>
<p>图3给出了一个直观的解释。如果我们只能根据唯一的正负样本点来预测，那我们就只能随机猜测，因为测试样本恰好落在了两个标注样本的中间位置；如果我们能够观测到一些未标注数据，例如图中的灰色样本点，我们就能以较高的置信度判定测试样本为正样本。在此处，尽管未标注样本没有明确的标签信息，它们却隐晦地包含了一些数据分布的信息，而这对于预测模型是有用的。</p>
<p>实际上，在半监督学习中有两个基本假设，即聚类假设（cluster assumption）和流形假设（manifold assumption）；两个假设都是关于数据分布的。前者假设数据具有内在的聚类结构，因此，落入同一个聚类的样本类别相同。后者假设数据分布在一个流形上，因此，相近的样本具有相似的预测。两个假设的本质都是相似的数据输入应该有相似的输出，而未标注数据有助于揭示出样本点之间的相似性</p>
<p>半监督学习有四种主要方法，即生成式方法（generative methods），基于图的方法（graph-based methods），低密度分割法（low-density separation methods）以及基于分歧的方法（disagreement methods）。</p>
<p><strong>生成式方法</strong>[19，20]假设标注数据和未标注数据都由一个固有的模型生成。因此，未标注数据的标签可以看作是模型参数的缺失，并可以通过EM算法（期望-最大化算法）等方法进行估计[21]。这类方法随着为拟合数据而选用的不同生成模型而有所差别。为了达到好的性能，通常需要相关领域的知识来选择合适的生成模型。也有一些将生成模型和判别模型的优点结合起来的尝试[22]。</p>
<p>基于图的方法构建一个图，其节点对应训练样本，其边对应样本之间的关系（通常是某种相似度或距离），而后依据某些准则将标注信息在图上进行扩散；例如标签可以在最小分割图算法得到的不同子图内传播[23]。很明显，模型的性能取决于图是如何构建的[26-28]。值得注意的是，对于m个样本点，这种方法通畅需要O(m^2)存储空间和O(m^3)计算时间复杂度。因此，这种方法严重受制于问题的规模；而且由于难以在不重建图的情况下增加新的节点，所以这种方法天生难以迁移。</p>
<p>基于分歧的方法[5，32，33]生成多个学习器，并让它们合作来挖掘未标注数据，其中不同学习器之间的分歧是让学习过程持续进行的关键。最为著名的典型方法——联合训练（co-traing），通过从两个不同的特征集合（或视角）训练得到的两个学习器来运作。在每个循环中，每个学习器选择其预测置信度最高的未标注样本，并将其预测作为样本的伪标签来训练另一个学习器。这种方法可以通过学习器集成来得到很大提升[34，35]。值得注意的是，基于分歧的方法提供了一种将半监督学习和主动学习自然地结合在一起的方式：它不仅可以让学习器相互学习，对于两个模型都不太确定或者都很确定但相互矛盾的未标注样本，还可以被选定询问“先知”。</p>
<h3 id="不确切监督"><a href="#不确切监督" class="headerlink" title="不确切监督"></a>不确切监督</h3><p>不确切监督是指在某种情况下，我们有一些监督信息，但是并不像我们所期望的那样精确。一个典型的情况是我们只有粗粒度的标注信息。例如，在药物活性预测中[40]，目标是建立一个模型学习已知分子的知识，来预测一种新的分子是否能够用于某种特殊药物的制造。一种分子可能有很多低能量的形态，这种分子能否用于制作该药物取决于这种分子是否有一些特殊形态。然而，即使对于已知的分子，人类专家也只知道其是否合格，而并不知道哪种特定形态是决定性的。</p>
<p>形式化表达为，这一任务是学习 $f: X\rightarrow Y$ ，其训练集为 $D = {(X_1, y_1), …, (X_m, y_m)}$，其中 $X_i = {x_{I, 1}, …, x_{I, m_i}}$, $X_i$ 属于X，且被称为一个包（bag），$x_{i, j}$ 属于 X，是一个样本（j属于 ${1, …, m_i}）$。$m_i$ 是 $X_i$ 中的样本个数，$y_i$ 属于 $Y = {Y, N}$。当存在 $x_{i, p}$ 是正样本时，$X_i$ 就是一个正包（positive bag），其中p是未知的且 p 属于 ${1, …, m_i}$。模型的目标就是预测未知包的标签。这被称为多示例学习（multi-instance learning）[40，41]</p>
<p>多示例学习已经成功应用于多种任务，例如图像分类、检索、注释[48-50]，文本分类[51，52]，垃圾邮件检测[53]，医疗诊断[54]，人脸、目标检测[55，56]，目标类别发现[57]，目标跟踪[58]等等。在这些任务中，我们可以很自然地将一个真实的目标（例如一张图片或一个文本文档）看作一个包；然而，不同于药物活性预测中包里有天然的示例（即分子的不同形态），这里的示例需要生成。一个包生成器明确如何生成示例来组成一个包。通常情况下，从一幅图像中提取的很多小图像块就作为可以这个图像的示例，而章节、段落甚至是句子可以作为一个文本文档的示例。尽管包生成器对于学习效果有重要的影响，但直到最近才出现关于图像包生成器的全面研究[59]；研究表明一些简单的密集取样包生成器要比复杂的生成器性能更好。图5显示了两个简单而有效的图像包生成器。</p>
<p><a target="_blank" rel="noopener" href="http://www.jmlr.org/papers/volume14/li13a/li13a.pdf">51.Convex and Scalable Weakly Labeled SVMs</a></p>
<p>[52.Towards making unlabeled data</p>
<p>never hurt](<a target="_blank" rel="noopener" href="http://www.icml-2011.org/papers/548_icmlpaper.pdf">http://www.icml-2011.org/papers/548_icmlpaper.pdf</a>)</p>
<h3 id="不准确监督"><a href="#不准确监督" class="headerlink" title="不准确监督"></a>不准确监督</h3><p>不准确监督关注监督信息不总是真值的情形；换句话说，有些标签信息可能是错误的。其形式化表示与概述结尾部分几乎完全相同，除了训练数据集中的y_i可能是错误的。</p>
<p>一个最近出现的不准确监督的情景发生在众包模式中(crowdsourcing)[74],即一个将工作外包给个人的流行模式。</p>
<p>在带有真值标签的大量训练样本的强监督条件下，监督学习技术已经取得了巨大的成功。然而，在真实的任务中，收集监督信息往往代价高昂，因此探索弱监督学习通常是更好的方式。</p>
<h2 id="Snorkel"><a href="#Snorkel" class="headerlink" title="Snorkel"></a>Snorkel</h2><p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1711.10160">paper:Snorkel: Rapid Training Data Creation with Weak Supervision</a></p>
<h3 id="motivation-1"><a href="#motivation-1" class="headerlink" title="motivation"></a>motivation</h3><p>deep learning 需要大量的标注数据。这对于一些大公司尚且能够雇佣标注人员，而很多小公司则将目标转向弱监督学习。尤其是，当数据的标注需要领域专家时(subject matter experts (SMEs))，标注数据变得更加困难。</p>
<p>弱监督学习包括一下形式：  </p>
<ul>
<li><p>distant supervision:  the records of an external knowledge base are heuristically aligned with data points to produce noisy labels [4,7,32]  </p>
</li>
<li><p>crowsourced labels[37,50]  </p>
</li>
<li><p>rules and heuristics for labeling data[39,52]  </p>
</li>
</ul>
<blockquote>
<p>Snorkel learns the accuracies of weak supervision sources withoust access to</p>
</blockquote>
<p>ground truth using a generative model [38]. Furthermore, it also learns correlations and other statistical dependencies among sources, correcting for dependencies in labeling functions that skew the estimated accuracies [5]  </p>
<p>Snorkel 生成训练数据的方法来自于作者的另外一篇论文：<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1605.07723.pdf">Data programming: Creating large training sets, quickly, NIPS 2016</a>,不仅能给出弱监督得到的样本的置信度，还能学习得到样本之间的相关性和统计依赖。</p>
</div></article></div></div><!--!--><div class="column column-right is-4-tablet is-4-desktop is-4-widescreen  order-3"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar" src="/img/avatar.png" alt="panxiaoxie"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">panxiaoxie</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Beijing, China</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">文章</p><a href="/archives"><p class="title">116</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">分类</p><a href="/categories"><p class="title">38</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">标签</p><a href="/tags"><p class="title">35</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/PanXiebit" target="_blank" rel="noopener">关注我</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/PanXiebit"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Email" href="/ftdpanxie@gmail.com"><i class="fa fa-envelope"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="RSS" href="/"><i class="fas fa-rss"></i></a></div></div></div><!--!--><div class="card widget" data-type="links"><div class="card-content"><div class="menu"><h3 class="menu-label">链接</h3><ul class="menu-list"><li><a class="level is-mobile" href="https://github.com/PanXiebit" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">github</span></span><span class="level-right"><span class="level-item tag">github.com</span></span></a></li><li><a class="level is-mobile" href="ftdpanxie@gmail.com" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">email</span></span><span class="level-right"><span class="level-item tag">ftdpanxie@gmail.com</span></span></a></li></ul></div></div></div><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">分类</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/C/"><span class="level-start"><span class="level-item">C++</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/CSAPP/"><span class="level-start"><span class="level-item">CSAPP</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/DRL/"><span class="level-start"><span class="level-item">DRL</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/GAN/"><span class="level-start"><span class="level-item">GAN</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li><li><a class="level is-mobile" href="/categories/GAN-RL/"><span class="level-start"><span class="level-item">GAN, RL</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/ML/"><span class="level-start"><span class="level-item">ML</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/NLP/"><span class="level-start"><span class="level-item">NLP</span></span><span class="level-end"><span class="level-item tag">14</span></span></a></li><li><a class="level is-mobile" href="/categories/TensorFlow/"><span class="level-start"><span class="level-item">TensorFlow</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/cs224d/"><span class="level-start"><span class="level-item">cs224d</span></span><span class="level-end"><span class="level-item tag">10</span></span></a></li><li><a class="level is-mobile" href="/categories/generation/"><span class="level-start"><span class="level-item">generation</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/interview/"><span class="level-start"><span class="level-item">interview</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/machine-translation/"><span class="level-start"><span class="level-item">machine translation</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/python/"><span class="level-start"><span class="level-item">python</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/pytorch/"><span class="level-start"><span class="level-item">pytorch</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/reinforcement-learning/"><span class="level-start"><span class="level-item">reinforcement learning</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/sign-language-recognition/"><span class="level-start"><span class="level-item">sign language recognition</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/transfer-learning/"><span class="level-start"><span class="level-item">transfer learning</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"><span class="level-start"><span class="level-item">数据结构与算法</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile" href="/categories/%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB/"><span class="level-start"><span class="level-item">文本分类</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"><span class="level-start"><span class="level-item">论文笔记</span></span><span class="level-end"><span class="level-item tag">40</span></span></a><ul><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/DL/"><span class="level-start"><span class="level-item">DL</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/ESA/"><span class="level-start"><span class="level-item">ESA</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/GAN/"><span class="level-start"><span class="level-item">GAN</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/MRC-and-QA/"><span class="level-start"><span class="level-item">MRC and QA</span></span><span class="level-end"><span class="level-item tag">7</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/Machine-Translation/"><span class="level-start"><span class="level-item">Machine Translation</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/NLP/"><span class="level-start"><span class="level-item">NLP</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/Transformer/"><span class="level-start"><span class="level-item">Transformer</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/capsules/"><span class="level-start"><span class="level-item">capsules</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/computer-vision/"><span class="level-start"><span class="level-item">computer vision</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/constrast-learning/"><span class="level-start"><span class="level-item">constrast learning</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/data-augmentation/"><span class="level-start"><span class="level-item">data augmentation</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/dialogue-system/"><span class="level-start"><span class="level-item">dialogue system</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/language-model/"><span class="level-start"><span class="level-item">language model</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/machine-translation/"><span class="level-start"><span class="level-item">machine translation</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/open-set-recognition/"><span class="level-start"><span class="level-item">open set recognition</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/sentence-embedding/"><span class="level-start"><span class="level-item">sentence embedding</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/text-matching/"><span class="level-start"><span class="level-item">text matching</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/vision-language/"><span class="level-start"><span class="level-item">vision-language</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li></ul></div></div></div></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/panxiaoxie.png" alt="潘小榭" height="28"></a><p class="is-size-7"><span>&copy; 2021 Xie Pan</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("zh-CN");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="回到顶端" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "此网站使用Cookie来改善您的体验。",
          dismiss: "知道了！",
          allow: "允许使用Cookie",
          deny: "拒绝",
          link: "了解更多",
          policy: "Cookie政策",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.5/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="想要查找什么..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"想要查找什么...","untitled":"(无标题)","posts":"文章","pages":"页面","categories":"分类","tags":"标签"});
        });</script></body></html>