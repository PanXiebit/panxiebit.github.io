<!doctype html>
<html lang="zh"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>åˆ†ç±»: æ–‡æœ¬åˆ†ç±» - æ½˜å°æ¦­</title><link rel="manifest" href="/manifest.json"><meta name="theme-color" content="black"><meta name="application-name" content="panxiaoxie"><meta name="msapplication-TileImage" content="/img/avatar.png"><meta name="msapplication-TileColor" content="black"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="panxiaoxie"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta property="og:type" content="blog"><meta property="og:title" content="panxiaoxie"><meta property="og:url" content="https://github.com/PanXiebit"><meta property="og:site_name" content="panxiaoxie"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://www.qt86.com/cache/1625298592_187938.png"><meta property="article:author" content="panxiaoxie"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="https://www.qt86.com/cache/1625298592_187938.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"http://www.panxiaoxie.cn"},"headline":"æ½˜å°æ¦­","image":["http://www.panxiaoxie.cn/img/og_image.png"],"author":{"@type":"Person","name":"Xie Pan"},"publisher":{"@type":"Organization","name":"æ½˜å°æ¦­","logo":{"@type":"ImageObject","url":"http://www.panxiaoxie.cn/img/panxiaoxie.png"}},"description":null}</script><link rel="icon" href="/img/avatar.png"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/css/justifiedGallery.min.css"><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script><!--!--><!--!--><meta name="generator" content="Hexo 5.4.0"></head><body class="is-2-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/panxiaoxie.png" alt="æ½˜å°æ¦­" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">ä¸»é¡µ</a><a class="navbar-item" href="/archives">å½’æ¡£</a><a class="navbar-item" href="/categories">åˆ†ç±»</a><a class="navbar-item" href="/tags">æ ‡ç­¾</a><a class="navbar-item" href="/about">å…³äºæˆ‘</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/PanXiebit"><i class="fab fa-github"></i></a><a class="navbar-item search" title="æœç´¢" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-10-widescreen"><div class="card"><div class="card-content"><nav class="breadcrumb" aria-label="breadcrumbs"><ul><li><a href="/categories">åˆ†ç±»</a></li><li class="is-active"><a href="#" aria-current="page">æ–‡æœ¬åˆ†ç±»</a></li></ul></nav></div></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2018-08-07T01:28:38.000Z" title="2018/8/7 ä¸Šåˆ9:28:38">2018-08-07</time>å‘è¡¨</span><span class="level-item"><time dateTime="2021-01-27T08:44:33.634Z" title="2021/1/27 ä¸‹åˆ4:44:33">2021-01-27</time>æ›´æ–°</span><span class="level-item"><a class="link-muted" href="/categories/%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB/">æ–‡æœ¬åˆ†ç±»</a></span><span class="level-item">34 åˆ†é’Ÿè¯»å®Œ (å¤§çº¦5038ä¸ªå­—)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2018/08/07/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E8%8B%B1%E6%96%87%E6%96%87%E6%9C%AC%E9%A2%84%E5%A4%84%E7%90%86/">æœºå™¨å­¦ä¹ -è‹±æ–‡æ–‡æœ¬é¢„å¤„ç†</a></h1><div class="content"><h3 id="è½¬è½½è‡ªï¼šhttp-www-cnblogs-com-pinard-p-6756534-html"><a href="#è½¬è½½è‡ªï¼šhttp-www-cnblogs-com-pinard-p-6756534-html" class="headerlink" title="è½¬è½½è‡ªï¼šhttp://www.cnblogs.com/pinard/p/6756534.html"></a>è½¬è½½è‡ªï¼š<a target="_blank" rel="noopener" href="http://www.cnblogs.com/pinard/p/6756534.html">http://www.cnblogs.com/pinard/p/6756534.html</a></h3><h2 id="è‹±æ–‡æ–‡æœ¬æŒ–æ˜é¢„å¤„ç†ç‰¹ç‚¹"><a href="#è‹±æ–‡æ–‡æœ¬æŒ–æ˜é¢„å¤„ç†ç‰¹ç‚¹" class="headerlink" title="è‹±æ–‡æ–‡æœ¬æŒ–æ˜é¢„å¤„ç†ç‰¹ç‚¹"></a>è‹±æ–‡æ–‡æœ¬æŒ–æ˜é¢„å¤„ç†ç‰¹ç‚¹</h2><p>è‹±æ–‡æ–‡æœ¬çš„é¢„å¤„ç†æ–¹æ³•å’Œä¸­æ–‡çš„æœ‰éƒ¨åˆ†åŒºåˆ«ã€‚é¦–å…ˆï¼Œè‹±æ–‡æ–‡æœ¬æŒ–æ˜é¢„å¤„ç†ä¸€èˆ¬å¯ä»¥ä¸åšåˆ†è¯ï¼ˆç‰¹æ®Šéœ€æ±‚é™¤å¤–ï¼‰ï¼Œè€Œä¸­æ–‡é¢„å¤„ç†åˆ†è¯æ˜¯å¿…ä¸å¯å°‘çš„ä¸€æ­¥ã€‚ç¬¬äºŒç‚¹ï¼Œå¤§éƒ¨åˆ†è‹±æ–‡æ–‡æœ¬éƒ½æ˜¯uft-8çš„ç¼–ç ï¼Œè¿™æ ·åœ¨å¤§å¤šæ•°æ—¶å€™å¤„ç†çš„æ—¶å€™ä¸ç”¨è€ƒè™‘ç¼–ç è½¬æ¢çš„é—®é¢˜ï¼Œè€Œä¸­æ–‡æ–‡æœ¬å¤„ç†å¿…é¡»è¦å¤„ç†unicodeçš„ç¼–ç é—®é¢˜ã€‚</p>
<p>è€Œè‹±æ–‡æ–‡æœ¬çš„é¢„å¤„ç†ä¹Ÿæœ‰è‡ªå·±ç‰¹æ®Šçš„åœ°æ–¹ï¼Œç¬¬ä¸‰ç‚¹å°±æ˜¯æ‹¼å†™é—®é¢˜ï¼Œå¾ˆå¤šæ—¶å€™ï¼Œæˆ‘ä»¬çš„é¢„å¤„ç†è¦åŒ…æ‹¬æ‹¼å†™æ£€æŸ¥ï¼Œæ¯”å¦‚â€œHelo Worldâ€è¿™æ ·çš„é”™è¯¯ï¼Œæˆ‘ä»¬ä¸èƒ½åœ¨åˆ†æçš„æ—¶å€™è®²é”™çº é”™ã€‚æ‰€ä»¥éœ€è¦åœ¨é¢„å¤„ç†å‰åŠ ä»¥çº æ­£ã€‚ç¬¬å››ç‚¹å°±æ˜¯è¯å¹²æå–(stemming)å’Œè¯å½¢è¿˜åŸ(lemmatization)ã€‚è¿™ä¸ªä¸œè¥¿ä¸»è¦æ˜¯è‹±æ–‡æœ‰å•æ•°ï¼Œå¤æ•°å’Œå„ç§æ—¶æ€ï¼Œå¯¼è‡´ä¸€ä¸ªè¯ä¼šæœ‰ä¸åŒçš„å½¢å¼ã€‚æ¯”å¦‚â€œcountriesâ€å’Œâ€countryâ€ï¼Œâ€wolfâ€å’Œâ€wolvesâ€ï¼Œæˆ‘ä»¬æœŸæœ›æ˜¯æœ‰ä¸€ä¸ªè¯ã€‚</p>
<h2 id="è‹±æ–‡æ–‡æœ¬æŒ–æ˜é¢„å¤„ç†ä¸€ï¼šæ•°æ®æ”¶é›†"><a href="#è‹±æ–‡æ–‡æœ¬æŒ–æ˜é¢„å¤„ç†ä¸€ï¼šæ•°æ®æ”¶é›†" class="headerlink" title="è‹±æ–‡æ–‡æœ¬æŒ–æ˜é¢„å¤„ç†ä¸€ï¼šæ•°æ®æ”¶é›†"></a>è‹±æ–‡æ–‡æœ¬æŒ–æ˜é¢„å¤„ç†ä¸€ï¼šæ•°æ®æ”¶é›†</h2><p>è¿™éƒ¨åˆ†è‹±æ–‡å’Œä¸­æ–‡ç±»ä¼¼ã€‚è·å–æ–¹æ³•ä¸€èˆ¬æœ‰ä¸¤ç§ï¼šä½¿ç”¨åˆ«äººåšå¥½çš„è¯­æ–™åº“å’Œè‡ªå·±ç”¨çˆ¬è™«å»åœ¨ç½‘ä¸Šå»çˆ¬è‡ªå·±çš„è¯­æ–™æ•°æ®ã€‚</p>
<p>å¯¹äºç¬¬ä¸€ç§æ–¹æ³•ï¼Œå¸¸ç”¨çš„æ–‡æœ¬è¯­æ–™åº“åœ¨ç½‘ä¸Šæœ‰å¾ˆå¤šï¼Œå¦‚æœå¤§å®¶åªæ˜¯å­¦ä¹ ï¼Œåˆ™å¯ä»¥ç›´æ¥ä¸‹è½½ä¸‹æ¥ä½¿ç”¨ï¼Œä½†å¦‚æœæ˜¯æŸäº›ç‰¹æ®Šä¸»é¢˜çš„è¯­æ–™åº“ï¼Œæ¯”å¦‚â€œdeep learningâ€ç›¸å…³çš„è¯­æ–™åº“ï¼Œåˆ™è¿™ç§æ–¹æ³•è¡Œä¸é€šï¼Œéœ€è¦æˆ‘ä»¬è‡ªå·±ç”¨ç¬¬äºŒç§æ–¹æ³•å»è·å–ã€‚</p>
<p>å¯¹äºç¬¬äºŒç§ä½¿ç”¨çˆ¬è™«çš„æ–¹æ³•ï¼Œå¼€æºå·¥å…·æœ‰å¾ˆå¤šï¼Œé€šç”¨çš„çˆ¬è™«æˆ‘ä¸€èˆ¬ä½¿ç”¨beautifulsoupã€‚ä½†æ˜¯æˆ‘ä»¬æˆ‘ä»¬éœ€è¦æŸäº›ç‰¹æ®Šçš„è¯­æ–™æ•°æ®ï¼Œæ¯”å¦‚ä¸Šé¢æåˆ°çš„â€œdeep learningâ€ç›¸å…³çš„è¯­æ–™åº“ï¼Œåˆ™éœ€è¦ç”¨ä¸»é¢˜çˆ¬è™«ï¼ˆä¹Ÿå«èšç„¦çˆ¬è™«ï¼‰æ¥å®Œæˆã€‚è¿™ä¸ªæˆ‘ä¸€èˆ¬ä½¿ç”¨acheã€‚ acheå…è®¸æˆ‘ä»¬ç”¨å…³é”®å­—æˆ–è€…ä¸€ä¸ªåˆ†ç±»ç®—æ³•æ¨¡å‹æ¥è¿‡æ»¤å‡ºæˆ‘ä»¬éœ€è¦çš„ä¸»é¢˜è¯­æ–™ï¼Œæ¯”è¾ƒå¼ºå¤§ã€‚</p>
<h2 id="è‹±æ–‡æ–‡æœ¬æŒ–æ˜é¢„å¤„ç†äºŒï¼šé™¤å»æ•°æ®ä¸­éæ–‡æœ¬éƒ¨åˆ†"><a href="#è‹±æ–‡æ–‡æœ¬æŒ–æ˜é¢„å¤„ç†äºŒï¼šé™¤å»æ•°æ®ä¸­éæ–‡æœ¬éƒ¨åˆ†" class="headerlink" title="è‹±æ–‡æ–‡æœ¬æŒ–æ˜é¢„å¤„ç†äºŒï¼šé™¤å»æ•°æ®ä¸­éæ–‡æœ¬éƒ¨åˆ†"></a>è‹±æ–‡æ–‡æœ¬æŒ–æ˜é¢„å¤„ç†äºŒï¼šé™¤å»æ•°æ®ä¸­éæ–‡æœ¬éƒ¨åˆ†</h2><p>è¿™ä¸€æ­¥ä¸»è¦æ˜¯é’ˆå¯¹æˆ‘ä»¬ç”¨çˆ¬è™«æ”¶é›†çš„è¯­æ–™æ•°æ®ï¼Œç”±äºçˆ¬ä¸‹æ¥çš„å†…å®¹ä¸­æœ‰å¾ˆå¤šhtmlçš„ä¸€äº›æ ‡ç­¾ï¼Œéœ€è¦å»æ‰ã€‚å°‘é‡çš„éæ–‡æœ¬å†…å®¹çš„å¯ä»¥ç›´æ¥ç”¨Pythonçš„æ­£åˆ™è¡¨è¾¾å¼(re)åˆ é™¤, å¤æ‚çš„åˆ™å¯ä»¥ç”¨<a target="_blank" rel="noopener" href="https://www.crummy.com/software/BeautifulSoup/">beautifulsoup</a>æ¥å»é™¤ã€‚å¦å¤–è¿˜æœ‰ä¸€äº›ç‰¹æ®Šçš„éè‹±æ–‡å­—ç¬¦(non-alpha),ä¹Ÿå¯ä»¥ç”¨Pythonçš„æ­£åˆ™è¡¨è¾¾å¼(re)åˆ é™¤ã€‚</p>
<h3 id="re-æ¨¡å—"><a href="#re-æ¨¡å—" class="headerlink" title="re æ¨¡å—"></a>re æ¨¡å—</h3><p>å‚è€ƒ <a target="_blank" rel="noopener" href="https://songlee24.github.io/2014/09/01/python-library-02/">blog</a>  </p>
<p>æ­£åˆ™è¡¨è¾¾å¼ï¼ˆRegular Expressionï¼‰æ˜¯å­—ç¬¦ä¸²å¤„ç†çš„å¸¸ç”¨å·¥å…·ï¼Œé€šå¸¸è¢«ç”¨æ¥æ£€ç´¢ã€æ›¿æ¢é‚£äº›ç¬¦åˆæŸä¸ªæ¨¡å¼ï¼ˆPatternï¼‰çš„æ–‡æœ¬ã€‚å¾ˆå¤šç¨‹åºè®¾è®¡è¯­è¨€éƒ½æ”¯æŒæ­£åˆ™è¡¨è¾¾å¼ï¼ŒåƒPerlã€Javaã€C/C++ã€‚åœ¨ Python ä¸­æ˜¯é€šè¿‡æ ‡å‡†åº“ä¸­çš„ re æ¨¡å— æä¾›å¯¹æ­£åˆ™çš„æ”¯æŒã€‚</p>
<p>å…³äºæ­£åˆ™è¡¨è¾¾å¼çš„è¯­æ³•å¯ä»¥çœ‹</p>
<ul>
<li><p><a href="https://www.panxiaoxie.cn/2018/04/09/chapter2-%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%E3%80%81%E6%96%87%E6%9C%AC%E6%A0%87%E5%87%86%E5%8C%96%E5%92%8C%E7%BC%96%E8%BE%91%E8%B7%9D%E7%A6%BB/">speech and language processing chapter2</a></p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/wl_ss/article/details/78241782">æ­£åˆ™è¡¨è¾¾å¼ä¸­çš„*ï¼Œ+ï¼Œï¼Ÿä»¥åŠ\wå’Œ\Wçš„åŒºåˆ«ç­‰å¸¸è§é—®é¢˜çš„æ€»ç»“</a></p>
</li>
</ul>
<h4 id="ç¼–è¯‘æ­£åˆ™è¡¨è¾¾å¼"><a href="#ç¼–è¯‘æ­£åˆ™è¡¨è¾¾å¼" class="headerlink" title="ç¼–è¯‘æ­£åˆ™è¡¨è¾¾å¼"></a>ç¼–è¯‘æ­£åˆ™è¡¨è¾¾å¼</h4><p>re æ¨¡å—æä¾›äº† re.compile() å‡½æ•°å°†ä¸€ä¸ªå­—ç¬¦ä¸²ç¼–è¯‘æˆ pattern objectï¼Œç”¨äºåŒ¹é…æˆ–æœç´¢ã€‚å‡½æ•°åŸå‹å¦‚ä¸‹ï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">re.<span class="built_in">compile</span>(pattern, flags=<span class="number">0</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>re.compile() è¿˜æ¥å—ä¸€ä¸ªå¯é€‰çš„å‚æ•° flagï¼Œç”¨äºæŒ‡å®šæ­£åˆ™åŒ¹é…çš„æ¨¡å¼ã€‚å…³äºåŒ¹é…æ¨¡å¼ï¼Œåé¢å°†ä¼šè®²åˆ°ã€‚</p>
<h4 id="åæ–œæ çš„å›°æ‰°"><a href="#åæ–œæ çš„å›°æ‰°" class="headerlink" title="åæ–œæ çš„å›°æ‰°"></a>åæ–œæ çš„å›°æ‰°</h4><p>åœ¨ python çš„å­—ç¬¦ä¸²ä¸­ï¼Œ\ æ˜¯è¢«å½“åšè½¬ä¹‰å­—ç¬¦çš„ã€‚åœ¨æ­£åˆ™è¡¨è¾¾å¼ä¸­ï¼Œ\ ä¹Ÿæ˜¯è¢«å½“åšè½¬ä¹‰å­—ç¬¦ã€‚è¿™å°±å¯¼è‡´äº†ä¸€ä¸ªé—®é¢˜ï¼šå¦‚æœä½ è¦åŒ¹é… \ å­—ç¬¦ä¸²ï¼Œé‚£ä¹ˆä¼ é€’ç»™ re.compile() çš„å­—ç¬¦ä¸²å¿…é¡»æ˜¯ <code>â€\\\\â€œ</code>ã€‚</p>
<p>ç”±äºå­—ç¬¦ä¸²çš„è½¬ä¹‰ï¼Œæ‰€ä»¥å®é™…ä¼ é€’ç»™ re.compile() çš„æ˜¯ <code>â€\\â€œ</code>ï¼Œç„¶åå†é€šè¿‡æ­£åˆ™è¡¨è¾¾å¼çš„è½¬ä¹‰ï¼Œ<code>â€\\â€œ</code> ä¼šåŒ¹é…åˆ°å­—ç¬¦â€\â€œã€‚è¿™æ ·è™½ç„¶å¯ä»¥æ­£ç¡®åŒ¹é…åˆ°å­—ç¬¦ \ï¼Œä½†æ˜¯å¾ˆéº»çƒ¦ï¼Œè€Œä¸”å®¹æ˜“æ¼å†™åæ–œæ è€Œå¯¼è‡´ Bugã€‚é‚£ä¹ˆæœ‰ä»€ä¹ˆå¥½çš„è§£å†³æ–¹æ¡ˆå‘¢ï¼Ÿ</p>
<p>åŸå§‹å­—ç¬¦ä¸²å¾ˆå¥½çš„è§£å†³äº†è¿™ä¸ªé—®é¢˜ï¼Œé€šè¿‡åœ¨å­—ç¬¦ä¸²å‰é¢æ·»åŠ ä¸€ä¸ªrï¼Œè¡¨ç¤ºåŸå§‹å­—ç¬¦ä¸²ï¼Œä¸è®©å­—ç¬¦ä¸²çš„åæ–œæ å‘ç”Ÿè½¬ä¹‰ã€‚é‚£ä¹ˆå°±å¯ä»¥ä½¿ç”¨<code>r&quot;\\\\&quot;</code>æ¥åŒ¹é…å­—ç¬¦ <code>\</code>äº†ã€‚</p>
<h3 id="patern-object-æ‰§è¡ŒåŒ¹é…"><a href="#patern-object-æ‰§è¡ŒåŒ¹é…" class="headerlink" title="patern object æ‰§è¡ŒåŒ¹é…"></a>patern object æ‰§è¡ŒåŒ¹é…</h3><p>ä¸€æ—¦ä½ ç¼–è¯‘å¾—åˆ°äº†ä¸€ä¸ª pattern objectï¼Œä½ å°±å¯ä»¥ä½¿ç”¨ pattern object çš„æ–¹æ³•æˆ–å±æ€§è¿›è¡ŒåŒ¹é…äº†ï¼Œä¸‹é¢åˆ—ä¸¾å‡ ä¸ªå¸¸ç”¨çš„æ–¹æ³•ï¼Œæ›´å¤šè¯·çœ‹<a target="_blank" rel="noopener" href="https://docs.python.org/3/library/re.html#regular-expression-objects">è¿™é‡Œ</a>ã€‚</p>
<p><code>Pattern.match(string[, pos[, endpos]])</code></p>
<ul>
<li><p>åŒ¹é…ä» pos åˆ° endpos çš„å­—ç¬¦å­ä¸²çš„å¼€å¤´ã€‚åŒ¹é…æˆåŠŸè¿”å›ä¸€ä¸ª match objectï¼Œä¸åŒ¹é…è¿”å› Noneã€‚  </p>
</li>
<li><p>pos çš„é»˜è®¤å€¼æ˜¯0ï¼Œendpos çš„é»˜è®¤å€¼æ˜¯ len(string)ï¼Œæ‰€ä»¥é»˜è®¤æƒ…å†µä¸‹æ˜¯åŒ¹é…æ•´ä¸ªå­—ç¬¦ä¸²çš„å¼€å¤´ã€‚</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">pattern = re.<span class="built_in">compile</span>(<span class="string">&quot;d&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(pattern.match(<span class="string">&#x27;dog&#x27;</span>))  <span class="comment"># åœ¨å­—ä¸²å¼€å¤´ï¼ŒåŒ¹é…æˆåŠŸ</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(pattern.match(<span class="string">&#x27;god&#x27;</span>))  <span class="comment"># ä¸å†å­ä¸²å¼€å¤´ï¼ŒåŒ¹é…ä¸æˆåŠŸ</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(pattern.match(<span class="string">&#x27;ddaa&#x27;</span>, <span class="number">1</span>,<span class="number">5</span>)) <span class="comment"># åœ¨å­ä¸²å¼€å¤´,åŒ¹é…æˆåŠŸ</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(pattern.match(<span class="string">&#x27;monday&#x27;</span>, <span class="number">3</span>))  </span><br><span class="line"></span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">&lt;_sre.SRE_Match object; span=(0, 1), match=&#x27;d&#x27;&gt;</span><br><span class="line"></span><br><span class="line">&lt;_sre.SRE_Match object; span=(0, 1), match=&#x27;g&#x27;&gt;</span><br><span class="line"></span><br><span class="line">&lt;_sre.SRE_Match object; span=(1, 2), match=&#x27;d&#x27;&gt;</span><br><span class="line"></span><br><span class="line">&lt;_sre.SRE_Match object; span=(3, 4), match=&#x27;d&#x27;&gt;</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<p><code>regex.search(string[, pos[, endpos]])</code></p>
<ul>
<li><p>æ‰«ææ•´ä¸ªå­—ç¬¦ä¸²ï¼Œå¹¶è¿”å›å®ƒæ‰¾åˆ°çš„ç¬¬ä¸€ä¸ªåŒ¹é…  </p>
</li>
<li><p>å’Œ regex.match() ä¸€æ ·ï¼Œå¯ä»¥é€šè¿‡ pos å’Œ endpos æŒ‡å®šèŒƒå›´</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">pattern = re.<span class="built_in">compile</span>(<span class="string">&quot;ar&#123;1&#125;&quot;</span>)</span><br><span class="line"></span><br><span class="line">match = pattern.search(<span class="string">&quot;marray&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(match)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&lt;_sre.SRE_Match <span class="built_in">object</span>; span=(<span class="number">1</span>, <span class="number">3</span>), match=<span class="string">&#x27;ar&#x27;</span>&gt;</span><br><span class="line"></span><br></pre></td></tr></table></figure>





<p><code>regex.findall(string[, pos[, endpos]])</code></p>
<ul>
<li><p>æ‰¾åˆ°æ‰€æœ‰åŒ¹é…çš„å­ä¸²ï¼Œå¹¶è¿”å›ä¸€ä¸ª list    </p>
</li>
<li><p>å¯é€‰å‚æ•° pos å’Œ endpos å’Œä¸Šé¢ä¸€æ ·  </p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">pattern = re.<span class="built_in">compile</span>(<span class="string">r&quot;\d+&quot;</span>) <span class="comment"># åŒ¹é…å­—ç¬¦ä¸²ä¸­çš„æ•°å­—</span></span><br><span class="line"></span><br><span class="line">lst = pattern.findall(<span class="string">&quot;abc1def2rst3xyz&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(lst)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">[<span class="string">&#x27;1&#x27;</span>, <span class="string">&#x27;2&#x27;</span>, <span class="string">&#x27;3&#x27;</span>]</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<p><code>regex.finditer(string[, pos[, endpos]])</code></p>
<ul>
<li><p>æ‰¾åˆ°æ‰€æœ‰åŒ¹é…çš„å­ä¸²ï¼Œå¹¶è¿”å›ç”±è¿™äº›åŒ¹é…ç»“æœï¼ˆmatch objectï¼‰ç»„æˆçš„è¿­ä»£å™¨  </p>
</li>
<li><p>å¯é€‰å‚æ•° pos å’Œ endpos å’Œä¸Šé¢ä¸€æ ·ã€‚</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">pattern = re.<span class="built_in">compile</span>(<span class="string">r&quot;\d+&quot;</span>)</span><br><span class="line"></span><br><span class="line">p = pattern.finditer(<span class="string">&quot;abc1def2rst3xyz&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> p:</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(i)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&lt;_sre.SRE_Match <span class="built_in">object</span>; span=(<span class="number">3</span>, <span class="number">4</span>), match=<span class="string">&#x27;1&#x27;</span>&gt;</span><br><span class="line"></span><br><span class="line">&lt;_sre.SRE_Match <span class="built_in">object</span>; span=(<span class="number">7</span>, <span class="number">8</span>), match=<span class="string">&#x27;2&#x27;</span>&gt;</span><br><span class="line"></span><br><span class="line">&lt;_sre.SRE_Match <span class="built_in">object</span>; span=(<span class="number">11</span>, <span class="number">12</span>), match=<span class="string">&#x27;3&#x27;</span>&gt;</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h4 id="match-object-è·å–ç»“æœ"><a href="#match-object-è·å–ç»“æœ" class="headerlink" title="match object è·å–ç»“æœ"></a>match object è·å–ç»“æœ</h4><p>åœ¨ä¸Šé¢è®²åˆ°ï¼Œé€šè¿‡ pattern object çš„æ–¹æ³•ï¼ˆé™¤ findall å¤–ï¼‰è¿›è¡ŒåŒ¹é…å¾—åˆ°çš„è¿”å›ç»“æœéƒ½æ˜¯ match objectã€‚æ¯ä¸€ä¸ª match object éƒ½åŒ…å«äº†åŒ¹é…åˆ°çš„ç›¸å…³ä¿¡æ¯ï¼Œæ¯”å¦‚ï¼Œèµ·å§‹ä½ç½®ã€åŒ¹é…åˆ°çš„å­ä¸²ã€‚é‚£ä¹ˆï¼Œæˆ‘ä»¬å¦‚ä½•ä» match object ä¸­æå–è¿™äº›ä¿¡æ¯å‘¢ï¼Ÿ</p>
<p><code>match.group([group1, ...])ï¼š</code></p>
<ul>
<li><p>è¿”å› match object ä¸­çš„å­—ç¬¦ä¸²ã€‚      </p>
</li>
<li><p>æ¯ä¸€ä¸ª ( ) éƒ½æ˜¯ä¸€ä¸ªåˆ†ç»„ï¼Œåˆ†ç»„ç¼–å·ä»1å¼€å§‹ï¼Œä»å·¦å¾€å³ï¼Œæ¯é‡åˆ°ä¸€ä¸ªå·¦æ‹¬å·ï¼Œåˆ†ç»„ç¼–å·+1ã€‚   </p>
</li>
<li><p>ç»„ 0 æ€»æ˜¯å­˜åœ¨çš„ï¼Œå®ƒå°±æ˜¯æ•´ä¸ªè¡¨è¾¾å¼  </p>
</li>
<li><p>æ²¡æœ‰å‚æ•°æ—¶ï¼Œgroup1é»˜è®¤ä¸º0ï¼Œè¿™æ—¶è¿”å›æ•´ä¸ªåŒ¹é…åˆ°çš„å­—ç¬¦ä¸²ã€‚  </p>
</li>
<li><p>æŒ‡å®šä¸€ä¸ªå‚æ•°ï¼ˆæ•´æ•°ï¼‰æ—¶ï¼Œè¿”å›è¯¥åˆ†ç»„åŒ¹é…åˆ°çš„å­—ç¬¦ä¸²ã€‚  </p>
</li>
<li><p>æŒ‡å®šå¤šä¸ªå‚æ•°æ—¶ï¼Œè¿”å›ç”±é‚£å‡ ä¸ªåˆ†ç»„åŒ¹é…åˆ°çš„å­—ç¬¦ä¸²ç»„æˆçš„ tupleã€‚</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">pattern = re.<span class="built_in">compile</span>(<span class="string">r&quot;(\w+) (\w+)&quot;</span>) <span class="comment"># \w åŒ¹é…ä»»æ„å­—æ¯ï¼Œæ•°å­—ï¼Œä¸‹åˆ’çº¿</span></span><br><span class="line"></span><br><span class="line">m = pattern.match(<span class="string">&quot;He _ Kobe Bryant, Lakers player&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(m)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(m.group())</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(m.group(<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(m.group(<span class="number">2</span>))</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(m.group(<span class="number">1</span>,<span class="number">2</span>))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&lt;_sre.SRE_Match <span class="built_in">object</span>; span=(<span class="number">0</span>, <span class="number">4</span>), match=<span class="string">&#x27;He _&#x27;</span>&gt;</span><br><span class="line"></span><br><span class="line">He _</span><br><span class="line"></span><br><span class="line">He</span><br><span class="line"></span><br><span class="line">_</span><br><span class="line"></span><br><span class="line">(<span class="string">&#x27;He&#x27;</span>, <span class="string">&#x27;_&#x27;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>







<p><code>match.groups()</code></p>
<ul>
<li>è¿”å›ç”±æ‰€æœ‰åˆ†ç»„åŒ¹é…åˆ°çš„å­—ç¬¦ä¸²ç»„æˆçš„ tupleã€‚</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">m = re.match(<span class="string">r&quot;(\d+)\.(\d+)&quot;</span>, <span class="string">&#x27;24.163&#x27;</span>)</span><br><span class="line"></span><br><span class="line">m.groups()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">(<span class="string">&#x27;24&#x27;</span>, <span class="string">&#x27;163&#x27;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<p><code>match.start([group])</code></p>
<ul>
<li><p>æ²¡æœ‰å‚æ•°æ—¶ï¼Œè¿”å›åŒ¹é…åˆ°çš„å­—ç¬¦ä¸²çš„èµ·å§‹ä½ç½®ã€‚  </p>
</li>
<li><p>æŒ‡å®šå‚æ•°ï¼ˆæ•´æ•°ï¼‰æ—¶ï¼Œè¿”å›è¯¥åˆ†ç»„åŒ¹é…åˆ°çš„å­—ç¬¦ä¸²çš„èµ·å§‹ä½ç½®ã€‚</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">pattern = re.<span class="built_in">compile</span>(<span class="string">r&quot;(\w+) (\w+)&quot;</span>)</span><br><span class="line"></span><br><span class="line">m = pattern.match(<span class="string">&quot;Kobe Bryant, Lakers&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(m.start())       <span class="comment"># 0</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(m.start(<span class="number">2</span>))      <span class="comment"># 5</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>



<p><code>match.end([group])ï¼š</code></p>
<ul>
<li><p>æ²¡æœ‰å‚æ•°æ—¶ï¼Œè¿”å›åŒ¹é…åˆ°çš„å­—ç¬¦ä¸²çš„ç»“æŸä½ç½®ã€‚  </p>
</li>
<li><p>æŒ‡å®šå‚æ•°ï¼ˆæ•´æ•°ï¼‰æ—¶ï¼Œè¿”å›è¯¥åˆ†ç»„åŒ¹é…åˆ°çš„å­—ç¬¦ä¸²çš„ç»“æŸä½ç½®ã€‚  </p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">pattern = re.<span class="built_in">compile</span>(<span class="string">r&quot;(\w+) (\w+)&quot;</span>)</span><br><span class="line"></span><br><span class="line">m = pattern.match(<span class="string">&quot;Kobe Bryant, Lakers&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(m.end())       <span class="comment"># 11</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(m.end(<span class="number">1</span>))      <span class="comment"># 4</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>



<p><code>match.span([group])ï¼š</code></p>
<ul>
<li><p>è¿”å›ä¸€ä¸ªäºŒå…ƒ tuple è¡¨ç¤ºåŒ¹é…åˆ°çš„å­—ç¬¦ä¸²çš„èŒƒå›´ï¼Œå³ (start, end)ã€‚  </p>
</li>
<li><p>æŒ‡å®šå‚æ•°æ—¶ï¼Œè¿”å›è¯¥åˆ†ç»„åŒ¹é…åˆ°çš„å­—ç¬¦ä¸²çš„ (start, end)ã€‚</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">pattern = re.<span class="built_in">compile</span>(<span class="string">r&quot;(\w+) (\w+)&quot;</span>)</span><br><span class="line"></span><br><span class="line">m = pattern.match(<span class="string">&quot;Kobe Bryant, Lakers&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(m.span())     <span class="comment"># (0, 11)</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(m.span(<span class="number">2</span>))    <span class="comment"># (5, 11)</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h3 id="æ¨¡å—çº§åˆ«çš„å‡½æ•°"><a href="#æ¨¡å—çº§åˆ«çš„å‡½æ•°" class="headerlink" title="æ¨¡å—çº§åˆ«çš„å‡½æ•°"></a>æ¨¡å—çº§åˆ«çš„å‡½æ•°</h3><p>ä¸Šé¢è®²åˆ°çš„å‡½æ•°éƒ½æ˜¯å¯¹è±¡çš„æ–¹æ³•ï¼Œè¦ä½¿ç”¨å®ƒä»¬å¿…é¡»å…ˆå¾—åˆ°ç›¸åº”çš„å¯¹è±¡ã€‚æœ¬èŠ‚å°†ä»‹ç»ä¸€äº›Module-Level Functionsï¼Œæ¯”å¦‚ match()ï¼Œsearch()ï¼Œfindall() ç­‰ç­‰ã€‚ä½ ä¸éœ€è¦åˆ›å»ºä¸€ä¸ª pattern object å°±å¯ä»¥ç›´æ¥è°ƒç”¨è¿™äº›å‡½æ•°ã€‚</p>
<p><code>re.match(pattern, string, flags=0)</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">pattern = re.<span class="built_in">compile</span>(<span class="string">r&quot;(\w+) (\w+)&quot;</span>)</span><br><span class="line"></span><br><span class="line">m = pattern.match(<span class="string">&quot;Kobe Bryant, Lakers&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(m)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># ç›¸å½“äº</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">m = re.match(<span class="string">r&quot;(\w+) (\w+)&quot;</span>,<span class="string">&quot;Kobe Bryant, Lakers&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(m)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&lt;_sre.SRE_Match <span class="built_in">object</span>; span=(<span class="number">0</span>, <span class="number">11</span>), match=<span class="string">&#x27;Kobe Bryant&#x27;</span>&gt;</span><br><span class="line"></span><br><span class="line">&lt;_sre.SRE_Match <span class="built_in">object</span>; span=(<span class="number">0</span>, <span class="number">11</span>), match=<span class="string">&#x27;Kobe Bryant&#x27;</span>&gt;</span><br><span class="line"></span><br></pre></td></tr></table></figure>





<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">pattern = re.<span class="built_in">compile</span>(<span class="string">r&quot;(\w+) (\w+)&quot;</span>)</span><br><span class="line"></span><br><span class="line">m = pattern.search(<span class="string">&quot;Kobe Bryant, Lakers&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(m)</span><br><span class="line"></span><br><span class="line"><span class="comment"># ç›¸å½“äº</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">m = re.search(<span class="string">r&quot;(\w+) (\w+)&quot;</span>,<span class="string">&quot;Kobe Bryant, Lakers&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(m)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&lt;_sre.SRE_Match <span class="built_in">object</span>; span=(<span class="number">0</span>, <span class="number">11</span>), match=<span class="string">&#x27;Kobe Bryant&#x27;</span>&gt;</span><br><span class="line"></span><br><span class="line">&lt;_sre.SRE_Match <span class="built_in">object</span>; span=(<span class="number">0</span>, <span class="number">11</span>), match=<span class="string">&#x27;Kobe Bryant&#x27;</span>&gt;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>



<p><code>re.findall(pattern, string, flags=0)</code>:ä¸ä¸Šé¢ç±»ä¼¼ã€‚</p>
<p><code>re.finditer(pattern, string, flags=0)</code>:ä¸ä¸Šé¢ç±»ä¼¼</p>
<h3 id="ç¼–è¯‘æ ‡å¿—ï¼ˆåŒ¹é…æ¨¡å¼ï¼‰"><a href="#ç¼–è¯‘æ ‡å¿—ï¼ˆåŒ¹é…æ¨¡å¼ï¼‰" class="headerlink" title="ç¼–è¯‘æ ‡å¿—ï¼ˆåŒ¹é…æ¨¡å¼ï¼‰"></a>ç¼–è¯‘æ ‡å¿—ï¼ˆåŒ¹é…æ¨¡å¼ï¼‰</h3><ul>
<li>re.IGNORECASEï¼šå¿½ç•¥å¤§å°å†™ï¼ŒåŒ re.Iã€‚  </li>
</ul>
<ul>
<li>re.MULTILINEï¼šå¤šè¡Œæ¨¡å¼ï¼Œæ”¹å˜^å’Œ$çš„è¡Œä¸ºï¼ŒåŒ re.Mã€‚  </li>
</ul>
<ul>
<li>re.DOTALLï¼šç‚¹ä»»æ„åŒ¹é…æ¨¡å¼ï¼Œè®©â€™.â€™å¯ä»¥åŒ¹é…åŒ…æ‹¬â€™\nâ€™åœ¨å†…çš„ä»»æ„å­—ç¬¦ï¼ŒåŒ re.Sã€‚  </li>
</ul>
<ul>
<li>re.LOCALEï¼šä½¿é¢„å®šå­—ç¬¦ç±» \w \W \b \B \s \S å–å†³äºå½“å‰åŒºåŸŸè®¾å®šï¼Œ åŒ re.Lã€‚  </li>
</ul>
<ul>
<li>re.ASCIIï¼šä½¿ \w \W \b \B \s \S åªåŒ¹é… ASCII å­—ç¬¦ï¼Œè€Œä¸æ˜¯ Unicode å­—ç¬¦ï¼ŒåŒ re.Aã€‚  </li>
</ul>
<ul>
<li>re.VERBOSEï¼šè¯¦ç»†æ¨¡å¼ã€‚è¿™ä¸ªæ¨¡å¼ä¸‹æ­£åˆ™è¡¨è¾¾å¼å¯ä»¥æ˜¯å¤šè¡Œï¼Œå¿½ç•¥ç©ºç™½å­—ç¬¦ï¼Œå¹¶å¯ä»¥åŠ å…¥æ³¨é‡Šã€‚ä¸»è¦æ˜¯ä¸ºäº†è®©æ­£åˆ™è¡¨è¾¾å¼æ›´æ˜“è¯»ï¼ŒåŒ re.Xã€‚ä¾‹å¦‚ï¼Œä»¥ä¸‹ä¸¤ä¸ªæ­£åˆ™è¡¨è¾¾å¼æ˜¯ç­‰ä»·çš„ï¼š</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">a = re.<span class="built_in">compile</span>(<span class="string">r&quot;\d + \. \d *#re.X&quot;</span>) the integral part</span><br><span class="line"></span><br><span class="line">b = re.<span class="built_in">compile</span>(<span class="string">r&quot;\d+\.\d*&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(b.match(<span class="string">&quot;123.45&quot;</span>))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&lt;_sre.SRE_Match <span class="built_in">object</span>; span=(<span class="number">0</span>, <span class="number">6</span>), match=<span class="string">&#x27;123.45&#x27;</span>&gt;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h3 id="ä¿®æ”¹å­—ç¬¦ä¸²"><a href="#ä¿®æ”¹å­—ç¬¦ä¸²" class="headerlink" title="ä¿®æ”¹å­—ç¬¦ä¸²"></a>ä¿®æ”¹å­—ç¬¦ä¸²</h3><p>ç¬¬äºŒéƒ¨åˆ†è®²çš„æ˜¯å­—ç¬¦ä¸²çš„åŒ¹é…å’Œæœç´¢ï¼Œä½†æ˜¯å¹¶æ²¡æœ‰æ”¹å˜å­—ç¬¦ä¸²ã€‚ä¸‹é¢å°±è®²ä¸€ä¸‹å¯ä»¥æ”¹å˜å­—ç¬¦ä¸²çš„æ“ä½œã€‚</p>
<h4 id="åˆ†å‰²å­—ç¬¦ä¸²"><a href="#åˆ†å‰²å­—ç¬¦ä¸²" class="headerlink" title="åˆ†å‰²å­—ç¬¦ä¸²"></a>åˆ†å‰²å­—ç¬¦ä¸²</h4><p>split()å‡½æ•°åœ¨åŒ¹é…çš„åœ°æ–¹å°†å­—ç¬¦ä¸²åˆ†å‰²ï¼Œå¹¶è¿”å›ä¸€ä¸ª listã€‚åŒæ ·çš„ï¼Œre æ¨¡å—æä¾›äº†ä¸¤ç§ split å‡½æ•°ï¼Œä¸€ä¸ªæ˜¯ pattern object çš„æ–¹æ³•ï¼Œä¸€ä¸ªæ˜¯æ¨¡å—çº§çš„å‡½æ•°ã€‚</p>
<p><code>regex.split(string, maxsplit=0)ï¼š</code></p>
<ul>
<li>maxsplitç”¨äºæŒ‡å®šæœ€å¤§åˆ†å‰²æ¬¡æ•°ï¼Œä¸æŒ‡å®šå°†å…¨éƒ¨åˆ†å‰²ã€‚</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">pattern = re.<span class="built_in">compile</span>(<span class="string">r&quot;[A-Z]+&quot;</span>)</span><br><span class="line"></span><br><span class="line">m = pattern.split(<span class="string">&quot;abcDefgHijkLmnoPqrs&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(m)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">[<span class="string">&#x27;abc&#x27;</span>, <span class="string">&#x27;efg&#x27;</span>, <span class="string">&#x27;ijk&#x27;</span>, <span class="string">&#x27;mno&#x27;</span>, <span class="string">&#x27;qrs&#x27;</span>]</span><br><span class="line"></span><br></pre></td></tr></table></figure>





<p><code>re.split(pattern, string, maxsplit=0, flags=0)ï¼š</code></p>
<ul>
<li><p>æ¨¡å—çº§å‡½æ•°ï¼ŒåŠŸèƒ½ä¸ regex.split() ç›¸åŒã€‚  </p>
</li>
<li><p>flagsç”¨äºæŒ‡å®šåŒ¹é…æ¨¡å¼ã€‚</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">m = re.split(<span class="string">r&quot;[A-Z]+&quot;</span>,<span class="string">&quot;abcDefgHijkLmnoPqrs&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(m)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># è¾“å‡ºç»“æœï¼š</span></span><br><span class="line"></span><br><span class="line">[<span class="string">&#x27;abc&#x27;</span>, <span class="string">&#x27;efg&#x27;</span>, <span class="string">&#x27;ijk&#x27;</span>, <span class="string">&#x27;mno&#x27;</span>, <span class="string">&#x27;qrs&#x27;</span>]</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h4 id="æœç´¢ä¸æ›¿æ¢"><a href="#æœç´¢ä¸æ›¿æ¢" class="headerlink" title="æœç´¢ä¸æ›¿æ¢"></a>æœç´¢ä¸æ›¿æ¢</h4><p>å¦ä¸€ä¸ªå¸¸ç”¨çš„åŠŸèƒ½æ˜¯æ‰¾åˆ°æ‰€æœ‰çš„åŒ¹é…ï¼Œå¹¶æŠŠå®ƒä»¬ç”¨ä¸åŒçš„å­—ç¬¦ä¸²æ›¿æ¢ã€‚re æ¨¡å—æä¾›äº†sub()å’Œsubn()æ¥å®ç°æ›¿æ¢çš„åŠŸèƒ½ï¼Œè€Œå®ƒä»¬ä¹Ÿåˆ†åˆ«æœ‰è‡ªå·±ä¸¤ä¸ªä¸åŒç‰ˆæœ¬çš„å‡½æ•°ã€‚</p>
<p><code>regex.sub(repl, string, count=0)ï¼š</code></p>
<ul>
<li><p>ä½¿ç”¨ repl æ›¿æ¢ string ä¸­æ¯ä¸€ä¸ªåŒ¹é…çš„å­ä¸²ï¼Œè¿”å›æ›¿æ¢åçš„å­—ç¬¦ä¸²ã€‚è‹¥æ‰¾ä¸åˆ°åŒ¹é…ï¼Œåˆ™è¿”å›åŸå­—ç¬¦ä¸²ã€‚</p>
</li>
<li><p>repl å¯ä»¥æ˜¯ä¸€ä¸ªå­—ç¬¦ä¸²ï¼Œä¹Ÿå¯ä»¥æ˜¯ä¸€ä¸ªå‡½æ•°ã€‚</p>
</li>
<li><p>å½“replæ˜¯ä¸€ä¸ªå­—ç¬¦ä¸²æ—¶ï¼Œä»»ä½•åœ¨å…¶ä¸­çš„åæ–œæ éƒ½ä¼šè¢«å¤„ç†ã€‚</p>
</li>
<li><p>å½“replæ˜¯ä¸€ä¸ªå‡½æ•°æ—¶ï¼Œè¿™ä¸ªå‡½æ•°åº”å½“åªæ¥å—ä¸€ä¸ªå‚æ•°ï¼ˆpatternå¯¹è±¡ï¼‰ï¼Œå¯¹åŒ¹é…åˆ°çš„å¯¹è±¡è¿›è¡Œå¤„ç†ï¼Œç„¶åè¿”å›ä¸€ä¸ªå­—ç¬¦ä¸²ç”¨äºæ›¿æ¢ã€‚</p>
</li>
<li><p>count ç”¨äºæŒ‡å®šæœ€å¤šæ›¿æ¢æ¬¡æ•°ï¼Œä¸æŒ‡å®šæ—¶å…¨éƒ¨æ›¿æ¢ã€‚</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">pattern = re.<span class="built_in">compile</span>(<span class="string">r&quot;like&quot;</span>, re.I)</span><br><span class="line"></span><br><span class="line">s1 = pattern.sub(<span class="string">r&quot;love&quot;</span>, <span class="string">&quot;I like you, do you like me?&quot;</span>)</span><br><span class="line"></span><br><span class="line">s2 = pattern.sub(<span class="keyword">lambda</span> m:m.group().upper(), <span class="string">&quot;I like you, do you like me?&quot;</span>)  <span class="comment"># repl æ˜¯å‡½æ•°ï¼Œå…¶å‚æ•°æ˜¯ pattern</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(s1)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(s2)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">I love you, do you love me?</span><br><span class="line"></span><br><span class="line">I LIKE you, do you LIKE me?</span><br><span class="line"></span><br></pre></td></tr></table></figure>







<p><code>re.sub(pattern, repl, string, count=0, flags=0)</code>ï¼š</p>
<ul>
<li><p>æ¨¡å—çº§å‡½æ•°ï¼Œä¸ regex.sub() å‡½æ•°åŠŸèƒ½ç›¸åŒã€‚  </p>
</li>
<li><p>flags ç”¨äºæŒ‡å®šåŒ¹é…æ¨¡å¼ã€‚</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">s1 = re.sub(<span class="string">r&quot;(\w)&#x27;s\b&quot;</span>, <span class="string">r&quot;\1 is&quot;</span>, <span class="string">&quot;She&#x27;s Xie Pan&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(s1)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">She <span class="keyword">is</span> Xie Pan</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<p><code>regex.subn(repl, string, count=0)</code></p>
<ul>
<li>åŒ sub()ï¼Œåªä¸è¿‡è¿”å›å€¼æ˜¯ä¸€ä¸ªäºŒå…ƒ tupleï¼Œå³(subå‡½æ•°è¿”å›å€¼, æ›¿æ¢æ¬¡æ•°)ã€‚</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">pattern = re.<span class="built_in">compile</span>(<span class="string">r&quot;like&quot;</span>, re.I)</span><br><span class="line"></span><br><span class="line">s1 = pattern.subn(<span class="string">r&quot;love&quot;</span>, <span class="string">&quot;I like you, do you like me?&quot;</span>)</span><br><span class="line"></span><br><span class="line">s2 = pattern.subn(<span class="keyword">lambda</span> m:m.group().upper(), <span class="string">&quot;I like you, do you like me?&quot;</span>)  <span class="comment"># repl æ˜¯å‡½æ•°ï¼Œå…¶å‚æ•°æ˜¯ pattern</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(s1)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(s2)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">(<span class="string">&#x27;I love you, do you love me?&#x27;</span>, <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">(<span class="string">&#x27;I LIKE you, do you LIKE me?&#x27;</span>, <span class="number">2</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>









<p><code>re.subn(pattern, repl, string, count=0, flags=0)ï¼š</code></p>
<ul>
<li>åŒä¸Š</li>
</ul>
<h3 id="è‹±æ–‡æ–‡æœ¬æŒ–æ˜é¢„å¤„ç†ä¸‰ï¼šæ‹¼å†™æ£€æŸ¥"><a href="#è‹±æ–‡æ–‡æœ¬æŒ–æ˜é¢„å¤„ç†ä¸‰ï¼šæ‹¼å†™æ£€æŸ¥" class="headerlink" title="è‹±æ–‡æ–‡æœ¬æŒ–æ˜é¢„å¤„ç†ä¸‰ï¼šæ‹¼å†™æ£€æŸ¥"></a>è‹±æ–‡æ–‡æœ¬æŒ–æ˜é¢„å¤„ç†ä¸‰ï¼šæ‹¼å†™æ£€æŸ¥</h3><p>ç”±äºè‹±æ–‡æ–‡æœ¬ä¸­å¯èƒ½æœ‰æ‹¼å†™é”™è¯¯ï¼Œå› æ­¤ä¸€èˆ¬éœ€è¦è¿›è¡Œæ‹¼å†™æ£€æŸ¥ã€‚å¦‚æœç¡®ä¿¡æˆ‘ä»¬åˆ†æçš„æ–‡æœ¬æ²¡æœ‰æ‹¼å†™é—®é¢˜ï¼Œå¯ä»¥ç•¥å»æ­¤æ­¥ã€‚</p>
<p>æ‹¼å†™æ£€æŸ¥ï¼Œæˆ‘ä»¬ä¸€èˆ¬ç”¨pyenchantç±»åº“å®Œæˆã€‚pyenchantçš„å®‰è£…å¾ˆç®€å•ï¼šâ€pip install pyenchantâ€å³å¯ã€‚</p>
<p>å¯¹äºä¸€æ®µæ–‡æœ¬ï¼Œæˆ‘ä»¬å¯ä»¥ç”¨ä¸‹é¢çš„æ–¹å¼å»æ‰¾å‡ºæ‹¼å†™é”™è¯¯ï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment"># å‘ç°è¿™æ ·å®‰è£…å¹¶ä¸æ˜¯åœ¨è™šæ‹Ÿç¯å¢ƒä¸‹ï¼Œéœ€è¦å»ç»ˆç«¯å¯¹åº”çš„è™šæ‹Ÿç¯å¢ƒä¸‹å®‰è£…</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># source avtivate NLP</span></span><br><span class="line"></span><br><span class="line">!pip install pyenchant</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<pre><code>/bin/sh: 1: source: not found

Requirement already satisfied: pyenchant in /home/panxie/anaconda3/lib/python3.6/site-packages (2.0.0)

[31mdistributed 1.21.8 requires msgpack, which is not installed.[0m

[33mYou are using pip version 10.0.1, however version 18.0 is available.

You should consider upgrading via the &#39;pip install --upgrade pip&#39; command.[0m
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">from</span> enchant.checker <span class="keyword">import</span> SpellChecker</span><br><span class="line"></span><br><span class="line">chkr = SpellChecker(<span class="string">&#x27;en_US&#x27;</span>)</span><br><span class="line"></span><br><span class="line">chkr.set_text(<span class="string">&quot;Many peopel like too watch In the Name of people&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> err <span class="keyword">in</span> chkr:</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;ERROR:&quot;</span>, err.word)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">ERROR: peopel</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<p>å‘ç°åªèƒ½æ‰¾å•è¯æ‹¼å†™é”™è¯¯çš„ï¼Œä½† too è¿™æ ·çš„æ˜¯æ²¡åŠæ³•æ‰¾å‡ºçš„ã€‚æ‰¾å‡ºé”™è¯¯åï¼Œæˆ‘ä»¬å¯ä»¥è‡ªå·±æ¥å†³å®šæ˜¯å¦è¦æ”¹æ­£ã€‚å½“ç„¶ï¼Œæˆ‘ä»¬ä¹Ÿå¯ä»¥ç”¨pyenchantä¸­çš„wxSpellCheckerDialogç±»æ¥ç”¨å¯¹è¯æ¡†çš„å½¢å¼æ¥äº¤äº’å†³å®šæ˜¯å¿½ç•¥ï¼Œæ”¹æ­£è¿˜æ˜¯å…¨éƒ¨æ”¹æ­£æ–‡æœ¬ä¸­çš„é”™è¯¯æ‹¼å†™ã€‚  </p>
<p>æ›´å¤šæ“ä½œå¯å‚è€ƒï¼š  </p>
<ul>
<li><p><a target="_blank" rel="noopener" href="https://www.jianshu.com/p/96c01666aeeb">https://www.jianshu.com/p/96c01666aeeb</a></p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://pythonhosted.org/pyenchant/tutorial.html">https://pythonhosted.org/pyenchant/tutorial.html</a></p>
</li>
</ul>
<h3 id="è‹±æ–‡æ–‡æœ¬æŒ–æ˜é¢„å¤„ç†å››ï¼šè¯å¹²æå–-stemming-å’Œè¯å½¢è¿˜åŸ-lemmatization"><a href="#è‹±æ–‡æ–‡æœ¬æŒ–æ˜é¢„å¤„ç†å››ï¼šè¯å¹²æå–-stemming-å’Œè¯å½¢è¿˜åŸ-lemmatization" class="headerlink" title="è‹±æ–‡æ–‡æœ¬æŒ–æ˜é¢„å¤„ç†å››ï¼šè¯å¹²æå–(stemming)å’Œè¯å½¢è¿˜åŸ(lemmatization)"></a>è‹±æ–‡æ–‡æœ¬æŒ–æ˜é¢„å¤„ç†å››ï¼šè¯å¹²æå–(stemming)å’Œè¯å½¢è¿˜åŸ(lemmatization)</h3><p>è¯å¹²æå–(stemming)å’Œè¯å‹è¿˜åŸ(lemmatization)æ˜¯è‹±æ–‡æ–‡æœ¬é¢„å¤„ç†çš„ç‰¹è‰²ã€‚ä¸¤è€…å…¶å®æœ‰å…±åŒç‚¹ï¼Œå³éƒ½æ˜¯è¦æ‰¾åˆ°è¯çš„åŸå§‹å½¢å¼ã€‚åªä¸è¿‡è¯å¹²æå–(stemming)ä¼šæ›´åŠ æ¿€è¿›ä¸€ç‚¹ï¼Œå®ƒåœ¨å¯»æ‰¾è¯å¹²çš„æ—¶å€™å¯ä»¥ä¼šå¾—åˆ°ä¸æ˜¯è¯çš„è¯å¹²ã€‚æ¯”å¦‚â€imagingâ€çš„è¯å¹²å¯èƒ½å¾—åˆ°çš„æ˜¯â€imagâ€, å¹¶ä¸æ˜¯ä¸€ä¸ªè¯ã€‚è€Œè¯å½¢è¿˜åŸåˆ™ä¿å®ˆä¸€äº›ï¼Œå®ƒä¸€èˆ¬åªå¯¹èƒ½å¤Ÿè¿˜åŸæˆä¸€ä¸ªæ­£ç¡®çš„è¯çš„è¯è¿›è¡Œå¤„ç†ã€‚ä¸ªäººæ¯”è¾ƒå–œæ¬¢ä½¿ç”¨è¯å‹è¿˜åŸè€Œä¸æ˜¯è¯å¹²æå–ã€‚</p>
<p>åœ¨å®é™…åº”ç”¨ä¸­ï¼Œä¸€èˆ¬ä½¿ç”¨nltkæ¥è¿›è¡Œè¯å¹²æå–å’Œè¯å‹è¿˜åŸã€‚å®‰è£…nltkä¹Ÿå¾ˆç®€å•ï¼Œâ€pip install nltkâ€å³å¯ã€‚åªä¸è¿‡æˆ‘ä»¬ä¸€èˆ¬éœ€è¦ä¸‹è½½nltkçš„è¯­æ–™åº“ï¼Œå¯ä»¥ç”¨ä¸‹é¢çš„ä»£ç å®Œæˆï¼Œnltkä¼šå¼¹å‡ºå¯¹è¯æ¡†é€‰æ‹©è¦ä¸‹è½½çš„å†…å®¹ã€‚é€‰æ‹©ä¸‹è½½è¯­æ–™åº“å°±å¯ä»¥äº†ã€‚</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">import</span> nltk</span><br><span class="line"></span><br><span class="line">nltk.download(<span class="string">&#x27;wordnet&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">[nltk_data] Downloading package wordnet to /home/panxie/nltk_data...</span><br><span class="line"></span><br><span class="line">[nltk_data]   Unzipping corpora/wordnet.<span class="built_in">zip</span>.</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="literal">True</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>



<p>åœ¨nltkä¸­ï¼Œåšè¯å¹²æå–çš„æ–¹æ³•æœ‰PorterStemmerï¼ŒLancasterStemmerå’ŒSnowballStemmerã€‚ä¸ªäººæ¨èä½¿ç”¨SnowballStemmerã€‚è¿™ä¸ªç±»å¯ä»¥å¤„ç†å¾ˆå¤šç§è¯­è¨€ï¼Œå½“ç„¶ï¼Œé™¤äº†ä¸­æ–‡ã€‚</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">from</span> nltk.stem <span class="keyword">import</span> SnowballStemmer</span><br><span class="line"></span><br><span class="line">stemmer = SnowballStemmer(<span class="string">&quot;english&quot;</span>)</span><br><span class="line"></span><br><span class="line">stemmer.stem(<span class="string">&quot;countries&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;countri&#x27;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>



<p>è¾“å‡ºæ˜¯â€countriâ€,è¿™ä¸ªè¯å¹²å¹¶ä¸æ˜¯ä¸€ä¸ªè¯ã€‚  </p>
<p>è€Œå¦‚æœæ˜¯åšè¯å‹è¿˜åŸï¼Œåˆ™ä¸€èˆ¬å¯ä»¥ä½¿ç”¨WordNetLemmatizerç±»ï¼Œå³wordnetè¯å½¢è¿˜åŸæ–¹æ³•ã€‚</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">from</span> nltk.stem <span class="keyword">import</span> WordNetLemmatizer</span><br><span class="line"></span><br><span class="line">wnl = WordNetLemmatizer()</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(wnl.lemmatize(<span class="string">&#x27;countries&#x27;</span>))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">country</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<p>è¾“å‡ºæ˜¯â€countryâ€,æ¯”è¾ƒç¬¦åˆéœ€æ±‚ã€‚  </p>
<p>åœ¨å®é™…çš„è‹±æ–‡æ–‡æœ¬æŒ–æ˜é¢„å¤„ç†çš„æ—¶å€™ï¼Œå»ºè®®ä½¿ç”¨åŸºäºwordnetçš„è¯å½¢è¿˜åŸå°±å¯ä»¥äº†ã€‚  </p>
<p>åœ¨<a target="_blank" rel="noopener" href="http://text-processing.com/demo/stem/">è¿™é‡Œ</a>æœ‰ä¸ªè¯å¹²æå–å’Œè¯å‹è¿˜åŸçš„demoï¼Œå¦‚æœæ˜¯è¿™å—çš„æ–°æ‰‹å¯ä»¥å»çœ‹çœ‹ï¼Œä¸Šæ‰‹å¾ˆåˆé€‚ã€‚</p>
<h3 id="è‹±æ–‡æ–‡æœ¬æŒ–æ˜é¢„å¤„ç†äº”ï¼šè½¬åŒ–ä¸ºå°å†™"><a href="#è‹±æ–‡æ–‡æœ¬æŒ–æ˜é¢„å¤„ç†äº”ï¼šè½¬åŒ–ä¸ºå°å†™" class="headerlink" title="è‹±æ–‡æ–‡æœ¬æŒ–æ˜é¢„å¤„ç†äº”ï¼šè½¬åŒ–ä¸ºå°å†™"></a>è‹±æ–‡æ–‡æœ¬æŒ–æ˜é¢„å¤„ç†äº”ï¼šè½¬åŒ–ä¸ºå°å†™</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">text = <span class="string">&#x27;XiePan&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(text.lower())</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">xiepan</span><br><span class="line"></span><br></pre></td></tr></table></figure>





<h3 id="è‹±æ–‡æ–‡æœ¬æŒ–æ˜é¢„å¤„ç†å…­ï¼šå¼•å…¥åœç”¨è¯"><a href="#è‹±æ–‡æ–‡æœ¬æŒ–æ˜é¢„å¤„ç†å…­ï¼šå¼•å…¥åœç”¨è¯" class="headerlink" title="è‹±æ–‡æ–‡æœ¬æŒ–æ˜é¢„å¤„ç†å…­ï¼šå¼•å…¥åœç”¨è¯"></a>è‹±æ–‡æ–‡æœ¬æŒ–æ˜é¢„å¤„ç†å…­ï¼šå¼•å…¥åœç”¨è¯</h3><p>åœ¨è‹±æ–‡æ–‡æœ¬ä¸­æœ‰å¾ˆå¤šæ— æ•ˆçš„è¯ï¼Œæ¯”å¦‚â€œaâ€ï¼Œâ€œtoâ€ï¼Œä¸€äº›çŸ­è¯ï¼Œè¿˜æœ‰ä¸€äº›æ ‡ç‚¹ç¬¦å·ï¼Œè¿™äº›æˆ‘ä»¬ä¸æƒ³åœ¨æ–‡æœ¬åˆ†æçš„æ—¶å€™å¼•å…¥ï¼Œå› æ­¤éœ€è¦å»æ‰ï¼Œè¿™äº›è¯å°±æ˜¯åœç”¨è¯ã€‚ä¸ªäººå¸¸ç”¨çš„è‹±æ–‡åœç”¨è¯è¡¨ä¸‹è½½åœ°å€åœ¨è¿™ã€‚å½“ç„¶ä¹Ÿæœ‰å…¶ä»–ç‰ˆæœ¬çš„åœç”¨è¯è¡¨ï¼Œä¸è¿‡è¿™ä¸ªç‰ˆæœ¬æ˜¯æˆ‘å¸¸ç”¨çš„ã€‚</p>
<p>åœ¨æˆ‘ä»¬ç”¨scikit-learnåšç‰¹å¾å¤„ç†çš„æ—¶å€™ï¼Œå¯ä»¥é€šè¿‡å‚æ•°stop_wordsæ¥å¼•å…¥ä¸€ä¸ªæ•°ç»„ä½œä¸ºåœç”¨è¯è¡¨ã€‚è¿™ä¸ªæ–¹æ³•å’Œå‰æ–‡è®²ä¸­æ–‡åœç”¨è¯çš„æ–¹æ³•ç›¸åŒï¼Œè¿™é‡Œå°±ä¸å†™å‡ºä»£ç ï¼Œå¤§å®¶å‚è€ƒå‰æ–‡å³å¯ã€‚</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">from</span> nltk <span class="keyword">import</span> word_tokenize</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> nltk.corpus <span class="keyword">import</span> stopwords</span><br><span class="line"></span><br><span class="line">stop = <span class="built_in">set</span>(stopwords.words(<span class="string">&#x27;english&#x27;</span>))  <span class="comment"># åœç”¨è¯</span></span><br><span class="line"></span><br><span class="line">stop.add(<span class="string">&quot;foo&quot;</span>)    <span class="comment"># å¢åŠ ä¸€ä¸ªè¯</span></span><br><span class="line"></span><br><span class="line">stop.remove(<span class="string">&quot;is&quot;</span>)  <span class="comment"># å»æ‰ä¸€ä¸ªè¯</span></span><br><span class="line"></span><br><span class="line">sentence = <span class="string">&quot;this is a foo bar sentence&quot;</span></span><br><span class="line"></span><br><span class="line">[i <span class="keyword">for</span> i <span class="keyword">in</span> word_tokenize(sentence.lower()) <span class="keyword">if</span> i <span class="keyword">not</span> <span class="keyword">in</span> stop]</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<pre><code>[&#39;is&#39;, &#39;bar&#39;, &#39;sentence&#39;]
</code></pre>
<h3 id="è‹±æ–‡æ–‡æœ¬æŒ–æ˜é¢„å¤„ç†ä¸ƒï¼šç‰¹å¾å¤„ç†"><a href="#è‹±æ–‡æ–‡æœ¬æŒ–æ˜é¢„å¤„ç†ä¸ƒï¼šç‰¹å¾å¤„ç†" class="headerlink" title="è‹±æ–‡æ–‡æœ¬æŒ–æ˜é¢„å¤„ç†ä¸ƒï¼šç‰¹å¾å¤„ç†"></a>è‹±æ–‡æ–‡æœ¬æŒ–æ˜é¢„å¤„ç†ä¸ƒï¼šç‰¹å¾å¤„ç†</h3><p>ç°åœ¨æˆ‘ä»¬å°±å¯ä»¥ç”¨scikit-learnæ¥å¯¹æˆ‘ä»¬çš„æ–‡æœ¬ç‰¹å¾è¿›è¡Œå¤„ç†äº†ï¼Œåœ¨<a target="_blank" rel="noopener" href="http://www.cnblogs.com/pinard/p/6688348.html">æ–‡æœ¬æŒ–æ˜é¢„å¤„ç†ä¹‹å‘é‡åŒ–ä¸Hash Trick</a>ä¸­ï¼Œæˆ‘ä»¬è®²åˆ°äº†ä¸¤ç§ç‰¹å¾å¤„ç†çš„æ–¹æ³•ï¼Œå‘é‡åŒ–ä¸Hash Trickã€‚è€Œå‘é‡åŒ–æ˜¯æœ€å¸¸ç”¨çš„æ–¹æ³•ï¼Œå› ä¸ºå®ƒå¯ä»¥æ¥ç€è¿›è¡ŒTF-IDFçš„ç‰¹å¾å¤„ç†ã€‚åœ¨æ–‡æœ¬æŒ–æ˜é¢„å¤„ç†ä¹‹TF-IDFä¸­ï¼Œæˆ‘ä»¬ä¹Ÿè®²åˆ°äº†<a target="_blank" rel="noopener" href="http://www.cnblogs.com/pinard/p/6693230.html">TF-IDFç‰¹å¾å¤„ç†çš„æ–¹æ³•</a>ã€‚</p>
<p>TfidfVectorizerç±»å¯ä»¥å¸®åŠ©æˆ‘ä»¬å®Œæˆå‘é‡åŒ–ï¼ŒTF-IDFå’Œæ ‡å‡†åŒ–ä¸‰æ­¥ã€‚å½“ç„¶ï¼Œè¿˜å¯ä»¥å¸®æˆ‘ä»¬å¤„ç†åœç”¨è¯ã€‚è¿™éƒ¨åˆ†å·¥ä½œå’Œä¸­æ–‡çš„ç‰¹å¾å¤„ç†ä¹Ÿæ˜¯å®Œå…¨ç›¸åŒçš„ï¼Œå¤§å®¶å‚è€ƒå‰æ–‡å³å¯ã€‚</p>
<h3 id="è‹±æ–‡æ–‡æœ¬æŒ–æ˜é¢„å¤„ç†å…«ï¼šå»ºç«‹åˆ†ææ¨¡å‹"><a href="#è‹±æ–‡æ–‡æœ¬æŒ–æ˜é¢„å¤„ç†å…«ï¼šå»ºç«‹åˆ†ææ¨¡å‹" class="headerlink" title="è‹±æ–‡æ–‡æœ¬æŒ–æ˜é¢„å¤„ç†å…«ï¼šå»ºç«‹åˆ†ææ¨¡å‹"></a>è‹±æ–‡æ–‡æœ¬æŒ–æ˜é¢„å¤„ç†å…«ï¼šå»ºç«‹åˆ†ææ¨¡å‹</h3><p>æœ‰äº†æ¯æ®µæ–‡æœ¬çš„TF-IDFçš„ç‰¹å¾å‘é‡ï¼Œæˆ‘ä»¬å°±å¯ä»¥åˆ©ç”¨è¿™äº›æ•°æ®å»ºç«‹åˆ†ç±»æ¨¡å‹ï¼Œæˆ–è€…èšç±»æ¨¡å‹äº†ï¼Œæˆ–è€…è¿›è¡Œä¸»é¢˜æ¨¡å‹çš„åˆ†æã€‚æ­¤æ—¶çš„åˆ†ç±»èšç±»æ¨¡å‹å’Œä¹‹å‰è®²çš„éè‡ªç„¶è¯­è¨€å¤„ç†çš„æ•°æ®åˆ†ææ²¡æœ‰ä»€ä¹ˆä¸¤æ ·ã€‚å› æ­¤å¯¹åº”çš„ç®—æ³•éƒ½å¯ä»¥ç›´æ¥ä½¿ç”¨ã€‚è€Œä¸»é¢˜æ¨¡å‹æ˜¯è‡ªç„¶è¯­è¨€å¤„ç†æ¯”è¾ƒç‰¹æ®Šçš„ä¸€å—ï¼Œè¿™ä¸ªæˆ‘ä»¬åé¢å†å•ç‹¬è®²ã€‚</p>
<h3 id="è‹±æ–‡æ–‡æœ¬æŒ–æ˜é¢„å¤„ç†æ€»ç»“"><a href="#è‹±æ–‡æ–‡æœ¬æŒ–æ˜é¢„å¤„ç†æ€»ç»“" class="headerlink" title="è‹±æ–‡æ–‡æœ¬æŒ–æ˜é¢„å¤„ç†æ€»ç»“"></a>è‹±æ–‡æ–‡æœ¬æŒ–æ˜é¢„å¤„ç†æ€»ç»“</h3><p>ä¸Šé¢æˆ‘ä»¬å¯¹è‹±æ–‡æ–‡æœ¬æŒ–æ˜é¢„å¤„ç†çš„è¿‡ç¨‹åšäº†ä¸€ä¸ªæ€»ç»“ï¼Œå¸Œæœ›å¯ä»¥å¸®åŠ©åˆ°å¤§å®¶ã€‚éœ€è¦æ³¨æ„çš„æ˜¯è¿™ä¸ªæµç¨‹ä¸»è¦é’ˆå¯¹ä¸€äº›å¸¸ç”¨çš„æ–‡æœ¬æŒ–æ˜ï¼Œå¹¶ä½¿ç”¨äº†è¯è¢‹æ¨¡å‹ï¼Œå¯¹äºæŸä¸€äº›è‡ªç„¶è¯­è¨€å¤„ç†çš„éœ€æ±‚åˆ™æµç¨‹éœ€è¦ä¿®æ”¹ã€‚æ¯”å¦‚æœ‰æ—¶å€™éœ€è¦åšè¯æ€§æ ‡æ³¨ï¼Œè€Œæœ‰æ—¶å€™æˆ‘ä»¬ä¹Ÿéœ€è¦è‹±æ–‡åˆ†è¯ï¼Œæ¯”å¦‚å¾—åˆ°â€New Yorkâ€è€Œä¸æ˜¯â€œNewâ€å’Œâ€œYorkâ€ï¼Œå› æ­¤è¿™ä¸ªæµç¨‹ä»…ä¾›è‡ªç„¶è¯­è¨€å¤„ç†å…¥é—¨è€…å‚è€ƒï¼Œæˆ‘ä»¬å¯ä»¥æ ¹æ®æˆ‘ä»¬çš„æ•°æ®åˆ†æç›®çš„é€‰æ‹©åˆé€‚çš„é¢„å¤„ç†æ–¹æ³•ã€‚</p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2018-08-07T01:28:38.000Z" title="2018/8/7 ä¸Šåˆ9:28:38">2018-08-07</time>å‘è¡¨</span><span class="level-item"><time dateTime="2021-01-27T08:44:33.537Z" title="2021/1/27 ä¸‹åˆ4:44:33">2021-01-27</time>æ›´æ–°</span><span class="level-item"><a class="link-muted" href="/categories/%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB/">æ–‡æœ¬åˆ†ç±»</a></span><span class="level-item">43 åˆ†é’Ÿè¯»å®Œ (å¤§çº¦6494ä¸ªå­—)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2018/08/07/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E4%B8%AD%E6%96%87%E6%96%87%E6%9C%AC%E9%A2%84%E5%A4%84%E7%90%86/">æœºå™¨å­¦ä¹ -ä¸­æ–‡æ–‡æœ¬é¢„å¤„ç†</a></h1><div class="content"><h3 id="ä¸­æ–‡æ–‡æœ¬æŒ–æ˜é¢„å¤„ç†ç‰¹ç‚¹"><a href="#ä¸­æ–‡æ–‡æœ¬æŒ–æ˜é¢„å¤„ç†ç‰¹ç‚¹" class="headerlink" title="ä¸­æ–‡æ–‡æœ¬æŒ–æ˜é¢„å¤„ç†ç‰¹ç‚¹"></a>ä¸­æ–‡æ–‡æœ¬æŒ–æ˜é¢„å¤„ç†ç‰¹ç‚¹</h3><p>å‚è€ƒï¼š<a target="_blank" rel="noopener" href="https://www.cnblogs.com/pinard/p/6744056.html">https://www.cnblogs.com/pinard/p/6744056.html</a></p>
<p>é¦–å…ˆæˆ‘ä»¬çœ‹çœ‹ä¸­æ–‡æ–‡æœ¬æŒ–æ˜é¢„å¤„ç†å’Œè‹±æ–‡æ–‡æœ¬æŒ–æ˜é¢„å¤„ç†ç›¸æ¯”çš„ä¸€äº›ç‰¹æ®Šç‚¹ã€‚  </p>
<p>é¦–å…ˆï¼Œä¸­æ–‡æ–‡æœ¬æ˜¯æ²¡æœ‰åƒè‹±æ–‡çš„å•è¯ç©ºæ ¼é‚£æ ·éš”å¼€çš„ï¼Œå› æ­¤ä¸èƒ½ç›´æ¥åƒè‹±æ–‡ä¸€æ ·å¯ä»¥ç›´æ¥ç”¨æœ€ç®€å•çš„ç©ºæ ¼å’Œæ ‡ç‚¹ç¬¦å·å®Œæˆåˆ†è¯ã€‚æ‰€ä»¥ä¸€èˆ¬æˆ‘ä»¬éœ€è¦ç”¨åˆ†è¯ç®—æ³•æ¥å®Œæˆåˆ†è¯ï¼Œåœ¨<a target="_blank" rel="noopener" href="http://www.cnblogs.com/pinard/p/6677078.html">æ–‡æœ¬æŒ–æ˜çš„åˆ†è¯åŸç†</a>ä¸­ï¼Œæˆ‘ä»¬å·²ç»è®²åˆ°äº†ä¸­æ–‡çš„åˆ†è¯åŸç†ï¼Œè¿™é‡Œå°±ä¸å¤šè¯´ã€‚</p>
<p>ç¬¬äºŒï¼Œä¸­æ–‡çš„ç¼–ç ä¸æ˜¯utf8ï¼Œè€Œæ˜¯unicodeã€‚è¿™æ ·ä¼šå¯¼è‡´åœ¨åˆ†è¯çš„æ—¶å€™ï¼Œå’Œè‹±æ–‡ç›¸æ¯”ï¼Œæˆ‘ä»¬è¦å¤„ç†ç¼–ç çš„é—®é¢˜ã€‚</p>
<p>è¿™ä¸¤ç‚¹æ„æˆäº†ä¸­æ–‡åˆ†è¯ç›¸æ¯”è‹±æ–‡åˆ†è¯çš„ä¸€äº›ä¸åŒç‚¹ï¼Œåé¢æˆ‘ä»¬ä¹Ÿä¼šé‡ç‚¹è®²è¿°è¿™éƒ¨åˆ†çš„å¤„ç†ã€‚å½“ç„¶ï¼Œè‹±æ–‡åˆ†è¯ä¹Ÿæœ‰è‡ªå·±çš„çƒ¦æ¼ï¼Œè¿™ä¸ªæˆ‘ä»¬åœ¨ä»¥åå†è®²ã€‚äº†è§£äº†ä¸­æ–‡é¢„å¤„ç†çš„ä¸€äº›ç‰¹ç‚¹åï¼Œæˆ‘ä»¬å°±è¨€å½’æ­£ä¼ ï¼Œé€šè¿‡å®è·µæ€»ç»“ä¸‹ä¸­æ–‡æ–‡æœ¬æŒ–æ˜é¢„å¤„ç†æµç¨‹ã€‚</p>
<h3 id="æ•°æ®é›†æ”¶é›†"><a href="#æ•°æ®é›†æ”¶é›†" class="headerlink" title="æ•°æ®é›†æ”¶é›†"></a>æ•°æ®é›†æ”¶é›†</h3><p>åœ¨æ–‡æœ¬æŒ–æ˜ä¹‹å‰ï¼Œæˆ‘ä»¬éœ€è¦å¾—åˆ°æ–‡æœ¬æ•°æ®ï¼Œæ–‡æœ¬æ•°æ®çš„è·å–æ–¹æ³•ä¸€èˆ¬æœ‰ä¸¤ç§ï¼šä½¿ç”¨åˆ«äººåšå¥½çš„è¯­æ–™åº“å’Œè‡ªå·±ç”¨çˆ¬è™«å»åœ¨ç½‘ä¸Šå»çˆ¬è‡ªå·±çš„è¯­æ–™æ•°æ®ã€‚</p>
<p>å¯¹äºç¬¬ä¸€ç§æ–¹æ³•ï¼Œå¸¸ç”¨çš„æ–‡æœ¬è¯­æ–™åº“åœ¨ç½‘ä¸Šæœ‰å¾ˆå¤šï¼Œå¦‚æœå¤§å®¶åªæ˜¯å­¦ä¹ ï¼Œåˆ™å¯ä»¥ç›´æ¥ä¸‹è½½ä¸‹æ¥ä½¿ç”¨ï¼Œä½†å¦‚æœæ˜¯æŸäº›ç‰¹æ®Šä¸»é¢˜çš„è¯­æ–™åº“ï¼Œæ¯”å¦‚â€œæœºå™¨å­¦ä¹ â€ç›¸å…³çš„è¯­æ–™åº“ï¼Œåˆ™è¿™ç§æ–¹æ³•è¡Œä¸é€šï¼Œéœ€è¦æˆ‘ä»¬è‡ªå·±ç”¨ç¬¬äºŒç§æ–¹æ³•å»è·å–ã€‚</p>
<p>å¯¹äºç¬¬äºŒç§ä½¿ç”¨çˆ¬è™«çš„æ–¹æ³•ï¼Œå¼€æºå·¥å…·æœ‰å¾ˆå¤šï¼Œé€šç”¨çš„çˆ¬è™«æˆ‘ä¸€èˆ¬ä½¿ç”¨<a target="_blank" rel="noopener" href="https://www.crummy.com/software/BeautifulSoup/">beautifulsoup</a>ã€‚ä½†æ˜¯æˆ‘ä»¬æˆ‘ä»¬éœ€è¦æŸäº›ç‰¹æ®Šçš„è¯­æ–™æ•°æ®ï¼Œæ¯”å¦‚ä¸Šé¢æåˆ°çš„â€œæœºå™¨å­¦ä¹ â€ç›¸å…³çš„è¯­æ–™åº“ï¼Œåˆ™éœ€è¦ç”¨ä¸»é¢˜çˆ¬è™«ï¼ˆä¹Ÿå«èšç„¦çˆ¬è™«ï¼‰æ¥å®Œæˆã€‚è¿™ä¸ªæˆ‘ä¸€èˆ¬ä½¿ç”¨<a target="_blank" rel="noopener" href="https://github.com/ViDA-NYU/ache">ache</a>ã€‚ acheå…è®¸æˆ‘ä»¬ç”¨å…³é”®å­—æˆ–è€…ä¸€ä¸ªåˆ†ç±»ç®—æ³•æ¥è¿‡æ»¤å‡ºæˆ‘ä»¬éœ€è¦çš„ä¸»é¢˜è¯­æ–™ï¼Œæ¯”è¾ƒå¼ºå¤§ã€‚</p>
<h3 id="é™¤å»æ•°æ®ä¸­éæ–‡æœ¬éƒ¨åˆ†"><a href="#é™¤å»æ•°æ®ä¸­éæ–‡æœ¬éƒ¨åˆ†" class="headerlink" title="é™¤å»æ•°æ®ä¸­éæ–‡æœ¬éƒ¨åˆ†"></a>é™¤å»æ•°æ®ä¸­éæ–‡æœ¬éƒ¨åˆ†</h3><p>è¿™ä¸€æ­¥ä¸»è¦æ˜¯é’ˆå¯¹æˆ‘ä»¬ç”¨çˆ¬è™«æ”¶é›†çš„è¯­æ–™æ•°æ®ï¼Œç”±äºçˆ¬ä¸‹æ¥çš„å†…å®¹ä¸­æœ‰å¾ˆå¤šhtmlçš„ä¸€äº›æ ‡ç­¾ï¼Œéœ€è¦å»æ‰ã€‚å°‘é‡çš„éæ–‡æœ¬å†…å®¹çš„å¯ä»¥ç›´æ¥ç”¨Pythonçš„æ­£åˆ™è¡¨è¾¾å¼(re)åˆ é™¤, å¤æ‚çš„åˆ™å¯ä»¥ç”¨beautifulsoupæ¥å»é™¤ã€‚å»é™¤æ‰è¿™äº›éæ–‡æœ¬çš„å†…å®¹åï¼Œæˆ‘ä»¬å°±å¯ä»¥è¿›è¡ŒçœŸæ­£çš„æ–‡æœ¬é¢„å¤„ç†äº†ã€‚</p>
<h3 id="å¤„ç†ä¸­æ–‡ç¼–ç é—®é¢˜"><a href="#å¤„ç†ä¸­æ–‡ç¼–ç é—®é¢˜" class="headerlink" title="å¤„ç†ä¸­æ–‡ç¼–ç é—®é¢˜"></a>å¤„ç†ä¸­æ–‡ç¼–ç é—®é¢˜</h3><p>ç”±äºPython2ä¸æ”¯æŒunicodeçš„å¤„ç†ï¼Œå› æ­¤æˆ‘ä»¬ä½¿ç”¨Python2åšä¸­æ–‡æ–‡æœ¬é¢„å¤„ç†æ—¶éœ€è¦éµå¾ªçš„åŸåˆ™æ˜¯ï¼Œå­˜å‚¨æ•°æ®éƒ½ç”¨utf8ï¼Œè¯»å‡ºæ¥è¿›è¡Œä¸­æ–‡ç›¸å…³å¤„ç†æ—¶ï¼Œä½¿ç”¨GBKä¹‹ç±»çš„ä¸­æ–‡ç¼–ç ï¼Œåœ¨ä¸‹é¢ä¸€èŠ‚çš„åˆ†è¯æ—¶ï¼Œæˆ‘ä»¬å†ç”¨ä¾‹å­è¯´æ˜è¿™ä¸ªé—®é¢˜ã€‚</p>
<h3 id="ä¸­æ–‡åˆ†è¯"><a href="#ä¸­æ–‡åˆ†è¯" class="headerlink" title="ä¸­æ–‡åˆ†è¯"></a>ä¸­æ–‡åˆ†è¯</h3><p>å¸¸ç”¨çš„ä¸­æ–‡åˆ†è¯è½¯ä»¶æœ‰å¾ˆå¤šï¼Œä¸ªäººæ¯”è¾ƒæ¨èç»“å·´åˆ†è¯ã€‚å®‰è£…ä¹Ÿå¾ˆç®€å•ï¼Œæ¯”å¦‚åŸºäºPythonçš„ï¼Œç”¨â€pip install jiebaâ€å°±å¯ä»¥å®Œæˆã€‚ä¸‹é¢æˆ‘ä»¬å°±ç”¨ä¾‹å­æ¥çœ‹çœ‹å¦‚ä½•ä¸­æ–‡åˆ†è¯ã€‚</p>
<p>é¦–å…ˆæˆ‘ä»¬å‡†å¤‡äº†ä¸¤æ®µæ–‡æœ¬ï¼Œè¿™ä¸¤æ®µæ–‡æœ¬åœ¨ä¸¤ä¸ªæ–‡ä»¶ä¸­ã€‚ä¸¤æ®µæ–‡æœ¬çš„å†…å®¹åˆ†åˆ«æ˜¯nlp_test0.txtå’Œnlp_test2.txtï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">import</span> jieba</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&quot;./nlp_test1.txt&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line"></span><br><span class="line">    document = f.read() <span class="comment"># å¦‚æœæ˜¯python2ï¼Œåˆ™éœ€è¦ç”¨ decode(&quot;GBK&quot;)</span></span><br><span class="line"></span><br><span class="line">    document_cut = jieba.cut(document)</span><br><span class="line"></span><br><span class="line">document_cut</span><br><span class="line"></span><br></pre></td></tr></table></figure>









<pre><code>&lt;generator object Tokenizer.cut at 0x7f6a84cf09e8&gt;
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">result = <span class="string">&quot; &quot;</span>.join(document_cut)</span><br><span class="line"></span><br><span class="line">result</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<pre><code>Building prefix dict from the default dictionary ...

Loading model from cache /tmp/jieba.cache

Loading model cost 0.438 seconds.

Prefix dict has been built succesfully.











&#39;        æ²™ ç‘é‡‘ èµå¹ æ˜“ å­¦ä¹  çš„ èƒ¸æ€€ ï¼Œ æ˜¯ é‡‘å±± çš„ ç™¾å§“ æœ‰ç¦ ï¼Œ å¯æ˜¯ è¿™ä»¶ äº‹å¯¹ æè¾¾åº· çš„ è§¦åŠ¨ å¾ˆå¤§ ã€‚ æ˜“ å­¦ä¹  åˆ å›å¿†èµ· ä»–ä»¬ ä¸‰äºº åˆ†å¼€ çš„ å‰ä¸€æ™š ï¼Œ å¤§å®¶ ä¸€èµ· å–é…’ è¯åˆ« ï¼Œ æ˜“ å­¦ä¹  è¢« é™èŒ åˆ° é“å£ å¿å½“ å¿é•¿ ï¼Œ ç‹ å¤§è·¯ ä¸‹æµ·ç»å•† ï¼Œ æè¾¾åº· è¿è¿ èµ”ç¤¼é“æ­‰ ï¼Œ è§‰å¾— å¯¹ä¸èµ· å¤§å®¶ ï¼Œ ä»– æœ€ å¯¹ä¸èµ· çš„ æ˜¯ ç‹ å¤§è·¯ ï¼Œ å°± å’Œ æ˜“ å­¦ä¹  ä¸€èµ· ç»™ ç‹ å¤§è·¯ å‡‘ äº† 5 ä¸‡å— é’± ï¼Œ ç‹ å¤§è·¯ è‡ªå·± ä¸œæŒªè¥¿æ’® äº† 5 ä¸‡å— ï¼Œ å¼€å§‹ ä¸‹æµ·ç»å•† ã€‚ æ²¡æƒ³åˆ° åæ¥ ç‹ å¤§è·¯ ç«Ÿç„¶ åš å¾— é£ç”Ÿæ°´ èµ· ã€‚ æ²™ ç‘é‡‘ è§‰å¾— ä»–ä»¬ ä¸‰äºº ï¼Œ åœ¨ å›°éš¾ æ—¶æœŸ è¿˜ èƒ½ ä»¥æ²« ç›¸åŠ© ï¼Œ å¾ˆ ä¸ å®¹æ˜“ ã€‚ \n \n         æ²™ ç‘é‡‘ å‘ æ¯›å¨… æ‰“å¬ ä»–ä»¬ å®¶ åœ¨ äº¬å· çš„ åˆ«å¢… ï¼Œ æ¯›å¨… ç¬‘ ç€ è¯´ ï¼Œ ç‹ å¤§è·¯ äº‹ä¸šæœ‰æˆ ä¹‹å ï¼Œ è¦ ç»™ æ¬§é˜³ è å’Œ å¥¹ å…¬å¸ çš„ è‚¡æƒ ï¼Œ å¥¹ä»¬ æ²¡æœ‰ è¦ ï¼Œ ç‹ å¤§è·¯ å°± åœ¨ äº¬å·å¸ è±ªå›­ ä¹° äº† ä¸‰å¥— åˆ«å¢… ï¼Œ å¯æ˜¯ æè¾¾ åº·å’Œæ˜“ å­¦ä¹  éƒ½ ä¸è¦ ï¼Œ è¿™äº› æˆ¿å­ éƒ½ åœ¨ ç‹ å¤§è·¯ çš„ åä¸‹ ï¼Œ æ¬§é˜³ è å¥½åƒ å» ä½ è¿‡ ï¼Œ æ¯›å¨… ä¸æƒ³ å» ï¼Œ å¥¹ è§‰å¾— æˆ¿å­ å¤ªå¤§ å¾ˆ æµªè´¹ ï¼Œ è‡ªå·± å®¶ä½ å¾— å°± å¾ˆ è¸å® ã€‚&#39;
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&quot;./nlp_test2.txt&quot;</span>, <span class="string">&quot;w&quot;</span>) <span class="keyword">as</span> f2:</span><br><span class="line"></span><br><span class="line">    f2.write(result)</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<p>å¯ä»¥å‘ç°å¯¹äºä¸€äº›äººåå’Œåœ°åï¼Œjiebaå¤„ç†çš„ä¸å¥½ï¼Œä¸è¿‡æˆ‘ä»¬å¯ä»¥å¸®jiebaåŠ å…¥è¯æ±‡å¦‚ä¸‹ï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">jieba.suggest_freq(<span class="string">&#x27;æ²™ç‘é‡‘&#x27;</span>, <span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">jieba.suggest_freq(<span class="string">&#x27;æ˜“å­¦ä¹ &#x27;</span>, <span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">jieba.suggest_freq(<span class="string">&#x27;ç‹å¤§è·¯&#x27;</span>, <span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">jieba.suggest_freq(<span class="string">&#x27;äº¬å·&#x27;</span>, <span class="literal">True</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>









<pre><code>3
</code></pre>
<p>æ‰€ä»¥åœ¨å¾ˆå¤š NLP ä»»åŠ¡ä¸­å…ˆåšå‘½ä»¤å®ä½“è¯†åˆ«çš„æ„ä¹‰å°±åœ¨è¿™é‡Œå¯¹å§?</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&quot;./nlp_test1.txt&quot;</span>, <span class="string">&quot;r&quot;</span>) <span class="keyword">as</span> f1:</span><br><span class="line"></span><br><span class="line">    text = f1.read()</span><br><span class="line"></span><br><span class="line">    text_cut = jieba.cut(text)  <span class="comment"># list</span></span><br><span class="line"></span><br><span class="line">    result = <span class="string">&quot; &quot;</span>.join(text_cut)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(result)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&quot;./nlp_test2.txt&quot;</span>, <span class="string">&quot;w&quot;</span>) <span class="keyword">as</span> f2:</span><br><span class="line"></span><br><span class="line">        f2.write(result)</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<pre><code>        æ²™ç‘é‡‘ èµå¹ æ˜“å­¦ä¹  çš„ èƒ¸æ€€ ï¼Œ æ˜¯ é‡‘å±± çš„ ç™¾å§“ æœ‰ç¦ ï¼Œ å¯æ˜¯ è¿™ä»¶ äº‹å¯¹ æè¾¾åº· çš„ è§¦åŠ¨ å¾ˆå¤§ ã€‚ æ˜“å­¦ä¹  åˆ å›å¿†èµ· ä»–ä»¬ ä¸‰äºº åˆ†å¼€ çš„ å‰ä¸€æ™š ï¼Œ å¤§å®¶ ä¸€èµ· å–é…’ è¯åˆ« ï¼Œ æ˜“å­¦ä¹  è¢« é™èŒ åˆ° é“å£ å¿å½“ å¿é•¿ ï¼Œ ç‹å¤§è·¯ ä¸‹æµ·ç»å•† ï¼Œ æè¾¾åº· è¿è¿ èµ”ç¤¼é“æ­‰ ï¼Œ è§‰å¾— å¯¹ä¸èµ· å¤§å®¶ ï¼Œ ä»– æœ€ å¯¹ä¸èµ· çš„ æ˜¯ ç‹å¤§è·¯ ï¼Œ å°± å’Œ æ˜“å­¦ä¹  ä¸€èµ· ç»™ ç‹å¤§è·¯ å‡‘ äº† 5 ä¸‡å— é’± ï¼Œ ç‹å¤§è·¯ è‡ªå·± ä¸œæŒªè¥¿æ’® äº† 5 ä¸‡å— ï¼Œ å¼€å§‹ ä¸‹æµ·ç»å•† ã€‚ æ²¡æƒ³åˆ° åæ¥ ç‹å¤§è·¯ ç«Ÿç„¶ åš å¾— é£ç”Ÿæ°´ èµ· ã€‚ æ²™ç‘é‡‘ è§‰å¾— ä»–ä»¬ ä¸‰äºº ï¼Œ åœ¨ å›°éš¾ æ—¶æœŸ è¿˜ èƒ½ ä»¥æ²« ç›¸åŠ© ï¼Œ å¾ˆ ä¸ å®¹æ˜“ ã€‚



         æ²™ç‘é‡‘ å‘ æ¯›å¨… æ‰“å¬ ä»–ä»¬ å®¶ åœ¨ äº¬å· çš„ åˆ«å¢… ï¼Œ æ¯›å¨… ç¬‘ ç€ è¯´ ï¼Œ ç‹å¤§è·¯ äº‹ä¸šæœ‰æˆ ä¹‹å ï¼Œ è¦ ç»™ æ¬§é˜³ è å’Œ å¥¹ å…¬å¸ çš„ è‚¡æƒ ï¼Œ å¥¹ä»¬ æ²¡æœ‰ è¦ ï¼Œ ç‹å¤§è·¯ å°± åœ¨ äº¬å· å¸è±ªå›­ ä¹° äº† ä¸‰å¥— åˆ«å¢… ï¼Œ å¯æ˜¯ æè¾¾åº· å’Œ æ˜“å­¦ä¹  éƒ½ ä¸è¦ ï¼Œ è¿™äº› æˆ¿å­ éƒ½ åœ¨ ç‹å¤§è·¯ çš„ åä¸‹ ï¼Œ æ¬§é˜³ è å¥½åƒ å» ä½ è¿‡ ï¼Œ æ¯›å¨… ä¸æƒ³ å» ï¼Œ å¥¹ è§‰å¾— æˆ¿å­ å¤ªå¤§ å¾ˆ æµªè´¹ ï¼Œ è‡ªå·± å®¶ä½ å¾— å°± å¾ˆ è¸å® ã€‚
</code></pre>
<h3 id="å¼•å…¥åœç”¨è¯"><a href="#å¼•å…¥åœç”¨è¯" class="headerlink" title="å¼•å…¥åœç”¨è¯"></a>å¼•å…¥åœç”¨è¯</h3><p>åœ¨ä¸Šé¢æˆ‘ä»¬è§£æçš„æ–‡æœ¬ä¸­æœ‰å¾ˆå¤šæ— æ•ˆçš„è¯ï¼Œæ¯”å¦‚â€œç€â€ï¼Œâ€œå’Œâ€ï¼Œè¿˜æœ‰ä¸€äº›æ ‡ç‚¹ç¬¦å·ï¼Œè¿™äº›æˆ‘ä»¬ä¸æƒ³åœ¨æ–‡æœ¬åˆ†æçš„æ—¶å€™å¼•å…¥ï¼Œå› æ­¤éœ€è¦å»æ‰ï¼Œè¿™äº›è¯å°±æ˜¯åœç”¨è¯ã€‚å¸¸ç”¨çš„ä¸­æ–‡åœç”¨è¯è¡¨æ˜¯1208ä¸ªï¼Œ<a target="_blank" rel="noopener" href="http://files.cnblogs.com/files/pinard/stop_words.zip">ä¸‹è½½åœ°å€åœ¨è¿™</a>ã€‚å½“ç„¶ä¹Ÿæœ‰å…¶ä»–ç‰ˆæœ¬çš„åœç”¨è¯è¡¨ï¼Œä¸è¿‡è¿™ä¸ª1208è¯ç‰ˆæ˜¯æˆ‘å¸¸ç”¨çš„ã€‚</p>
<p>åœ¨æˆ‘ä»¬ç”¨scikit-learnåšç‰¹å¾å¤„ç†çš„æ—¶å€™ï¼Œå¯ä»¥é€šè¿‡å‚æ•°stop_wordsæ¥å¼•å…¥ä¸€ä¸ªæ•°ç»„ä½œä¸ºåœç”¨è¯è¡¨ã€‚</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">stpword_path = <span class="string">&quot;stop_words.txt&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(stpword_path, encoding=<span class="string">&quot;gbk&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line"></span><br><span class="line">    stpword_content = f.read()</span><br><span class="line"></span><br><span class="line">    stpword_list = stpword_content.splitlines()</span><br><span class="line"></span><br></pre></td></tr></table></figure>





<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="built_in">print</span>(stpword_list[:<span class="number">100</span>])</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<pre><code>[&#39;,&#39;, &#39;?&#39;, &#39;ã€&#39;, &#39;ã€‚&#39;, &#39;â€œ&#39;, &#39;â€&#39;, &#39;ã€Š&#39;, &#39;ã€‹&#39;, &#39;ï¼&#39;, &#39;ï¼Œ&#39;, &#39;ï¼š&#39;, &#39;ï¼›&#39;, &#39;ï¼Ÿ&#39;, &#39;äººæ°‘&#39;, &#39;æœ«##æœ«&#39;, &#39;å•Š&#39;, &#39;é˜¿&#39;, &#39;å“&#39;, &#39;å“å‘€&#39;, &#39;å“å“Ÿ&#39;, &#39;å”‰&#39;, &#39;ä¿º&#39;, &#39;ä¿ºä»¬&#39;, &#39;æŒ‰&#39;, &#39;æŒ‰ç…§&#39;, &#39;å§&#39;, &#39;å§å“’&#39;, &#39;æŠŠ&#39;, &#39;ç½¢äº†&#39;, &#39;è¢«&#39;, &#39;æœ¬&#39;, &#39;æœ¬ç€&#39;, &#39;æ¯”&#39;, &#39;æ¯”æ–¹&#39;, &#39;æ¯”å¦‚&#39;, &#39;é„™äºº&#39;, &#39;å½¼&#39;, &#39;å½¼æ­¤&#39;, &#39;è¾¹&#39;, &#39;åˆ«&#39;, &#39;åˆ«çš„&#39;, &#39;åˆ«è¯´&#39;, &#39;å¹¶&#39;, &#39;å¹¶ä¸”&#39;, &#39;ä¸æ¯”&#39;, &#39;ä¸æˆ&#39;, &#39;ä¸å•&#39;, &#39;ä¸ä½†&#39;, &#39;ä¸ç‹¬&#39;, &#39;ä¸ç®¡&#39;, &#39;ä¸å…‰&#39;, &#39;ä¸è¿‡&#39;, &#39;ä¸ä»…&#39;, &#39;ä¸æ‹˜&#39;, &#39;ä¸è®º&#39;, &#39;ä¸æ€•&#39;, &#39;ä¸ç„¶&#39;, &#39;ä¸å¦‚&#39;, &#39;ä¸ç‰¹&#39;, &#39;ä¸æƒŸ&#39;, &#39;ä¸é—®&#39;, &#39;ä¸åª&#39;, &#39;æœ&#39;, &#39;æœç€&#39;, &#39;è¶&#39;, &#39;è¶ç€&#39;, &#39;ä¹˜&#39;, &#39;å†²&#39;, &#39;é™¤&#39;, &#39;é™¤æ­¤ä¹‹å¤–&#39;, &#39;é™¤é&#39;, &#39;é™¤äº†&#39;, &#39;æ­¤&#39;, &#39;æ­¤é—´&#39;, &#39;æ­¤å¤–&#39;, &#39;ä»&#39;, &#39;ä»è€Œ&#39;, &#39;æ‰“&#39;, &#39;å¾…&#39;, &#39;ä½†&#39;, &#39;ä½†æ˜¯&#39;, &#39;å½“&#39;, &#39;å½“ç€&#39;, &#39;åˆ°&#39;, &#39;å¾—&#39;, &#39;çš„&#39;, &#39;çš„è¯&#39;, &#39;ç­‰&#39;, &#39;ç­‰ç­‰&#39;, &#39;åœ°&#39;, &#39;ç¬¬&#39;, &#39;å®å’š&#39;, &#39;å¯¹&#39;, &#39;å¯¹äº&#39;, &#39;å¤š&#39;, &#39;å¤šå°‘&#39;, &#39;è€Œ&#39;, &#39;è€Œå†µ&#39;, &#39;è€Œä¸”&#39;, &#39;è€Œæ˜¯&#39;]
</code></pre>
<h3 id="ç‰¹å¾å¤„ç†"><a href="#ç‰¹å¾å¤„ç†" class="headerlink" title="ç‰¹å¾å¤„ç†"></a>ç‰¹å¾å¤„ç†</h3><p>ç°åœ¨æˆ‘ä»¬å°±å¯ä»¥ç”¨scikit-learnæ¥å¯¹æˆ‘ä»¬çš„æ–‡æœ¬ç‰¹å¾è¿›è¡Œå¤„ç†äº†ï¼Œåœ¨<a target="_blank" rel="noopener" href="http://www.cnblogs.com/pinard/p/6688348.html">æ–‡æœ¬æŒ–æ˜é¢„å¤„ç†ä¹‹å‘é‡åŒ–ä¸Hash Trickä¸­</a>ï¼Œæˆ‘ä»¬è®²åˆ°äº†ä¸¤ç§ç‰¹å¾å¤„ç†çš„æ–¹æ³•ï¼Œå‘é‡åŒ–ä¸Hash Trickã€‚è€Œå‘é‡åŒ–æ˜¯æœ€å¸¸ç”¨çš„æ–¹æ³•ï¼Œå› ä¸ºå®ƒå¯ä»¥æ¥ç€è¿›è¡ŒTF-IDFçš„ç‰¹å¾å¤„ç†ã€‚åœ¨<a target="_blank" rel="noopener" href="http://www.cnblogs.com/pinard/p/6693230.html">æ–‡æœ¬æŒ–æ˜é¢„å¤„ç†ä¹‹TF-IDF</a>ä¸­ï¼Œæˆ‘ä»¬ä¹Ÿè®²åˆ°äº†TF-IDFç‰¹å¾å¤„ç†çš„æ–¹æ³•ã€‚è¿™é‡Œæˆ‘ä»¬å°±ç”¨scikit-learnçš„TfidfVectorizerç±»æ¥è¿›è¡ŒTF-IDFç‰¹å¾å¤„ç†ã€‚</p>
<h4 id="å‘é‡åŒ–ä¸-Hash-Trick"><a href="#å‘é‡åŒ–ä¸-Hash-Trick" class="headerlink" title="å‘é‡åŒ–ä¸ Hash Trick"></a>å‘é‡åŒ–ä¸ Hash Trick</h4><h5 id="è¯è¢‹æ¨¡å‹"><a href="#è¯è¢‹æ¨¡å‹" class="headerlink" title="è¯è¢‹æ¨¡å‹"></a>è¯è¢‹æ¨¡å‹</h5><p>åœ¨è®²å‘é‡åŒ–ä¸Hash Trickä¹‹å‰ï¼Œæˆ‘ä»¬å…ˆè¯´è¯´è¯è¢‹æ¨¡å‹(Bag of Words,ç®€ç§°BoW)ã€‚è¯è¢‹æ¨¡å‹å‡è®¾æˆ‘ä»¬ä¸è€ƒè™‘æ–‡æœ¬ä¸­è¯ä¸è¯ä¹‹é—´çš„ä¸Šä¸‹æ–‡å…³ç³»ï¼Œä»…ä»…åªè€ƒè™‘æ‰€æœ‰è¯çš„æƒé‡ã€‚è€Œæƒé‡ä¸è¯åœ¨æ–‡æœ¬ä¸­å‡ºç°çš„é¢‘ç‡æœ‰å…³ã€‚</p>
<p>è¯è¢‹æ¨¡å‹é¦–å…ˆä¼šè¿›è¡Œåˆ†è¯ï¼Œåœ¨åˆ†è¯ä¹‹åï¼Œé€šè¿‡ç»Ÿè®¡æ¯ä¸ªè¯åœ¨æ–‡æœ¬ä¸­å‡ºç°çš„æ¬¡æ•°ï¼Œæˆ‘ä»¬å°±å¯ä»¥å¾—åˆ°è¯¥æ–‡æœ¬åŸºäºè¯çš„ç‰¹å¾ï¼Œå¦‚æœå°†å„ä¸ªæ–‡æœ¬æ ·æœ¬çš„è¿™äº›è¯ä¸å¯¹åº”çš„è¯é¢‘æ”¾åœ¨ä¸€èµ·ï¼Œå°±æ˜¯æˆ‘ä»¬å¸¸è¯´çš„å‘é‡åŒ–ã€‚å‘é‡åŒ–å®Œæ¯•åä¸€èˆ¬ä¹Ÿä¼šä½¿ç”¨TF-IDFè¿›è¡Œç‰¹å¾çš„æƒé‡ä¿®æ­£ï¼Œå†å°†ç‰¹å¾è¿›è¡Œæ ‡å‡†åŒ–ã€‚ å†è¿›è¡Œä¸€äº›å…¶ä»–çš„ç‰¹å¾å·¥ç¨‹åï¼Œå°±å¯ä»¥å°†æ•°æ®å¸¦å…¥æœºå™¨å­¦ä¹ ç®—æ³•è¿›è¡Œåˆ†ç±»èšç±»äº†ã€‚</p>
<p>æ€»ç»“ä¸‹è¯è¢‹æ¨¡å‹çš„ä¸‰éƒ¨æ›²ï¼šåˆ†è¯ï¼ˆtokenizingï¼‰ï¼Œç»Ÿè®¡ä¿®è®¢è¯ç‰¹å¾å€¼ï¼ˆcountingï¼‰ä¸æ ‡å‡†åŒ–ï¼ˆnormalizingï¼‰ã€‚</p>
<p>è¯è¢‹æ¨¡å‹æœ‰å¾ˆå¤§çš„å±€é™æ€§ï¼Œå› ä¸ºå®ƒä»…ä»…è€ƒè™‘äº†è¯é¢‘ï¼Œæ²¡æœ‰è€ƒè™‘ä¸Šä¸‹æ–‡çš„å…³ç³»ï¼Œå› æ­¤ä¼šä¸¢å¤±ä¸€éƒ¨åˆ†æ–‡æœ¬çš„è¯­ä¹‰ã€‚ä½†æ˜¯å¤§å¤šæ•°æ—¶å€™ï¼Œå¦‚æœæˆ‘ä»¬çš„ç›®çš„æ˜¯åˆ†ç±»èšç±»ï¼Œåˆ™è¯è¢‹æ¨¡å‹è¡¨ç°çš„å¾ˆå¥½ã€‚</p>
<h5 id="è¯è¢‹æ¨¡å‹ä¹‹å‘é‡åŒ–"><a href="#è¯è¢‹æ¨¡å‹ä¹‹å‘é‡åŒ–" class="headerlink" title="è¯è¢‹æ¨¡å‹ä¹‹å‘é‡åŒ–"></a>è¯è¢‹æ¨¡å‹ä¹‹å‘é‡åŒ–</h5><p>åœ¨è¯è¢‹æ¨¡å‹çš„ç»Ÿè®¡è¯é¢‘è¿™ä¸€æ­¥ï¼Œæˆ‘ä»¬ä¼šå¾—åˆ°è¯¥æ–‡æœ¬ä¸­æ‰€æœ‰è¯çš„è¯é¢‘ï¼Œæœ‰äº†è¯é¢‘ï¼Œæˆ‘ä»¬å°±å¯ä»¥ç”¨è¯å‘é‡è¡¨ç¤ºè¿™ä¸ªæ–‡æœ¬ã€‚è¿™é‡Œæˆ‘ä»¬ä¸¾ä¸€ä¸ªä¾‹å­ï¼Œä¾‹å­ç›´æ¥ç”¨scikit-learnçš„CountVectorizerç±»æ¥å®Œæˆï¼Œè¿™ä¸ªç±»å¯ä»¥å¸®æˆ‘ä»¬å®Œæˆæ–‡æœ¬çš„è¯é¢‘ç»Ÿè®¡ä¸å‘é‡åŒ–ï¼Œä»£ç å¦‚ä¸‹ï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.feature_extraction.text <span class="keyword">import</span> CountVectorizer</span><br><span class="line"></span><br><span class="line">vectorizer = CountVectorizer()</span><br><span class="line"></span><br></pre></td></tr></table></figure>





<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">corpus=[<span class="string">&quot;I come to China to travel&quot;</span>,</span><br><span class="line"></span><br><span class="line">    <span class="string">&quot;This is a car polupar in China&quot;</span>,          </span><br><span class="line"></span><br><span class="line">    <span class="string">&quot;I love tea and Apple &quot;</span>,   </span><br><span class="line"></span><br><span class="line">    <span class="string">&quot;The work is to write some papers in science&quot;</span>]</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(vectorizer.fit_transform(corpus))</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<pre><code>  (0, 16)    1

  (0, 3)    1

  (0, 15)    2

  (0, 4)    1

  (1, 5)    1

  (1, 9)    1

  (1, 2)    1

  (1, 6)    1

  (1, 14)    1

  (1, 3)    1

  (2, 1)    1

  (2, 0)    1

  (2, 12)    1

  (2, 7)    1

  (3, 10)    1

  (3, 8)    1

  (3, 11)    1

  (3, 18)    1

  (3, 17)    1

  (3, 13)    1

  (3, 5)    1

  (3, 6)    1

  (3, 15)    1
</code></pre>
<p>å¯ä»¥çœ‹å‡º4ä¸ªæ–‡æœ¬çš„è¯é¢‘å·²ç»ç»Ÿè®¡å‡ºï¼Œåœ¨è¾“å‡ºä¸­ï¼Œå·¦è¾¹çš„æ‹¬å·ä¸­çš„ç¬¬ä¸€ä¸ªæ•°å­—æ˜¯æ–‡æœ¬çš„åºå·ï¼Œç¬¬2ä¸ªæ•°å­—æ˜¯è¯çš„åºå·ï¼Œæ³¨æ„è¯çš„åºå·æ˜¯åŸºäºæ‰€æœ‰çš„æ–‡æ¡£çš„ã€‚ç¬¬ä¸‰ä¸ªæ•°å­—å°±æ˜¯æˆ‘ä»¬çš„è¯é¢‘ã€‚</p>
<p>æˆ‘ä»¬å¯ä»¥è¿›ä¸€æ­¥çœ‹çœ‹æ¯ä¸ªæ–‡æœ¬çš„è¯å‘é‡ç‰¹å¾å’Œå„ä¸ªç‰¹å¾ä»£è¡¨çš„è¯ï¼Œä»£ç å¦‚ä¸‹ï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="built_in">print</span>(vectorizer.fit_transform(corpus).toarray())</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<pre><code>[[0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 2 1 0 0]

 [0 0 1 1 0 1 1 0 0 1 0 0 0 0 1 0 0 0 0]

 [1 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0]

 [0 0 0 0 0 1 1 0 1 0 1 1 0 1 0 1 0 1 1]]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="built_in">print</span>(vectorizer.get_feature_names())</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<pre><code>[&#39;and&#39;, &#39;apple&#39;, &#39;car&#39;, &#39;china&#39;, &#39;come&#39;, &#39;in&#39;, &#39;is&#39;, &#39;love&#39;, &#39;papers&#39;, &#39;polupar&#39;, &#39;science&#39;, &#39;some&#39;, &#39;tea&#39;, &#39;the&#39;, &#39;this&#39;, &#39;to&#39;, &#39;travel&#39;, &#39;work&#39;, &#39;write&#39;]
</code></pre>
<p>ä¹Ÿå°±æ˜¯å…ˆç»Ÿè®¡æ•´ä¸ªæ–‡æœ¬corpus, å»æ‰åœç”¨è¯ï¼Œå‰©ä¸‹çš„è¯å°±æ˜¯å‘é‡çš„ç»´åº¦ã€‚ç„¶åç»Ÿè®¡æ¯ä¸€è¡Œæ–‡å­—å‡ºç°çš„è¯é¢‘ï¼Œå¾—åˆ°ç›¸åº”çš„å‘é‡ã€‚æ˜¾ç„¶è¯è¡¨æ˜¯æŒ‰ç…§å­—æ¯é¡ºåºæ’åºçš„ã€‚</p>
<p>å¯ä»¥çœ‹åˆ°æˆ‘ä»¬ä¸€å…±æœ‰19ä¸ªè¯ï¼Œæ‰€ä»¥4ä¸ªæ–‡æœ¬éƒ½æ˜¯19ç»´çš„ç‰¹å¾å‘é‡ã€‚è€Œæ¯ä¸€ç»´çš„å‘é‡ä¾æ¬¡å¯¹åº”äº†ä¸‹é¢çš„19ä¸ªè¯ã€‚å¦å¤–ç”±äºè¯â€Iâ€åœ¨è‹±æ–‡ä¸­æ˜¯åœç”¨è¯ï¼Œä¸å‚åŠ è¯é¢‘çš„ç»Ÿè®¡ã€‚</p>
<p>ç”±äºå¤§éƒ¨åˆ†çš„æ–‡æœ¬éƒ½åªä¼šä½¿ç”¨è¯æ±‡è¡¨ä¸­çš„å¾ˆå°‘ä¸€éƒ¨åˆ†çš„è¯ï¼Œå› æ­¤æˆ‘ä»¬çš„è¯å‘é‡ä¸­ä¼šæœ‰å¤§é‡çš„0ã€‚ä¹Ÿå°±æ˜¯è¯´è¯å‘é‡æ˜¯ç¨€ç–çš„ã€‚åœ¨å®é™…åº”ç”¨ä¸­ä¸€èˆ¬ä½¿ç”¨ç¨€ç–çŸ©é˜µæ¥å­˜å‚¨ã€‚</p>
<blockquote>
<p><strong>è¿™é‡Œæœ‰ä¸ªç–‘é—®ï¼Ÿ</strong> å‘é‡åŒ–ä¹‹åçš„ç»´åº¦æ˜¯æ ¹æ®è‡ªå·±çš„æ•°æ®é›†æ¥å®šï¼Œä¸ºä»€ä¹ˆä¸å°±æ˜¯è¯è¡¨å¤§å°å‘¢ã€‚è¿™é‡Œæ˜¯æ ¹æ®è‡ªå·±çš„æ•°æ®é›†æ¥çš„ï¼Œä½†æˆ‘ä»¬å¯¹æµ‹è¯•é›†åˆ†ç±»æ—¶ï¼Œä¼šå‡ºç° UNK è¯å§ï¼Œä½†æ˜¯è¿™ä¸ªè¯å…¶å®åœ¨è¯è¡¨ä¸­æ˜¯æœ‰çš„ã€‚é‚£ä¹ˆåœ¨è®­ç»ƒé›†ä¸­å¦‚æœåŠ ä¸Šè¿™ä¸ªç»´åº¦ï¼Œå…¶å®ä¹Ÿæ²¡æœ‰å¤ªå¤§æ„ä¹‰ï¼Œå› ä¸ºåœ¨è®­ç»ƒé›†ä¸­è¿™ä¸ªç»´åº¦ä¸Šæ‰€æœ‰çš„å€¼éƒ½ä¸º0.</p>
</blockquote>
<p>å°†æ–‡æœ¬åšäº†è¯é¢‘ç»Ÿè®¡åï¼Œæˆ‘ä»¬ä¸€èˆ¬ä¼šé€šè¿‡TF-IDFè¿›è¡Œè¯ç‰¹å¾å€¼ä¿®è®¢ï¼Œè¿™éƒ¨åˆ†æˆ‘ä»¬åé¢å†è®²ã€‚</p>
<p>å‘é‡åŒ–çš„æ–¹æ³•å¾ˆå¥½ç”¨ï¼Œä¹Ÿå¾ˆç›´æ¥ï¼Œä½†æ˜¯åœ¨æœ‰äº›åœºæ™¯ä¸‹å¾ˆéš¾ä½¿ç”¨ï¼Œæ¯”å¦‚åˆ†è¯åçš„è¯æ±‡è¡¨éå¸¸å¤§ï¼Œè¾¾åˆ°100ä¸‡+ï¼Œæ­¤æ—¶å¦‚æœæˆ‘ä»¬ç›´æ¥ä½¿ç”¨å‘é‡åŒ–çš„æ–¹æ³•ï¼Œå°†å¯¹åº”çš„æ ·æœ¬å¯¹åº”ç‰¹å¾çŸ©é˜µè½½å…¥å†…å­˜ï¼Œæœ‰å¯èƒ½å°†å†…å­˜æ’‘çˆ†ï¼Œåœ¨è¿™ç§æƒ…å†µä¸‹æˆ‘ä»¬æ€ä¹ˆåŠå‘¢ï¼Ÿç¬¬ä¸€ååº”æ˜¯æˆ‘ä»¬è¦è¿›è¡Œç‰¹å¾çš„é™ç»´ï¼Œè¯´çš„æ²¡é”™ï¼è€ŒHash Trickå°±æ˜¯éå¸¸å¸¸ç”¨çš„æ–‡æœ¬ç‰¹å¾é™ç»´æ–¹æ³•ã€‚</p>
<h5 id="Hash-Trick"><a href="#Hash-Trick" class="headerlink" title="Hash Trick"></a>Hash Trick</h5><p>åœ¨å¤§è§„æ¨¡çš„æ–‡æœ¬å¤„ç†ä¸­ï¼Œç”±äºç‰¹å¾çš„ç»´åº¦å¯¹åº”åˆ†è¯è¯æ±‡è¡¨çš„å¤§å°ï¼Œæ‰€ä»¥ç»´åº¦å¯èƒ½éå¸¸ææ€–ï¼Œæ­¤æ—¶éœ€è¦è¿›è¡Œé™ç»´ï¼Œä¸èƒ½ç›´æ¥ç”¨æˆ‘ä»¬ä¸Šä¸€èŠ‚çš„å‘é‡åŒ–æ–¹æ³•ã€‚è€Œæœ€å¸¸ç”¨çš„æ–‡æœ¬é™ç»´æ–¹æ³•æ˜¯Hash Trickã€‚è¯´åˆ°Hashï¼Œä¸€ç‚¹ä¹Ÿä¸ç¥ç§˜ï¼Œå­¦è¿‡æ•°æ®ç»“æ„çš„åŒå­¦éƒ½çŸ¥é“ã€‚è¿™é‡Œçš„Hashæ„ä¹‰ä¹Ÿç±»ä¼¼ã€‚</p>
<p>åœ¨Hash Trické‡Œï¼Œæˆ‘ä»¬ä¼šå®šä¹‰ä¸€ä¸ªç‰¹å¾Hashåå¯¹åº”çš„å“ˆå¸Œè¡¨çš„å¤§å°ï¼Œè¿™ä¸ªå“ˆå¸Œè¡¨çš„ç»´åº¦ä¼šè¿œè¿œå°äºæˆ‘ä»¬çš„è¯æ±‡è¡¨çš„ç‰¹å¾ç»´åº¦ï¼Œå› æ­¤å¯ä»¥çœ‹æˆæ˜¯é™ç»´ã€‚å…·ä½“çš„æ–¹æ³•æ˜¯ï¼Œå¯¹åº”ä»»æ„ä¸€ä¸ªç‰¹å¾åï¼Œæˆ‘ä»¬ä¼šç”¨Hashå‡½æ•°æ‰¾åˆ°å¯¹åº”å“ˆå¸Œè¡¨çš„ä½ç½®ï¼Œç„¶åå°†è¯¥ç‰¹å¾åå¯¹åº”çš„è¯é¢‘ç»Ÿè®¡å€¼ç´¯åŠ åˆ°è¯¥å“ˆå¸Œè¡¨ä½ç½®ã€‚å¦‚æœç”¨æ•°å­¦è¯­è¨€è¡¨ç¤º,å‡å¦‚å“ˆå¸Œå‡½æ•°hä½¿ç¬¬iä¸ªç‰¹å¾å“ˆå¸Œåˆ°ä½ç½®j,å³ $h(i)=j$,åˆ™ç¬¬iä¸ªåŸå§‹ç‰¹å¾çš„è¯é¢‘æ•°å€¼ $\phi(i)$ å°†ç´¯åŠ åˆ°å“ˆå¸Œåçš„ç¬¬jä¸ªç‰¹å¾çš„è¯é¢‘æ•°å€¼ $\hat \phi(i)$ä¸Šï¼Œå³ï¼š</p>
<p>$$\hat \phi(i)=\sum_{i\in J;h(i)=j}\phi(i)$$</p>
<p>å…¶ä¸­ J æ˜¯åŸå§‹ç‰¹å¾çš„ç»´åº¦ã€‚</p>
<p>ä½†æ˜¯ä¸Šé¢çš„æ–¹æ³•æœ‰ä¸€ä¸ªé—®é¢˜ï¼Œæœ‰å¯èƒ½ä¸¤ä¸ªåŸå§‹ç‰¹å¾çš„å“ˆå¸Œåä½ç½®åœ¨ä¸€èµ·å¯¼è‡´è¯é¢‘ç´¯åŠ ç‰¹å¾å€¼çªç„¶å˜å¤§ï¼Œä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œå‡ºç°äº†hash Trickçš„å˜ç§signed hash trick,æ­¤æ—¶é™¤äº†å“ˆå¸Œå‡½æ•°h,æˆ‘ä»¬å¤šäº†ä¸€ä¸ªä¸€ä¸ªå“ˆå¸Œå‡½æ•°ï¼š</p>
<p>$$\xi:N\rightarrow \pm1$$</p>
<p>æ­¤æ—¶æˆ‘ä»¬æœ‰</p>
<p>$$\hat \phi(j)=\sum_{i\in J;h(i)=j}\phi(i)\xi(i)$$</p>
<p>è¿™æ ·åšçš„å¥½å¤„æ˜¯ï¼Œå“ˆå¸Œåçš„ç‰¹å¾ä»ç„¶æ˜¯ä¸€ä¸ªæ— åçš„ä¼°è®¡ï¼Œä¸ä¼šå¯¼è‡´æŸäº›å“ˆå¸Œä½ç½®çš„å€¼è¿‡å¤§ã€‚</p>
<p>å½“ç„¶ï¼Œå¤§å®¶ä¼šæœ‰ç–‘æƒ‘ï¼Œè¿™ç§æ–¹æ³•æ¥å¤„ç†ç‰¹å¾ï¼Œå“ˆå¸Œåçš„ç‰¹å¾æ˜¯å¦èƒ½å¤Ÿå¾ˆå¥½çš„ä»£è¡¨å“ˆå¸Œå‰çš„ç‰¹å¾å‘¢ï¼Ÿä»å®é™…åº”ç”¨ä¸­è¯´ï¼Œç”±äºæ–‡æœ¬ç‰¹å¾çš„é«˜ç¨€ç–æ€§ï¼Œè¿™ä¹ˆåšæ˜¯å¯è¡Œçš„ã€‚å¦‚æœå¤§å®¶å¯¹ç†è®ºä¸Šä¸ºä½•è¿™ç§æ–¹æ³•æœ‰æ•ˆï¼Œå»ºè®®å‚è€ƒè®ºæ–‡ï¼š<a target="_blank" rel="noopener" href="http://alex.smola.org/papers/2009/Weinbergeretal09.pdf">Feature hashing for large scale multitask learning</a>.è¿™é‡Œå°±ä¸å¤šè¯´äº†ã€‚</p>
<p>åœ¨scikit-learnçš„HashingVectorizerç±»ä¸­ï¼Œå®ç°äº†åŸºäºsigned hash trickçš„ç®—æ³•ï¼Œè¿™é‡Œæˆ‘ä»¬å°±ç”¨HashingVectorizeræ¥å®è·µä¸€ä¸‹Hash Trickï¼Œä¸ºäº†ç®€å•ï¼Œæˆ‘ä»¬ä½¿ç”¨ä¸Šé¢çš„19ç»´è¯æ±‡è¡¨ï¼Œå¹¶å“ˆå¸Œé™ç»´åˆ°6ç»´ã€‚å½“ç„¶åœ¨å®é™…åº”ç”¨ä¸­ï¼Œ19ç»´çš„æ•°æ®æ ¹æœ¬ä¸éœ€è¦Hash Trickï¼Œè¿™é‡Œåªæ˜¯åšä¸€ä¸ªæ¼”ç¤ºï¼Œä»£ç å¦‚ä¸‹ï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.feature_extraction.text <span class="keyword">import</span> HashingVectorizer</span><br><span class="line"></span><br><span class="line">vectorizer2 = HashingVectorizer(n_features=<span class="number">6</span>, norm=<span class="literal">None</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(vectorizer2.fit_transform(corpus))</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<pre><code>  (0, 1)    2.0

  (0, 2)    -1.0

  (0, 4)    1.0

  (0, 5)    -1.0

  (1, 0)    1.0

  (1, 1)    1.0

  (1, 2)    -1.0

  (1, 5)    -1.0

  (2, 0)    2.0

  (2, 5)    -2.0

  (3, 0)    0.0

  (3, 1)    4.0

  (3, 2)    -1.0

  (3, 3)    1.0

  (3, 5)    -1.0
</code></pre>
<p>å¤§å®¶å¯ä»¥çœ‹åˆ°ç»“æœé‡Œé¢æœ‰è´Ÿæ•°ï¼Œè¿™æ˜¯å› ä¸ºæˆ‘ä»¬çš„å“ˆå¸Œå‡½æ•°Î¾å¯ä»¥å“ˆå¸Œåˆ°1æˆ–è€…-1å¯¼è‡´çš„ã€‚</p>
<p>å’ŒPCAç±»ä¼¼ï¼ŒHash Trické™ç»´åçš„ç‰¹å¾æˆ‘ä»¬å·²ç»ä¸çŸ¥é“å®ƒä»£è¡¨çš„ç‰¹å¾åå­—å’Œæ„ä¹‰ã€‚æ­¤æ—¶æˆ‘ä»¬ä¸èƒ½åƒä¸Šä¸€èŠ‚å‘é‡åŒ–æ—¶å€™å¯ä»¥çŸ¥é“æ¯ä¸€åˆ—çš„æ„ä¹‰ï¼Œæ‰€ä»¥Hash Trickçš„è§£é‡Šæ€§ä¸å¼ºã€‚</p>
<h5 id="å‘é‡åŒ–ä¸-Hash-Track-å°ç»“"><a href="#å‘é‡åŒ–ä¸-Hash-Track-å°ç»“" class="headerlink" title="å‘é‡åŒ–ä¸ Hash Track å°ç»“"></a>å‘é‡åŒ–ä¸ Hash Track å°ç»“</h5><p>è¿™é‡Œæˆ‘ä»¬å¯¹å‘é‡åŒ–ä¸å®ƒçš„ç‰¹ä¾‹Hash Trickåšä¸€ä¸ªæ€»ç»“ã€‚åœ¨ç‰¹å¾é¢„å¤„ç†çš„æ—¶å€™ï¼Œæˆ‘ä»¬ä»€ä¹ˆæ—¶å€™ç”¨ä¸€èˆ¬æ„ä¹‰çš„å‘é‡åŒ–ï¼Œä»€ä¹ˆæ—¶å€™ç”¨Hash Trickå‘¢ï¼Ÿæ ‡å‡†ä¹Ÿå¾ˆç®€å•ã€‚</p>
<p>ä¸€èˆ¬æ¥è¯´ï¼Œåªè¦è¯æ±‡è¡¨çš„ç‰¹å¾ä¸è‡³äºå¤ªå¤§ï¼Œå¤§åˆ°å†…å­˜ä¸å¤Ÿç”¨ï¼Œè‚¯å®šæ˜¯ä½¿ç”¨ä¸€èˆ¬æ„ä¹‰çš„å‘é‡åŒ–æ¯”è¾ƒå¥½ã€‚å› ä¸ºå‘é‡åŒ–çš„æ–¹æ³•è§£é‡Šæ€§å¾ˆå¼ºï¼Œæˆ‘ä»¬çŸ¥é“æ¯ä¸€ç»´ç‰¹å¾å¯¹åº”å“ªä¸€ä¸ªè¯ï¼Œè¿›è€Œæˆ‘ä»¬è¿˜å¯ä»¥ä½¿ç”¨TF-IDFå¯¹å„ä¸ªè¯ç‰¹å¾çš„æƒé‡ä¿®æ”¹ï¼Œè¿›ä¸€æ­¥å®Œå–„ç‰¹å¾çš„è¡¨ç¤ºã€‚</p>
<p>è€ŒHash Trickç”¨å¤§è§„æ¨¡æœºå™¨å­¦ä¹ ä¸Šï¼Œæ­¤æ—¶æˆ‘ä»¬çš„è¯æ±‡é‡æå¤§ï¼Œä½¿ç”¨å‘é‡åŒ–æ–¹æ³•å†…å­˜ä¸å¤Ÿç”¨ï¼Œè€Œä½¿ç”¨Hash Trické™ç»´é€Ÿåº¦å¾ˆå¿«ï¼Œé™ç»´åçš„ç‰¹å¾ä»ç„¶å¯ä»¥å¸®æˆ‘ä»¬å®Œæˆåç»­çš„åˆ†ç±»å’Œèšç±»å·¥ä½œã€‚å½“ç„¶ç”±äºåˆ†å¸ƒå¼è®¡ç®—æ¡†æ¶çš„å­˜åœ¨ï¼Œå…¶å®ä¸€èˆ¬æˆ‘ä»¬ä¸ä¼šå‡ºç°å†…å­˜ä¸å¤Ÿçš„æƒ…å†µã€‚å› æ­¤ï¼Œå®é™…å·¥ä½œä¸­æˆ‘ä½¿ç”¨çš„éƒ½æ˜¯ç‰¹å¾å‘é‡åŒ–ã€‚</p>
<p>å‘é‡åŒ–ä¸Hash Trickå°±ä»‹ç»åˆ°è¿™é‡Œï¼Œä¸‹ä¸€ç¯‡æˆ‘ä»¬è®¨è®ºTF-IDFã€‚</p>
<h4 id="æ–‡æœ¬å‘é‡åŒ–ç‰¹å¾çš„ä¸è¶³"><a href="#æ–‡æœ¬å‘é‡åŒ–ç‰¹å¾çš„ä¸è¶³" class="headerlink" title="æ–‡æœ¬å‘é‡åŒ–ç‰¹å¾çš„ä¸è¶³"></a>æ–‡æœ¬å‘é‡åŒ–ç‰¹å¾çš„ä¸è¶³</h4><p>åœ¨å°†æ–‡æœ¬åˆ†è¯å¹¶å‘é‡åŒ–åï¼Œæˆ‘ä»¬å¯ä»¥å¾—åˆ°è¯æ±‡è¡¨ä¸­æ¯ä¸ªè¯åœ¨å„ä¸ªæ–‡æœ¬ä¸­å½¢æˆçš„è¯å‘é‡ï¼Œæ¯”å¦‚åœ¨æ–‡æœ¬æŒ–æ˜é¢„å¤„ç†ä¹‹å‘é‡åŒ–ä¸Hash Trickè¿™ç¯‡æ–‡ç« ä¸­ï¼Œæˆ‘ä»¬å°†ä¸‹é¢4ä¸ªçŸ­æ–‡æœ¬åšäº†è¯é¢‘ç»Ÿè®¡ï¼š</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">corpus=[&quot;I come to China to travel&quot;,</span><br><span class="line"></span><br><span class="line">    &quot;This is a car polupar in China&quot;,          </span><br><span class="line"></span><br><span class="line">    &quot;I love tea and Apple &quot;,   </span><br><span class="line"></span><br><span class="line">    &quot;The work is to write some papers in science&quot;]</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<p>ä¸è€ƒè™‘åœç”¨è¯ï¼Œå¤„ç†åå¾—åˆ°çš„è¯å‘é‡å¦‚ä¸‹ï¼š  </p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">[[0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 2 1 0 0]</span><br><span class="line"></span><br><span class="line"> [0 0 1 1 0 1 1 0 0 1 0 0 0 0 1 0 0 0 0]</span><br><span class="line"></span><br><span class="line"> [1 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0]</span><br><span class="line"></span><br><span class="line"> [0 0 0 0 0 1 1 0 1 0 1 1 0 1 0 1 0 1 1]]</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<p>å¦‚æœæˆ‘ä»¬ç›´æ¥å°†ç»Ÿè®¡è¯é¢‘åçš„19ç»´ç‰¹å¾åšä¸ºæ–‡æœ¬åˆ†ç±»çš„è¾“å…¥ï¼Œä¼šå‘ç°æœ‰ä¸€äº›é—®é¢˜ã€‚æ¯”å¦‚ç¬¬ä¸€ä¸ªæ–‡æœ¬ï¼Œæˆ‘ä»¬å‘ç°â€comeâ€,â€Chinaâ€å’Œâ€œTravelâ€å„å‡ºç°1æ¬¡ï¼Œè€Œâ€œtoâ€œå‡ºç°äº†ä¸¤æ¬¡ã€‚ä¼¼ä¹çœ‹èµ·æ¥è¿™ä¸ªæ–‡æœ¬ä¸â€toâ€œè¿™ä¸ªç‰¹å¾æ›´å…³ç³»ç´§å¯†ã€‚ä½†æ˜¯å®é™…ä¸Šâ€toâ€œæ˜¯ä¸€ä¸ªéå¸¸æ™®éçš„è¯ï¼Œå‡ ä¹æ‰€æœ‰çš„æ–‡æœ¬éƒ½ä¼šç”¨åˆ°ï¼Œå› æ­¤è™½ç„¶å®ƒçš„è¯é¢‘ä¸º2ï¼Œä½†æ˜¯é‡è¦æ€§å´æ¯”è¯é¢‘ä¸º1çš„â€Chinaâ€å’Œâ€œTravelâ€è¦ä½çš„å¤šã€‚å¦‚æœæˆ‘ä»¬çš„å‘é‡åŒ–ç‰¹å¾ä»…ä»…ç”¨è¯é¢‘è¡¨ç¤ºå°±æ— æ³•ååº”è¿™ä¸€ç‚¹ã€‚å› æ­¤æˆ‘ä»¬éœ€è¦è¿›ä¸€æ­¥çš„é¢„å¤„ç†æ¥ååº”æ–‡æœ¬çš„è¿™ä¸ªç‰¹å¾ï¼Œè€Œè¿™ä¸ªé¢„å¤„ç†å°±æ˜¯TF-IDFã€‚</p>
<h4 id="TF-IDFæ¦‚è¿°"><a href="#TF-IDFæ¦‚è¿°" class="headerlink" title="TF-IDFæ¦‚è¿°"></a>TF-IDFæ¦‚è¿°</h4><p>TF-IDFæ˜¯Term Frequency -  Inverse Document Frequencyçš„ç¼©å†™ï¼Œå³â€œè¯é¢‘-é€†æ–‡æœ¬é¢‘ç‡â€ã€‚å®ƒç”±ä¸¤éƒ¨åˆ†ç»„æˆï¼ŒTFå’ŒIDFã€‚</p>
<p>å‰é¢çš„TFä¹Ÿå°±æ˜¯æˆ‘ä»¬å‰é¢è¯´åˆ°çš„è¯é¢‘ï¼Œæˆ‘ä»¬ä¹‹å‰åšçš„å‘é‡åŒ–ä¹Ÿå°±æ˜¯åšäº†æ–‡æœ¬ä¸­å„ä¸ªè¯çš„å‡ºç°é¢‘ç‡ç»Ÿè®¡ï¼Œå¹¶ä½œä¸ºæ–‡æœ¬ç‰¹å¾ï¼Œè¿™ä¸ªå¾ˆå¥½ç†è§£ã€‚å…³é”®æ˜¯åé¢çš„è¿™ä¸ªIDFï¼Œå³â€œé€†æ–‡æœ¬é¢‘ç‡â€å¦‚ä½•ç†è§£ã€‚åœ¨ä¸Šä¸€èŠ‚ä¸­ï¼Œæˆ‘ä»¬è®²åˆ°å‡ ä¹æ‰€æœ‰æ–‡æœ¬éƒ½ä¼šå‡ºç°çš„â€toâ€å…¶è¯é¢‘è™½ç„¶é«˜ï¼Œä½†æ˜¯é‡è¦æ€§å´åº”è¯¥æ¯”è¯é¢‘ä½çš„â€Chinaâ€å’Œâ€œTravelâ€è¦ä½ã€‚æˆ‘ä»¬çš„IDFå°±æ˜¯æ¥å¸®åŠ©æˆ‘ä»¬æ¥ååº”è¿™ä¸ªè¯çš„é‡è¦æ€§çš„ï¼Œè¿›è€Œä¿®æ­£ä»…ä»…ç”¨è¯é¢‘è¡¨ç¤ºçš„è¯ç‰¹å¾å€¼ã€‚</p>
<p>æ¦‚æ‹¬æ¥è®²ï¼Œ IDFååº”äº†ä¸€ä¸ªè¯åœ¨æ‰€æœ‰æ–‡æœ¬ä¸­å‡ºç°çš„é¢‘ç‡ï¼Œå¦‚æœä¸€ä¸ªè¯åœ¨å¾ˆå¤šçš„æ–‡æœ¬ä¸­å‡ºç°ï¼Œé‚£ä¹ˆå®ƒçš„IDFå€¼åº”è¯¥ä½ï¼Œæ¯”å¦‚ä¸Šæ–‡ä¸­çš„â€œtoâ€ã€‚è€Œåè¿‡æ¥å¦‚æœä¸€ä¸ªè¯åœ¨æ¯”è¾ƒå°‘çš„æ–‡æœ¬ä¸­å‡ºç°ï¼Œé‚£ä¹ˆå®ƒçš„IDFå€¼åº”è¯¥é«˜ã€‚æ¯”å¦‚ä¸€äº›ä¸“ä¸šçš„åè¯å¦‚â€œMachine Learningâ€ã€‚è¿™æ ·çš„è¯IDFå€¼åº”è¯¥é«˜ã€‚ä¸€ä¸ªæç«¯çš„æƒ…å†µï¼Œå¦‚æœä¸€ä¸ªè¯åœ¨æ‰€æœ‰çš„æ–‡æœ¬ä¸­éƒ½å‡ºç°ï¼Œé‚£ä¹ˆå®ƒçš„IDFå€¼åº”è¯¥ä¸º0ã€‚</p>
<p>ä¸Šé¢æ˜¯ä»å®šæ€§ä¸Šè¯´æ˜çš„IDFçš„ä½œç”¨ï¼Œé‚£ä¹ˆå¦‚ä½•å¯¹ä¸€ä¸ªè¯çš„IDFè¿›è¡Œå®šé‡åˆ†æå‘¢ï¼Ÿè¿™é‡Œç›´æ¥ç»™å‡ºä¸€ä¸ªè¯xçš„IDFçš„åŸºæœ¬å…¬å¼å¦‚ä¸‹ï¼š</p>
<p>$$IDF(x)=\dfrac{N}{N(x)}$$</p>
<p>å…¶ä¸­ï¼ŒNä»£è¡¨è¯­æ–™åº“ä¸­æ–‡æœ¬çš„æ€»æ•°ï¼Œè€Œ $N(x)$ ä»£è¡¨è¯­æ–™åº“ä¸­åŒ…å«è¯xçš„æ–‡æœ¬æ€»æ•°ã€‚ä¸ºä»€ä¹ˆIDFçš„åŸºæœ¬å…¬å¼åº”è¯¥æ˜¯æ˜¯ä¸Šé¢è¿™æ ·çš„è€Œä¸æ˜¯åƒ $N/N(x)$ è¿™æ ·çš„å½¢å¼å‘¢ï¼Ÿè¿™å°±æ¶‰åŠåˆ°ä¿¡æ¯è®ºç›¸å…³çš„ä¸€äº›çŸ¥è¯†äº†ã€‚æ„Ÿå…´è¶£çš„æœ‹å‹å»ºè®®é˜…è¯»å´å†›åšå£«çš„ã€Šæ•°å­¦ä¹‹ç¾ã€‹ç¬¬11ç« ã€‚</p>
<p>ä¸Šé¢çš„IDFå…¬å¼å·²ç»å¯ä»¥ä½¿ç”¨äº†ï¼Œä½†æ˜¯åœ¨ä¸€äº›ç‰¹æ®Šçš„æƒ…å†µä¼šæœ‰ä¸€äº›å°é—®é¢˜ï¼Œæ¯”å¦‚æŸä¸€ä¸ªç”Ÿåƒ»è¯åœ¨è¯­æ–™åº“ä¸­æ²¡æœ‰ï¼Œè¿™æ ·æˆ‘ä»¬çš„åˆ†æ¯ä¸º0ï¼Œ IDFæ²¡æœ‰æ„ä¹‰äº†ã€‚æ‰€ä»¥å¸¸ç”¨çš„IDFæˆ‘ä»¬éœ€è¦åšä¸€äº›å¹³æ»‘ï¼Œä½¿è¯­æ–™åº“ä¸­æ²¡æœ‰å‡ºç°çš„è¯ä¹Ÿå¯ä»¥å¾—åˆ°ä¸€ä¸ªåˆé€‚çš„IDFå€¼ã€‚å¹³æ»‘çš„æ–¹æ³•æœ‰å¾ˆå¤šç§ï¼Œæœ€å¸¸è§çš„IDFå¹³æ»‘åçš„å…¬å¼ä¹‹ä¸€ä¸ºï¼š</p>
<p>$$IDF(x)=log\dfrac{N+1}{N(x)+1}+1$$</p>
<p>æœ‰äº†IDFçš„å®šä¹‰ï¼Œæˆ‘ä»¬å°±å¯ä»¥è®¡ç®—æŸä¸€ä¸ªè¯çš„TF-IDFå€¼äº†ï¼š</p>
<p>$$\text{TF-IDF(x)}=TF(x)*IDF(x)$$</p>
<p>å…¶ä¸­TF(x)æŒ‡è¯xåœ¨å½“å‰æ–‡æœ¬ä¸­çš„è¯é¢‘ã€‚</p>
<h4 id="ç”¨scikit-learnè¿›è¡ŒTF-IDFé¢„å¤„ç†"><a href="#ç”¨scikit-learnè¿›è¡ŒTF-IDFé¢„å¤„ç†" class="headerlink" title="ç”¨scikit-learnè¿›è¡ŒTF-IDFé¢„å¤„ç†"></a>ç”¨scikit-learnè¿›è¡ŒTF-IDFé¢„å¤„ç†</h4><p>åœ¨scikit-learnä¸­ï¼Œæœ‰ä¸¤ç§æ–¹æ³•è¿›è¡ŒTF-IDFçš„é¢„å¤„ç†ã€‚</p>
<p>ç¬¬ä¸€ç§æ–¹æ³•æ˜¯åœ¨ç”¨CountVectorizerç±»å‘é‡åŒ–ä¹‹åå†è°ƒç”¨TfidfTransformerç±»è¿›è¡Œé¢„å¤„ç†ã€‚ç¬¬äºŒç§æ–¹æ³•æ˜¯ç›´æ¥ç”¨TfidfVectorizerå®Œæˆå‘é‡åŒ–ä¸TF-IDFé¢„å¤„ç†ã€‚</p>
<p>é¦–å…ˆæˆ‘ä»¬æ¥çœ‹ç¬¬ä¸€ç§æ–¹æ³•ï¼ŒCountVectorizer+TfidfTransformerçš„ç»„åˆï¼Œä»£ç å¦‚ä¸‹ï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.feature_extraction.text <span class="keyword">import</span> TfidfTransformer</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.feature_extraction.text <span class="keyword">import</span> CountVectorizer</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">corpus = [<span class="string">&quot;I come to China to travel&quot;</span>,</span><br><span class="line"></span><br><span class="line">    <span class="string">&quot;This is a car polupar in China&quot;</span>,          </span><br><span class="line"></span><br><span class="line">    <span class="string">&quot;I love tea and Apple &quot;</span>,   </span><br><span class="line"></span><br><span class="line">    <span class="string">&quot;The work is to write some papers in science&quot;</span>]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">vectorizer = CountVectorizer()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">transformer = TfidfTransformer()</span><br><span class="line"></span><br><span class="line">tfidf = transformer.fit_transform(vectorizer.fit_transform(corpus))</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(tfidf)</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<pre><code>  (0, 4)    0.4424621378947393

  (0, 15)    0.697684463383976

  (0, 3)    0.348842231691988

  (0, 16)    0.4424621378947393

  (1, 3)    0.3574550433419527

  (1, 14)    0.45338639737285463

  (1, 6)    0.3574550433419527

  (1, 2)    0.45338639737285463

  (1, 9)    0.45338639737285463

  (1, 5)    0.3574550433419527

  (2, 7)    0.5

  (2, 12)    0.5

  (2, 0)    0.5

  (2, 1)    0.5

  (3, 15)    0.2811316284405006

  (3, 6)    0.2811316284405006

  (3, 5)    0.2811316284405006

  (3, 13)    0.3565798233381452

  (3, 17)    0.3565798233381452

  (3, 18)    0.3565798233381452

  (3, 11)    0.3565798233381452

  (3, 8)    0.3565798233381452

  (3, 10)    0.3565798233381452
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.feature_extraction.text <span class="keyword">import</span> TfidfVectorizer</span><br><span class="line"></span><br><span class="line">tfidf2 = TfidfVectorizer()</span><br><span class="line"></span><br><span class="line">re = tfidf2.fit_transform(corpus)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(re)</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<pre><code>  (0, 4)    0.4424621378947393

  (0, 15)    0.697684463383976

  (0, 3)    0.348842231691988

  (0, 16)    0.4424621378947393

  (1, 3)    0.3574550433419527

  (1, 14)    0.45338639737285463

  (1, 6)    0.3574550433419527

  (1, 2)    0.45338639737285463

  (1, 9)    0.45338639737285463

  (1, 5)    0.3574550433419527

  (2, 7)    0.5

  (2, 12)    0.5

  (2, 0)    0.5

  (2, 1)    0.5

  (3, 15)    0.2811316284405006

  (3, 6)    0.2811316284405006

  (3, 5)    0.2811316284405006

  (3, 13)    0.3565798233381452

  (3, 17)    0.3565798233381452

  (3, 18)    0.3565798233381452

  (3, 11)    0.3565798233381452

  (3, 8)    0.3565798233381452

  (3, 10)    0.3565798233381452
</code></pre>
<p>è¾“å‡ºçš„å„ä¸ªæ–‡æœ¬å„ä¸ªè¯çš„TF-IDFå€¼å’Œç¬¬ä¸€ç§çš„è¾“å‡ºå®Œå…¨ç›¸åŒã€‚å¤§å®¶å¯ä»¥è‡ªå·±å»éªŒè¯ä¸€ä¸‹ã€‚</p>
<p>ç”±äºç¬¬äºŒç§æ–¹æ³•æ¯”è¾ƒçš„ç®€æ´ï¼Œå› æ­¤åœ¨å®é™…åº”ç”¨ä¸­æ¨èä½¿ç”¨ï¼Œä¸€æ­¥åˆ°ä½å®Œæˆå‘é‡åŒ–ï¼ŒTF-IDFä¸æ ‡å‡†åŒ–ã€‚</p>
<p>TF-IDFæ˜¯éå¸¸å¸¸ç”¨çš„æ–‡æœ¬æŒ–æ˜é¢„å¤„ç†åŸºæœ¬æ­¥éª¤ï¼Œä½†æ˜¯å¦‚æœé¢„å¤„ç†ä¸­ä½¿ç”¨äº†Hash Trickï¼Œåˆ™ä¸€èˆ¬å°±æ— æ³•ä½¿ç”¨TF-IDFäº†ï¼Œå› ä¸ºHash Trickåæˆ‘ä»¬å·²ç»æ— æ³•å¾—åˆ°å“ˆå¸Œåçš„å„ç‰¹å¾çš„IDFçš„å€¼ã€‚ä½¿ç”¨äº†IF-IDFå¹¶æ ‡å‡†åŒ–ä»¥åï¼Œæˆ‘ä»¬å°±å¯ä»¥ä½¿ç”¨å„ä¸ªæ–‡æœ¬çš„è¯ç‰¹å¾å‘é‡ä½œä¸ºæ–‡æœ¬çš„ç‰¹å¾ï¼Œè¿›è¡Œåˆ†ç±»æˆ–è€…èšç±»åˆ†æã€‚</p>
<p>å½“ç„¶TF-IDFä¸å…‰å¯ä»¥ç”¨äºæ–‡æœ¬æŒ–æ˜ï¼Œåœ¨ä¿¡æ¯æ£€ç´¢ç­‰å¾ˆå¤šé¢†åŸŸéƒ½æœ‰ä½¿ç”¨ã€‚å› æ­¤å€¼å¾—å¥½å¥½çš„ç†è§£è¿™ä¸ªæ–¹æ³•çš„æ€æƒ³</p>
<p><strong>è¿˜çš„å¥½å¥½ç†è§£ä¸‹ TF-IDF æ˜¯æ€ä¹ˆå®ç°çš„ï¼</strong></p>
<h3 id="å»ºç«‹åˆ†ææ¨¡å‹"><a href="#å»ºç«‹åˆ†ææ¨¡å‹" class="headerlink" title="å»ºç«‹åˆ†ææ¨¡å‹"></a>å»ºç«‹åˆ†ææ¨¡å‹</h3><p>æœ‰äº†æ¯æ®µæ–‡æœ¬çš„TF-IDFçš„ç‰¹å¾å‘é‡ï¼Œæˆ‘ä»¬å°±å¯ä»¥åˆ©ç”¨è¿™äº›æ•°æ®å»ºç«‹åˆ†ç±»æ¨¡å‹ï¼Œæˆ–è€…èšç±»æ¨¡å‹äº†ï¼Œæˆ–è€…è¿›è¡Œä¸»é¢˜æ¨¡å‹çš„åˆ†æã€‚æ¯”å¦‚æˆ‘ä»¬ä¸Šé¢çš„ä¸¤æ®µæ–‡æœ¬ï¼Œå°±å¯ä»¥æ˜¯ä¸¤ä¸ªè®­ç»ƒæ ·æœ¬äº†ã€‚æ­¤æ—¶çš„åˆ†ç±»èšç±»æ¨¡å‹å’Œä¹‹å‰è®²çš„éè‡ªç„¶è¯­è¨€å¤„ç†çš„æ•°æ®åˆ†ææ²¡æœ‰ä»€ä¹ˆä¸¤æ ·ã€‚å› æ­¤å¯¹åº”çš„ç®—æ³•éƒ½å¯ä»¥ç›´æ¥ä½¿ç”¨ã€‚è€Œ <strong>ä¸»é¢˜æ¨¡å‹</strong> æ˜¯è‡ªç„¶è¯­è¨€å¤„ç†æ¯”è¾ƒç‰¹æ®Šçš„ä¸€å—ï¼Œè¿™ä¸ªæˆ‘ä»¬åé¢å†å•ç‹¬è®²ã€‚</p>
<h3 id="ä¸­æ–‡æ–‡æœ¬æŒ–æ˜é¢„å¤„ç†æ€»ç»“"><a href="#ä¸­æ–‡æ–‡æœ¬æŒ–æ˜é¢„å¤„ç†æ€»ç»“" class="headerlink" title="ä¸­æ–‡æ–‡æœ¬æŒ–æ˜é¢„å¤„ç†æ€»ç»“"></a>ä¸­æ–‡æ–‡æœ¬æŒ–æ˜é¢„å¤„ç†æ€»ç»“</h3><p>ä¸Šé¢æˆ‘ä»¬å¯¹ä¸­æ–‡æ–‡æœ¬æŒ–æ˜é¢„å¤„ç†çš„è¿‡ç¨‹åšäº†ä¸€ä¸ªæ€»ç»“ï¼Œå¸Œæœ›å¯ä»¥å¸®åŠ©åˆ°å¤§å®¶ã€‚éœ€è¦æ³¨æ„çš„æ˜¯è¿™ä¸ªæµç¨‹ä¸»è¦é’ˆå¯¹ä¸€äº›å¸¸ç”¨çš„æ–‡æœ¬æŒ–æ˜ï¼Œå¹¶ä½¿ç”¨äº†è¯è¢‹æ¨¡å‹ï¼Œå¯¹äºæŸä¸€äº›è‡ªç„¶è¯­è¨€å¤„ç†çš„éœ€æ±‚åˆ™æµç¨‹éœ€è¦ä¿®æ”¹ã€‚æ¯”å¦‚æˆ‘ä»¬æ¶‰åŠåˆ°è¯ä¸Šä¸‹æ–‡å…³ç³»çš„ä¸€äº›éœ€æ±‚ï¼Œæ­¤æ—¶ä¸èƒ½ä½¿ç”¨è¯è¢‹æ¨¡å‹ã€‚è€Œæœ‰æ—¶å€™æˆ‘ä»¬å¯¹äºç‰¹å¾çš„å¤„ç†æœ‰è‡ªå·±çš„ç‰¹æ®Šéœ€æ±‚ï¼Œå› æ­¤è¿™ä¸ªæµç¨‹ä»…ä¾›è‡ªç„¶è¯­è¨€å¤„ç†å…¥é—¨è€…å‚è€ƒã€‚</p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2018-06-03T01:47:50.000Z" title="2018/6/3 ä¸Šåˆ9:47:50">2018-06-03</time>å‘è¡¨</span><span class="level-item"><time dateTime="2021-06-29T08:12:08.200Z" title="2021/6/29 ä¸‹åˆ4:12:08">2021-06-29</time>æ›´æ–°</span><span class="level-item"><a class="link-muted" href="/categories/%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB/">æ–‡æœ¬åˆ†ç±»</a></span><span class="level-item">7 åˆ†é’Ÿè¯»å®Œ (å¤§çº¦1103ä¸ªå­—)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2018/06/03/%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E7%B3%BB%E5%88%975-Hierarchical-Attention-Networks/">æ–‡æœ¬åˆ†ç±»ç³»åˆ—5-Hierarchical Attention Networks</a></h1><div class="content"><p><a target="_blank" rel="noopener" href="https://www.cs.cmu.edu/~diyiy/docs/naacl16.pdf">Hierarchical Attention Networks for Document Classification</a></p>
<h3 id="paper-reading"><a href="#paper-reading" class="headerlink" title="paper reading"></a>paper reading</h3><p>ä¸»è¦åŸç†ï¼š</p>
<p>the Hierarchical Attention Network (HAN) that is designed to capture two basic insights about document structure. First, since **documents</p>
<p>have a hierarchical structure (words form sentences, sentences form a document)**, we likewise construct a document representation by first building representations of sentences and then aggregating those into</p>
<p>a document representation. Second, it is observed that different words and sentences in a documents are differentially informative.</p>
<p>å¯¹äºä¸€ä¸ªdocumentå«æœ‰è¿™æ ·çš„å±‚æ¬¡ç»“æ„ï¼Œdocumentç”±sentencesç»„æˆï¼Œsentenceç”±wordsç»„æˆã€‚</p>
<p>the importance of words and sentences are highly context dependent, i.e. the same word or sentence may be differentially important in different context (x3.5). To include sensitivity to this fact, our model includes two levels of attention mechanisms (Bahdanau et al., 2014; Xu et al., 2015) â€” one at the word level and one at the sentence level â€” that let the model to pay more or less attention to individual words and sentences when constructing the representation of the document.</p>
<p>wordså’Œsentenceséƒ½æ˜¯é«˜åº¦ä¸Šä¸‹æ–‡ä¾èµ–çš„ï¼ŒåŒä¸€ä¸ªè¯æˆ–sentenceåœ¨ä¸åŒçš„ä¸Šä¸‹æ–‡ä¸­ï¼Œå…¶è¡¨ç°çš„é‡è¦æ€§ä¼šæœ‰å·®åˆ«ã€‚å› æ­¤ï¼Œè¿™ç¯‡è®ºæ–‡ä¸­ä½¿ç”¨äº†ä¸¤ä¸ªattentionæœºåˆ¶ï¼Œæ¥è¡¨ç¤ºç»“åˆäº†ä¸Šä¸‹æ–‡ä¿¡æ¯çš„è¯æˆ–å¥å­çš„é‡è¦ç¨‹åº¦ã€‚ï¼ˆè¿™é‡Œç»“åˆçš„ä¸Šä¸‹æ–‡çš„è¯æˆ–å¥å­ï¼Œå°±æ˜¯ç»è¿‡RNNå¤„ç†åçš„éšè—çŠ¶æ€ï¼‰ã€‚</p>
<p>Attention serves two benefits: not only does it often result in better performance, but it also provides insight into which words and sentences contribute to the classification decision which can be of value in applications and analysis (Shen et al., 2014; Gao et</p>
<p>al., 2014)</p>
<p>attentionä¸ä»…æœ‰å¥½çš„æ•ˆæœï¼Œè€Œä¸”èƒ½å¤Ÿå¯è§†åŒ–çš„çœ‹è§å“ªäº›è¯æˆ–å¥å­å¯¹å“ªä¸€ç±»documentçš„åˆ†ç±»å½±å“å¤§ã€‚</p>
<p>æœ¬æ–‡çš„åˆ›æ–°ç‚¹åœ¨äºï¼Œè€ƒè™‘äº†ducumentä¸­sentenceè¿™ä¸€å±‚æ¬¡ç»“æ„ï¼Œå› ä¸ºå¯¹äºä¸€ä¸ªdocumentçš„åˆ†ç±»ï¼Œå¯èƒ½å‰é¢å‡ å¥è¯éƒ½æ˜¯åºŸè¯ï¼Œè€Œæœ€åä¸€å¥è¯æ¥äº†ä¸€ä¸ªè½¬æŠ˜ï¼Œå¯¹documentçš„åˆ†ç±»èµ·å†³å®šæ€§ä½œç”¨ã€‚è€Œä¹‹å‰çš„ç ”ç©¶ï¼Œåªè€ƒè™‘äº†documentä¸­çš„è¯ã€‚</p>
<h3 id="Model-Architecture"><a href="#Model-Architecture" class="headerlink" title="Model Architecture"></a>Model Architecture</h3><p><img src="/2018/06/03/%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E7%B3%BB%E5%88%975-Hierarchical-Attention-Networks/%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E7%B3%BB%E5%88%975-Hierarchical-Attention-Networks%5Chan.png"></p>
<h4 id="GRU-based-sequence-encoder"><a href="#GRU-based-sequence-encoder" class="headerlink" title="GRU-based sequence encoder"></a>GRU-based sequence encoder</h4><p><strong>reset gate:</strong> controls how much the past state contributes to the candidate state.</p>
<p>$$r_t=\sigma(W_rx_t+U_rh_{t-1}+b_r)$$</p>
<p><strong>candidate state:</strong></p>
<p>$$\tilde h_t=tanh(W_hx_t+r_t\circ (U_hh_{t-1})+b_h)$$</p>
<p><strong>update gate:</strong> decides how much past information is kept and how much new information is added.</p>
<p>$$z_t=\sigma(W_zx_t+U_zh_{t-1}+b_z)$$</p>
<p><strong>new state:</strong> a linear interpolation between the previous state $h_{tâˆ’1}$ and the current new state $\tilde h_t$ computed with new sequence information.</p>
<p>$$h_t=(1-z_t)\circ h_{t-1}+z_t\circ \tilde h_t$$</p>
<h4 id="Hierarchical-Attention"><a href="#Hierarchical-Attention" class="headerlink" title="Hierarchical Attention"></a>Hierarchical Attention</h4><h5 id="Word-Encoder"><a href="#Word-Encoder" class="headerlink" title="Word Encoder"></a>Word Encoder</h5><p>$$x_{it}=W_ew_{it}, t\in [1, T]$$</p>
<p>$$\overrightarrow h_{it}=\overrightarrow {GRU}(x_{it}),t\in[1,T]$$</p>
<p>$$\overleftarrow h_{it}=\overleftarrow {GRU}(x_{it}),t\in [T,1]$$</p>
<p>$$h_{it} = [\overrightarrow h_{it},\overleftarrow h_{it}]$$</p>
<p>i means the $i^{th}$ sentence in the document, and t means the $t^{th}$ word in the sentence.</p>
<h5 id="Word-Attention"><a href="#Word-Attention" class="headerlink" title="Word Attention"></a>Word Attention</h5><p>Not all words contribute equally to the representation of the sentence meaning.</p>
<p>Hence, we introduce attention mechanism to extract such words that are important to the meaning of the sentence and aggregate the representation of those informative words to form a sentence vector.</p>
<p>Attentionæœºåˆ¶è¯´åˆ°åº•å°±æ˜¯ç»™äºˆsentenceä¸­æ¯ä¸ªç»“åˆäº†ä¸Šä¸‹æ–‡ä¿¡æ¯çš„è¯ä¸€ä¸ªæƒé‡ã€‚å…³é”®åœ¨äºè¿™ä¸ªæƒé‡æ€ä¹ˆç¡®å®šï¼Ÿ</p>
<p>$$u_{it}=tanh(W_wh_{it}+b_w)$$</p>
<p>$$\alpha_{it}=\dfrac{exp(u_{it}^Tu_w)}{\sum_t^Texp(u_{it}^Tu_w)}$$</p>
<p>$$s_i=\sum_t^T\alpha_{it}h_{it}$$</p>
<p>è¿™é‡Œé¦–å…ˆæ˜¯å°† $h_{it}$ é€šè¿‡ä¸€ä¸ªå…¨è¿æ¥å±‚å¾—åˆ° hidden representation $u_{it}$,ç„¶åè®¡ç®— $u_{it}$ ä¸ $u_w$ çš„ç›¸ä¼¼æ€§ã€‚å¹¶é€šè¿‡softmaxå½’ä¸€åŒ–å¾—åˆ°æ¯ä¸ªè¯ä¸ $u_w$ ç›¸ä¼¼çš„æ¦‚ç‡ã€‚è¶Šç›¸ä¼¼çš„è¯ï¼Œè¿™ä¸ªè¯æ‰€å æ¯”é‡è¶Šå¤§ï¼Œå¯¹æ•´ä¸ªsentenceçš„å‘é‡è¡¨ç¤ºå½±å“è¶Šå¤§ã€‚</p>
<p>é‚£ä¹ˆå…³é”®æ˜¯è¿™ä¸ª $u_w$ æ€ä¹ˆè¡¨ç¤ºï¼Ÿ</p>
<p>The context vector $u_w$ can be seen as a high level representation of a fixed</p>
<p>query â€œwhat is the informative wordâ€ over the words like that used in memory networks (<a target="_blank" rel="noopener" href="https://arxiv.org/abs/1503.08895">Sukhbaatar et al., 2015, End-to-end memory networks.</a>; <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1506.07285">Kumar et al., 2015, Ask me anything: Dynamic memory networks for natural language processing.</a>). The word context vector $u_w$ is randomly initialized and jointly learned during the training process.</p>
<h5 id="Sentence-Encoder"><a href="#Sentence-Encoder" class="headerlink" title="Sentence Encoder"></a>Sentence Encoder</h5><p>$$\overrightarrow h_{i}=\overrightarrow {GRU}(s_{i}),t\in[1,L]$$</p>
<p>$$\overleftarrow h_{i}=\overleftarrow {GRU}(s_{i}),t\in [L,1]$$</p>
<p>$$H_i=[\overrightarrow h_{i}, \overleftarrow h_{i}]$$</p>
<p>hi summarizes the neighbor sentences around sentence i but still focus on sentence i.</p>
<h5 id="Sentence-Attention"><a href="#Sentence-Attention" class="headerlink" title="Sentence Attention"></a>Sentence Attention</h5><p>$$u_i=tanh(W_sH_i+b_s)$$</p>
<p>$$\alpha_i=\dfrac{exp(u_i^Tu_s)}{\sum_i^Lexp(u_i^Tu_s)}$$</p>
<p>$$v = \sum_i^L\alpha_ih_i$$</p>
<p>åŒæ ·çš„ $u_s$ è¡¨ç¤ºï¼š a sentence level context vector $u_s$</p>
<h4 id="Document-Classification"><a href="#Document-Classification" class="headerlink" title="Document Classification"></a>Document Classification</h4><p>The document vector v is a high level representation</p>
<p>of the document and can be used as features for document classification:</p>
<p>$$p=softmax(W_cv+b_c)$$</p>
<h3 id="ä»£ç å®ç°"><a href="#ä»£ç å®ç°" class="headerlink" title="ä»£ç å®ç°"></a>ä»£ç å®ç°</h3><h4 id="éœ€è¦æ³¨æ„çš„é—®é¢˜"><a href="#éœ€è¦æ³¨æ„çš„é—®é¢˜" class="headerlink" title="éœ€è¦æ³¨æ„çš„é—®é¢˜"></a>éœ€è¦æ³¨æ„çš„é—®é¢˜</h4><ul>
<li><p>å¦‚æœä½¿ç”¨tensorboardå¯è§†åŒ–</p>
</li>
<li><p>å˜é‡èŒƒå›´çš„é—®é¢˜</p>
</li>
</ul>
<h3 id="Context-dependent-attention-weights"><a href="#Context-dependent-attention-weights" class="headerlink" title="Context dependent attention weights"></a>Context dependent attention weights</h3><h3 id="Visualization-of-attention"><a href="#Visualization-of-attention" class="headerlink" title="Visualization of attention"></a>Visualization of attention</h3></div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2018-06-01T06:09:10.000Z" title="2018/6/1 ä¸‹åˆ2:09:10">2018-06-01</time>å‘è¡¨</span><span class="level-item"><time dateTime="2021-06-29T08:12:08.522Z" title="2021/6/29 ä¸‹åˆ4:12:08">2021-06-29</time>æ›´æ–°</span><span class="level-item"><a class="link-muted" href="/categories/%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB/">æ–‡æœ¬åˆ†ç±»</a></span><span class="level-item">7 åˆ†é’Ÿè¯»å®Œ (å¤§çº¦1107ä¸ªå­—)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2018/06/01/%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E7%B3%BB%E5%88%974-textRCNN/">æ–‡æœ¬åˆ†ç±»ç³»åˆ—4-textRCNN</a></h1><div class="content"><h3 id="paper-reading"><a href="#paper-reading" class="headerlink" title="paper reading"></a>paper reading</h3><p>paper: <a target="_blank" rel="noopener" href="https://www.aaai.org/ocs/index.php/AAAI/AAAI15/paper/download/9745/9552">Recurrent Convolutional Neural Networks for Text Classification</a></p>
<h4 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h4><p>å…ˆå¯¹ä¹‹å‰çš„ç ”ç©¶è¿›è¡Œä¸€ç•ªæ‰¹åˆ¤(0.0).</p>
<ol>
<li>ä¼ ç»Ÿçš„æ–‡æœ¬åˆ†ç±»æ–¹æ³•éƒ½æ˜¯åŸºäºç‰¹å¾å·¥ç¨‹ feature representationï¼Œä¸»è¦åŒ…æ‹¬ï¼š</li>
</ol>
<ul>
<li><p>è¯è¢‹æ¨¡å‹ bag-of-words(BOW)modelï¼Œç”¨äºæå–unigram, bigram, n-gramsçš„ç‰¹å¾ã€‚</p>
</li>
<li><p>å¸¸è§çš„ç‰¹å¾é€‰æ‹©çš„æ–¹æ³•ï¼šfrequency, MI (Cover and Thomas 2012), pLSA (Cai and Hofmann 2003), LDA (Hingmire et al. 2013)ï¼Œç”¨äºé€‰æ‹©å…·æœ‰æ›´å¥½çš„åˆ¤åˆ«æ•ˆæœçš„ç‰¹å¾ã€‚</p>
</li>
</ul>
<p>å…¶åŸç†å°±æ˜¯å»å™ªå£°æ¥æé«˜åˆ†ç±»æ•ˆæœã€‚æ¯”å¦‚å»æ‰åœç”¨è¯ï¼Œä½¿ç”¨ä¿¡æ¯å¢ç›Šï¼Œäº’ä¿¡æ¯ï¼Œæˆ–è€…L1æ­£åˆ™åŒ–æ¥è·å–æœ‰ç”¨çš„ç‰¹å¾ã€‚ä½†ä¼ ç»Ÿçš„ç‰¹å¾è¡¨ç¤ºçš„æ–¹æ³•é€šå¸¸å¿½è§†äº†ä¸Šä¸‹æ–‡ä¿¡æ¯å’Œè¯åºä¿¡æ¯ã€‚</p>
<ol start="2">
<li>Richard Socher æå‡ºçš„ <strong>Recursive Neural Network</strong></li>
</ol>
<p>RecusiveNN é€šè¿‡è¯­è¨€çš„treeç»“æ„æ¥è·å–å¥å­çš„è¯­ä¹‰ä¿¡æ¯ã€‚ä½†æ˜¯åˆ†ç±»çš„å‡†ç¡®ç‡å¤ªä¾èµ–æ–‡æœ¬çš„æ ‘ç»“æ„ã€‚åœ¨æ–‡æœ¬åˆ†ç±»ä¹‹å‰å»ºç«‹ä¸€ä¸ªæ ‘ç»“æ„éœ€è¦çš„è®¡ç®—å¤æ‚åº¦å°±æ˜¯ $O(n^2)$ ï¼ˆnæ˜¯å¥å­çš„é•¿åº¦ï¼‰ã€‚æ‰€ä»¥å¯¹äºå¾ˆé•¿çš„å¥å­å¹¶ä¸é€‚ç”¨ã€‚</p>
<ol start="3">
<li>å¾ªç¯ç¥ç»ç½‘ç»œ Recurrent Neural Network</li>
</ol>
<p>è®¡ç®—å¤æ‚åº¦æ˜¯ $O(n)$ï¼Œä¼˜ç‚¹æ˜¯èƒ½å¤Ÿå¾ˆå¥½çš„æ•è·é•¿æ–‡æœ¬çš„è¯­ä¹‰ä¿¡æ¯ï¼Œä½†æ˜¯åœ¨rnnæ¨¡å‹ä¸­ï¼Œlater words are more dominatant than earlier words. ä½†æ˜¯å¦‚æœå¯¹ä¸æŸä¸€ä¸ªæ–‡æœ¬çš„åˆ†ç±»ï¼Œå‡ºç°åœ¨ä¹‹å‰çš„wordå½±å“æ›´å¤§çš„è¯ï¼ŒRNNçš„è¡¨ç°å°±ä¸ä¼šå¾ˆå¥½ã€‚</p>
<p>ä¸ºè§£å†³RNNè¿™ä¸ªé—®é¢˜ï¼Œå¯ä»¥å°†CNNè¿™ä¸ªæ²¡æœ‰åè§çš„æ¨¡å‹å¼•å…¥åˆ°NLPçš„å·¥ä½œä¸­æ¥ï¼ŒCNNèƒ½å…¬å¹³çš„å¯¹å¾…å¥å­ä¸­çš„æ¯ä¸€ä¸ªçŸ­è¯­ã€‚ To tackle the bias problem, the Convolutional Neural Network (CNN), an unbiased model is introduced to NLP tasks, which can fairly determine discriminative phrases in a text with a max-pooling layer.</p>
<p>ä½†æ˜¯å‘¢ï¼Œé€šè¿‡å‰é¢çš„å­¦ä¹ æˆ‘ä»¬çŸ¥é“CNNçš„filteræ˜¯å›ºå®šå°ºå¯¸çš„ï¼ˆfixed windowï¼‰ï¼Œå¦‚æœå°ºå¯¸å¤ªçŸ­ï¼Œä¼šä¸¢å¤±å¾ˆå¤šä¿¡æ¯ï¼Œå¦‚æœå°ºå¯¸è¿‡é•¿ï¼Œè®¡ç®—å¤æ‚åº¦åˆå¤ªå¤§ã€‚æ‰€ä»¥ä½œè€…æå‡ºä¸ªé—®é¢˜ï¼šèƒ½ä¸èƒ½é€šè¿‡åŸºäºçª—å£çš„ç¥ç»ç½‘ç»œï¼ˆCNNï¼‰å­¦åˆ°æ›´å¤šçš„ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œæ›´å¥½çš„è¡¨ç¤ºæ–‡æœ¬çš„è¯­ä¹‰ä¿¡æ¯å‘¢ï¼Ÿ Therefore, it raises a question: can we learn more contextual information than conventional window-based neural networks and represent the semantic of texts more precisely for text classification.</p>
<p>äºæ˜¯ï¼Œè¿™ç¯‡è®ºæ–‡æå‡ºäº† Recurrent Concolution Neural Network(RCNN).</p>
<h4 id="Model"><a href="#Model" class="headerlink" title="Model"></a>Model</h4><p><img src="/2018/06/01/%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E7%B3%BB%E5%88%974-textRCNN/model.png"></p>
<p>$$c_l{(w_i)} = f(W^{(l)}c_l(w_{i-1})+W^{(sl)}e(w_{i-1}))$$</p>
<p>$$c_r{(w_i)} = f(W^{(r)}c_r(w_{i-1})+W^{(sr)}e(w_{i-1}))$$</p>
<p>è¿™ä¸¤ä¸ªå…¬å¼ç±»ä¼¼äºåŒå‘RNNï¼Œå°† $c_l(w_i)$ çœ‹ä½œå‰ä¸€ä¸ªæ—¶åˆ»çš„éšè—çŠ¶æ€ $h_{t-1}$, $c_l(w_{i-1})$ å°±æ˜¯ t-2 æ—¶åˆ»çš„éšè—çŠ¶æ€ $h_{t-2}$â€¦ æ‰€ä»¥è¿™å°±æ˜¯ä¸ªåŒå‘RNNâ€¦. ç„¶åæ¯”è¾ƒæœ‰åˆ›æ–°çš„æ˜¯ï¼Œä½œè€…å°†éšè—çŠ¶æ€ $h_{t-1}$ å’Œ $\tilde h_{t+1}$ ($\tilde h$ è¡¨ç¤ºåå‘), ä»¥åŠå½“å‰wordçš„è¯å‘é‡å †åœ¨ä¸€èµ·ï¼Œä½œä¸ºå½“å‰è¯ä»¥åŠè·å–äº†ä¸Šä¸‹æ–‡ä¿¡æ¯çš„å‘é‡è¡¨ç¤ºã€‚</p>
<p>$$x_i = [c_l(w_i);e(w_i);c_r(w_i)]$$</p>
<p>ç„¶åæ˜¯ä¸€ä¸ªå…¨è¿æ¥å±‚ï¼Œè¿™ä¸ªå¯ä»¥çœ‹åštextCNNä¸­çš„å·ç§¯å±‚,åªæ˜¯filter_size=1ï¼š</p>
<p>$$y_i^{(2)}=tanh(W^{(2)}x_i+b^{(2)})$$</p>
<p>æ¥ç€æ˜¯æœ€å¤§æ± åŒ–å±‚ï¼š</p>
<p>$$y^{(3)} = max_{i=1}^ny_i^{(2)}$$</p>
<p>ç„¶åæ˜¯å…¨è¿æ¥å±‚+softmaxï¼š</p>
<p>$$y^{(4)} = W^{(4)}y^{(3)}+b^{(4)}$$</p>
<p>$$p_i=\dfrac{exp(y_i^{(4)})}{\sum_{k=1}^nexp(y_k^{(4)})}$$</p>
<p>æ„Ÿè§‰å°±æ˜¯åŒå‘rnnå‘€ï¼Œåªä¸è¿‡ä¹‹å‰çš„æ–¹æ³•æ˜¯ç”¨æœ€åä¸€ä¸ªéšè—å±‚çš„è¾“å‡ºä½œä¸ºæ•´ä¸ªsentenceçš„å‘é‡è¡¨ç¤ºï¼Œä½†è¿™ç¯‡è®ºæ–‡æ˜¯ç”¨æ¯ä¸€ä¸ªæ—¶åˆ»çš„å‘é‡è¡¨ç¤º(å åŠ äº†ä¸Šä¸‹æ—¶åˆ»çš„éšè—çŠ¶æ€)ï¼Œé€šè¿‡å·ç§¯å±‚ã€maxpoolåå¾—åˆ°çš„å‘é‡æ¥è¡¨ç¤ºæ•´ä¸ªsentence.</p>
<p>ç¡®å®æ˜¯è§£å†³äº†RNNè¿‡äºé‡è§†å¥å­ä¸­é åçš„è¯çš„é—®é¢˜ï¼Œä½†æ˜¯RNNè®­ç»ƒæ…¢çš„é—®é¢˜è¿˜æ˜¯æ²¡æœ‰è§£å†³å‘€ã€‚ä½†æ˜¯åœ¨è¿™é‡Œ <a target="_blank" rel="noopener" href="https://github.com/brightmart/text_classification#3textrnn">brightmart/text_classification</a> ä¸­textCNN å’Œ RCNNçš„è®­ç»ƒæ—¶é—´å±…ç„¶æ˜¯ä¸€æ ·çš„ã€‚whyï¼Ÿ</p>
<h4 id="Results-and-Discussion"><a href="#Results-and-Discussion" class="headerlink" title="Results and Discussion"></a>Results and Discussion</h4><h3 id="ä»£ç å®ç°"><a href="#ä»£ç å®ç°" class="headerlink" title="ä»£ç å®ç°"></a>ä»£ç å®ç°</h3><h3 id="éœ€è¦æ³¨æ„çš„é—®é¢˜ï¼š"><a href="#éœ€è¦æ³¨æ„çš„é—®é¢˜ï¼š" class="headerlink" title="éœ€è¦æ³¨æ„çš„é—®é¢˜ï¼š"></a>éœ€è¦æ³¨æ„çš„é—®é¢˜ï¼š</h3><ul>
<li>tf.nn.rnn_cell.DropoutWrapper</li>
</ul>
<ul>
<li>tf.nn.bidirectional_dynamic_rnn</li>
</ul>
<ul>
<li>tf.einsum</li>
</ul>
<ul>
<li>æŸå¤±å‡½æ•°çš„å¯¹æ¯” tf.nn.softmax_cross_entropy_with_logits</li>
</ul>
<ul>
<li>è¯å‘é‡æ˜¯å¦éœ€è¦æ­£åˆ™åŒ–</li>
</ul>
<ul>
<li>tensorflow.contrib.layers.python.layers import optimize_loss å’Œ tf.train.AdamOptimizer(learning_rate).minimize(self.loss, self.global_steps) çš„åŒºåˆ«</li>
</ul>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2018-05-31T13:25:54.000Z" title="2018/5/31 ä¸‹åˆ9:25:54">2018-05-31</time>å‘è¡¨</span><span class="level-item"><time dateTime="2021-01-27T08:44:33.479Z" title="2021/1/27 ä¸‹åˆ4:44:33">2021-01-27</time>æ›´æ–°</span><span class="level-item"><a class="link-muted" href="/categories/%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB/">æ–‡æœ¬åˆ†ç±»</a></span><span class="level-item">4 åˆ†é’Ÿè¯»å®Œ (å¤§çº¦625ä¸ªå­—)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2018/05/31/%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E7%B3%BB%E5%88%973-TextRNN/">æ–‡æœ¬åˆ†ç±»ç³»åˆ—3-TextRNN</a></h1><div class="content"><h3 id="paper-reading"><a href="#paper-reading" class="headerlink" title="paper reading"></a>paper reading</h3><p>å°½ç®¡TextCNNèƒ½å¤Ÿåœ¨å¾ˆå¤šä»»åŠ¡é‡Œé¢èƒ½æœ‰ä¸é”™çš„è¡¨ç°ï¼Œä½†CNNæœ‰ä¸ªæœ€å¤§é—®é¢˜æ˜¯å›ºå®š filter_size çš„è§†é‡ï¼Œä¸€æ–¹é¢æ— æ³•å»ºæ¨¡æ›´é•¿çš„åºåˆ—ä¿¡æ¯ï¼Œå¦ä¸€æ–¹é¢ filter_size çš„è¶…å‚è°ƒèŠ‚ä¹Ÿå¾ˆç¹çã€‚CNNæœ¬è´¨æ˜¯åšæ–‡æœ¬çš„ç‰¹å¾è¡¨è¾¾å·¥ä½œï¼Œè€Œè‡ªç„¶è¯­è¨€å¤„ç†ä¸­æ›´å¸¸ç”¨çš„æ˜¯é€’å½’ç¥ç»ç½‘ç»œï¼ˆRNN, Recurrent Neural Networkï¼‰ï¼Œèƒ½å¤Ÿæ›´å¥½çš„è¡¨è¾¾ä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚å…·ä½“åœ¨æ–‡æœ¬åˆ†ç±»ä»»åŠ¡ä¸­ï¼ŒBi-directional RNNï¼ˆå®é™…ä½¿ç”¨çš„æ˜¯åŒå‘LSTMï¼‰ä»æŸç§æ„ä¹‰ä¸Šå¯ä»¥ç†è§£ä¸ºå¯ä»¥æ•è·å˜é•¿ä¸”åŒå‘çš„çš„ â€œn-gramâ€ ä¿¡æ¯ã€‚</p>
<p>RNNç®—æ˜¯åœ¨è‡ªç„¶è¯­è¨€å¤„ç†é¢†åŸŸéå¸¸ä¸€ä¸ªæ ‡é…ç½‘ç»œäº†ï¼Œåœ¨åºåˆ—æ ‡æ³¨/å‘½åä½“è¯†åˆ«/seq2seqæ¨¡å‹ç­‰å¾ˆå¤šåœºæ™¯éƒ½æœ‰åº”ç”¨ï¼Œ<a target="_blank" rel="noopener" href="https://www.ijcai.org/Proceedings/16/Papers/408.pdf">Recurrent Neural Network for Text Classification with Multi-Task Learning</a>æ–‡ä¸­ä»‹ç»äº†RNNç”¨äºåˆ†ç±»é—®é¢˜çš„è®¾è®¡ï¼Œä¸‹å›¾LSTMç”¨äºç½‘ç»œç»“æ„åŸç†ç¤ºæ„å›¾ï¼Œç¤ºä¾‹ä¸­çš„æ˜¯åˆ©ç”¨æœ€åä¸€ä¸ªè¯çš„ç»“æœç›´æ¥æ¥å…¨è¿æ¥å±‚softmaxè¾“å‡ºäº†ã€‚</p>
<h3 id="å…³äºè§£å†³RNNæ— æ³•å¹¶è¡ŒåŒ–ï¼Œè®¡ç®—æ•ˆç‡ä½çš„é—®é¢˜"><a href="#å…³äºè§£å†³RNNæ— æ³•å¹¶è¡ŒåŒ–ï¼Œè®¡ç®—æ•ˆç‡ä½çš„é—®é¢˜" class="headerlink" title="å…³äºè§£å†³RNNæ— æ³•å¹¶è¡ŒåŒ–ï¼Œè®¡ç®—æ•ˆç‡ä½çš„é—®é¢˜"></a>å…³äºè§£å†³RNNæ— æ³•å¹¶è¡ŒåŒ–ï¼Œè®¡ç®—æ•ˆç‡ä½çš„é—®é¢˜</h3><p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1703.10722">Factorization tricks for LSTM networks</a></p>
<ul>
<li>We present two simple ways of reducing the number of parameters and accelerating the training of large Long Short-Term Memory (LSTM) networks: the first one is â€œmatrix factorization by designâ€ of LSTM matrix into the product of two smaller matrices, and the second one is partitioning of LSTM matrix, its inputs and states into the independent groups. Both approaches allow us to train large LSTM networks significantly faster to the near state-of the art perplexity while using significantly less RNN parameters.</li>
</ul>
<p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1701.06538">Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer</a></p>
<ul>
<li>The capacity of a neural network to absorb information is limited by its number of parameters. Conditional computation, where parts of the network are active on a per-example basis, has been proposed in theory as a way of dramatically increasing model capacity without a proportional increase in computation. In practice, however, there are significant algorithmic and performance challenges. In this work, we address these challenges and finally realize the promise of conditional computation, achieving greater than 1000x improvements in model capacity with only minor losses in computational efficiency on modern GPU clusters. We introduce a Sparsely-Gated Mixture-of-Experts layer (MoE), consisting of up to thousands of feed-forward sub-networks. A trainable gating network determines a sparse combination of these experts to use for each example. We apply the MoE to the tasks of language modeling and machine translation, where model capacity is critical for absorbing the vast quantities of knowledge available in the training corpora. We present model architectures in which a MoE with up to 137 billion parameters is applied convolutionally between stacked LSTM layers. On large language modeling and machine translation benchmarks, these models achieve significantly better results than state-of-the-art at lower computational cost.</li>
</ul>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2018-05-30T07:37:47.000Z" title="2018/5/30 ä¸‹åˆ3:37:47">2018-05-30</time>å‘è¡¨</span><span class="level-item"><time dateTime="2021-06-29T08:12:08.540Z" title="2021/6/29 ä¸‹åˆ4:12:08">2021-06-29</time>æ›´æ–°</span><span class="level-item"><a class="link-muted" href="/categories/%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB/">æ–‡æœ¬åˆ†ç±»</a></span><span class="level-item">8 åˆ†é’Ÿè¯»å®Œ (å¤§çº¦1222ä¸ªå­—)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2018/05/30/%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E7%B3%BB%E5%88%972-textCNN/">æ–‡æœ¬åˆ†ç±»ç³»åˆ—2-textCNN</a></h1><div class="content"><h3 id="paper-reading"><a href="#paper-reading" class="headerlink" title="paper reading"></a>paper reading</h3><p>ä¸»è¦æ¡†æ¶å’Œä½¿ç”¨CNNè¿›è¡Œæ–‡æœ¬åˆ†ç±»çš„æ„å›¾å‚è€ƒpaper: <a target="_blank" rel="noopener" href="http://www.aclweb.org/anthology/D14-1181">Convolutional Neural Networks for Sentence Classification</a> å¯å‚è€ƒcs224dä¸­çš„è¯¾å ‚ç¬”è®°ï¼Œè¿™å ‚è¯¾å°±æ˜¯è®²çš„è¿™ç¯‡paperï¼š</p>
<p><a href="http://www.panxiaoxie.cn/2018/05/14/cs224d-lecture13-%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/#more">cs224d-lecture13 å·ç§¯ç¥ç»ç½‘ç»œ</a></p>
<p><img src="/2018/05/30/%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E7%B3%BB%E5%88%972-textCNN/TextCNN.JPG"></p>
<p><strong>TextCNNè¯¦ç»†è¿‡ç¨‹</strong>ï¼š</p>
<ul>
<li>ç¬¬ä¸€å±‚æ˜¯å›¾ä¸­æœ€å·¦è¾¹çš„7ä¹˜5çš„å¥å­çŸ©é˜µï¼Œæ¯è¡Œæ˜¯è¯å‘é‡ï¼Œç»´åº¦=5ï¼Œè¿™ä¸ªå¯ä»¥ç±»æ¯”ä¸ºå›¾åƒä¸­çš„åŸå§‹åƒç´ ç‚¹äº†,ç„¶ååœ¨å›¾åƒä¸­å›¾åƒçš„è¡¨ç¤ºæ˜¯[length, width, channel],è¿™é‡Œå°†æ–‡æœ¬çš„è¡¨ç¤º[sequence_len, embed_size, 1]ã€‚å¯ä»¥çœ‹åˆ°ä¸‹é¢ä»£ç ä¸­ï¼š</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">embeded_words = tf.nn.embedding_lookup(self.embedding, self.input_x) <span class="comment"># [None, sentence_len, embed_size]</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># three channels similar to the image. using the tf.nn.conv2d</span></span><br><span class="line"></span><br><span class="line">self.sentence_embedding_expanded = tf.expand_dims(embeded_words, axis=-<span class="number">1</span>) <span class="comment"># [None, sentence_len, embed_size, 1]</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>



<ul>
<li><p>ç„¶åç»è¿‡æœ‰ filter_size=(2,3,4) çš„ä¸€ç»´å·ç§¯å±‚ï¼Œæ¯ä¸ªfilter_size æœ‰ä¸¤ä¸ªè¾“å‡º channelã€‚ä¸Šå›¾ä¸­çš„filteræœ‰3ä¸ªï¼Œåˆ†åˆ«ä¸ºï¼š</p>
<ul>
<li><p>filter:[2, 5, 2] ==&gt; feature map:[6,1,2]</p>
</li>
<li><p>filter:[3, 5, 2] ==&gt; feature map:[5,1,2]</p>
</li>
<li><p>filter:[4, 5, 2] ==&gt; feature map:[4,1,2]</p>
</li>
<li><p>ç¬¬ä¸‰ç»´è¡¨ç¤ºchannelsï¼Œå·ç§¯åå¾—åˆ°ä¸¤ä¸ªfeature maps.</p>
</li>
</ul>
</li>
</ul>
<ul>
<li>ç¬¬ä¸‰å±‚æ˜¯ä¸€ä¸ª1-max poolingå±‚ï¼Œè¿™æ ·ä¸åŒé•¿åº¦å¥å­ç»è¿‡poolingå±‚ä¹‹åéƒ½èƒ½å˜æˆscaleï¼Œè¿™é‡Œæ¯ä¸ªfiter_sizeçš„channelä¸º2ï¼Œæ‰€ä»¥è¾“å…¥çš„pooling.shape=[batch_size,1,1,2], ç„¶åconcatä¸ºä¸€ä¸ªflattenå‘é‡ã€‚</li>
</ul>
<ul>
<li>æœ€åæ¥ä¸€å±‚å…¨è¿æ¥çš„ softmax å±‚ï¼Œè¾“å‡ºæ¯ä¸ªç±»åˆ«çš„æ¦‚ç‡ã€‚</li>
</ul>
<p><strong>ç‰¹å¾</strong>ï¼šè¿™é‡Œçš„ç‰¹å¾å°±æ˜¯è¯å‘é‡ï¼Œæœ‰é™æ€ï¼ˆstaticï¼‰å’Œéé™æ€ï¼ˆnon-staticï¼‰æ–¹å¼ã€‚staticæ–¹å¼é‡‡ç”¨æ¯”å¦‚word2vecé¢„è®­ç»ƒçš„è¯å‘é‡ï¼Œè®­ç»ƒè¿‡ç¨‹ä¸æ›´æ–°è¯å‘é‡ï¼Œå®è´¨ä¸Šå±äºè¿ç§»å­¦ä¹ äº†ï¼Œç‰¹åˆ«æ˜¯æ•°æ®é‡æ¯”è¾ƒå°çš„æƒ…å†µä¸‹ï¼Œé‡‡ç”¨é™æ€çš„è¯å‘é‡å¾€å¾€æ•ˆæœä¸é”™ã€‚non-staticåˆ™æ˜¯åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­æ›´æ–°è¯å‘é‡ã€‚æ¨èçš„æ–¹å¼æ˜¯ non-static ä¸­çš„ fine-tunningæ–¹å¼ï¼Œå®ƒæ˜¯ä»¥é¢„è®­ç»ƒï¼ˆpre-trainï¼‰çš„word2vecå‘é‡åˆå§‹åŒ–è¯å‘é‡ï¼Œè®­ç»ƒè¿‡ç¨‹ä¸­è°ƒæ•´è¯å‘é‡ï¼Œèƒ½åŠ é€Ÿæ”¶æ•›ï¼Œå½“ç„¶å¦‚æœæœ‰å……è¶³çš„è®­ç»ƒæ•°æ®å’Œèµ„æºï¼Œç›´æ¥éšæœºåˆå§‹åŒ–è¯å‘é‡æ•ˆæœä¹Ÿæ˜¯å¯ä»¥çš„ã€‚</p>
<p><strong>é€šé“ï¼ˆChannelsï¼‰</strong>ï¼šå›¾åƒä¸­å¯ä»¥åˆ©ç”¨ (R, G, B) ä½œä¸ºä¸åŒchannelï¼Œè€Œæ–‡æœ¬çš„è¾“å…¥çš„channelé€šå¸¸æ˜¯ä¸åŒæ–¹å¼çš„embeddingæ–¹å¼ï¼ˆæ¯”å¦‚ word2vecæˆ–Gloveï¼‰ï¼Œå®è·µä¸­ä¹Ÿæœ‰åˆ©ç”¨é™æ€è¯å‘é‡å’Œfine-tunningè¯å‘é‡ä½œä¸ºä¸åŒchannelçš„åšæ³•ã€‚ä¸‹é¢ä»£ç ä¸­çš„é€šé“ä¸º1.</p>
<p><strong>ä¸€ç»´å·ç§¯ï¼ˆconv-1dï¼‰</strong>ï¼šå›¾åƒæ˜¯äºŒç»´æ•°æ®ï¼Œç»è¿‡è¯å‘é‡è¡¨è¾¾çš„æ–‡æœ¬ä¸ºä¸€ç»´æ•°æ®ï¼Œå› æ­¤åœ¨TextCNNå·ç§¯ç”¨çš„æ˜¯ä¸€ç»´å·ç§¯ã€‚ä¸€ç»´å·ç§¯å¸¦æ¥çš„é—®é¢˜æ˜¯éœ€è¦è®¾è®¡é€šè¿‡ä¸åŒ filter_size çš„ filter è·å–ä¸åŒå®½åº¦çš„è§†é‡ã€‚</p>
<p><strong>Poolingå±‚</strong>ï¼šåˆ©ç”¨CNNè§£å†³æ–‡æœ¬åˆ†ç±»é—®é¢˜çš„æ–‡ç« è¿˜æ˜¯å¾ˆå¤šçš„ï¼Œæ¯”å¦‚è¿™ç¯‡ <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1404.2188.pdf">A Convolutional Neural Network for Modelling Sentences</a> æœ€æœ‰æ„æ€çš„è¾“å…¥æ˜¯åœ¨ pooling æ”¹æˆ (dynamic) k-max pooling ï¼Œpoolingé˜¶æ®µä¿ç•™ k ä¸ªæœ€å¤§çš„ä¿¡æ¯ï¼Œä¿ç•™äº†å…¨å±€çš„åºåˆ—ä¿¡æ¯ã€‚æ¯”å¦‚åœ¨æƒ…æ„Ÿåˆ†æåœºæ™¯ï¼Œä¸¾ä¸ªä¾‹å­ï¼š</p>
<pre><code>        â€œ æˆ‘è§‰å¾—è¿™ä¸ªåœ°æ–¹æ™¯è‰²è¿˜ä¸é”™ï¼Œä½†æ˜¯äººä¹Ÿå®åœ¨å¤ªå¤šäº† â€
</code></pre>
<p>è™½ç„¶å‰åŠéƒ¨åˆ†ä½“ç°æƒ…æ„Ÿæ˜¯æ­£å‘çš„ï¼Œå…¨å±€æ–‡æœ¬è¡¨è¾¾çš„æ˜¯åè´Ÿé¢çš„æƒ…æ„Ÿï¼Œåˆ©ç”¨ k-max poolingèƒ½å¤Ÿå¾ˆå¥½æ•æ‰è¿™ç±»ä¿¡æ¯ã€‚</p>
<h3 id="ä»£ç å®ç°"><a href="#ä»£ç å®ç°" class="headerlink" title="ä»£ç å®ç°"></a>ä»£ç å®ç°</h3><p>å‚æ•°è®¾ç½®å’Œæ¨¡å‹å…·ä½“å®ç°å‚è€ƒpaper: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1510.03820">A Sensitivity Analysis of (and Practitionersâ€™ Guide to) Convolutional Neural Networks for Sentence Classification</a></p>
<p>è®¾è®¡ä¸€ä¸ªæ¨¡å‹éœ€è¦è€ƒè™‘çš„ï¼š  </p>
<ul>
<li><p>input word vector representations è¾“å…¥çš„è¯å‘é‡è¡¨ç¤º  </p>
</li>
<li><p>filter region size(s); å·ç§¯æ ¸çš„å¤§å°  </p>
</li>
<li><p>the number of feature maps; ç‰¹å¾å›¾çš„é€šé“æ•°  </p>
</li>
<li><p>the activation function æ¿€æ´»å‡½æ•°  </p>
</li>
<li><p>the pooling strategy æ± åŒ–çš„æ–¹å¼  </p>
</li>
<li><p>regularization terms (dropout/l2) æ­£åˆ™åŒ–é¡¹ï¼ˆdropout/l2ï¼‰  </p>
</li>
</ul>
<h3 id="éœ€è¦æ³¨æ„çš„é—®é¢˜"><a href="#éœ€è¦æ³¨æ„çš„é—®é¢˜" class="headerlink" title="éœ€è¦æ³¨æ„çš„é—®é¢˜"></a>éœ€è¦æ³¨æ„çš„é—®é¢˜</h3><h4 id="ä¸€ä¸ªå•æœ¬å¯¹åº”å•ä¸ªæ ‡ç­¾å’Œå¤šä¸ªæ ‡ç­¾çš„åŒºåˆ«ï¼Ÿ"><a href="#ä¸€ä¸ªå•æœ¬å¯¹åº”å•ä¸ªæ ‡ç­¾å’Œå¤šä¸ªæ ‡ç­¾çš„åŒºåˆ«ï¼Ÿ" class="headerlink" title="ä¸€ä¸ªå•æœ¬å¯¹åº”å•ä¸ªæ ‡ç­¾å’Œå¤šä¸ªæ ‡ç­¾çš„åŒºåˆ«ï¼Ÿ"></a>ä¸€ä¸ªå•æœ¬å¯¹åº”å•ä¸ªæ ‡ç­¾å’Œå¤šä¸ªæ ‡ç­¾çš„åŒºåˆ«ï¼Ÿ</h4><p>å…³äºå¤šæ ‡ç­¾åˆ†ç±»ï¼Œåº”è¯¥çœ‹çœ‹å‘¨å¿—åè€å¸ˆçš„è¿™ç¯‡æ–‡ç« <a target="_blank" rel="noopener" href="http://cse.seu.edu.cn/people/zhangml/files/TKDE%2713.pdf">A Review on Multi-Label Learning Algorithms</a>, çŸ¥ä¹ä¸Šè¿˜æœ‰å…¶ä»–èµ„æ–™<a target="_blank" rel="noopener" href="https://www.zhihu.com/question/35486862">å¤šæ ‡ç­¾ï¼ˆmulti-labelï¼‰æ•°æ®çš„å­¦ä¹ é—®é¢˜ï¼Œå¸¸ç”¨çš„åˆ†ç±»å™¨æˆ–è€…åˆ†ç±»ç­–ç•¥æœ‰å“ªäº›ï¼Ÿ</a></p>
<p>æœ¬æ–‡ä»£ç ä¸­çš„æ–¹æ³•ï¼š</p>
<ul>
<li>çœŸå®å€¼labelsçš„è¾“å…¥ï¼šå•ä¸ªæ ‡ç­¾çš„çœŸå®å€¼æ˜¯ <code>input_y.shape=[batch_size]</code>, å¤šä¸ªæ ‡ç­¾çš„çœŸå®å€¼æ˜¯ <code>input_y_multilabels.shape=[batch_size, label_size]</code></li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">self.input_y = tf.placeholder(dtype=tf.int32, shape=[<span class="literal">None</span>], name=<span class="string">&#x27;input_y&#x27;</span>)</span><br><span class="line"></span><br><span class="line">self.input_y_multilabels = tf.placeholder(dtype=tf.float32, shape=[<span class="literal">None</span>, num_classes], name=<span class="string">&quot;input_y_multilabels&quot;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<ul>
<li>æŸå¤±å‡½æ•°çš„é€‰æ‹©ï¼š</li>
</ul>
<ul>
<li>è¯„ä»·æŒ‡æ ‡çš„åŒºåˆ«ï¼š</li>
</ul>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2018-05-25T07:12:40.000Z" title="2018/5/25 ä¸‹åˆ3:12:40">2018-05-25</time>å‘è¡¨</span><span class="level-item"><time dateTime="2021-06-29T08:12:08.522Z" title="2021/6/29 ä¸‹åˆ4:12:08">2021-06-29</time>æ›´æ–°</span><span class="level-item"><a class="link-muted" href="/categories/%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB/">æ–‡æœ¬åˆ†ç±»</a></span><span class="level-item">19 åˆ†é’Ÿè¯»å®Œ (å¤§çº¦2870ä¸ªå­—)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2018/05/25/%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E7%B3%BB%E5%88%970%EF%BC%9ANLTK%E5%AD%A6%E4%B9%A0%E5%92%8C%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B/">æ–‡æœ¬åˆ†ç±»ç³»åˆ—0ï¼šNLTKå­¦ä¹ å’Œç‰¹å¾å·¥ç¨‹</a></h1><div class="content"><h3 id="è®¡ç®—è¯­è¨€ï¼šç®€å•çš„ç»Ÿè®¡"><a href="#è®¡ç®—è¯­è¨€ï¼šç®€å•çš„ç»Ÿè®¡" class="headerlink" title="è®¡ç®—è¯­è¨€ï¼šç®€å•çš„ç»Ÿè®¡"></a>è®¡ç®—è¯­è¨€ï¼šç®€å•çš„ç»Ÿè®¡</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">from</span> nltk.book <span class="keyword">import</span> *</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<pre><code>*** Introductory Examples for the NLTK Book ***

Loading text1, ..., text9 and sent1, ..., sent9

Type the name of the text or sentence to view it.

Type: &#39;texts()&#39; or &#39;sents()&#39; to list the materials.

text1: Moby Dick by Herman Melville 1851

text2: Sense and Sensibility by Jane Austen 1811

text3: The Book of Genesis

text4: Inaugural Address Corpus

text5: Chat Corpus

text6: Monty Python and the Holy Grail

text7: Wall Street Journal

text8: Personals Corpus

text9: The Man Who Was Thursday by G . K . Chesterton 1908
</code></pre>
<p>æ‰¾å‡ºtext1,ã€Šç™½é²¸è®°ã€‹ä¸­çš„è¯monstrousï¼Œä»¥åŠå…¶ä¸Šä¸‹æ–‡</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">text1.concordance(<span class="string">&quot;monstrous&quot;</span>, width=<span class="number">40</span>, lines=<span class="number">10</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<pre><code>Displaying 10 of 11 matches:

 was of a most monstrous size . ... Thi

 Touching that monstrous bulk of the wh

enish array of monstrous clubs and spea

 wondered what monstrous cannibal and s

e flood ; most monstrous and most mount

Moby Dick as a monstrous fable , or sti

PTER 55 Of the Monstrous Pictures of Wh

exion with the monstrous pictures of wh

ose still more monstrous stories of the

ed out of this monstrous cabinet there
</code></pre>
<p>æ‰¾å‡ºtext1ä¸­ä¸monstrouså…·æœ‰ç›¸åŒè¯­å¢ƒçš„è¯ã€‚æ¯”å¦‚monstrousçš„ä¸Šä¸‹æ–‡ the __ pictures, the __ size. åŒæ ·åœ¨text1ä¸­ä¸monstrousç±»ä¼¼çš„ä¸Šä¸‹æ–‡çš„è¯ã€‚å¾ˆå¥½å¥‡è¿™ä¸ªæ˜¯æ€ä¹ˆå®ç°çš„ï¼Ÿ</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">similar</span>(<span class="params">self, word, num=<span class="number">20</span></span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Distributional similarity: find other words which appear in the</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    same contexts as the specified word; list most similar words first.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>





<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">text1.similar(<span class="string">&quot;monstrous&quot;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<pre><code>true contemptible christian abundant few part mean careful puzzled

mystifying passing curious loving wise doleful gamesome singular

delightfully perilous fearless
</code></pre>
<p>å…±ç”¨ä¸¤ä¸ªæˆ–ä¸¤ä¸ªä»¥ä¸Šè¯æ±‡çš„ä¸Šä¸‹æ–‡ï¼Œå¦‚monstrouså’Œvery</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">text2.common_contexts([<span class="string">&quot;monstrous&quot;</span>, <span class="string">&quot;very&quot;</span>])</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<pre><code>a_pretty am_glad a_lucky is_pretty be_glad
</code></pre>
<p>è‡ªåŠ¨æ£€æµ‹å‡ºç°åœ¨æ–‡æœ¬ä¸­çš„ç‰¹å®šè¯ï¼Œå¹¶æ˜¾ç¤ºåŒä¸€ä¸Šä¸‹æ–‡ä¸­å‡ºç°çš„å…¶ä»–è¯ã€‚text4æ˜¯ã€Šå°±èŒæ¼”è¯´è¯­æ–™ã€‹ï¼Œ</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line"></span><br><span class="line">    text4.dispersion_plot([<span class="string">&quot;citizens&quot;</span>, <span class="string">&quot;liberty&quot;</span>, <span class="string">&quot;freedom&quot;</span>])</span><br><span class="line"></span><br></pre></td></tr></table></figure>





<pre><code>&lt;matplotlib.figure.Figure at 0x7f3794818588&gt;
</code></pre>
<p>å¦‚æœä¸ä½¿ç”¨ if <strong>name</strong>==â€<strong>main</strong>â€œ çš„è¯ä¼šæŠ¥é”™``` â€˜NoneTypeâ€™ object has no attribute â€˜showâ€™</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">```python</span><br><span class="line"></span><br><span class="line">fdist1 = FreqDist(text1)</span><br><span class="line"></span><br><span class="line">vocabulary1 = list(fdist1.keys())  # keys() è¿”å›keyå€¼ç»„æˆçš„list</span><br><span class="line"></span><br><span class="line">print(vocabulary1[:10])</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<pre><code>[&#39;[&#39;, &#39;Moby&#39;, &#39;Dick&#39;, &#39;by&#39;, &#39;Herman&#39;, &#39;Melville&#39;, &#39;1851&#39;, &#39;]&#39;, &#39;ETYMOLOGY&#39;, &#39;.&#39;]
</code></pre>
<p>éœ€è¦åŠ listï¼Œä¸ç„¶å›æŠ¥é”™ï¼Œ<code>â€œTypeError: &#39;dict_keys&#39; object is not subscriptableâ€</code></p>
<p>dict.keys() returns an iteratable but not indexable object. The most simple (but not so efficient) solution would be:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment"># åŒæ ·çš„é“ç†è¿™é‡Œä¹Ÿéœ€è¦åŠ listï¼Œå› ä¸ºç”Ÿæˆçš„&lt;class &#x27;dict_items&#x27;&gt;zåœ¨python3ä¸­æ˜¯è¿­ä»£å™¨</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">type</span>(fdist1.items()))</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">list</span>(fdist1.items())[:<span class="number">10</span>])</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<pre><code>&lt;class &#39;dict_items&#39;&gt;

[(&#39;[&#39;, 3), (&#39;Moby&#39;, 84), (&#39;Dick&#39;, 84), (&#39;by&#39;, 1137), (&#39;Herman&#39;, 1), (&#39;Melville&#39;, 1), (&#39;1851&#39;, 3), (&#39;]&#39;, 1), (&#39;ETYMOLOGY&#39;, 1), (&#39;.&#39;, 6862)]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment"># dict.items() å®é™…ä¸Šæ˜¯å°†dictè½¬æ¢ä¸ºå¯è¿­ä»£å¯¹è±¡listï¼Œlistçš„å¯¹è±¡æ˜¯ (&#x27;[&#x27;, 3), (&#x27;Moby&#x27;, 84), (&#x27;Dick&#x27;, 84), (&#x27;by&#x27;, 1137)è¿™æ ·çš„</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># è¿™ä¸‹æ€»èƒ½è®°ä½dictæŒ‰ç…§valueæ’åºäº†å§ã€‚ã€‚ã€‚å°´å°¬ï¼Œä»¥å‰å±…ç„¶æ²¡å¼„æ‡‚ï¼Ÿï¼Ÿ</span></span><br><span class="line"></span><br><span class="line">fdist_sorted = <span class="built_in">sorted</span>(fdist1.items(), key=<span class="keyword">lambda</span> item:item[<span class="number">1</span>], reverse=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(fdist_sorted[:<span class="number">10</span>])</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<pre><code>[(&#39;,&#39;, 18713), (&#39;the&#39;, 13721), (&#39;.&#39;, 6862), (&#39;of&#39;, 6536), (&#39;and&#39;, 6024), (&#39;a&#39;, 4569), (&#39;to&#39;, 4542), (&#39;;&#39;, 4072), (&#39;in&#39;, 3916), (&#39;that&#39;, 2982)]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment"># è¿™ä¸ªå°±æ˜¯æŒ‰ç…§keyæ’åºã€‚</span></span><br><span class="line"></span><br><span class="line">fdist_sorted2 = <span class="built_in">sorted</span>(fdist1.keys(), reverse=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(fdist_sorted2[:<span class="number">10</span>])</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<pre><code>[&#39;zoology&#39;, &#39;zones&#39;, &#39;zoned&#39;, &#39;zone&#39;, &#39;zodiac&#39;, &#39;zig&#39;, &#39;zephyr&#39;, &#39;zeal&#39;, &#39;zay&#39;, &#39;zag&#39;]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">fdist1.plot(<span class="number">20</span>, cumulative=<span class="literal">True</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>





<p><img src="/2018/05/25/%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E7%B3%BB%E5%88%970%EF%BC%9ANLTK%E5%AD%A6%E4%B9%A0%E5%92%8C%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B/output_16_0.png" alt="png"></p>
<p>å¯ä»¥çœ‹åˆ°é«˜é¢‘è¯å¤§éƒ½æ˜¯æ— ç”¨çš„åœç”¨è¯</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment"># ä½é¢‘è¯ fdist.hapaxes() å‡ºç°æ¬¡æ•°ä¸º1çš„è¯</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">len</span>(fdist1.hapaxes()))</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> fdist1.hapaxes():</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> fdist1[i] <span class="keyword">is</span> <span class="keyword">not</span> <span class="number">1</span>:</span><br><span class="line"></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;hh&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>



<pre><code>9002
</code></pre>
<p>å¯ä»¥çœ‹åˆ°ä½é¢‘è¯ä¹Ÿå¾ˆå¤šï¼Œè€Œä¸”å¤§éƒ½ä¹Ÿæ˜¯å¾ˆæ— ç”¨çš„è¯ã€‚</p>
<h4 id="è¯è¯­æ­é…"><a href="#è¯è¯­æ­é…" class="headerlink" title="è¯è¯­æ­é…"></a>è¯è¯­æ­é…</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="built_in">list</span>(bigrams([<span class="string">&#x27;more&#x27;</span>, <span class="string">&#x27;is&#x27;</span>, <span class="string">&#x27;sad&#x27;</span>, <span class="string">&#x27;than&#x27;</span>, <span class="string">&#x27;done&#x27;</span>]))</span><br><span class="line"></span><br></pre></td></tr></table></figure>









<pre><code>[(&#39;more&#39;, &#39;is&#39;), (&#39;is&#39;, &#39;sad&#39;), (&#39;sad&#39;, &#39;than&#39;), (&#39;than&#39;, &#39;done&#39;)]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">text4.collocations(window_size=<span class="number">4</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<pre><code>United States; fellow citizens; four years; years ago; men women;

Federal Government; General Government; self government; Vice

President; American people; every citizen; within limits; Old World;

Almighty God; Fellow citizens; Chief Magistrate; Chief Justice; one

another; Declaration Independence; protect defend
</code></pre>
<p>æ–‡æœ¬4æ˜¯å°±èŒæ¼”è¯´è¯­æ–™ï¼Œå¯ä»¥çœ‹åˆ°n-gramsèƒ½å¤Ÿå¾ˆå¥½çš„å±•ç°å‡ºæ–‡æœ¬çš„ç‰¹æ€§ï¼Œè¯´æ˜n-gramsæ˜¯ä¸é”™çš„ç‰¹å¾ã€‚</p>
<p>collections()æºç </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">collocations</span>(<span class="params">self, num=<span class="number">20</span>, window_size=<span class="number">2</span></span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Print collocations derived from the text, ignoring stopwords.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    :seealso: find_collocations</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    :param num: The maximum number of collocations to print.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    :type num: int</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    :param window_size: The number of tokens spanned by a collocation (default=2)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    :type window_size: int</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> (<span class="string">&#x27;_collocations&#x27;</span> <span class="keyword">in</span> self.__dict__ <span class="keyword">and</span> self._num == num <span class="keyword">and</span> self._window_size == window_size):</span><br><span class="line"></span><br><span class="line">        self._num = num</span><br><span class="line"></span><br><span class="line">        self._window_size = window_size</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="comment">#print(&quot;Building collocations list&quot;)</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">from</span> nltk.corpus <span class="keyword">import</span> stopwords</span><br><span class="line"></span><br><span class="line">        ignored_words = stopwords.words(<span class="string">&#x27;english&#x27;</span>)</span><br><span class="line"></span><br><span class="line">        finder = BigramCollocationFinder.from_words(self.tokens, window_size)</span><br><span class="line"></span><br><span class="line">        finder.apply_freq_filter(<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">        finder.apply_word_filter(<span class="keyword">lambda</span> w: <span class="built_in">len</span>(w) &lt; <span class="number">3</span> <span class="keyword">or</span> w.lower() <span class="keyword">in</span> ignored_words)</span><br><span class="line"></span><br><span class="line">        bigram_measures = BigramAssocMeasures()</span><br><span class="line"></span><br><span class="line">        self._collocations = finder.nbest(bigram_measures.likelihood_ratio, num)</span><br><span class="line"></span><br><span class="line">    colloc_strings = [w1+<span class="string">&#x27; &#x27;</span>+w2 <span class="keyword">for</span> w1, w2 <span class="keyword">in</span> self._collocations]</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(tokenwrap(colloc_strings, separator=<span class="string">&quot;; &quot;</span>))</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h3 id="è‡ªåŠ¨ç†è§£è‡ªç„¶è¯­è¨€"><a href="#è‡ªåŠ¨ç†è§£è‡ªç„¶è¯­è¨€" class="headerlink" title="è‡ªåŠ¨ç†è§£è‡ªç„¶è¯­è¨€"></a>è‡ªåŠ¨ç†è§£è‡ªç„¶è¯­è¨€</h3><ul>
<li><p>è¯ä¹‰æ¶ˆæ­§ Ambiguity å…³äºè¯ä¹‰æ¶ˆæ­§çš„ç†è§£å¯ä»¥çœ‹ä¹‹å‰çš„ç¬”è®°<a href="http://www.panxiaoxie.cn/2018/04/20/chapter12-%E5%8F%A5%E6%B3%95%E5%88%86%E6%9E%90/">chapter12-å¥æ³•åˆ†æ</a></p>
</li>
<li><p>æŒ‡ä»£æ¶ˆè§£ anaphora resolution</p>
</li>
<li><p>è‡ªåŠ¨é—®ç­”</p>
</li>
<li><p>æœºå™¨ç¿»è¯‘</p>
</li>
<li><p>äººæœºå¯¹è¯ç³»ç»Ÿ</p>
</li>
</ul>
<h3 id="è·å¾—æ–‡æœ¬è¯­æ–™å’Œè¯æ±‡èµ„æº"><a href="#è·å¾—æ–‡æœ¬è¯­æ–™å’Œè¯æ±‡èµ„æº" class="headerlink" title="è·å¾—æ–‡æœ¬è¯­æ–™å’Œè¯æ±‡èµ„æº"></a>è·å¾—æ–‡æœ¬è¯­æ–™å’Œè¯æ±‡èµ„æº</h3><h4 id="å¸ƒæœ—è¯­æ–™åº“"><a href="#å¸ƒæœ—è¯­æ–™åº“" class="headerlink" title="å¸ƒæœ—è¯­æ–™åº“"></a>å¸ƒæœ—è¯­æ–™åº“</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">from</span> nltk.corpus <span class="keyword">import</span> brown</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<p>æœ‰ä»¥ä¸‹è¿™äº›ç±»åˆ«çš„æ–‡æœ¬</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="built_in">print</span>(brown.categories())</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<pre><code>[&#39;adventure&#39;, &#39;belles_lettres&#39;, &#39;editorial&#39;, &#39;fiction&#39;, &#39;government&#39;, &#39;hobbies&#39;, &#39;humor&#39;, &#39;learned&#39;, &#39;lore&#39;, &#39;mystery&#39;, &#39;news&#39;, &#39;religion&#39;, &#39;reviews&#39;, &#39;romance&#39;, &#39;science_fiction&#39;]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">import</span> nltk</span><br><span class="line"></span><br><span class="line">news_text = brown.words(categories=<span class="string">&quot;news&quot;</span>)</span><br><span class="line"></span><br><span class="line">fdist_news = nltk.FreqDist([w.lower() <span class="keyword">for</span> w <span class="keyword">in</span> news_text])</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">len</span>(fdist_news))</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<pre><code>13112
</code></pre>
<h3 id="æ ‡æ³¨æ–‡æœ¬è¯­æ–™åº“"><a href="#æ ‡æ³¨æ–‡æœ¬è¯­æ–™åº“" class="headerlink" title="æ ‡æ³¨æ–‡æœ¬è¯­æ–™åº“"></a>æ ‡æ³¨æ–‡æœ¬è¯­æ–™åº“</h3><p>ç»è¿‡äº†æ ‡æ³¨çš„è¯­æ–™åº“ï¼Œæœ‰è¯æ€§æ ‡æ³¨ã€å‘½åå®ä½“ã€å¥æ³•ç»“æ„ã€è¯­ä¹‰è§’è‰²ç­‰ã€‚</p>
<h4 id="åˆ†ç±»å’Œæ ‡æ³¨è¯æ±‡"><a href="#åˆ†ç±»å’Œæ ‡æ³¨è¯æ±‡" class="headerlink" title="åˆ†ç±»å’Œæ ‡æ³¨è¯æ±‡"></a>åˆ†ç±»å’Œæ ‡æ³¨è¯æ±‡</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">text = nltk.word_tokenize(<span class="string">&quot;and now for something completely differences!&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(text)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(nltk.pos_tag(text))</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<pre><code>[&#39;and&#39;, &#39;now&#39;, &#39;for&#39;, &#39;something&#39;, &#39;completely&#39;, &#39;differences&#39;, &#39;!&#39;]

[(&#39;and&#39;, &#39;CC&#39;), (&#39;now&#39;, &#39;RB&#39;), (&#39;for&#39;, &#39;IN&#39;), (&#39;something&#39;, &#39;NN&#39;), (&#39;completely&#39;, &#39;RB&#39;), (&#39;differences&#39;, &#39;VBZ&#39;), (&#39;!&#39;, &#39;.&#39;)]
</code></pre>
<h5 id="è¯æ€§æ ‡æ³¨"><a href="#è¯æ€§æ ‡æ³¨" class="headerlink" title="è¯æ€§æ ‡æ³¨"></a>è¯æ€§æ ‡æ³¨</h5><p>NLTKä¸­é‡‡ç”¨çš„æ–¹æ³•å¯å‚è€ƒï¼š<a target="_blank" rel="noopener" href="https://explosion.ai/blog/part-of-speech-pos-tagger-in-python">A Good Part-of-Speech Tagger in about 200 Lines of Python</a></p>
<p>å¯¹äºä¸€äº›åŒå½¢åŒéŸ³å¼‚ä¹‰è¯ï¼Œé€šè¿‡è¯æ€§æ ‡æ³¨èƒ½æ¶ˆé™¤æ­§ä¹‰.å¾ˆå¤šæ–‡æœ¬è½¬è¯­éŸ³ç³»ç»Ÿé€šå¸¸éœ€è¦è¿›è¡Œè¯æ€§æ ‡æ³¨ï¼Œå› ä¸ºä¸åŒæ„æ€å‘éŸ³ä¼šä¸å¤ªä¸€æ ·ã€‚</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">text1 = nltk.word_tokenize(<span class="string">&quot;They refuse to permit us tpo obtain the refuse permit&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(nltk.pos_tag(text1))</span><br><span class="line"></span><br><span class="line">text2 = nltk.word_tokenize(<span class="string">&quot;They refuse to permit us to obtain the refuse permit&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(nltk.pos_tag(text2))</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<pre><code>[(&#39;They&#39;, &#39;PRP&#39;), (&#39;refuse&#39;, &#39;VBP&#39;), (&#39;to&#39;, &#39;TO&#39;), (&#39;permit&#39;, &#39;VB&#39;), (&#39;us&#39;, &#39;PRP&#39;), (&#39;tpo&#39;, &#39;VB&#39;), (&#39;obtain&#39;, &#39;VB&#39;), (&#39;the&#39;, &#39;DT&#39;), (&#39;refuse&#39;, &#39;NN&#39;), (&#39;permit&#39;, &#39;NN&#39;)]

[(&#39;They&#39;, &#39;PRP&#39;), (&#39;refuse&#39;, &#39;VBP&#39;), (&#39;to&#39;, &#39;TO&#39;), (&#39;permit&#39;, &#39;VB&#39;), (&#39;us&#39;, &#39;PRP&#39;), (&#39;to&#39;, &#39;TO&#39;), (&#39;obtain&#39;, &#39;VB&#39;), (&#39;the&#39;, &#39;DT&#39;), (&#39;refuse&#39;, &#39;NN&#39;), (&#39;permit&#39;, &#39;NN&#39;)]
</code></pre>
<h5 id="è·å–å·²ç»æ ‡æ³¨å¥½çš„è¯­æ–™åº“"><a href="#è·å–å·²ç»æ ‡æ³¨å¥½çš„è¯­æ–™åº“" class="headerlink" title="è·å–å·²ç»æ ‡æ³¨å¥½çš„è¯­æ–™åº“"></a>è·å–å·²ç»æ ‡æ³¨å¥½çš„è¯­æ–™åº“</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="built_in">print</span>(nltk.corpus.brown.tagged_words())</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<pre><code>[(&#39;The&#39;, &#39;AT&#39;), (&#39;Fulton&#39;, &#39;NP-TL&#39;), ...]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="built_in">print</span>(nltk.corpus.treebank.tagged_words())</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(nltk.corpus.treebank.tagged_sents()[<span class="number">0</span>])</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<pre><code>[(&#39;Pierre&#39;, &#39;NNP&#39;), (&#39;Vinken&#39;, &#39;NNP&#39;), (&#39;,&#39;, &#39;,&#39;), ...]

[(&#39;Pierre&#39;, &#39;NNP&#39;), (&#39;Vinken&#39;, &#39;NNP&#39;), (&#39;,&#39;, &#39;,&#39;), (&#39;61&#39;, &#39;CD&#39;), (&#39;years&#39;, &#39;NNS&#39;), (&#39;old&#39;, &#39;JJ&#39;), (&#39;,&#39;, &#39;,&#39;), (&#39;will&#39;, &#39;MD&#39;), (&#39;join&#39;, &#39;VB&#39;), (&#39;the&#39;, &#39;DT&#39;), (&#39;board&#39;, &#39;NN&#39;), (&#39;as&#39;, &#39;IN&#39;), (&#39;a&#39;, &#39;DT&#39;), (&#39;nonexecutive&#39;, &#39;JJ&#39;), (&#39;director&#39;, &#39;NN&#39;), (&#39;Nov.&#39;, &#39;NNP&#39;), (&#39;29&#39;, &#39;CD&#39;), (&#39;.&#39;, &#39;.&#39;)]
</code></pre>
<p>æŸ¥çœ‹brownè¯­æ–™åº“ä¸­æ–°é—»ç±»æœ€å¸¸è§çš„è¯æ€§</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">brown_news_tagged = brown.tagged_words(categories=<span class="string">&#x27;news&#x27;</span>, tagset=<span class="string">&#x27;universal&#x27;</span>)</span><br><span class="line"></span><br><span class="line">tag_fd = nltk.FreqDist(tag <span class="keyword">for</span> (word, tag) <span class="keyword">in</span> brown_news_tagged)</span><br><span class="line"></span><br><span class="line">tag_fd.keys()</span><br><span class="line"></span><br></pre></td></tr></table></figure>









<pre><code>dict_keys([&#39;DET&#39;, &#39;NOUN&#39;, &#39;ADJ&#39;, &#39;VERB&#39;, &#39;ADP&#39;, &#39;.&#39;, &#39;ADV&#39;, &#39;CONJ&#39;, &#39;PRT&#39;, &#39;PRON&#39;, &#39;NUM&#39;, &#39;X&#39;])
</code></pre>
<h3 id="æ–‡æœ¬åˆ†ç±»"><a href="#æ–‡æœ¬åˆ†ç±»" class="headerlink" title="æ–‡æœ¬åˆ†ç±»"></a>æ–‡æœ¬åˆ†ç±»</h3><h4 id="æœ´ç´ è´å¶æ–¯åˆ†ç±»"><a href="#æœ´ç´ è´å¶æ–¯åˆ†ç±»" class="headerlink" title="æœ´ç´ è´å¶æ–¯åˆ†ç±»"></a>æœ´ç´ è´å¶æ–¯åˆ†ç±»</h4><p>é€‰å–ç‰¹å¾ï¼Œå°†åå­—çš„æœ€åä¸€ä¸ªå­—æ¯ä½œä¸ºç‰¹å¾. è¿”å›çš„å­—å…¸ç§°ä¸ºç‰¹å¾é›†</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">gender_features</span>(<span class="params">word</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">&#x27;last_letter&#x27;</span>:word[-<span class="number">1</span>]&#125;</span><br><span class="line"></span><br><span class="line">gender_features(<span class="string">&#x27;Shrek&#x27;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<pre><code>&#123;&#39;last_letter&#39;: &#39;k&#39;&#125;
</code></pre>
<p>å®šä¹‰ä¸€ä¸ªç‰¹å¾æå–å™¨</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">from</span> nltk.corpus <span class="keyword">import</span> names</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"></span><br><span class="line">names = ([(name, <span class="string">&#x27;male&#x27;</span>) <span class="keyword">for</span> name <span class="keyword">in</span> names.words(<span class="string">&#x27;male.txt&#x27;</span>)] +</span><br><span class="line"></span><br><span class="line">        [(name, <span class="string">&#x27;female&#x27;</span>) <span class="keyword">for</span> name <span class="keyword">in</span> names.words(<span class="string">&#x27;female.txt&#x27;</span>)])</span><br><span class="line"></span><br></pre></td></tr></table></figure>





<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="built_in">print</span>(nltk.corpus.names.words(<span class="string">&#x27;male.txt&#x27;</span>)[:<span class="number">10</span>])</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(names[:<span class="number">10</span>])</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<pre><code>[&#39;Aamir&#39;, &#39;Aaron&#39;, &#39;Abbey&#39;, &#39;Abbie&#39;, &#39;Abbot&#39;, &#39;Abbott&#39;, &#39;Abby&#39;, &#39;Abdel&#39;, &#39;Abdul&#39;, &#39;Abdulkarim&#39;]

[(&#39;Aamir&#39;, &#39;male&#39;), (&#39;Aaron&#39;, &#39;male&#39;), (&#39;Abbey&#39;, &#39;male&#39;), (&#39;Abbie&#39;, &#39;male&#39;), (&#39;Abbot&#39;, &#39;male&#39;), (&#39;Abbott&#39;, &#39;male&#39;), (&#39;Abby&#39;, &#39;male&#39;), (&#39;Abdel&#39;, &#39;male&#39;), (&#39;Abdul&#39;, &#39;male&#39;), (&#39;Abdulkarim&#39;, &#39;male&#39;)]
</code></pre>
<p>ä½¿ç”¨ç‰¹å¾æå–å™¨å¤„ç†namesæ•°æ®ï¼Œå¹¶æŠŠæ•°æ®é›†åˆ†ä¸ºè®­ç»ƒé›†å’Œæµ‹è¯•é›†</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment"># äºŒåˆ†ç±»</span></span><br><span class="line"></span><br><span class="line">features = [(gender_features(n), g) <span class="keyword">for</span> (n, g) <span class="keyword">in</span> names]</span><br><span class="line"></span><br></pre></td></tr></table></figure>





<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">train_set, test_set = features[<span class="number">500</span>:], features[:<span class="number">500</span>]</span><br><span class="line"></span><br></pre></td></tr></table></figure>





<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="built_in">print</span>(train_set[:<span class="number">10</span>])</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<pre><code>[(&#123;&#39;last_letter&#39;: &#39;n&#39;&#125;, &#39;male&#39;), (&#123;&#39;last_letter&#39;: &#39;e&#39;&#125;, &#39;male&#39;), (&#123;&#39;last_letter&#39;: &#39;e&#39;&#125;, &#39;male&#39;), (&#123;&#39;last_letter&#39;: &#39;b&#39;&#125;, &#39;male&#39;), (&#123;&#39;last_letter&#39;: &#39;b&#39;&#125;, &#39;male&#39;), (&#123;&#39;last_letter&#39;: &#39;e&#39;&#125;, &#39;male&#39;), (&#123;&#39;last_letter&#39;: &#39;y&#39;&#125;, &#39;male&#39;), (&#123;&#39;last_letter&#39;: &#39;y&#39;&#125;, &#39;male&#39;), (&#123;&#39;last_letter&#39;: &#39;t&#39;&#125;, &#39;male&#39;), (&#123;&#39;last_letter&#39;: &#39;e&#39;&#125;, &#39;male&#39;)]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">classifier = nltk.NaiveBayesClassifier.train(train_set)</span><br><span class="line"></span><br></pre></td></tr></table></figure>





<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment"># é¢„æµ‹ä¸€ä¸ªæœªå‡ºç°çš„åå­—</span></span><br><span class="line"></span><br><span class="line">classifier.classify(gender_features(<span class="string">&#x27;Pan&#x27;</span>))</span><br><span class="line"></span><br></pre></td></tr></table></figure>









<pre><code>&#39;male&#39;
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment"># æµ‹è¯•é›†ä¸Šçš„å‡†ç¡®ç‡</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(nltk.classify.accuracy(classifier, test_set))</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<pre><code>0.602
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">classifier.show_most_informative_features(<span class="number">5</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<pre><code>Most Informative Features

             last_letter = &#39;a&#39;            female : male   =     35.5 : 1.0

             last_letter = &#39;k&#39;              male : female =     34.1 : 1.0

             last_letter = &#39;f&#39;              male : female =     15.9 : 1.0

             last_letter = &#39;p&#39;              male : female =     13.5 : 1.0

             last_letter = &#39;v&#39;              male : female =     12.7 : 1.0
</code></pre>
<p>æ„å»ºåŒ…å«æ‰€æœ‰å®ä¾‹ç‰¹å¾çš„å•ç‹¬listä¼šå ç”¨å¤§é‡å†…å­˜ï¼Œæ‰€æœ‰åº”è¯¥æŠŠè¿™äº›ç‰¹å¾é›†æˆèµ·æ¥ã€‚</p>
<h4 id="å®šä¹‰ä¸€ä¸ªç‰¹å¾æå–å™¨åŒ…å«å¤šä¸ªç‰¹å¾"><a href="#å®šä¹‰ä¸€ä¸ªç‰¹å¾æå–å™¨åŒ…å«å¤šä¸ªç‰¹å¾" class="headerlink" title="å®šä¹‰ä¸€ä¸ªç‰¹å¾æå–å™¨åŒ…å«å¤šä¸ªç‰¹å¾"></a>å®šä¹‰ä¸€ä¸ªç‰¹å¾æå–å™¨åŒ…å«å¤šä¸ªç‰¹å¾</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment"># æ·»åŠ å¤šä¸ªç‰¹å¾</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> nltk.classify <span class="keyword">import</span> apply_features</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">gender_features2</span>(<span class="params">word</span>):</span></span><br><span class="line"></span><br><span class="line">    features = &#123;&#125;</span><br><span class="line"></span><br><span class="line">    features[<span class="string">&#x27;firstletter&#x27;</span>] = word[<span class="number">0</span>].lower()</span><br><span class="line"></span><br><span class="line">    features[<span class="string">&#x27;lastletter&#x27;</span>] = word[-<span class="number">1</span>].lower()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> letter <span class="keyword">in</span> <span class="string">&#x27;abcdefghijklmnopqrstuvwxyz&#x27;</span>:</span><br><span class="line"></span><br><span class="line">        features[<span class="string">&quot;count(%s)&quot;</span>%letter] = word.lower().count(letter)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> features</span><br><span class="line"></span><br></pre></td></tr></table></figure>





<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="built_in">print</span>(gender_features2(<span class="string">&#x27;xiepan&#x27;</span>))</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">len</span>(gender_features2(<span class="string">&#x27;xiepan&#x27;</span>))) <span class="comment"># æœ‰28ä¸ªç‰¹å¾ï¼Œ 2+26=28</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>



<pre><code>&#123;&#39;firstletter&#39;: &#39;x&#39;, &#39;lastletter&#39;: &#39;n&#39;, &#39;count(a)&#39;: 1, &#39;count(b)&#39;: 0, &#39;count(c)&#39;: 0, &#39;count(d)&#39;: 0, &#39;count(e)&#39;: 1, &#39;count(f)&#39;: 0, &#39;count(g)&#39;: 0, &#39;count(h)&#39;: 0, &#39;count(i)&#39;: 1, &#39;count(j)&#39;: 0, &#39;count(k)&#39;: 0, &#39;count(l)&#39;: 0, &#39;count(m)&#39;: 0, &#39;count(n)&#39;: 1, &#39;count(o)&#39;: 0, &#39;count(p)&#39;: 1, &#39;count(q)&#39;: 0, &#39;count(r)&#39;: 0, &#39;count(s)&#39;: 0, &#39;count(t)&#39;: 0, &#39;count(u)&#39;: 0, &#39;count(v)&#39;: 0, &#39;count(w)&#39;: 0, &#39;count(x)&#39;: 1, &#39;count(y)&#39;: 0, &#39;count(z)&#39;: 0&#125;

28
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment"># å¯¹æ¯ä¸ªæ ·æœ¬è¿›è¡Œç‰¹å¾å¤„ç†</span></span><br><span class="line"></span><br><span class="line">features = [(gender_features(n), g) <span class="keyword">for</span> (n,g) <span class="keyword">in</span> names]</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">len</span>(features))</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<pre><code>7944
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment"># è®­ç»ƒé›†ï¼Œå¼€å‘é›†å’Œæµ‹è¯•é›†</span></span><br><span class="line"></span><br><span class="line">train_set = features[<span class="number">1500</span>:]</span><br><span class="line"></span><br><span class="line">dev_set = apply_features(gender_features2, names[<span class="number">500</span>:<span class="number">1500</span>])</span><br><span class="line"></span><br><span class="line">test_set = apply_features(gender_features2, names[:<span class="number">500</span>])</span><br><span class="line"></span><br></pre></td></tr></table></figure>





<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">classifier = nltk.NaiveBayesClassifier.train(train_set)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(nltk.classify.accuracy(classifier, dev_set))</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(nltk.classify.accuracy(classifier, test_set))</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(nltk.classify.accuracy(classifier, train_set))  <span class="comment">## æ˜æ˜¾è¿‡æ‹Ÿåˆäº†ï½</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>



<pre><code>0.007

0.008

0.883302296710118
</code></pre>
<h3 id="æ–‡æ¡£åˆ†ç±»"><a href="#æ–‡æ¡£åˆ†ç±»" class="headerlink" title="æ–‡æ¡£åˆ†ç±»"></a>æ–‡æ¡£åˆ†ç±»</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">from</span> nltk.corpus <span class="keyword">import</span> movie_reviews</span><br><span class="line"></span><br><span class="line">documents = [(<span class="built_in">list</span>(movie_reviews.words(fileid)), category) <span class="keyword">for</span> category <span class="keyword">in</span> movie_reviews.categories()</span><br><span class="line"></span><br><span class="line">             <span class="keyword">for</span> fileid <span class="keyword">in</span> movie_reviews.fileids(category) ]</span><br><span class="line"></span><br></pre></td></tr></table></figure>





<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">movie_reviews.categories()</span><br><span class="line"></span><br></pre></td></tr></table></figure>









<pre><code>[&#39;neg&#39;, &#39;pos&#39;]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">neg_docu = movie_reviews.fileids(<span class="string">&#x27;neg&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">len</span>(neg_docu))   <span class="comment"># negç±»åˆ«çš„æ–‡æ¡£æ•°ã€€1000</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">len</span>(documents))  <span class="comment">#ã€€æ€»çš„æ–‡æ¡£æ•°    1000</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">len</span>(movie_reviews.words(neg_docu[<span class="number">0</span>])) <span class="comment"># ç¬¬ä¸€ä¸ªæ–‡ä»¶ä¸­å•è¯æ•°  879</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<pre><code>1000

2000

879
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">random.shuffle(documents)</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h4 id="æ–‡æ¡£åˆ†ç±»çš„ç‰¹å¾æå–å™¨"><a href="#æ–‡æ¡£åˆ†ç±»çš„ç‰¹å¾æå–å™¨" class="headerlink" title="æ–‡æ¡£åˆ†ç±»çš„ç‰¹å¾æå–å™¨"></a>æ–‡æ¡£åˆ†ç±»çš„ç‰¹å¾æå–å™¨</h4><p>æ‰€è°“ç‰¹å¾æå–å™¨å®é™…ä¸Šå°±æ˜¯å°†æ–‡æ¡£åŸæœ¬çš„å†…å®¹ç”¨è®¤ä¸ºé€‰å®šçš„ç‰¹å¾æ¥è¡¨ç¤ºã€‚ç„¶åç”¨åˆ†ç±»å™¨æ‰¾å‡ºè¿™äº›ç‰¹å¾å’Œå¯¹åº”ç±»æ ‡ç­¾çš„æ˜ å°„å…³ç³»ã€‚</p>
<p>é‚£ä¹ˆä»€ä¹ˆæ ·çš„ç‰¹å¾æ‰æ˜¯å¥½çš„ç‰¹å¾ï¼Œè¿™å°±æ˜¯ç‰¹å¾å·¥ç¨‹äº†å§ã€‚</p>
<h4 id="æ–‡æœ¬åˆ†ç±»æ¦‚è¿°"><a href="#æ–‡æœ¬åˆ†ç±»æ¦‚è¿°" class="headerlink" title="æ–‡æœ¬åˆ†ç±»æ¦‚è¿°"></a>æ–‡æœ¬åˆ†ç±»æ¦‚è¿°</h4><p>æ–‡æœ¬åˆ†ç±»ï¼Œé¡¾åæ€ä¹‰ï¼Œå°±æ˜¯æ ¹æ®æ–‡æœ¬å†…å®¹æœ¬èº«å°†æ–‡æœ¬å½’ä¸ºä¸åŒçš„ç±»åˆ«ï¼Œé€šå¸¸æ˜¯æœ‰ç›‘ç£å­¦ä¹ çš„ä»»åŠ¡ã€‚æ ¹æ®æ–‡æœ¬å†…å®¹çš„é•¿çŸ­ï¼Œæœ‰åšå¥å­ã€æ®µè½æˆ–è€…æ–‡ç« çš„åˆ†ç±»ï¼›æ–‡æœ¬çš„é•¿çŸ­ä¸åŒå¯èƒ½ä¼šå¯¼è‡´æ–‡æœ¬å¯æŠ½å–çš„ç‰¹å¾ä¸Šçš„ç•¥å¾®å·®å¼‚ï¼Œ<strong>ä½†æ˜¯æ€»ä½“ä¸Šæ¥è¯´ï¼Œæ–‡æœ¬åˆ†ç±»çš„æ ¸å¿ƒéƒ½æ˜¯å¦‚ä½•ä»æ–‡æœ¬ä¸­æŠ½å–å‡ºèƒ½å¤Ÿä½“ç°æ–‡æœ¬ç‰¹ç‚¹çš„å…³é”®ç‰¹å¾ï¼ŒæŠ“å–ç‰¹å¾åˆ°ç±»åˆ«ä¹‹é—´çš„æ˜ å°„ã€‚</strong> æ‰€ä»¥ï¼Œç‰¹å¾å·¥ç¨‹å°±æ˜¾å¾—éå¸¸é‡è¦ï¼Œç‰¹å¾æ‰¾çš„å¥½ï¼Œåˆ†ç±»æ•ˆæœä¹Ÿä¼šå¤§å¹…æé«˜ï¼ˆå½“ç„¶å‰ææ˜¯æ ‡æ³¨æ•°æ®è´¨é‡å’Œæ•°é‡ä¹Ÿè¦åˆé€‚ï¼Œæ•°æ®çš„å¥½åå†³å®šæ•ˆæœçš„ä¸‹é™ï¼Œç‰¹å¾å·¥ç¨‹å†³å®šæ•ˆæœçš„ä¸Šé™ï¼‰ã€‚</p>
<p>ä¹Ÿè®¸ä¼šæœ‰äººé—®æœ€è¿‘çš„æ·±åº¦å­¦ä¹ æŠ€æœ¯èƒ½å¤Ÿé¿å…æˆ‘ä»¬æ„é€ ç‰¹å¾è¿™ä»¶äº‹ï¼Œä¸ºä»€ä¹ˆè¿˜éœ€è¦ç‰¹å¾å·¥ç¨‹ï¼Ÿæ·±åº¦å­¦ä¹ å¹¶ä¸æ˜¯ä¸‡èƒ½çš„ï¼Œåœ¨NLPé¢†åŸŸæ·±åº¦å­¦ä¹ æŠ€æœ¯å–å¾—çš„æ•ˆæœæœ‰é™ï¼ˆæ¯•ç«Ÿè¯­è¨€æ˜¯é«˜é˜¶æŠ½è±¡çš„ä¿¡æ¯ï¼Œæ·±åº¦å­¦ä¹ åœ¨å›¾åƒã€è¯­éŸ³è¿™äº›ä½é˜¶å…·ä½“çš„ä¿¡æ¯å¤„ç†ä¸Šæ›´é€‚åˆï¼Œå› ä¸ºåœ¨ä½é˜¶å…·ä½“çš„ä¿¡æ¯ä¸Šæ„é€ ç‰¹å¾æ˜¯ä¸€ä»¶è´¹åŠ›çš„äº‹æƒ…ï¼‰ï¼Œå¹¶ä¸æ˜¯å¦è®¤æ·±åº¦å­¦ä¹ åœ¨NLPé¢†åŸŸä¸Šå–å¾—çš„æˆç»©ï¼Œå·¥ä¸šç•Œç°åœ¨é€šç”¨çš„åšæ³•éƒ½æ˜¯ä¼šæŠŠæ·±åº¦å­¦ä¹ æ¨¡å‹ä½œä¸ºç³»ç»Ÿçš„ä¸€ä¸ªå­æ¨¡å—ï¼ˆä¹Ÿæ˜¯ä¸€ç»´ç‰¹å¾ï¼‰ï¼Œå’Œä¸€äº›ä¼ ç»Ÿçš„åŸºäºç»Ÿè®¡çš„è‡ªç„¶è¯­è¨€æŠ€æœ¯çš„ç‰¹å¾ï¼Œè¿˜æœ‰ä¸€äº›é’ˆå¯¹å…·ä½“ä»»åŠ¡æœ¬èº«ä¸“é—¨è®¾è®¡çš„ç‰¹å¾ï¼Œä¸€èµ·ä½œä¸ºä¸€ä¸ªæˆ–å¤šä¸ªæ¨¡å‹ï¼ˆä¹Ÿç§°Ensembleï¼Œå³æ¨¡å‹é›†æˆï¼‰çš„è¾“å…¥ï¼Œæœ€ç»ˆæ„æˆä¸€ä¸ªæ–‡æœ¬å¤„ç†ç³»ç»Ÿã€‚</p>
<h4 id="ç‰¹å¾å·¥ç¨‹"><a href="#ç‰¹å¾å·¥ç¨‹" class="headerlink" title="ç‰¹å¾å·¥ç¨‹"></a>ç‰¹å¾å·¥ç¨‹</h4><p>é‚£ä¹ˆï¼Œå¯¹äºæ–‡æœ¬åˆ†ç±»ä»»åŠ¡è€Œè¨€ï¼Œå·¥ä¸šç•Œå¸¸ç”¨åˆ°çš„ç‰¹å¾æœ‰å“ªäº›å‘¢ï¼Ÿä¸‹é¢ç”¨ä¸€å¼ å›¾ä»¥æ¦‚æ‹¬ï¼š</p>
<p><img src="/2018/05/25/%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E7%B3%BB%E5%88%970%EF%BC%9ANLTK%E5%AD%A6%E4%B9%A0%E5%92%8C%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B/01.png"></p>
<p>æˆ‘ä¸»è¦å°†è¿™äº›ç‰¹å¾åˆ†ä¸ºå››ä¸ªå±‚æ¬¡ï¼Œç”±ä¸‹å¾€ä¸Šï¼Œç‰¹å¾ç”±æŠ½è±¡åˆ°å…·ä½“ï¼Œç²’åº¦ä»ç»†åˆ°ç²—ã€‚æˆ‘ä»¬å¸Œæœ›èƒ½å¤Ÿä»ä¸åŒçš„è§’åº¦å’Œçº¬åº¦æ¥è®¾è®¡ç‰¹å¾ï¼Œä»¥æ•æ‰è¿™äº›ç‰¹å¾å’Œç±»åˆ«ä¹‹é—´çš„å…³ç³»ã€‚ä¸‹é¢è¯¦ç»†ä»‹ç»è¿™å››ä¸ªå±‚æ¬¡ä¸Šå¸¸ç”¨åˆ°çš„ç‰¹å¾è¡¨ç¤ºã€‚</p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2018-05-23T02:15:48.000Z" title="2018/5/23 ä¸Šåˆ10:15:48">2018-05-23</time>å‘è¡¨</span><span class="level-item"><time dateTime="2021-06-29T08:12:08.200Z" title="2021/6/29 ä¸‹åˆ4:12:08">2021-06-29</time>æ›´æ–°</span><span class="level-item"><a class="link-muted" href="/categories/%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB/">æ–‡æœ¬åˆ†ç±»</a></span><span class="level-item">13 åˆ†é’Ÿè¯»å®Œ (å¤§çº¦1950ä¸ªå­—)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2018/05/23/%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E7%B3%BB%E5%88%971-fasttext/">æ–‡æœ¬åˆ†ç±»ç³»åˆ—1-fasttext</a></h1><div class="content"><p>åœ¨Facebook fasttext githubä¸»é¡µä¸­ï¼Œå…³äºfasttextçš„ä½¿ç”¨åŒ…æ‹¬ä¸¤ä¸ªæ–¹é¢ï¼Œè¯å‘é‡è¡¨ç¤ºå­¦ä¹ ä»¥åŠæ–‡æœ¬åˆ†ç±»ã€‚</p>
<ul>
<li><p>è¯å‘é‡è¡¨ç¤ºå­¦ä¹ ï¼š<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1607.04606.pdf">Enriching Word Vectors with Subword Information</a></p>
</li>
<li><p>æ–‡æœ¬åˆ†ç±»ï¼š<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1607.01759.pdf">Bag of Tricks for Efficient Text Classification, Armand Joulin, Edouard Grave, Piotr Bojanowski, Tomas Mikolov</a></p>
</li>
</ul>
<h3 id="Paper-Reading1"><a href="#Paper-Reading1" class="headerlink" title="Paper Reading1"></a>Paper Reading1</h3><p>è¿™ç¯‡æ–‡ç« æ˜¯ç”¨æ¥è¿›è¡Œæ–‡æœ¬åˆ†ç±»çš„: <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1607.01759.pdf">Bag of Tricks for Efficient Text Classification, Armand Joulin, Edouard Grave, Piotr Bojanowski, Tomas Mikolov</a></p>
<p>è¿™ä¸ªæ¨¡å‹è·Ÿword2vec ä¸­çš„CBOwæ¨¡å‹æå…¶ç›¸ä¼¼ï¼ŒåŒºåˆ«åœ¨äºå°†ä¸­å¿ƒè¯æ¢æˆæ–‡æœ¬æ ‡ç­¾ã€‚é‚£ä¹ˆè¾“å…¥å±‚æ˜¯æ–‡æœ¬ä¸­å•è¯ç»è¿‡åµŒå…¥æ›¾ä¹‹åçš„è¯å‘é‡æ„æˆçš„çš„n-gramï¼Œç„¶åæ±‚å¹³å‡æ“ä½œå¾—åˆ°ä¸€ä¸ªæ–‡æœ¬sentenceçš„å‘é‡ï¼Œä¹Ÿå°±æ˜¯éšè—å±‚hï¼Œç„¶åå†ç»è¿‡ä¸€ä¸ªè¾“å‡ºå±‚æ˜ å°„åˆ°æ‰€æœ‰ç±»åˆ«ä¸­ï¼Œè®ºæ–‡é‡Œé¢è¿˜è¯¦ç»†è®ºè¿°äº†å¦‚ä½•ä½¿ç”¨n-gram featureè€ƒè™‘å•è¯çš„é¡ºåºå…³ç³»ï¼Œä»¥åŠå¦‚ä½•ä½¿ç”¨Hierarchical softmaxæœºåˆ¶åŠ é€Ÿsoftmaxå‡½æ•°çš„è®¡ç®—é€Ÿåº¦ã€‚æ¨¡å‹çš„åŸç†å›¾å¦‚ä¸‹æ‰€ç¤ºï¼š</p>
<p><img src="/2018/05/23/%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E7%B3%BB%E5%88%971-fasttext/01.png"></p>
<p>ç›®æ ‡å‡½æ•°ï¼š</p>
<p>$$\dfrac{1}{N}\sum_{n=1}^Ny_nlog(f(BAx_n))$$</p>
<ul>
<li><p>Nè¡¨ç¤ºæ–‡æœ¬æ•°é‡ï¼Œè®­ç»ƒæ—¶å°±æ˜¯Batch sizeå§ï¼Ÿ</p>
</li>
<li><p>$x_n$ è¡¨ç¤ºç¬¬nä¸ªæ–‡æœ¬çš„ normalized bag of features</p>
</li>
<li><p>$y_n$ è¡¨ç¤ºç¬¬nä¸ªæ–‡æœ¬çš„ç±»æ ‡ç­¾</p>
</li>
<li><p>A is the look up table over n-gram. ç±»ä¼¼äºattentionä¸­çš„æƒé‡å§</p>
</li>
<li><p>B is the weight matrix</p>
</li>
</ul>
<p>éšè—å±‚åˆ°è¾“å‡ºå±‚çš„è®¡ç®—å¤æ‚åº¦æ˜¯ $O(hk)$. hæ˜¯éšè—å±‚çš„ç»´åº¦ï¼Œkæ˜¯æ€»çš„ç±»åˆ«æ•°ã€‚ç»è¿‡hierarchical softmaxå¤„ç†åï¼Œå¤æ‚åº¦ä¸º $O(hlog_2k)$</p>
<ul>
<li><p>è¿™ç§æ¨¡å‹çš„ä¼˜ç‚¹åœ¨äºç®€å•ï¼Œæ— è®ºè®­ç»ƒè¿˜æ˜¯é¢„æµ‹çš„é€Ÿåº¦éƒ½å¾ˆå¿«ï¼Œæ¯”å…¶ä»–æ·±åº¦å­¦ä¹ æ¨¡å‹é«˜äº†å‡ ä¸ªé‡çº§</p>
</li>
<li><p>ç¼ºç‚¹æ˜¯æ¨¡å‹è¿‡äºç®€å•ï¼Œå‡†ç¡®åº¦è¾ƒä½ã€‚</p>
</li>
</ul>
<h3 id="paper-reading2"><a href="#paper-reading2" class="headerlink" title="paper reading2"></a>paper reading2</h3><p>è¿™ç¯‡æ–‡ç« æ˜¯åœ¨word2vecçš„åŸºç¡€ä¸Šæ‹“å±•äº†ï¼Œç”¨æ¥å­¦ä¹ è¯å‘é‡è¡¨ç¤º <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1607.04606.pdf">Enriching Word Vectors with Subword Information</a></p>
<h4 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h4><p>Popular models that learn such representations ignore the morphology of words, by assigning a distinct vector to each word.</p>
<p>ä¹‹å‰çš„æ¨¡å‹åœ¨ç”¨ç¦»æ•£çš„å‘é‡è¡¨ç¤ºå•è¯æ—¶éƒ½å¿½ç•¥äº†å•è¯çš„å½¢æ€ã€‚</p>
<p>In this paper, we propose a new approach based on the skipgram model, where each word is represented as a bag of character n-grams. A vector representation is associated to each character n-gram; words being represented as the sum of these representations.</p>
<p>è¿™ç¯‡æ–‡ç« æå‡ºäº†ä¸€ä¸ªskipgramæ¨¡å‹,å…¶ä¸­æ¯ä¸€ä¸ªå•è¯è¡¨ç¤ºä¸ºç»„æˆè¿™ä¸ªå•è¯çš„å­—è¢‹æ¨¡å‹ a bag of character n-grams. ä¸€ä¸ªå•è¯çš„è¯å‘é‡è¡¨ç¤ºä¸ºè¿™äº› n-gramsè¡¨ç¤ºçš„æ€»å’Œã€‚</p>
<p>Our main contribution is to introduce an extension of the continuous skipgram model (Mikolov et al., 2013b), which takes into account subword information. We evaluate this model on nine languages exhibiting different morphologies, showing the benefit of our approach. è¿™ç¯‡æ–‡ç« å¯ä»¥çœ‹ä½œæ˜¯word2vecçš„æ‹“å±•ï¼Œä¸»è¦æ˜¯é’ˆå¯¹ä¸€äº›å½¢æ€ç‰¹åˆ«å¤æ‚çš„è¯­è¨€ã€‚</p>
<p>word2vecåœ¨è¯æ±‡å»ºæ¨¡æ–¹é¢äº§ç”Ÿäº†å·¨å¤§çš„è´¡çŒ®ï¼Œç„¶è€Œå…¶ä¾èµ–äºå¤§é‡çš„æ–‡æœ¬æ•°æ®è¿›è¡Œå­¦ä¹ ï¼Œå¦‚æœä¸€ä¸ªwordå‡ºç°æ¬¡æ•°è¾ƒå°‘é‚£ä¹ˆå­¦åˆ°çš„vectorè´¨é‡ä¹Ÿä¸ç†æƒ³ã€‚é’ˆå¯¹è¿™ä¸€é—®é¢˜ä½œè€…æå‡ºä½¿ç”¨subwordä¿¡æ¯æ¥å¼¥è¡¥è¿™ä¸€é—®é¢˜ï¼Œç®€å•æ¥è¯´å°±æ˜¯é€šè¿‡è¯ç¼€çš„vectoræ¥è¡¨ç¤ºè¯ã€‚æ¯”å¦‚unofficialæ˜¯ä¸ªä½é¢‘è¯ï¼Œå…¶æ•°æ®é‡ä¸è¶³ä»¥è®­ç»ƒå‡ºé«˜è´¨é‡çš„vectorï¼Œä½†æ˜¯å¯ä»¥é€šè¿‡un+officialè¿™ä¸¤ä¸ªé«˜é¢‘çš„è¯ç¼€å­¦ä¹ åˆ°ä¸é”™çš„vectorã€‚æ–¹æ³•ä¸Šï¼Œæœ¬æ–‡æ²¿ç”¨äº†word2vecçš„skip-gramæ¨¡å‹ï¼Œä¸»è¦åŒºåˆ«ä½“ç°åœ¨ç‰¹å¾ä¸Šã€‚word2vecä½¿ç”¨wordä½œä¸ºæœ€åŸºæœ¬çš„å•ä½ï¼Œå³é€šè¿‡ä¸­å¿ƒè¯é¢„æµ‹å…¶ä¸Šä¸‹æ–‡ä¸­çš„å…¶ä»–è¯æ±‡ã€‚è€Œsubword modelä½¿ç”¨å­—æ¯n-gramä½œä¸ºå•ä½ï¼Œæœ¬æ–‡nå–å€¼ä¸º3~6ã€‚è¿™æ ·æ¯ä¸ªè¯æ±‡å°±å¯ä»¥è¡¨ç¤ºæˆä¸€ä¸²å­—æ¯n-gramï¼Œä¸€ä¸ªè¯çš„embeddingè¡¨ç¤ºä¸ºå…¶æ‰€æœ‰n-gramçš„å’Œã€‚è¿™æ ·æˆ‘ä»¬è®­ç»ƒä¹Ÿä»ç”¨ä¸­å¿ƒè¯çš„embeddingé¢„æµ‹ç›®æ ‡è¯ï¼Œè½¬å˜æˆç”¨ä¸­å¿ƒè¯çš„n-gram embeddingé¢„æµ‹ç›®æ ‡è¯ã€‚</p>
<h4 id="Related-work"><a href="#Related-work" class="headerlink" title="Related work"></a>Related work</h4><h5 id="Morphological-word-representations"><a href="#Morphological-word-representations" class="headerlink" title="Morphological word representations"></a>Morphological word representations</h5><p>é’ˆå¯¹å½¢æ€è¯è¡¨ç¤ºå·²æœ‰çš„å·¥ä½œï¼š</p>
<p>ä¼ ç»Ÿçš„ç”¨å•è¯çš„å½¢æ€ç‰¹å¾æ¥è¡¨ç¤ºå•è¯ï¼š</p>
<ul>
<li><p>[Andrei Alexandrescu and Katrin Kirchhoff. 2006. Factored neural language models. In Proc. NAACL] introduced factored neural language models. å› å¼åˆ†è§£æ¨¡å‹</p>
<ul>
<li><p>words are represented as sets of features.</p>
</li>
<li><p>These features might include morphological information</p>
</li>
</ul>
</li>
</ul>
<ul>
<li>SchÃ¼tze (1993) learned representations of character four-grams through singular value decomposition, and derived representations for words by summing</li>
</ul>
<p>the four-grams representations. è¿™ç¯‡æ–‡æ­£çš„å·¥ä½œè·Ÿæœ¬æ–‡çš„æ–¹æ³•æ˜¯æ¯”è¾ƒæ¥è¿‘çš„ã€‚</p>
<h5 id="Character-level-features-for-NLP-NLPçš„å­—ç¬¦ç‰¹å¾"><a href="#Character-level-features-for-NLP-NLPçš„å­—ç¬¦ç‰¹å¾" class="headerlink" title="Character level features for NLP NLPçš„å­—ç¬¦ç‰¹å¾"></a>Character level features for NLP NLPçš„å­—ç¬¦ç‰¹å¾</h5><p>å­—ç¬¦çº§åˆ«çš„ç ”ç©¶å·¥ä½œæœ€è¿‘å¾ˆå¤šäº†ã€‚ä¸€ç±»æ˜¯åŸºäºRNNçš„ï¼Œå¦ä¸€ç±»æ˜¯åŸºäºCNNçš„ã€‚</p>
<h4 id="General-Model"><a href="#General-Model" class="headerlink" title="General Model"></a>General Model</h4><p>è¿™ä¸€éƒ¨åˆ†æ˜¯å¯¹word2vecä¸­è·³å­—æ¨¡å‹çš„å›é¡¾ã€‚<a href="http://www.panxiaoxie.cn/2018/04/25/cs224d-lecture1-%E8%AF%8D%E5%90%91%E9%87%8F%E8%A1%A8%E7%A4%BA/">Skip-gram predicts the distribution (probability) of context words from a center word.</a></p>
<p>giving a sequence of words $w_1, w_2,â€¦,w_T$</p>
<p>é‚£ä¹ˆskipgram æ¨¡å‹å°±æ˜¯æœ€å¤§åŒ–å¯¹æ•°ä¼¼ç„¶å‡½æ•°ï¼š</p>
<p>$$\sum_{t=1}^T\sum_{c\in C_t}logp(w_c|w_t)$$</p>
<p>we are given a scoring function s which maps pairs of (word, context) to scores in R.</p>
<p>$$p(w_c|w_t)=\dfrac{e^{s(w_t,w_c)}}{\sum_{j=1}^We^{s(w_t,j)}}$$</p>
<p>The problem of predicting context words can instead be framed as a set of independent binary classification tasks. Then the goal is to independently predict the presence (or absence) of context words. For the word at position t we consider all context words as positive examples and sample negatives at</p>
<p>random from the dictionary.</p>
<p>è¿™ç¯‡æ–‡ç« é‡‡ç”¨è´Ÿé‡‡æ ·çš„æ–¹æ³•ã€‚ä¸åŸæœ¬çš„softmaxæˆ–è€…æ˜¯hierarchical softmaxä¸ä¸€æ ·çš„æ˜¯ï¼Œè´Ÿé‡‡æ ·ä¸­é¢„æµ‹ä¸€ä¸ªä¸Šä¸‹æ–‡çš„å•è¯context $w_c$ æ˜¯æŠŠå®ƒçœ‹åšä¸€ä¸ªç‹¬ç«‹çš„äºŒåˆ†ç±»ï¼Œå­˜åœ¨æˆ–è€…æ˜¯ä¸å­˜åœ¨ã€‚</p>
<p>å› æ­¤é€‰æ‹©ä¸€ä¸ªä¸Šä¸‹æ–‡ position c, using binary logistic loss we obtain the following negative log-likelihood::</p>
<p>$$log(1+e^{-s(w_t,w_c)})+\sum_{n\in N_{t,c}}log(1+e^{s(w_t,n)})$$</p>
<p>å…¶å®è·Ÿword2vecä¸­æ˜¯ä¸€æ ·çš„å°±æ˜¯ $-log\sigma(s(w_t,w_c))=-log\dfrac{1}{1+e^{-s(w_t,w_c)}}=log(1+e^{-s(w_t,w_c)})$</p>
<p>é‚£ä¹ˆå¯¹äºæ•´ä¸ªSequenceï¼Œè®¾å®š $l: x\rightarrow log(1+e^{-x})$ é‚£ä¹ˆï¼š</p>
<p>$$\sum_{t=1}^T[\sum_{c\in C_t}l(s(w_t,w_c))+\sum_{n\in N_{t,c}}l(-s(w_t,n))]$$</p>
<p>$N_{t,c}$ is a set of negative examples sampled from the vocabulary. æ€ä¹ˆé€‰è´Ÿé‡‡æ ·å‘¢ï¼Ÿã€€æ¯ä¸ªå•è¯éƒ½è¢«ç»™äºˆä¸€ä¸ªç­‰äºå®ƒé¢‘ç‡çš„æƒé‡ï¼ˆå•è¯å‡ºç°çš„æ•°ç›®ï¼‰çš„3/4æ¬¡æ–¹ã€‚é€‰æ‹©æŸä¸ªå•è¯çš„æ¦‚ç‡å°±æ˜¯å®ƒçš„æƒé‡é™¤ä»¥æ‰€æœ‰å•è¯æƒé‡ä¹‹å’Œã€‚</p>
<p>$$p(w_i)=\dfrac{f(w_i)^{3/4}}{\sum_{j=0}^W(f(w_j)^{3/4})}$$</p>
<p>Then the score can be computed as the scalar product between word and context vectors as:</p>
<p>$$s(w_t,w_c) = u_{w_t}^Tv_{w_v}$$</p>
<h4 id="Subword-model"><a href="#Subword-model" class="headerlink" title="Subword model"></a>Subword model</h4><p>By using a distinct vector representation for each word, the skipgram model ignores the internal structure of words. In this section, we propose a different scoring function s, in order to take into account this information. å•è¯çš„ç¦»æ•£è¯å‘é‡è¡¨ç¤ºæ˜¯å¿½ç•¥äº†å•è¯å†…éƒ¨çš„ç»“æ„ä¿¡æ¯çš„ï¼Œä¹Ÿå°±æ˜¯å…¶å­—æ¯ç»„æˆã€‚</p>
<p>ç»™æ¯ä¸ªå•è¯å·¦å³åŠ ä¸Š &lt; å’Œ &gt;ï¼Œç”¨æ¥åŒºåˆ†å‰ç¼€å’Œåç¼€ã€‚å¯¹äºå•è¯ where æ¥è¯´ï¼Œç”¨ character trigram è¡¨ç¤ºï¼š</p>
<p><img src="/2018/05/23/%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E7%B3%BB%E5%88%971-fasttext/03.png"></p>
<p>ç”¨ $z_g$ è¡¨ç¤ºn-gram g çš„å‘é‡è¡¨ç¤ºã€‚é‚£ä¹ˆ scoring function:</p>
<p>$$s(w,c)=\sum_{g\in G_w}z_g^Tv_c$$</p>
<p>å¦‚æœè¯è¡¨å¾ˆå¤§çš„è¯ï¼Œå…¶å¯¹åº”çš„ n-gram ä¹Ÿä¼šéå¸¸å¤šå§ï¼Œä¸ºäº†é™åˆ¶å ç”¨çš„å†…å­˜ï¼Œwe use a hashing function that maps n-grams to integers in 1 to K. We hash character sequences using the Fowler-Noll-Vo hashing function (specifically the FNV-1a variant).1 We set $K = 2.10^6$ below.</p>
<h3 id="ä»£ç å®ç°"><a href="#ä»£ç å®ç°" class="headerlink" title="ä»£ç å®ç°"></a>ä»£ç å®ç°</h3><h3 id="éœ€è¦æ³¨æ„çš„é—®é¢˜"><a href="#éœ€è¦æ³¨æ„çš„é—®é¢˜" class="headerlink" title="éœ€è¦æ³¨æ„çš„é—®é¢˜"></a>éœ€è¦æ³¨æ„çš„é—®é¢˜</h3><ul>
<li>ä»£ç å®ç°ä¸­å¯¹äºsentenceçš„å‘é‡è¡¨ç¤ºï¼Œæ˜¯unigramçš„å¹³å‡å€¼ï¼Œå¦‚æœè¦è®©æ•ˆæœæ›´å¥½ï¼Œå¯ä»¥æ·»åŠ bigram, trigramç­‰ã€‚</li>
</ul>
<ul>
<li>tf.train.exponential_decay</li>
</ul>
<ul>
<li>tf.nn.nce_loss</li>
</ul>
</div></article></div></div><!--!--><div class="column column-right is-4-tablet is-4-desktop is-4-widescreen  order-3"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar" src="/img/avatar.png" alt="panxiaoxie"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">panxiaoxie</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Beijing, China</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">æ–‡ç« </p><a href="/archives"><p class="title">116</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">åˆ†ç±»</p><a href="/categories"><p class="title">39</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">æ ‡ç­¾</p><a href="/tags"><p class="title">36</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/PanXiebit" target="_blank" rel="noopener">å…³æ³¨æˆ‘</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/PanXiebit"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Email" href="/ftdpanxie@gmail.com"><i class="fa fa-envelope"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="RSS" href="/"><i class="fas fa-rss"></i></a></div></div></div><!--!--><div class="card widget" data-type="links"><div class="card-content"><div class="menu"><h3 class="menu-label">é“¾æ¥</h3><ul class="menu-list"><li><a class="level is-mobile" href="https://github.com/PanXiebit" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">github</span></span><span class="level-right"><span class="level-item tag">github.com</span></span></a></li><li><a class="level is-mobile" href="ftdpanxie@gmail.com" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">email</span></span><span class="level-right"><span class="level-item tag">ftdpanxie@gmail.com</span></span></a></li></ul></div></div></div><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">åˆ†ç±»</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/C/"><span class="level-start"><span class="level-item">C++</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/CSAPP/"><span class="level-start"><span class="level-item">CSAPP</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/DRL/"><span class="level-start"><span class="level-item">DRL</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/GAN/"><span class="level-start"><span class="level-item">GAN</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li><li><a class="level is-mobile" href="/categories/GAN-RL/"><span class="level-start"><span class="level-item">GAN, RL</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/ML/"><span class="level-start"><span class="level-item">ML</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/NLP/"><span class="level-start"><span class="level-item">NLP</span></span><span class="level-end"><span class="level-item tag">14</span></span></a></li><li><a class="level is-mobile" href="/categories/TensorFlow/"><span class="level-start"><span class="level-item">TensorFlow</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/cs224d/"><span class="level-start"><span class="level-item">cs224d</span></span><span class="level-end"><span class="level-item tag">10</span></span></a></li><li><a class="level is-mobile" href="/categories/generation/"><span class="level-start"><span class="level-item">generation</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/interview/"><span class="level-start"><span class="level-item">interview</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/leetcode/"><span class="level-start"><span class="level-item">leetcode</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/machine-translation/"><span class="level-start"><span class="level-item">machine translation</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/python/"><span class="level-start"><span class="level-item">python</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/pytorch/"><span class="level-start"><span class="level-item">pytorch</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/reinforcement-learning/"><span class="level-start"><span class="level-item">reinforcement learning</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/sign-language-recognition/"><span class="level-start"><span class="level-item">sign language recognition</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/transfer-learning/"><span class="level-start"><span class="level-item">transfer learning</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"><span class="level-start"><span class="level-item">æ•°æ®ç»“æ„ä¸ç®—æ³•</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile" href="/categories/%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB/"><span class="level-start"><span class="level-item">æ–‡æœ¬åˆ†ç±»</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"><span class="level-start"><span class="level-item">è®ºæ–‡ç¬”è®°</span></span><span class="level-end"><span class="level-item tag">40</span></span></a><ul><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/DL/"><span class="level-start"><span class="level-item">DL</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/ESA/"><span class="level-start"><span class="level-item">ESA</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/GAN/"><span class="level-start"><span class="level-item">GAN</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/MRC-and-QA/"><span class="level-start"><span class="level-item">MRC and QA</span></span><span class="level-end"><span class="level-item tag">7</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/Machine-Translation/"><span class="level-start"><span class="level-item">Machine Translation</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/NLP/"><span class="level-start"><span class="level-item">NLP</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/Transformer/"><span class="level-start"><span class="level-item">Transformer</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/capsules/"><span class="level-start"><span class="level-item">capsules</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/computer-vision/"><span class="level-start"><span class="level-item">computer vision</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/constrast-learning/"><span class="level-start"><span class="level-item">constrast learning</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/data-augmentation/"><span class="level-start"><span class="level-item">data augmentation</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/dialogue-system/"><span class="level-start"><span class="level-item">dialogue system</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/language-model/"><span class="level-start"><span class="level-item">language model</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/machine-translation/"><span class="level-start"><span class="level-item">machine translation</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/open-set-recognition/"><span class="level-start"><span class="level-item">open set recognition</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/sentence-embedding/"><span class="level-start"><span class="level-item">sentence embedding</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/text-matching/"><span class="level-start"><span class="level-item">text matching</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/vision-language/"><span class="level-start"><span class="level-item">vision-language</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li></ul></div></div></div></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/panxiaoxie.png" alt="æ½˜å°æ¦­" height="28"></a><p class="is-size-7"><span>&copy; 2021 Xie Pan</span>Â Â Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>Â &amp;Â <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("zh-CN");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="å›åˆ°é¡¶ç«¯" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "æ­¤ç½‘ç«™ä½¿ç”¨Cookieæ¥æ”¹å–„æ‚¨çš„ä½“éªŒã€‚",
          dismiss: "çŸ¥é“äº†ï¼",
          allow: "å…è®¸ä½¿ç”¨Cookie",
          deny: "æ‹’ç»",
          link: "äº†è§£æ›´å¤š",
          policy: "Cookieæ”¿ç­–",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.5/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="æƒ³è¦æŸ¥æ‰¾ä»€ä¹ˆ..."></div><a class="searchbox-close" href="javascript:;">Ã—</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"æƒ³è¦æŸ¥æ‰¾ä»€ä¹ˆ...","untitled":"(æ— æ ‡é¢˜)","posts":"æ–‡ç« ","pages":"é¡µé¢","categories":"åˆ†ç±»","tags":"æ ‡ç­¾"});
        });</script></body></html>