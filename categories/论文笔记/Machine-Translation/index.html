<!doctype html>
<html lang="zh"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>分类: machine translation - 潘小榭</title><link rel="manifest" href="/manifest.json"><meta name="theme-color" content="black"><meta name="application-name" content="panxiaoxie"><meta name="msapplication-TileImage" content="/img/avatar.png"><meta name="msapplication-TileColor" content="black"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="panxiaoxie"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta property="og:type" content="blog"><meta property="og:title" content="panxiaoxie"><meta property="og:url" content="https://github.com/PanXiebit"><meta property="og:site_name" content="panxiaoxie"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://www.qt86.com/cache/1625298592_187938.png"><meta property="article:author" content="panxiaoxie"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="https://www.qt86.com/cache/1625298592_187938.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"http://www.panxiaoxie.cn"},"headline":"潘小榭","image":["http://www.panxiaoxie.cn/img/og_image.png"],"author":{"@type":"Person","name":"Xie Pan"},"publisher":{"@type":"Organization","name":"潘小榭","logo":{"@type":"ImageObject","url":"http://www.panxiaoxie.cn/img/panxiaoxie.png"}},"description":null}</script><link rel="icon" href="/img/avatar.png"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/css/justifiedGallery.min.css"><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script><!--!--><!--!--><meta name="generator" content="Hexo 5.4.0"></head><body class="is-2-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/panxiaoxie.png" alt="潘小榭" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">主页</a><a class="navbar-item" href="/archives">归档</a><a class="navbar-item" href="/categories">分类</a><a class="navbar-item" href="/tags">标签</a><a class="navbar-item" href="/about">关于我</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/PanXiebit"><i class="fab fa-github"></i></a><a class="navbar-item search" title="搜索" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-10-widescreen"><div class="card"><div class="card-content"><nav class="breadcrumb" aria-label="breadcrumbs"><ul><li><a href="/categories">分类</a></li><li><a href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/">论文笔记</a></li><li class="is-active"><a href="#" aria-current="page">machine translation</a></li></ul></nav></div></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2019-04-07T09:04:49.000Z" title="2019/4/7 下午5:04:49">2019-04-07</time>发表</span><span class="level-item"><time dateTime="2021-06-29T08:12:08.200Z" title="2021/6/29 下午4:12:08">2021-06-29</time>更新</span><span class="level-item"><a class="link-muted" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/">论文笔记</a><span> / </span><a class="link-muted" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/machine-translation/">machine translation</a></span><span class="level-item">13 分钟读完 (大约1963个字)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2019/04/07/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-%E6%97%A0%E7%9B%91%E7%9D%A3%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91-Extract-and-Eit/">论文笔记-无监督机器翻译</a></h1><div class="content"><h2 id="Extract-and-Edit-An-Alternative-to-Back-Translation-for-Unsupervised-Neural-Machine-Translation"><a href="#Extract-and-Edit-An-Alternative-to-Back-Translation-for-Unsupervised-Neural-Machine-Translation" class="headerlink" title="Extract and Edit: An Alternative to Back-Translation for Unsupervised Neural Machine Translation"></a><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1904.02331">Extract and Edit: An Alternative to Back-Translation for Unsupervised Neural Machine Translation</a></h2><p>王威廉老师组的一篇文章，大致看了下跟最近自己做的研究相关性挺大的。文中也简单的介绍了无监督机器翻译的一些方法，所以借这个机会把无监督机器翻译也好好了解下。记得在三星研究院实习时，有个中科院自动化所的师姐（据说是宗成庆老师的学生）说过一句话，2018年是无监督机器翻译元年。但当时我在搞QA，就没怎么深入研究。感觉很多NLP其他方向的做法都是源于 NMT，所以还是很有必要看一下的。</p>
<h2 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h2><p>Back-translation 得到的伪平行语料，是基于 pure target sentence 得到 pesudo source sentence，然后把 prue target sentence 作为 label 进行监督学习(保证target 端是pure sentence，source端的sentence可以稍微 noisy)。这实质上就是一个 reconstruction loss.  其缺点在于 pesudo source sentence 质量无法保证，会导致误差累积（pesudo source sentence 并没有得到更新，所以并没有纠正存在的错误）。</p>
<p>基于此，作者提出了一种新的范式，extract-edit.</p>
<h2 id="related-work"><a href="#related-work" class="headerlink" title="related work"></a>related work</h2><h3 id="单语语料的选择"><a href="#单语语料的选择" class="headerlink" title="单语语料的选择"></a>单语语料的选择</h3><p>neural-based methods aim to select potential parallel sentences from monolingual corpora in the same domain. However, these neural models need to be trained on a large parallel dataset first, which is not applicable to language pairs with limited supervision.   </p>
<p>通过平行语料训练翻译模型，进而从单语中选择 domain related sentences. 这并不是完全的无监督，还是需要有限的平行语料得到 NMT 模型之后，去选择合适的单语。</p>
<ul>
<li><p>Parallel sentence extraction from comparable corpora with neural network features, LERC 2016  </p>
</li>
<li><p>Bilingual word embeddings with bucketed cnn for parallel sentence extraction, ACL 2017  </p>
</li>
<li><p>Extracting parallel sentences with bidirectional recurrent neural networks to improve machine translation, COLING 2018</p>
</li>
</ul>
<h3 id="完全的无监督机器翻译"><a href="#完全的无监督机器翻译" class="headerlink" title="完全的无监督机器翻译"></a>完全的无监督机器翻译</h3><p>The main technical protocol of these approaches can be summarized as three steps:   </p>
<ul>
<li><p>Initialization  </p>
</li>
<li><p>Language Modeling  </p>
</li>
<li><p>Back-Translation</p>
</li>
</ul>
<h4 id="Initialization"><a href="#Initialization" class="headerlink" title="Initialization"></a>Initialization</h4><p>Given the ill-posed nature of the unsupervised NMT task, a suitable initialization method can help model the natural priors over the mapping of two language spaces we expect to reach.  </p>
<p>初始化的目的基于自然语言的一些先验知识来对两种语言的映射关系进行建模。</p>
<p>there two main initiazation methods:  </p>
<ul>
<li><p>bilingual dictionary inference 基于双语词典的推理  </p>
<ul>
<li><p>Word translation without parallel data.  Conneau, et al. ICLR 2018  </p>
</li>
<li><p>Unsupervised neural machine translation, ICLR 2018  </p>
</li>
<li><p>Unsupervised machine translation using monolingual corpora only, ICLR 2018a  </p>
</li>
</ul>
</li>
<li><p>BPE    </p>
<ul>
<li>Phrase-based &amp; neural unsupervised machine translation. emnlp Lample et al. 2018b  </li>
</ul>
</li>
</ul>
<p>本文作者采用的是 <strong>Conneau, et al. 中的方式，并且类似于 Lample 2018b 中的方式两种语言共享 bpe</strong>(需要在看下相关论文). 这里实际上就是训练得到两种语言的 word embedding，并不是 word2vec 那种对单种语言的无监督，而是训练得到两种语言的 share embedding.</p>
<h4 id="language-modeling"><a href="#language-modeling" class="headerlink" title="language modeling"></a>language modeling</h4><p>Train language models on both source and target languages. These models express a data-driven prior about the composition of sentences in each language.   </p>
<p>在初始化之后，在 share embedding 的基础上分别对 source 和 target 的语言进行建模。</p>
<p>In NMT, language modeling is accomplished via denosing autoencoding, by minimizing:</p>
<p><img src="/2019/04/07/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-%E6%97%A0%E7%9B%91%E7%9D%A3%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91-Extract-and-Eit/01.png"></p>
<p>本文作者采用的 Lample 2018a 的方式。共享 encoder 和 decoder 的参数？？？</p>
<h4 id="Back-Translation"><a href="#Back-Translation" class="headerlink" title="Back-Translation"></a>Back-Translation</h4><ul>
<li><p>Dual learning for machine translation,  NIPS 2016</p>
</li>
<li><p>Improving neural machine translation models with monolingual data. ACL 2016</p>
</li>
</ul>
<h4 id="Extract-Edit"><a href="#Extract-Edit" class="headerlink" title="Extract-Edit"></a>Extract-Edit</h4><ul>
<li><p>Extract: 先根据前两步得到的 sentence 表示，从 target language space 中选择与 source sentence 最接近的 sentence（依据相似度？）.  </p>
</li>
<li><p>Edit: 然后对选择的 sentence 进行 edit.</p>
</li>
</ul>
<p>作者还提出了一个 comparative translation loss。</p>
<p><img src="/2019/04/07/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-%E6%97%A0%E7%9B%91%E7%9D%A3%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91-Extract-and-Eit/02.png"></p>
<h5 id="Extract"><a href="#Extract" class="headerlink" title="Extract"></a>Extract</h5><p>因为在 language model 阶段作者已经共享了 encoder 和 decoder，所以在这个场景下对于 two language 的表示，都可以用 encoder 得到。</p>
<p>在 target language  space 中选择出与 source sentence 最接近的 top-k extracted sentences. 为什么是 top-k 而不是 top-1 呢，确保召回率，并获得更多更相关的 samples.</p>
<p><img src="/2019/04/07/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-%E6%97%A0%E7%9B%91%E7%9D%A3%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91-Extract-and-Eit/03.png"></p>
<h5 id="Edit"><a href="#Edit" class="headerlink" title="Edit"></a>Edit</h5><p>简单点就是 max-pooling + decode</p>
<p><img src="/2019/04/07/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-%E6%97%A0%E7%9B%91%E7%9D%A3%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91-Extract-and-Eit/04.png"></p>
<p>employ a maxpooling layer to reserve the more significant features between the source sentence embedding $e_s$ and the extracted sentence embedding $e_t$ ($t\in M$), and then decode it into a new sentence $t’$.</p>
<p>具体是怎么操作的呢，这似乎需要看代码。</p>
<p>$e_s$: [es_length, encoder_size]  </p>
<p>$e_t$: [et_length, encoder_size]</p>
<p>这怎么 max-pooling 呢（句子长度都可能不一样），然后 decode 得到新的 sentence 吧。。</p>
<h5 id="Evaluate"><a href="#Evaluate" class="headerlink" title="Evaluate"></a>Evaluate</h5><p>虽然 M’ 中可能存在潜在的 parallel sentence 对应 source sentence s. 但是依然不能用  (s, t’) 作为 ground-truth stence pairs 来训练 NMT 模型。因为 NMT 模型对噪声非常敏感。</p>
<p>作者提出了一个 evaluation network R, 实际上就是多层感知机，也许是个两层神经网络吧，具体没说。two labguage 共享 R.</p>
<p>$$r_s=f(W_2f(W_1e_s+b_1)+b_2)$$</p>
<p>$$r_t=f(W_2f(W_1e_t’+b_1)+b_2)$$</p>
<p>假设是这样，也就是将 t’ 转换成 t* 了。</p>
<p><strong>理解错了</strong></p>
<p>其目的是将 s 和 t’ 映射到同一向量空间，然后计算两者的相似度：</p>
<p><img src="/2019/04/07/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-%E6%97%A0%E7%9B%91%E7%9D%A3%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91-Extract-and-Eit/05.png"></p>
<p>接下来将 $\alpha$ 转换成概率分布。 也就是计算 top-k 个 extracted-edited 得到的 target sentences t* 与  source sentence s 相似的概率，并且这些概率相加为 1.</p>
<p><img src="/2019/04/07/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-%E6%97%A0%E7%9B%91%E7%9D%A3%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91-Extract-and-Eit/06.png"></p>
<p>其中 $\lambda$ 可以看作是 inverse temperature， $\lambda$ 越小，表示所有 t* 平等看待，越大，表示更看重 $\alpha$ 最大的那一句。显然前面的 $\alpha$ 是通过 cosine 计算的，也就是更看重 k 个 t* 中与 s 距离最近的那个 sentence.</p>
<h5 id="learning"><a href="#learning" class="headerlink" title="learning"></a>learning</h5><p><strong>Comparative Translation</strong></p>
<p><img src="/2019/04/07/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-%E6%97%A0%E7%9B%91%E7%9D%A3%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91-Extract-and-Eit/08.png"></p>
<p>cosine 相似度越大越接近，所以 -logP 越小越好。这里面涉及到的参数 $\theta_{enc}, \theta_R$</p>
<blockquote>
<p>Basically, the translation model is trying to minimize the relative distance of the translated sentence t* to the source sentence s compared to the top-k extracted-and-edited sentences in the target language space. Intuitively, we view the top-k extracted-and-edited sentences as the <strong>anchor points</strong> to locate a probable region in the target language space, and iteratively improve the <strong>source-to-target mapping</strong> via the comparative learning scheme.</p>
</blockquote>
<p><img src="/2019/04/07/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-%E6%97%A0%E7%9B%91%E7%9D%A3%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91-Extract-and-Eit/09.png"></p>
<p><strong>Adversarial Objective</strong></p>
<blockquote>
<p>we can view our translation system as a “generator” that learns to generate a good translation with a higher similarity score than the extracted-and-edited sentences, and the evaluation network R as a “discriminator” that learns to rank the extracted- and-edited sentences (real sentences in the target language space) higher than the translated sentences.  </p>
</blockquote>
<p>借助于对抗学习的思想，可以把 translation system 看作是 生成器 generator， 用来学习得到 translated target sentence，使得其优于 extracted-and-edited sentences.</p>
<p><img src="/2019/04/07/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-%E6%97%A0%E7%9B%91%E7%9D%A3%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91-Extract-and-Eit/11.png"></p>
<p>把 evalution newtork R 看作是判别器，其目的就是判别 extracted-and-edited sentences 优于 translated target sentences.</p>
<p><img src="/2019/04/07/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-%E6%97%A0%E7%9B%91%E7%9D%A3%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91-Extract-and-Eit/12.png"></p>
<p>因此对于 evaluation network R，有</p>
<p><img src="/2019/04/07/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-%E6%97%A0%E7%9B%91%E7%9D%A3%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91-Extract-and-Eit/13.png"></p>
<p><strong>final adversarial objective</strong></p>
<p><img src="/2019/04/07/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-%E6%97%A0%E7%9B%91%E7%9D%A3%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91-Extract-and-Eit/14.png"></p>
<h5 id="Model-selection"><a href="#Model-selection" class="headerlink" title="Model selection"></a>Model selection</h5><p>无监督学习因为没有平行语料，所以需要一个指标来表示模型的好坏，也就是翻译质量。</p>
<p><img src="/2019/04/07/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-%E6%97%A0%E7%9B%91%E7%9D%A3%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91-Extract-and-Eit/15.png"></p>
<blockquote>
<p>Basically, we choose the hyper-parameters with the maximum expectation of the ranking scores of all translated sentences.</p>
</blockquote>
<p><img src="/2019/04/07/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-%E6%97%A0%E7%9B%91%E7%9D%A3%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91-Extract-and-Eit/16.png"></p>
<h3 id="Implementation-details"><a href="#Implementation-details" class="headerlink" title="Implementation details"></a>Implementation details</h3><h4 id="Initialization-1"><a href="#Initialization-1" class="headerlink" title="Initialization"></a>Initialization</h4><p>cross-lingual BPE embedding, set BPE number 60000.</p>
<p>然后用 Fasttext 训练得到 embedding， 512 dimension. 其中 Fasettext 设置 window size 5 and 10 negative samples</p>
<h4 id="Model-structure"><a href="#Model-structure" class="headerlink" title="Model structure"></a>Model structure</h4><p>all encoder parameters are shared across two languages. Similarly, we share all decoder parameters across two languages.</p>
<p>The λ for calculating ranking scores is 0.5. As for the evaluation network R, we use a multilayer perceptron with two hidden layers of size 512.</p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2019-03-19T01:25:22.000Z" title="2019/3/19 上午9:25:22">2019-03-19</time>发表</span><span class="level-item"><time dateTime="2021-06-29T08:12:08.200Z" title="2021/6/29 下午4:12:08">2021-06-29</time>更新</span><span class="level-item"><a class="link-muted" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/">论文笔记</a><span> / </span><a class="link-muted" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/machine-translation/">machine translation</a></span><span class="level-item">6 分钟读完 (大约881个字)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2019/03/19/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-Using-monoligual-data-in-machine-transaltion/">论文笔记-Using monoligual data in machine transaltion</a></h1><div class="content"><h2 id="Monolingual-Data-in-NMT"><a href="#Monolingual-Data-in-NMT" class="headerlink" title="Monolingual Data in NMT"></a>Monolingual Data in NMT</h2><p><img src="/2019/03/19/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-Using-monoligual-data-in-machine-transaltion/01.png"></p>
<h2 id="Why-Monolingual-data-enhancement"><a href="#Why-Monolingual-data-enhancement" class="headerlink" title="Why Monolingual data enhancement"></a>Why Monolingual data enhancement</h2><ul>
<li>Large scale source-side data:  </li>
</ul>
<p>enhancing encoder network to obtain high quality context vector</p>
<p>representation of source sentence.</p>
<ul>
<li>Large scale target-side data:  </li>
</ul>
<p>boosting fluency for machine translation when decoding.</p>
<h2 id="The-methods-of-using-monolingual-data"><a href="#The-methods-of-using-monolingual-data" class="headerlink" title="The methods of using monolingual data"></a>The methods of using monolingual data</h2><p><img src="/2019/03/19/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-Using-monoligual-data-in-machine-transaltion/02.png"></p>
<h3 id="Multi-task-learning"><a href="#Multi-task-learning" class="headerlink" title="Multi-task learning"></a>Multi-task learning</h3><p>Target-side language model:  Integrating Language Model into the Decoder</p>
<p><strong>shallow fusion</strong></p>
<p><img src="/2019/03/19/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-Using-monoligual-data-in-machine-transaltion/05.png"></p>
<p><img src="/2019/03/19/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-Using-monoligual-data-in-machine-transaltion/06.png"></p>
<p>both an NMT model (on parallel corpora) as well as a recurrent neural network language model (RNNLM, on larger monolingual corpora) have been pre-trained separately before being integrated.</p>
<p>Shallow fusion: rescore the probability of the candidate words.</p>
<p><strong>deep fusion</strong></p>
<p><img src="/2019/03/19/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-Using-monoligual-data-in-machine-transaltion/03.png"></p>
<p><img src="/2019/03/19/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-Using-monoligual-data-in-machine-transaltion/04.png"></p>
<p><strong>multi-task learning</strong></p>
<p><img src="/2019/03/19/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-Using-monoligual-data-in-machine-transaltion/07.png"></p>
<p><img src="/2019/03/19/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-Using-monoligual-data-in-machine-transaltion/08.png"></p>
<p>Using Target-side Monolingual Data for Neural Machine Translation through Multi-task Learning, EMNLP, 2017</p>
<p>利用 target-side 的单语多了一个训练语言模型的任务。事实上（b）就是上一张 PPT 中的方法，这篇paper在这个基础上增加了语言模型的 loss。</p>
<p>$\sigma$ 参数在两个任务训练时都会更新。而 $\theta$ 参数仅仅在训练翻译模型时才会更新参数。</p>
<h3 id="auto-encoder"><a href="#auto-encoder" class="headerlink" title="auto-encoder"></a>auto-encoder</h3><p><img src="/2019/03/19/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-Using-monoligual-data-in-machine-transaltion/10.png"></p>
<p><img src="/2019/03/19/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-Using-monoligual-data-in-machine-transaltion/11.png"></p>
<p>通过 自编码 的形式，重构对应的 mono-data，作为辅助任务，与 NMT 模型共享 encoder 参数。</p>
<p>Semi-Supervised Learning for Neural Machine Translation, ACL, 2016</p>
<h3 id="Back-translation"><a href="#Back-translation" class="headerlink" title="Back-translation"></a>Back-translation</h3><h4 id="What-is-back-translation"><a href="#What-is-back-translation" class="headerlink" title="What is back-translation?"></a>What is back-translation?</h4><p>Synthetic pseudo parallel data from target-side monolingual data using a reverse translation model.</p>
<h4 id="why-back-translation-and-motivation"><a href="#why-back-translation-and-motivation" class="headerlink" title="why back-translation and motivation?"></a>why back-translation and motivation?</h4><p>It mitigates the problem of overfitting and fluency by exploiting additional data in the target language.</p>
<p>目标语言必须始终是真实句子才能让翻译模型翻译的结果更流畅、更准确，而源语言即便有少量用词不当、语序不对、语法错误，只要不影响理解就无所谓。其实人做翻译的时候也是一样的：翻译质量取决于一个人译出语言的水平，而不是源语言的水平（源语言的水平只要足够看懂句子即可）</p>
<p>Different aspects of the BT which influence the performance of translation:  </p>
<ul>
<li><p>Size of the Synthetic Data  </p>
</li>
<li><p>Direction of Back-Translation  </p>
</li>
<li><p>Quality of the Synthetic Data  </p>
</li>
</ul>
<h4 id="Size-of-the-Synthetic-Data"><a href="#Size-of-the-Synthetic-Data" class="headerlink" title="Size of the Synthetic Data"></a>Size of the Synthetic Data</h4><p><img src="/2019/03/19/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-Using-monoligual-data-in-machine-transaltion/12.png"></p>
<h4 id="Direction-of-Back-Translation"><a href="#Direction-of-Back-Translation" class="headerlink" title="Direction of Back-Translation"></a>Direction of Back-Translation</h4><p><img src="/2019/03/19/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-Using-monoligual-data-in-machine-transaltion/13.png"></p>
<h4 id="Quality-of-the-Synthetic-Data"><a href="#Quality-of-the-Synthetic-Data" class="headerlink" title="Quality of the Synthetic Data"></a>Quality of the Synthetic Data</h4><p><img src="/2019/03/19/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-Using-monoligual-data-in-machine-transaltion/14.png"></p>
<h3 id="copy-mechanism"><a href="#copy-mechanism" class="headerlink" title="copy mechanism"></a>copy mechanism</h3><p><img src="/2019/03/19/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-Using-monoligual-data-in-machine-transaltion/15.png"></p>
<p>作者的实验设置：用 target-side mono-data 来构建伪平行语料，一部分是直接 copy，另一部分是通过 back-translate 得到的。也就是 mono-data 出现了两次。</p>
<p>总觉得哪里不对。。。</p>
<h3 id="Dummy-source-sentence"><a href="#Dummy-source-sentence" class="headerlink" title="Dummy source sentence"></a>Dummy source sentence</h3><p>Pseudo parallel data:</p>
<p><null> +  target-side mono-data</null></p>
<p>The downside:</p>
<p>the network  ‘unlearns’  its conditioning on the source context if the ratio of monolingual training instances is too high.</p>
<p>Improving Neural Machine Translation Models with Monolingual Data, Sennrich et al, ACL 2016</p>
<h3 id="Self-learning"><a href="#Self-learning" class="headerlink" title="Self-learning"></a>Self-learning</h3><p>Synthetic target sentences from source-side mono-data:</p>
<ul>
<li><p>Build a baseline machine translation (MT) system on parallel data  </p>
</li>
<li><p>Translate source-side mono-data into target sentences  </p>
</li>
<li><p>Real parallel data + pseudo parallel data</p>
</li>
</ul>
<h2 id="reference"><a href="#reference" class="headerlink" title="reference"></a>reference</h2><ol>
<li><p>Improving Neural Machine Translation Models with Monolingual Data, Sennrich et al, ACL 2016  </p>
</li>
<li><p>Using Monolingual Data in Neural Machine Translation: a Systematic Study, Burlot et al. ACL 2018  </p>
</li>
<li><p>Copied Monolingual Data Improves Low-Resource Neural Machine Translation, Currey et al. 2017 In Proceedings of the Second Conference on Machine Translation  </p>
</li>
<li><p>Semi-Supervised Learning for Neural Machine Translation, Cheng et al. ACL 2016  </p>
</li>
<li><p>Exploiting Source-side Monolingual Data in Neural Machine Translation, Zhang et al. EMNLP 2016  </p>
</li>
<li><p>Using Target-side Monolingual Data for Neural Machine Translation through Multi-task Learning, Domhan et al. EMNLP 2018</p>
</li>
</ol>
<p>On Using Monolingual Corpora in Neural Machine Translation, Gulcehre, 2015  </p>
<ol start="7">
<li><p>Back-Translation Sampling by Targeting Difficult Words in Neural Machine Translation, EMNLP 2018  </p>
</li>
<li><p>Understanding Back-Translation at Scale, Edunov et al. EMNLP 2018  </p>
</li>
</ol>
</div></article></div></div><!--!--><div class="column column-right is-4-tablet is-4-desktop is-4-widescreen  order-3"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar" src="/img/avatar.png" alt="panxiaoxie"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">panxiaoxie</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Beijing, China</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">文章</p><a href="/archives"><p class="title">120</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">分类</p><a href="/categories"><p class="title">40</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">标签</p><a href="/tags"><p class="title">38</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/PanXiebit" target="_blank" rel="noopener">关注我</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/PanXiebit"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Email" href="/ftdpanxie@gmail.com"><i class="fa fa-envelope"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="RSS" href="/"><i class="fas fa-rss"></i></a></div></div></div><!--!--><div class="card widget" data-type="links"><div class="card-content"><div class="menu"><h3 class="menu-label">链接</h3><ul class="menu-list"><li><a class="level is-mobile" href="https://github.com/PanXiebit" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">github</span></span><span class="level-right"><span class="level-item tag">github.com</span></span></a></li><li><a class="level is-mobile" href="ftdpanxie@gmail.com" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">email</span></span><span class="level-right"><span class="level-item tag">ftdpanxie@gmail.com</span></span></a></li></ul></div></div></div><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">分类</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/C/"><span class="level-start"><span class="level-item">C++</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/CSAPP/"><span class="level-start"><span class="level-item">CSAPP</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/DRL/"><span class="level-start"><span class="level-item">DRL</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/GAN/"><span class="level-start"><span class="level-item">GAN</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li><li><a class="level is-mobile" href="/categories/GAN-RL/"><span class="level-start"><span class="level-item">GAN, RL</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/ML/"><span class="level-start"><span class="level-item">ML</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/NLP/"><span class="level-start"><span class="level-item">NLP</span></span><span class="level-end"><span class="level-item tag">14</span></span></a></li><li><a class="level is-mobile" href="/categories/TensorFlow/"><span class="level-start"><span class="level-item">TensorFlow</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/cs224d/"><span class="level-start"><span class="level-item">cs224d</span></span><span class="level-end"><span class="level-item tag">10</span></span></a></li><li><a class="level is-mobile" href="/categories/generation/"><span class="level-start"><span class="level-item">generation</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/generative-models/"><span class="level-start"><span class="level-item">generative models</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/interview/"><span class="level-start"><span class="level-item">interview</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/machine-translation/"><span class="level-start"><span class="level-item">machine translation</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/python/"><span class="level-start"><span class="level-item">python</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/pytorch/"><span class="level-start"><span class="level-item">pytorch</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/reinforcement-learning/"><span class="level-start"><span class="level-item">reinforcement learning</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/sign-language-recognition/"><span class="level-start"><span class="level-item">sign language recognition</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/transfer-learning/"><span class="level-start"><span class="level-item">transfer learning</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/transformer/"><span class="level-start"><span class="level-item">transformer</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"><span class="level-start"><span class="level-item">数据结构与算法</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile" href="/categories/%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB/"><span class="level-start"><span class="level-item">文本分类</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"><span class="level-start"><span class="level-item">论文笔记</span></span><span class="level-end"><span class="level-item tag">40</span></span></a><ul><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/DL/"><span class="level-start"><span class="level-item">DL</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/ESA/"><span class="level-start"><span class="level-item">ESA</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/GAN/"><span class="level-start"><span class="level-item">GAN</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/MRC-and-QA/"><span class="level-start"><span class="level-item">MRC and QA</span></span><span class="level-end"><span class="level-item tag">7</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/Machine-Translation/"><span class="level-start"><span class="level-item">Machine Translation</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/NLP/"><span class="level-start"><span class="level-item">NLP</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/Transformer/"><span class="level-start"><span class="level-item">Transformer</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/capsules/"><span class="level-start"><span class="level-item">capsules</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/computer-vision/"><span class="level-start"><span class="level-item">computer vision</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/constrast-learning/"><span class="level-start"><span class="level-item">constrast learning</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/data-augmentation/"><span class="level-start"><span class="level-item">data augmentation</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/dialogue-system/"><span class="level-start"><span class="level-item">dialogue system</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/language-model/"><span class="level-start"><span class="level-item">language model</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/machine-translation/"><span class="level-start"><span class="level-item">machine translation</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/open-set-recognition/"><span class="level-start"><span class="level-item">open set recognition</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/sentence-embedding/"><span class="level-start"><span class="level-item">sentence embedding</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/text-matching/"><span class="level-start"><span class="level-item">text matching</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/vision-language/"><span class="level-start"><span class="level-item">vision-language</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li></ul></div></div></div></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/panxiaoxie.png" alt="潘小榭" height="28"></a><p class="is-size-7"><span>&copy; 2022 Xie Pan</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("zh-CN");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="回到顶端" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "此网站使用Cookie来改善您的体验。",
          dismiss: "知道了！",
          allow: "允许使用Cookie",
          deny: "拒绝",
          link: "了解更多",
          policy: "Cookie政策",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.5/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="想要查找什么..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"想要查找什么...","untitled":"(无标题)","posts":"文章","pages":"页面","categories":"分类","tags":"标签"});
        });</script></body></html>string"></span></span><br><span class="line"><span class="string">        by the same name.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        A &#x27;Tensor&#x27; with one more rank than inputs&#x27;s, with the dimensionality should be &#x27;num_units&#x27;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    N, T = inputs.get_shape().as_list()  <span class="comment"># N means batch_size, T means the sentence length.</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> tf.variable_scope(scope, reuse=reuse):</span><br><span class="line"></span><br><span class="line">        position_ind = tf.tile(tf.expand_dims(tf.<span class="built_in">range</span>(T), <span class="number">0</span>), [N, <span class="number">1</span>])  <span class="comment"># [N, T]</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># First part of the PE function: sin and cos argument</span></span><br><span class="line"></span><br><span class="line">        position_enc = np.array([</span><br><span class="line"></span><br><span class="line">            [pos / np.power(<span class="number">10000</span>, <span class="number">2.</span>*i/num_units) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(num_units)]</span><br><span class="line"></span><br><span class="line">            <span class="keyword">for</span> pos <span class="keyword">in</span> <span class="built_in">range</span>(T)])                                       <span class="comment"># [T, num_units]</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="comment"># Second part, apply the cosine to even columns and sin to odds.</span></span><br><span class="line"></span><br><span class="line">        position_enc[:, <span class="number">0</span>::<span class="number">2</span>] = np.sin(position_enc[:, <span class="number">0</span>::<span class="number">2</span>])  <span class="comment"># dim 2i</span></span><br><span class="line"></span><br><span class="line">        position_enc[:, <span class="number">1</span>::<span class="number">2</span>] = np.cos(position_enc[:, <span class="number">1</span>::<span class="number">2</span>])  <span class="comment"># dim 2i+1</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="comment"># Convert to a tensor</span></span><br><span class="line"></span><br><span class="line">        lookup_table = tf.convert_to_tensor(position_enc, dtype=tf.float32)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> zero_pad:</span><br><span class="line"></span><br><span class="line">            lookup_table = tf.concat((tf.zeros(shape=[<span class="number">1</span>, num_units]),</span><br><span class="line"></span><br><span class="line">                                      lookup_table[<span class="number">1</span>:, :]), axis=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">        outputs = tf.nn.embedding_lookup(lookup_table, position_ind)  <span class="comment"># [N, T, num_units]</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> scale:</span><br><span class="line"></span><br><span class="line">            outputs = outputs * num_units**<span class="number">0.5</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> outputs</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<p>关于 position encoding 的解释，可以参考这篇blog</p>
<p><a target="_blank" rel="noopener" href="https://mchromiak.github.io/articles/2017/Sep/12/Transformer-Attention-is-all-you-need/#sf-Transformer-Attention-is-all-you-need-3">The Transformer – Attention is all you need.</a></p>
<p>In RNN (LSTM), the notion of time step is encoded in the sequence as inputs/outputs flow one at a time. In FNN, the positional encoding must be preserved to represent the time in some way to preserve the positional encoding. <strong>In case of the Transformer authors propose to encode time as sine wave, as an added extra input. Such signal is added to inputs and outputs to represent time passing.</strong></p>
<p>In general, adding positional encodings to the input embeddings is a quite interesting topic. One way is to embed the absolute position of input elements (as in ConvS2S). However, authors use “sine and cosine functions of different frequencies”. The “sinusoidal” version is quite complicated, while giving similar performance to the absolute position version. <strong>The crux is however, that it may allow the model to produce better translation on longer sentences at test time (at least longer than the sentences in the training data). This way sinusoidal method allows the model to extrapolate to longer sequence lengths.</strong></p>
<p>说真的，还是不太理解。。。</p>
<p><a target="_blank" rel="noopener" href="https://stackoverflow.com/questions/46452020/sinusoidal-embedding-attention-is-all-you-need">可视化 encoding 矩阵</a>:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">num_units = <span class="number">100</span></span><br><span class="line"></span><br><span class="line">sentence_len = <span class="number">10</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">i = np.tile(np.expand_dims(<span class="built_in">range</span>(num_units), <span class="number">0</span>), [sentence_len, <span class="number">1</span>]) <span class="comment"># (100,)-&gt; (1, 100) -&gt;(10, 100)</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">pos = np.tile(np.expand_dims(<span class="built_in">range</span>(sentence_len), <span class="number">1</span>), [<span class="number">1</span>, num_units]) <span class="comment">#(10,)-&gt; (10, 1) -&gt; (10, 100)</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">pos = np.multiply(pos, <span class="number">1</span>/<span class="number">10000.0</span>)</span><br><span class="line"></span><br><span class="line">i = np.multiply(i, <span class="number">2.0</span>/num_units)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">matrix = np.power(pos, i)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">matrix[:, <span class="number">1</span>::<span class="number">2</span>] = np.sin(matrix[:, <span class="number">1</span>::<span class="number">2</span>])</span><br><span class="line"></span><br><span class="line">matrix[:, ::<span class="number">2</span>] = np.cos(matrix[:, ::<span class="number">2</span>])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">im = plt.imshow(matrix, aspect=<span class="string">&#x27;auto&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<p><img src="/2018/06/02/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-Attention-Is-All-You-Need/09.png"></p>
<h4 id="Stage2"><a href="#Stage2" class="headerlink" title="Stage2"></a>Stage2</h4><h5 id="scaled-dot-product-attention"><a href="#scaled-dot-product-attention" class="headerlink" title="scaled dot-product attention"></a>scaled dot-product attention</h5><p>$$Attention(Q,K,V)=softmax\dfrac{QK^T}{\sqrt d_k}V$$</p>
<h5 id="Multi-head-attention"><a href="#Multi-head-attention" class="headerlink" title="Multi-head attention"></a>Multi-head attention</h5><p>Transformer reduces the number of operations required to relate (especially distant) positions in input and output sequence to a O(1). However, this comes at cost of reduced effective resolution because of averaging attention-weighted positions.</p>
<p><img src="/2018/06/02/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-Attention-Is-All-You-Need/11.png"></p>
<ul>
<li>h = 8 attention layers (aka “heads”): that represent linear projection (for the purpose of dimension reduction) of key K and query Q into $d_k$-dimension and value V into $d_v$-dimension:</li>
</ul>
<p>$$head_i = Attention(Q W^Q_i, K W^K_i, V W^V_i) , i=1,\dots,h$$</p>
<p>其中：</p>
<p>$$W^Q_i, W^K_i\in\mathbb{R}^{d_{model}\times d_k}, W^V_i\in\mathbb{R}^{d_{model}\times d_v}, for\ d_k=d_v=d_{model}/h = 64$$</p>
<ul>
<li>scaled-dot attention applied in parallel on each layer (different linear projections of k,q,v) results in $d_v$-dimensional output.</li>
</ul>
<ul>
<li>concatenate outputs of each layer (different linear projection; also referred as ”head”): Concat$(head_1,…,head_h)$</li>
</ul>
<ul>
<li>linearly project the concatenation result form the previous step:</li>
</ul>
<p>$$MultiHeadAttention(Q,K,V) = Concat(head_1,\dots,head_h) W^O$$</p>
<p>where $W^0\in\mathbb{R}^{d_{hd_v}\times d_{model}}$</p>
<h5 id="关于-attention-在模型中的应用，有三种情况"><a href="#关于-attention-在模型中的应用，有三种情况" class="headerlink" title="关于 attention 在模型中的应用，有三种情况"></a>关于 attention 在模型中的应用，有三种情况</h5><ul>
<li>1.In “encoder-decoder attention” layers, the queries come from the previous decoder layer, and the memory keys and values come from the output of the encoder。</li>
</ul>
<ul>
<li>2.The encoder contains self-attention layers. In a self-attention layer all of the keys, values and queries come from the same place, in this case, the output of the previous layer in the encoder. Each position in the encoder can attend to all positions in the previous layer of the encoder.</li>
</ul>
<ul>
<li>3.Similarly, self-attention layers in the decoder allow each position in the decoder to attend to all positions in the decoder up to and including that position. We need to prevent leftward information flow in the decoder to preserve the auto-regressive property. We implement this</li>
</ul>
<p>inside of scaled dot-product attention by masking out (setting to −1) all values in the input of the softmax which correspond to illegal connections.</p>
<p>总结下就是：</p>
<p>Transformer 中的attention机制总共有三种情况：</p>
<ul>
<li>1.encoder模块中的 self-attention，其中 queries, keys, values 都是来自 input_x, 也就是源语言的词表示。通过多层 multi-head attention, FFN, 得到最后的 input sentence 的向量表示，在没有使用RNN，CNN的情况下，其中的每个词都包含了其他所有词的信息，而且效果比 RNN，CNN 得到的向量表示要好。</li>
</ul>
<ul>
<li>2.encoder-encoder模块中的 attention. 其中 queries 来自上一个sub-layer, 也就是 decoder 中 masked multi-head attention 的输出，keys-values 来自 encoder 的输出。</li>
</ul>
<ul>
<li>3.decoder模块中的 self-attention，其中 queries, keys, values 都是来自于上一个 decoder 的输出。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">multiheadattention</span>(<span class="params">q,</span></span></span><br><span class="line"><span class="params"><span class="function"></span></span></span><br><span class="line"><span class="params"><span class="function">                       k,</span></span></span><br><span class="line"><span class="params"><span class="function"></span></span></span><br><span class="line"><span class="params"><span class="function">                       v,</span></span></span><br><span class="line"><span class="params"><span class="function"></span></span></span><br><span class="line"><span class="params"><span class="function">                       d_model,</span></span></span><br><span class="line"><span class="params"><span class="function"></span></span></span><br><span class="line"><span class="params"><span class="function">                       heads,</span></span></span><br><span class="line"><span class="params"><span class="function"></span></span></span><br><span class="line"><span class="params"><span class="function">                       keys_mask=<span class="literal">None</span>,</span></span></span><br><span class="line"><span class="params"><span class="function"></span></span></span><br><span class="line"><span class="params"><span class="function">                       causality=<span class="literal">None</span>,</span></span></span><br><span class="line"><span class="params"><span class="function"></span></span></span><br><span class="line"><span class="params"><span class="function">                       dropout_keep_prob=<span class="number">0.1</span>,</span></span></span><br><span class="line"><span class="params"><span class="function"></span></span></span><br><span class="line"><span class="params"><span class="function">                       is_training=<span class="literal">True</span></span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="string">&quot;&quot;&quot; multi scaled dot product attention</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    :param q: A 3d tensor with shape of [batch, length_q, d_k].</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    :param k: A 3d tensor with shape of [batch, lenght_kv, d_k].</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    :param v:</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    :param heads:An int. Number of heads.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    :param dropout_keep_prob:</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    :param causality: If true, units that reference the future are masked.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    :return:</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 1. Linear projections</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> tf.variable_scope(<span class="string">&#x27;linear-projection-multiheads&#x27;</span>):</span><br><span class="line"></span><br><span class="line">        q_proj = tf.layers.dense(q, d_model) <span class="comment"># [batch, lenght_q, d_model]</span></span><br><span class="line"></span><br><span class="line">        k_proj = tf.layers.dense(k, d_model) <span class="comment"># [batch, lenght_kv, d_model]</span></span><br><span class="line"></span><br><span class="line">        v_proj = tf.layers.dense(v, d_model) <span class="comment"># [batch, lenght_kv, d_model]</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> tf.variable_scope(<span class="string">&quot;multihead-attention&quot;</span>):</span><br><span class="line"></span><br><span class="line">        <span class="comment"># d_k = d_v = d_model/heads</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> d_model % heads != <span class="number">0</span>:</span><br><span class="line"></span><br><span class="line">            <span class="keyword">raise</span> ValueError(<span class="string">&quot;Key\values\query depth (%d) must be divisible by&quot;</span></span><br><span class="line"></span><br><span class="line">                             <span class="string">&quot;the number of attention heads (%d)&quot;</span> %(d_model, heads))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 2. split and concat</span></span><br><span class="line"></span><br><span class="line">        q_ = tf.concat(tf.split(q_proj, heads, axis=<span class="number">2</span>), axis=<span class="number">0</span>)  <span class="comment"># [batch*heads, length_q, d_k]</span></span><br><span class="line"></span><br><span class="line">        k_ = tf.concat(tf.split(k_proj, heads, axis=<span class="number">2</span>), axis=<span class="number">0</span>)  <span class="comment"># [batch*heads, length_kv, d_k]</span></span><br><span class="line"></span><br><span class="line">        v_ = tf.concat(tf.split(v_proj, heads, axis=<span class="number">2</span>), axis=<span class="number">0</span>)  <span class="comment"># [batch*heads, length_kv, d_v]</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 3. attention score</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># outputs.shape=[batch*heads, length_q, length_kv]</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 要理解这个矩阵运算，对一个keys的句子长度为length_kv,需要计算的其中的每一个词与query中每一个词的內积。所以最后的score是[length_q, lenght_kv]</span></span><br><span class="line"></span><br><span class="line">        scalar = tf.rsqrt(d_model/heads)  <span class="comment"># 1/sqrt(d_k)</span></span><br><span class="line"></span><br><span class="line">        outputs = tf.matmul(q_*scalar, k_, transpose_b=<span class="literal">True</span>)   <span class="comment"># [batch*heads, length_q, lenght_kv]</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 4. mask</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> keys_mask <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line"></span><br><span class="line">            <span class="comment"># `y = sign(x) = -1` if `x &lt; 0`; 0 if `x == 0` or `tf.is_nan(x)`; 1 if `x &gt; 0`.</span></span><br><span class="line"></span><br><span class="line">            key_masks = tf.sign(tf.<span class="built_in">abs</span>(tf.reduce_sum(k, axis=-<span class="number">1</span>)))  <span class="comment"># (batch, length_kv)</span></span><br><span class="line"></span><br><span class="line">            key_masks = tf.tile(key_masks, [heads, <span class="number">1</span>])              <span class="comment"># (batch*heads, length_kv)</span></span><br><span class="line"></span><br><span class="line">            key_masks = tf.tile(tf.expand_dims(key_masks, <span class="number">1</span>), [<span class="number">1</span>, q.get_shape()[<span class="number">1</span>], <span class="number">1</span>])  <span class="comment"># (batch*heads, length_q, length_kv)</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">            <span class="comment"># def where(condition, x=None, y=None, name=None)</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># The `condition` tensor acts as a mask that chooses, based on the value at each</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># element, whether the corresponding element / row in the output should be taken</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># from `x` (if true) or `y` (if false).</span></span><br><span class="line"></span><br><span class="line">            paddings = tf.ones_like(outputs) * (-<span class="number">2</span> ** <span class="number">32</span> + <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">            outputs = tf.where(tf.equal(key_masks, <span class="number">0</span>), paddings, outputs)  <span class="comment"># [batch*heads, length_q, lenght_kv]</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">            <span class="comment"># Causality = Future blinding</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># causality参数告知我们是否屏蔽未来序列的信息（解码器self attention的时候不能看到自己之后的那些信息），</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># 这里即causality为True时的屏蔽操作。</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> causality:</span><br><span class="line"></span><br><span class="line">            diag_vals = tf.ones_like(outputs[<span class="number">0</span>, :, :])  <span class="comment"># [length_q, lenght_kv]</span></span><br><span class="line"></span><br><span class="line">            tril = LinearOperatorLowerTriangular(diag_vals).to_dense()  <span class="comment"># [length_q, lenght_kv] 得到一个三角阵，下标index大于当前行的值都变为0</span></span><br><span class="line"></span><br><span class="line">            masks = tf.tile(tf.expand_dims(tril, <span class="number">0</span>), [tf.shape(outputs)[<span class="number">0</span>], <span class="number">1</span>, <span class="number">1</span>])  <span class="comment"># [batch*heads, length_q, lenght_kv]</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">            paddings = tf.ones_like(masks) * (-<span class="number">2</span> ** <span class="number">32</span> + <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">            outputs = tf.where(tf.equal(masks, <span class="number">0</span>), paddings, outputs)  <span class="comment"># [batch*heads, length_q, lenght_kv]</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 将socre转换为概率</span></span><br><span class="line"></span><br><span class="line">        outpts = tf.nn.softmax(outputs)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="comment"># Query Masking</span></span><br><span class="line"></span><br><span class="line">        query_mask = tf.sign(tf.<span class="built_in">abs</span>(tf.reduce_sum(q, axis=-<span class="number">1</span>, keepdims=<span class="literal">False</span>))) <span class="comment"># [batch, lenght_q]</span></span><br><span class="line"></span><br><span class="line">        query_mask = tf.tile(query_mask, [heads, <span class="number">1</span>])  <span class="comment"># [batch*heads, length_q] # 目的是为了让query和outputs保持形状一致</span></span><br><span class="line"></span><br><span class="line">        query_mask = tf.tile(tf.expand_dims(query_mask, axis=-<span class="number">1</span>), [<span class="number">1</span>, <span class="number">1</span>, tf.shape(k)[-<span class="number">1</span>]]) <span class="comment"># [batch*heads, length_q, length_kv]</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        paddings = tf.ones_like(outputs) * (-<span class="number">2</span> ** <span class="number">32</span> + <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        outputs = tf.where(tf.equal(query_mask, <span class="number">0</span>), paddings, outputs) <span class="comment"># [batch*heads, length_q, length_kv]</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="comment"># Dropout</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> is_training:</span><br><span class="line"></span><br><span class="line">            outputs = tf.layers.dropout(outputs, dropout_keep_prob, )</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="comment"># weights sum</span></span><br><span class="line"></span><br><span class="line">        outputs = tf.matmul(outputs, v_)  <span class="comment"># [batch*heads, length_q, k_v]</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="comment"># restore shape</span></span><br><span class="line"></span><br><span class="line">        outputs = tf.concat(tf.split(outputs, heads, axis=<span class="number">0</span>), axis=-<span class="number">1</span>) <span class="comment">#[batch,length_q, k_v*heads] = [batch, lenght_q, d_model]</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="comment"># Residual connection</span></span><br><span class="line"></span><br><span class="line">        outputs += q    <span class="comment"># [batch, lenght_q, d_model]</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="comment"># Normalize</span></span><br><span class="line"></span><br><span class="line">        outputs = Normalize(outputs)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> outputs   <span class="comment"># [batch, length_q, d_model]</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>



<p>关于代码的详细解析，可以看这篇blog <a target="_blank" rel="noopener" href="http://lib.csdn.net/article/aiframework/68187">机器翻译模型Transformer代码详细解析</a>.</p>
<h4 id="Stage3-Position-wise-Feed-Forward-Networks"><a href="#Stage3-Position-wise-Feed-Forward-Networks" class="headerlink" title="Stage3: Position-wise Feed-Forward Networks"></a>Stage3: Position-wise Feed-Forward Networks</h4><p>$$FFN(x) = MAX(0, xW_1+b_1)W_2+b_2$$</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">position_wise_feed_forward</span>(<span class="params">inputs,</span></span></span><br><span class="line"><span class="params"><span class="function"></span></span></span><br><span class="line"><span class="params"><span class="function">                               num_units1=<span class="number">2048</span>,</span></span></span><br><span class="line"><span class="params"><span class="function"></span></span></span><br><span class="line"><span class="params"><span class="function">                               num_units2=<span class="number">512</span>,</span></span></span><br><span class="line"><span class="params"><span class="function"></span></span></span><br><span class="line"><span class="params"><span class="function">                               reuse=<span class="literal">None</span></span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="string">&quot;&quot;&quot; Point-wise feed forward net.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    :param inputs: A 3D tensor with shape of [batch, length_q, d_model]</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    :param num_units1: A integers.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    :param num_units2: A integers</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    :param reuse: Boolean, whether to reuse the weights of a previous layer</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        by the same name.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    :return: A 3d tensor with the same shape and dtype as inputs</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> tf.variable_scope(<span class="string">&quot;feed-forward-networks&quot;</span>):</span><br><span class="line"></span><br><span class="line">        <span class="comment"># inner layers</span></span><br><span class="line"></span><br><span class="line">        params1 = &#123;<span class="string">&quot;inputs&quot;</span>:inputs, <span class="string">&quot;filters&quot;</span>:num_units1, <span class="string">&quot;kernel_size&quot;</span>:<span class="number">1</span>,</span><br><span class="line"></span><br><span class="line">                  <span class="string">&quot;activation&quot;</span>:tf.nn.relu, <span class="string">&quot;use_bias&quot;</span>:<span class="literal">True</span>, <span class="string">&quot;strides&quot;</span>:<span class="number">1</span>&#125;</span><br><span class="line"></span><br><span class="line">        outputs = tf.layers.conv1d(**params1)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="comment"># readout layer</span></span><br><span class="line"></span><br><span class="line">        params2 = &#123;<span class="string">&quot;inputs&quot;</span>:outputs, <span class="string">&quot;filters&quot;</span>:num_units2, <span class="string">&quot;kernel_size&quot;</span>:<span class="number">1</span>,</span><br><span class="line"></span><br><span class="line">                  <span class="string">&quot;activation&quot;</span>:<span class="literal">None</span>, <span class="string">&quot;use_bias&quot;</span>:<span class="literal">True</span>, <span class="string">&quot;strides&quot;</span>:<span class="number">1</span>&#125;</span><br><span class="line"></span><br><span class="line">        outputs = tf.layers.conv1d(**params2)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="comment"># residual connection</span></span><br><span class="line"></span><br><span class="line">        outputs += inputs</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="comment"># Normalize</span></span><br><span class="line"></span><br><span class="line">        outputs = Normalize(outputs)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> outputs</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">position_wise_feed_forward_mine</span>(<span class="params">inputs,</span></span></span><br><span class="line"><span class="params"><span class="function"></span></span></span><br><span class="line"><span class="params"><span class="function">                               num_units1=<span class="number">2048</span>,</span></span></span><br><span class="line"><span class="params"><span class="function"></span></span></span><br><span class="line"><span class="params"><span class="function">                               num_units2=<span class="number">512</span>,</span></span></span><br><span class="line"><span class="params"><span class="function"></span></span></span><br><span class="line"><span class="params"><span class="function">                               reuse=<span class="literal">None</span></span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> tf.variable_scope(<span class="string">&quot;feed-forward-networks&quot;</span>):</span><br><span class="line"></span><br><span class="line">        W1 = tf.get_variable(<span class="string">&quot;weight1&quot;</span>, [inputs.get_shape()[-<span class="number">1</span>], num_units1],initializer=xavier_initializer())</span><br><span class="line"></span><br><span class="line">        b1 = tf.get_variable(<span class="string">&#x27;bias1&#x27;</span>, [num_units1], initializer=tf.constant_initializer(<span class="number">0.1</span>))</span><br><span class="line"></span><br><span class="line">        outputs = tf.einsum(<span class="string">&#x27;aij,jk-&gt;aik&#x27;</span>, inputs, W1) + b1  <span class="comment"># [batch, length_q, num_units1]</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        W2 = tf.get_variable(<span class="string">&quot;weight1&quot;</span>, [outputs.get_shape()[-<span class="number">1</span>], num_units2], initializer=xavier_initializer())</span><br><span class="line"></span><br><span class="line">        b2 = tf.get_variable(<span class="string">&#x27;bias1&#x27;</span>, [num_units2], initializer=tf.constant_initializer(<span class="number">0.1</span>))</span><br><span class="line"></span><br><span class="line">        outputs = tf.einsum(<span class="string">&#x27;aij,jk-&gt;aik&#x27;</span>, inputs, W2) + b2  <span class="comment"># [batch, length_q, num_units1]</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="comment"># residual connection</span></span><br><span class="line"></span><br><span class="line">        outputs += inputs</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="comment"># Normalize</span></span><br><span class="line"></span><br><span class="line">        outputs = Normalize(outputs)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> outputs</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="encoder-各模块组合在一起"><a href="#encoder-各模块组合在一起" class="headerlink" title="encoder 各模块组合在一起"></a>encoder 各模块组合在一起</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_encoder</span>(<span class="params">self</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> tf.variable_scope(<span class="string">&quot;encoder&quot;</span>):</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 1. embedding</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">with</span> tf.variable_scope(<span class="string">&quot;embedding-layer&quot;</span>):</span><br><span class="line"></span><br><span class="line">            self.enc = embedding(inputs=self.input_x,</span><br><span class="line"></span><br><span class="line">                                   vocab_size=self.vocab_size_cn,</span><br><span class="line"></span><br><span class="line">                                   num_units=self.d_model,</span><br><span class="line"></span><br><span class="line">                                   scale=<span class="literal">True</span>)   <span class="comment"># [batch, sentence_len, d_model]</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 2. position encoding</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">with</span> tf.variable_scope(<span class="string">&quot;position_encoding&quot;</span>):</span><br><span class="line"></span><br><span class="line">            encoding = position_encoding_mine(self.enc.get_shape()[<span class="number">1</span>], self.d_model)</span><br><span class="line"></span><br><span class="line">            self.enc *= encoding</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 3.dropout</span></span><br><span class="line"></span><br><span class="line">        self.enc = tf.layers.dropout(self.enc,</span><br><span class="line"></span><br><span class="line">                                     rate=self.dropout_keep_prob,</span><br><span class="line"></span><br><span class="line">                                     training=self.is_training)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 4. Blocks</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(self.num_layers):</span><br><span class="line"></span><br><span class="line">            <span class="keyword">with</span> tf.variable_scope(<span class="string">&quot;num_layer_&#123;&#125;&quot;</span>.<span class="built_in">format</span>(i)):</span><br><span class="line"></span><br><span class="line">                <span class="comment"># multihead attention</span></span><br><span class="line"></span><br><span class="line">                <span class="comment"># encoder: self-attention</span></span><br><span class="line"></span><br><span class="line">                self.enc = multiheadattention(q=self.enc,</span><br><span class="line"></span><br><span class="line">                                              k=self.enc,</span><br><span class="line"></span><br><span class="line">                                              v=self.enc,</span><br><span class="line"></span><br><span class="line">                                              d_model=self.d_model,</span><br><span class="line"></span><br><span class="line">                                              heads=self.heads,</span><br><span class="line"></span><br><span class="line">                                              causality=<span class="literal">False</span>,</span><br><span class="line"></span><br><span class="line">                                              dropout_keep_prob=self.dropout_keep_prob,</span><br><span class="line"></span><br><span class="line">                                              is_training=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">                <span class="comment"># Feed Froward</span></span><br><span class="line"></span><br><span class="line">                self.enc = position_wise_feed_forward(self.enc,</span><br><span class="line"></span><br><span class="line">                                                      num_units1= <span class="number">4</span>*self.d_model,</span><br><span class="line"></span><br><span class="line">                                                      num_units2= self.d_model,</span><br><span class="line"></span><br><span class="line">                                                      reuse=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> self.enc</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h3 id="Decoder-1"><a href="#Decoder-1" class="headerlink" title="Decoder"></a>Decoder</h3><p>decoder 模块中 self-attention 的初始输入：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment"># define decoder inputs</span></span><br><span class="line"></span><br><span class="line">self.decoder_inputs = tf.concat([tf.ones_like(self.input_y[:,:<span class="number">1</span>])*<span class="number">2</span>, self.input_y[:,:-<span class="number">1</span>]],axis=-<span class="number">1</span>) <span class="comment"># 2:&lt;S&gt;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>



<p>与encoder 不同的是，分为 encoder-decoder attention 和 self-attention.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_decoder</span>(<span class="params">self</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> tf.variable_scope(<span class="string">&quot;decoder&quot;</span>):</span><br><span class="line"></span><br><span class="line">        <span class="comment"># embedding</span></span><br><span class="line"></span><br><span class="line">        self.dec = embedding(self.decoder_inputs,</span><br><span class="line"></span><br><span class="line">                             vocab_size=self.vocab_size_en,</span><br><span class="line"></span><br><span class="line">                             num_units=self.d_model)   <span class="comment"># [batch, sentence_len, d_model]</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="comment"># position decoding</span></span><br><span class="line"></span><br><span class="line">        encoding = position_encoding_mine(self.dec.get_shape()[<span class="number">1</span>], self.d_model)</span><br><span class="line"></span><br><span class="line">        self.dec *= encoding</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="comment"># blocks</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(self.num_layers):</span><br><span class="line"></span><br><span class="line">            <span class="keyword">with</span> tf.variable_scope(<span class="string">&quot;num_layers_&#123;&#125;&quot;</span>.<span class="built_in">format</span>(i)):</span><br><span class="line"></span><br><span class="line">                <span class="comment"># self-attention</span></span><br><span class="line"></span><br><span class="line">                <span class="keyword">with</span> tf.variable_scope(<span class="string">&quot;self.attention&quot;</span>):</span><br><span class="line"></span><br><span class="line">                    self.dec = multiheadattention(q=self.dec,</span><br><span class="line"></span><br><span class="line">                                                  k=self.dec,</span><br><span class="line"></span><br><span class="line">                                                  v=self.dec,</span><br><span class="line"></span><br><span class="line">                                                  d_model=self.d_model,</span><br><span class="line"></span><br><span class="line">                                                  heads=self.heads,</span><br><span class="line"></span><br><span class="line">                                                  keys_mask=<span class="literal">True</span>,</span><br><span class="line"></span><br><span class="line">                                                  causality=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">                <span class="comment"># encoder-decoder-attention</span></span><br><span class="line"></span><br><span class="line">                <span class="keyword">with</span> tf.variable_scope(<span class="string">&quot;encoder-decoder-attention&quot;</span>):</span><br><span class="line"></span><br><span class="line">                    self.dec = multiheadattention(q=self.dec,</span><br><span class="line"></span><br><span class="line">                                                  k=self.enc,</span><br><span class="line"></span><br><span class="line">                                                  v=self.enc,</span><br><span class="line"></span><br><span class="line">                                                  d_model=self.d_model,</span><br><span class="line"></span><br><span class="line">                                                  heads=self.heads,</span><br><span class="line"></span><br><span class="line">                                                  keys_mask=<span class="literal">True</span>,</span><br><span class="line"></span><br><span class="line">                                                  causality=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">                self.dec = position_wise_feed_forward(self.dec,</span><br><span class="line"></span><br><span class="line">                                                      num_units1= <span class="number">4</span>*self.d_model,</span><br><span class="line"></span><br><span class="line">                                                      num_units2= self.d_model)   <span class="comment"># [batch, sentence_len, d_model]</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> self.dec</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h4 id="Optimizer"><a href="#Optimizer" class="headerlink" title="Optimizer"></a>Optimizer</h4><p><img src="/2018/06/02/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-Attention-Is-All-You-Need/12.png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">add_train_op</span>(<span class="params">self</span>):</span></span><br><span class="line"></span><br><span class="line">    self.optimizer = tf.train.AdamOptimizer(self.lr, beta1=<span class="number">0.9</span>, beta2=<span class="number">0.98</span>, epsilon=<span class="number">1e-9</span>)</span><br><span class="line"></span><br><span class="line">    self.train_op = self.optimizer.minimize(self.loss, global_step=self.global_step)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> self.train_op</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h4 id="Regularization"><a href="#Regularization" class="headerlink" title="Regularization"></a>Regularization</h4><h5 id="Residual-Dropout"><a href="#Residual-Dropout" class="headerlink" title="Residual Dropout"></a>Residual Dropout</h5><h5 id="label-smoothing"><a href="#label-smoothing" class="headerlink" title="label smoothing"></a>label smoothing</h5><p>During training, we employed label smoothing of value ls = 0:1 [36]. This hurts perplexity, as the model learns to be more unsure, but improves accuracy and BLEU score.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">label_smoothing</span>(<span class="params">inputs, epsilon=<span class="number">0.1</span></span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="string">&quot;&quot;&quot; Applies label smoothing. See https://arxiv.org/abs/1512.00567</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    :param inputs: A 3d tensor with shape of [N, T, V], where V is the number of vocabulary.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    :param epsilon: Smoothing rate.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        For example,</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    K = inputs.get_shape().as_list()[-<span class="number">1</span>]  <span class="comment"># number of channels</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> ((<span class="number">1</span>-epsilon) * inputs) + (epsilon/K)</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<p>Reference:</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://distill.pub/2016/augmented-rnns/#attentional-interfaces">Attention and Augmented Recurrent Neural Networks</a></li>
</ul>
<ul>
<li><a target="_blank" rel="noopener" href="https://mchromiak.github.io/articles/2017/Sep/12/Transformer-Attention-is-all-you-need/#sf-Transformer-Attention-is-all-you-need-3">The Transformer – Attention is all you need.</a></li>
</ul>
<ul>
<li><a target="_blank" rel="noopener" href="http://lib.csdn.net/article/aiframework/68187">机器翻译模型Transformer代码详细解析</a></li>
</ul>
</div></article></div></div><!--!--><div class="column column-right is-4-tablet is-4-desktop is-4-widescreen  order-3"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar" src="/img/avatar.png" alt="panxiaoxie"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">panxiaoxie</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Beijing, China</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">文章</p><a href="/archives"><p class="title">120</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">分类</p><a href="/categories"><p class="title">40</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">标签</p><a href="/tags"><p class="title">38</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/PanXiebit" target="_blank" rel="noopener">关注我</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/PanXiebit"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Email" href="/ftdpanxie@gmail.com"><i class="fa fa-envelope"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="RSS" href="/"><i class="fas fa-rss"></i></a></div></div></div><!--!--><div class="card widget" data-type="links"><div class="card-content"><div class="menu"><h3 class="menu-label">链接</h3><ul class="menu-list"><li><a class="level is-mobile" href="https://github.com/PanXiebit" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">github</span></span><span class="level-right"><span class="level-item tag">github.com</span></span></a></li><li><a class="level is-mobile" href="ftdpanxie@gmail.com" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">email</span></span><span class="level-right"><span class="level-item tag">ftdpanxie@gmail.com</span></span></a></li></ul></div></div></div><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">分类</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/C/"><span class="level-start"><span class="level-item">C++</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/CSAPP/"><span class="level-start"><span class="level-item">CSAPP</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/DRL/"><span class="level-start"><span class="level-item">DRL</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/GAN/"><span class="level-start"><span class="level-item">GAN</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li><li><a class="level is-mobile" href="/categories/GAN-RL/"><span class="level-start"><span class="level-item">GAN, RL</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/ML/"><span class="level-start"><span class="level-item">ML</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/NLP/"><span class="level-start"><span class="level-item">NLP</span></span><span class="level-end"><span class="level-item tag">14</span></span></a></li><li><a class="level is-mobile" href="/categories/TensorFlow/"><span class="level-start"><span class="level-item">TensorFlow</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/cs224d/"><span class="level-start"><span class="level-item">cs224d</span></span><span class="level-end"><span class="level-item tag">10</span></span></a></li><li><a class="level is-mobile" href="/categories/generation/"><span class="level-start"><span class="level-item">generation</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/generative-models/"><span class="level-start"><span class="level-item">generative models</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/interview/"><span class="level-start"><span class="level-item">interview</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/machine-translation/"><span class="level-start"><span class="level-item">machine translation</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/python/"><span class="level-start"><span class="level-item">python</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/pytorch/"><span class="level-start"><span class="level-item">pytorch</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/reinforcement-learning/"><span class="level-start"><span class="level-item">reinforcement learning</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/sign-language-recognition/"><span class="level-start"><span class="level-item">sign language recognition</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/transfer-learning/"><span class="level-start"><span class="level-item">transfer learning</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/transformer/"><span class="level-start"><span class="level-item">transformer</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"><span class="level-start"><span class="level-item">数据结构与算法</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile" href="/categories/%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB/"><span class="level-start"><span class="level-item">文本分类</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"><span class="level-start"><span class="level-item">论文笔记</span></span><span class="level-end"><span class="level-item tag">40</span></span></a><ul><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/DL/"><span class="level-start"><span class="level-item">DL</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/ESA/"><span class="level-start"><span class="level-item">ESA</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/GAN/"><span class="level-start"><span class="level-item">GAN</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/MRC-and-QA/"><span class="level-start"><span class="level-item">MRC and QA</span></span><span class="level-end"><span class="level-item tag">7</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/Machine-Translation/"><span class="level-start"><span class="level-item">Machine Translation</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/NLP/"><span class="level-start"><span class="level-item">NLP</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/Transformer/"><span class="level-start"><span class="level-item">Transformer</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/capsules/"><span class="level-start"><span class="level-item">capsules</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/computer-vision/"><span class="level-start"><span class="level-item">computer vision</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/constrast-learning/"><span class="level-start"><span class="level-item">constrast learning</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/data-augmentation/"><span class="level-start"><span class="level-item">data augmentation</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/dialogue-system/"><span class="level-start"><span class="level-item">dialogue system</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/language-model/"><span class="level-start"><span class="level-item">language model</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/machine-translation/"><span class="level-start"><span class="level-item">machine translation</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/open-set-recognition/"><span class="level-start"><span class="level-item">open set recognition</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/sentence-embedding/"><span class="level-start"><span class="level-item">sentence embedding</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/text-matching/"><span class="level-start"><span class="level-item">text matching</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/vision-language/"><span class="level-start"><span class="level-item">vision-language</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li></ul></div></div></div></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/panxiaoxie.png" alt="潘小榭" height="28"></a><p class="is-size-7"><span>&copy; 2022 Xie Pan</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("zh-CN");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="回到顶端" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "此网站使用Cookie来改善您的体验。",
          dismiss: "知道了！",
          allow: "允许使用Cookie",
          deny: "拒绝",
          link: "了解更多",
          policy: "Cookie政策",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.5/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="想要查找什么..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"想要查找什么...","untitled":"(无标题)","posts":"文章","pages":"页面","categories":"分类","tags":"标签"});
        });</script></body></html>