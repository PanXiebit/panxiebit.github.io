<!doctype html>
<html lang="de"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>Category: GAN - 潘小榭</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="潘小榭"><meta name="msapplication-TileImage" content="/img/favicon.svg"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="潘小榭"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta property="og:type" content="blog"><meta property="og:title" content="潘小榭"><meta property="og:url" content="http://www.panxiaoxie.cn/"><meta property="og:site_name" content="潘小榭"><meta property="og:image" content="http://www.panxiaoxie.cn/img/og_image.png"><meta property="article:author" content="Xie Pan"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="/img/og_image.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"http://www.panxiaoxie.cn"},"headline":"潘小榭","image":["http://www.panxiaoxie.cn/img/og_image.png"],"author":{"@type":"Person","name":"Xie Pan"},"publisher":{"@type":"Organization","name":"潘小榭","logo":{"@type":"ImageObject","url":"http://www.panxiaoxie.cn/img/logo.svg"}},"description":null}</script><link rel="icon" href="/img/favicon.svg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/css/justifiedGallery.min.css"><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script><!--!--><!--!--><meta name="generator" content="Hexo 5.4.0"></head><body class="is-2-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/logo.svg" alt="潘小榭" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-8-widescreen"><div class="card"><div class="card-content"><nav class="breadcrumb" aria-label="breadcrumbs"><ul><li><a href="/categories">Categories</a></li><li><a href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/">论文笔记</a></li><li class="is-active"><a href="#" aria-current="page">GAN</a></li></ul></nav></div></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2019-01-09T00:44:13.000Z" title="2019/1/9 上午8:44:13">2019-01-09</time></span><span class="level-item">Updated&nbsp;<time dateTime="2021-06-29T08:12:08.200Z" title="2021/6/29 下午4:12:08">2021-06-29</time></span><span class="level-item"><a class="link-muted" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/">论文笔记</a><span> / </span><a class="link-muted" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/GAN/">GAN</a></span><span class="level-item">20 minutes read (About 2930 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2019/01/09/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-GAN-tutorial-NIPS-2016/">论文笔记-GAN tutorial NIPS 2016</a></h1><div class="content"><h1 id="为什么要学习-GAN？"><a href="#为什么要学习-GAN？" class="headerlink" title="为什么要学习 GAN？"></a>为什么要学习 GAN？</h1><ul>
<li>High-dimensional probability distributions, 从高维概率分布中训练和采样的生成模型具有很强的能力来表示高维概率分布。</li>
</ul>
<ul>
<li>Reinforcement learning. 和强化学习结合。</li>
</ul>
<ul>
<li>Missing data. 生成模型能有效的利用无标签数据，也就是半监督学习 semi-supervised learning。</li>
</ul>
<h1 id="生成模型如何工作的"><a href="#生成模型如何工作的" class="headerlink" title="生成模型如何工作的"></a>生成模型如何工作的</h1><h2 id="Maximum-likehood-estimation"><a href="#Maximum-likehood-estimation" class="headerlink" title="Maximum likehood estimation"></a>Maximum likehood estimation</h2><p>极大似然估计就是在给定数据集的情况下，通过合理的模型（比如语言模型）计算相应的似然（概率），使得这个概率最大的情况下，估计模型的参数。</p>
<p>$$\sum_i^mp_{\text{model}}(x^{(i)}; \theta)$$</p>
<p>m 是样本数量。</p>
<p><img src="/2019/01/09/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-GAN-tutorial-NIPS-2016/05.png"></p>
<p>将上诉概率转换到 log 空间（log 函数是单调递增的），可以将乘积转换为相加，简化了计算。</p>
<p>同样的，也可以把上诉似然估计的极大化看做是最小化 KL 散度（或者交叉熵）。这样一来，相当于把无监督问题转换成了有监督问题。（不知理解的是否正确？）</p>
<h3 id="相对熵"><a href="#相对熵" class="headerlink" title="相对熵"></a>相对熵</h3><p>熵是信息量 $log{\dfrac{1}{p(i)}}$ (概率越大信息量越少)。</p>
<p>p 是真实分布， q 是非真实分布。  </p>
<p>交叉熵是用 q 分布来估计 p 分布所需要消除的代价 cost:</p>
<p>$$H(p,q) = \sum_ip(i)log{\dfrac{1}{q(i)}}$$</p>
<p>用真实分布 p 估计真实分布所需要的 cost:</p>
<p>$$H(p) = \sum_ip(i)log{\dfrac{1}{p(i)}}$$</p>
<p>从这里也能看出，当概率 p 为 1 时，所需要的 cost 就为 0 了。</p>
<p>相对熵，又称 KL 散度(Kullback–Leibler divergence)，就是指上诉两者所需要消耗的 cost 的差值：</p>
<p>$$D(p||q) = H(p,q)-H(p) =  \sum_ip(i)log{\dfrac{p(i)}{q(i)}}$$</p>
<h1 id="GAN-是如何工作的？"><a href="#GAN-是如何工作的？" class="headerlink" title="GAN 是如何工作的？"></a>GAN 是如何工作的？</h1><h2 id="GAN-框架"><a href="#GAN-框架" class="headerlink" title="GAN 框架"></a>GAN 框架</h2><p><img src="/2019/01/09/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-GAN-tutorial-NIPS-2016/01.png"></p>
<ul>
<li><p>判别器 discriminator  </p>
</li>
<li><p>生成器 gererator  </p>
</li>
</ul>
<p>在左边场景，判别器学习如何分别样本是 real or fake. 所以左边的输入是 half real and half fake.</p>
<p>在右边的v场景，判别器和生成器都参与了。G 用来生成 G(z), D 用来判别 G(z) 是 real or fake.</p>
<p><img src="/2019/01/09/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-GAN-tutorial-NIPS-2016/02.png"></p>
<p>结构化概率模型 <a target="_blank" rel="noopener" href="http://www.deeplearningbook.org/contents/graphical_models.html">Structured Probabilistic Modelsfor Deep Learning</a></p>
<p>containing latent variables z and observed variables x.  </p>
<p>z 是需要学习的隐藏变量，x 是可观察到的变量。</p>
<p>判别器 D 的输入是 x，其需要学习的参数是 $\theta^{(D)}$. 生成器 G 的输入是 z, 其需要学习的参数是 $\theta^{(G)}$.  </p>
<p>两个玩家都有各自的损失函数。 $J^{(D)}(\theta^{(D)}, \theta^{(G)})$, 但是 $J^{(D)}$ 并不影响参数 $\theta^{(G)}$. 同样的道理，反过来也是 $J^{(G)}(\theta^{(G)}, \theta^{(D)})$.</p>
<p>每个玩家的损失函数依赖于另一个玩家的参数，但是确不能控制它的参数。所以这是一种 Nash equilibrium 问题。找到这样一个局部最优解 $tuple(\theta^{(G)}, \theta^{(D)})$ 使得 $J^{(D)}$ 关于 $\theta^{(D)}$ 局部最小，$J^{(G)}$ 关于 $\theta^{(G)}$ 局部最小。</p>
<h3 id="Generator"><a href="#Generator" class="headerlink" title="Generator"></a>Generator</h3><p>differentiable function G, 可微分函数 G. 实际上就是 神经网络。z 来自简单的先验分布，G(z) 通过模型 $p_{model}$ 生成样本 x. 实践中，对于 G 的输入不一定只在第一层 layer, 也可以在 第二层 等等。总之，生成器的设计很灵活。</p>
<h3 id="Training-process"><a href="#Training-process" class="headerlink" title="Training process"></a>Training process</h3><p>两个 minibatch 的输入： x 来自 training dataset. z 来自先验隐藏变量构成的模型 $p_\text{model}$。通过优化算法 SGD/Adam 对两个损失 $J^{(D)} J^{(G)}$ 通过进行优化。梯度下降一般是同步的，也有人认为两者的迭代步数可以不一样。在这篇 tutorial 的时候，得到的共识是同步的。</p>
<h2 id="cost-function"><a href="#cost-function" class="headerlink" title="cost function"></a>cost function</h2><p>目前大多数 GAN 的损失函数，$J(D)$ 都是一样的。区别在于 $J(G)$.</p>
<h3 id="The-discriminator’s-cost-J-D"><a href="#The-discriminator’s-cost-J-D" class="headerlink" title="The discriminator’s cost, J (D)"></a>The discriminator’s cost, J (D)</h3><p><img src="/2019/01/09/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-GAN-tutorial-NIPS-2016/03.png"></p>
<p>这是个标准的用于二分类的交叉熵损失函数。只不过这里，正分类都来自于训练集，正分类的概率是 $\dfrac{1}{2}E_{x～d_{data}}$, 负分类来自于生成器，则其概率是 $\dfrac{1}{2}E_z$</p>
<p>通过训练判别器，我们可以得到这样一个比例:  </p>
<p>$$\dfrac{p_{data}(x)}{p_{\text{model}}(x)}$$</p>
<p>GANs 通过监督学习来获得这个 ratio 的估计，这也是 GANs 不同于 变分自编码 和 波尔兹曼机 (variational autoencoders and Boltzmann machines) 的区别。</p>
<p>但是 GANs 通过监督学习来估计这个 ratio,会向监督学习一样遇到同样的问题：过拟合和欠拟合。但是通过足够的数据和完美的优化可以解决这个问题。</p>
<h3 id="Minimax-zero-sum-game"><a href="#Minimax-zero-sum-game" class="headerlink" title="Minimax, zero-sum game"></a>Minimax, zero-sum game</h3><p>设计 cost function for generator.  </p>
<p>前面我们知道，两个玩家 player 或者说 神经网络 G，D 实际上是一种博弈，D 希望能找出 G(z) 是 fake，而 G 希望能让 G(z) 尽可能像 real. 所以最简单的一种方式就是 all player’s cost is always zero.  </p>
<p>$$J^{(G)} = -J^{(D)}$$</p>
<p>这样 $J^{(G)}, J^{(D)}$ 都可以用 value function 表示：</p>
<p>$$V(\theta^{(D)}, \theta^{(G)})=-J^{(D)}(\theta^{(D)}, \theta^{(G)})$$</p>
<p>那么整个 game 也就是一个 minmax 游戏：</p>
<p><img src="/2019/01/09/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-GAN-tutorial-NIPS-2016/04.png"></p>
<p>outer loop 是关于 $\theta^{(G)}$ 的最小化，inner loop 是关于 $\theta^{(D)}$ 的最大化。</p>
<p>但是这种 function 在实际中并不能使用，因为其非凸性。  </p>
<blockquote>
<p>In practice, the players are represented with deep neural nets and updates are made in parameter space, so these results, which depend on convexity, do not apply</p>
</blockquote>
<h3 id="Heuristic-non-saturating-game"><a href="#Heuristic-non-saturating-game" class="headerlink" title="Heuristic, non-saturating game"></a>Heuristic, non-saturating game</h3><blockquote>
<p>Minimizing the cross-entropy between a target class and a classifier’s predicted distribution is highly effective because the cost never saturates when the classifier has the wrong output.  </p>
</blockquote>
<p>对一个分类器，最小化 目标类和预测概率的交叉熵 是一个非常有效的方法，因为当 分类器 存在误分类时，损失函数就永远不可能饱和。</p>
<p>所以，对于生成器的 cost 依旧使用交叉熵，但如果使用和 判别器一模一样的 cost(这里应该就是把正负分类反过来？)：</p>
<p>$$J^{(G)}(\theta^{(D)}, \theta^{(G)})=-\dfrac{1}{2}E_zlogD(G(z))-\dfrac{1}{2}E_{x～p_{data}}log(1-D(x))$$</p>
<p>猜想应该是这样，文中没有给出。</p>
<p>不幸的是这样的在是实际中，也并不可行。当 判别器 拒绝一个高置信度(high confidence) 的样本时，生成器会出现梯度消失。</p>
<p>所以，改进之后就是:  </p>
<p>$$J^{(G)}(\theta^{(D)}, \theta^{(G)})=-\dfrac{1}{2}E_zlogD(G(z))$$</p>
<blockquote>
<p>In the minimax game, the generator minimizes the log-probability of the discriminator being correct. In this game, the generator maximizes the logprobability of the discriminator being mistaken.  </p>
</blockquote>
<p>在 Minmax，zero-game 中，生成器的目的是最小化 判别器 自认为自己判别对了的 log-probability, 而在 non-saturating game 中，生成器是最大化 判别器判别错误 的 log-probability.  </p>
<h3 id="Maximum-likelihood-game"><a href="#Maximum-likelihood-game" class="headerlink" title="Maximum likelihood game"></a>Maximum likelihood game</h3><p>前面提到极大似然估计是最小化模型与数据之间的 KL 散度。 GANs 使用极大似然估计则是对比不同的模型。</p>
<p>$$J^{(G)}=-\dfrac{1}{2}E_zexp(\sigma^{-1}(D(G(z))))$$</p>
<blockquote>
<p>in practice, both stochastic gradient descent on the KL divergence and the GAN training procedure will have some variance around the true expected gradient due to the use of sampling (of x for maximum likelihood and z for GANs) to construct the estimated gradient.  </p>
</blockquote>
<p>在实践中，由于使用采样（x表示最大似然，z表示GAN）来构建估计的梯度，因此KL散度和GAN训练过程的随机梯度下降都会在真实预期梯度附近产生一些变化。</p>
<h3 id="Is-the-choice-of-divergence-a-distinguishing-feature-of-GANs"><a href="#Is-the-choice-of-divergence-a-distinguishing-feature-of-GANs" class="headerlink" title="Is the choice of divergence a distinguishing feature of GANs?"></a>Is the choice of divergence a distinguishing feature of GANs?</h3><h4 id="Jensen-Shannon-divergence，-reverse-KL"><a href="#Jensen-Shannon-divergence，-reverse-KL" class="headerlink" title="Jensen-Shannon divergence， reverse KL"></a>Jensen-Shannon divergence， reverse KL</h4><p>许多人认为 GANs 能够生成更加清晰、逼真的样本是因为他们最小化的是 Jensen-Shannon divergence. 而 VAEs 生成模糊的样本是因为他们最小化的是 KL divergence between the data and the model.  </p>
<p>KL 散度并不是对称的。$D_{KL}(p_{data}||q_{model})$ 与 $D_{KL}(p_{model}||q_{data})$ 是不一样的。极大似然估计是前者，最小化 Jensen-Shannon divergence 则更像后者。</p>
<p><img src="/2019/01/09/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-GAN-tutorial-NIPS-2016/06.png"></p>
<p>比较 $D_{KL}(p_{data}||q_{model})$ 与 $D_{KL}(p_{model}||q_{data})$ 区别。在模型能力不足以拟合数据的分布时，表现的尤为明显，如上图。给定的数据是两个高斯分布混合的分布。而模型是一个高斯模型。然后分别用极大似然 Maximum likehood 、reverse KL 散度作为 criterion，也就是 cost.</p>
<p>可以看到前者选择去平均两个模态，并希望在两个模态上都能得到较高的概率。而后者只选择其中一个模态，也有可能是另外一个模态，两个模态对于 reverse KL 都含有局部最优解。</p>
<p>所以，从这个视角来看， Maximum likehood 倾向于给 data 出现的位置更高的概率，而 reverse KL 则倾向于给没有出现 data 的位置较低的概率。所以 $D_{KL}(p_{model}||q_{data})$ 可以生成更棒的样本，因为模型不会生成不常见的样本，因为数据之间具有欺骗性的模态。</p>
<p>然而，也有一些新的研究表明，Jensen-Shannon divergence 并不是 GANs 能生成更清晰样本的原因。</p>
<p><img src="/2019/01/09/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-GAN-tutorial-NIPS-2016/07.png"></p>
<p>f-GAN 证明，KL 散度也能生成清晰的sample，并且也只选择少量的modes, 说明 Jensen-Shannon divergence 并不是 GANs 不同于其他模型的特征。</p>
<p><img src="/2019/01/09/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-GAN-tutorial-NIPS-2016/08.png"></p>
<p>GANs 通常选择少量的 mode 来生成样本，这个少量指的是小于模型的能力。 而 reverse KL 则是选择更可能多的 mode of the data distribution 在模型能力范围内。它通常不会选择更少的 mode. 这也解释了 mode collapse 并不是散度选择的原因。</p>
<blockquote>
<p>Altogether, this suggests that GANs choose to generate a small number of modes due to a defect in the training procedure, rather than due to the divergence they aim to minimize.  </p>
</blockquote>
<p>所以，GANs 选择少量的 mode 是因为训练过程中的其他缺陷，而不是 散度 选择的问题。</p>
<h3 id="Comparison-of-cost-functions"><a href="#Comparison-of-cost-functions" class="headerlink" title="Comparison of cost functions"></a>Comparison of cost functions</h3><p>生成对抗网络可以看做一种 reinforcement learning. 但是$j^{(G)}$ 并没有直接参考 training data，所有关于 training data 的信息都来自于 判别器 的学习。</p>
<p>所以和传统的强化学习是有区别的：</p>
<p><img src="/2019/01/09/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-GAN-tutorial-NIPS-2016/09.png"></p>
<p>比较不同的 cost function：</p>
<p><img src="/2019/01/09/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-GAN-tutorial-NIPS-2016/10.png"></p>
<p>$D(G(z))$ 表示 判别器 给 generate sample 为真的概率。</p>
<p>在左侧，Minimax 和 Maximum likehood 都趋向于饱和。也就是说，当一个样本很明显为 fake 时，cost 接近于 0.</p>
<p>似然估计还有个问题，cost 主要来源于 特别像真 的少部分样本，这也是不好的。需要用到 variance reduction techniques.</p>
<blockquote>
<p>Maximum likelihood also suffers from the problem that nearly all of the gradient comes from the right end of the curve, meaning that a very small number of samples dominate the gradient computation for each minibatch. This suggests that variance reduction techniques could be an important research area for improving the performance of GANs, especially GANs based on maximum likelihood.</p>
</blockquote>
<h2 id="The-DCGAN-architecture"><a href="#The-DCGAN-architecture" class="headerlink" title="The DCGAN architecture"></a>The DCGAN architecture</h2><p><img src="/2019/01/09/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-GAN-tutorial-NIPS-2016/11.png"></p>
<p><img src="/2019/01/09/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-GAN-tutorial-NIPS-2016/12.png"></p>
<p>DCGAN 的结构。</p>
<h2 id="GAN，NCE，-MLE-的对比"><a href="#GAN，NCE，-MLE-的对比" class="headerlink" title="GAN，NCE， MLE 的对比"></a>GAN，NCE， MLE 的对比</h2><p><img src="/2019/01/09/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-GAN-tutorial-NIPS-2016/13.png"></p>
<p>相同点：  </p>
<ul>
<li>MiniMax GAN 和 NCE 的 cost function 相同</li>
</ul>
<p>不同点：  </p>
<ul>
<li>更新策略不一样，GAN 和 MLE 都是梯度下降，而 MLE copies the density model learned inside the discriminator and converts it into a sampler to be used as the generator. NCE never updates the generator; it is just a fixed source of noise.</li>
</ul>
<h1 id="Tips-and-Tricks"><a href="#Tips-and-Tricks" class="headerlink" title="Tips and Tricks"></a>Tips and Tricks</h1><p>How to train a GAN: <a target="_blank" rel="noopener" href="https://github.com/soumith/ganhacks">https://github.com/soumith/ganhacks</a></p>
<h1 id="Research-Frontiers"><a href="#Research-Frontiers" class="headerlink" title="Research Frontiers"></a>Research Frontiers</h1><h2 id="Non-convergence"><a href="#Non-convergence" class="headerlink" title="Non-convergence"></a>Non-convergence</h2><h2 id="mode-collapse"><a href="#mode-collapse" class="headerlink" title="mode collapse"></a>mode collapse</h2><p><img src="/2019/01/09/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-GAN-tutorial-NIPS-2016/14.png"></p>
<h2 id><a href="#" class="headerlink" title></a></h2></div></article></div></div><div class="column column-left is-4-tablet is-4-desktop is-4-widescreen  order-1"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar" src="/img/avatar.png" alt="潘小榭"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">潘小榭</p><p class="is-size-6 is-block">Blogging is happier than writing essays!</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Beijing</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">Posts</p><a href="/archives"><p class="title">110</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Categories</p><a href="/categories"><p class="title">32</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Tags</p><a href="/tags"><p class="title">31</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/ppoffice" target="_blank" rel="noopener">Follow</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/ppoffice"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Facebook" href="https://facebook.com"><i class="fab fa-facebook"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Twitter" href="https://twitter.com"><i class="fab fa-twitter"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Dribbble" href="https://dribbble.com"><i class="fab fa-dribbble"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="RSS" href="/"><i class="fas fa-rss"></i></a></div></div></div><!--!--><div class="card widget" data-type="links"><div class="card-content"><div class="menu"><h3 class="menu-label">Links</h3><ul class="menu-list"><li><a class="level is-mobile" href="https://github.com/PanXiebit" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">github</span></span><span class="level-right"><span class="level-item tag">github.com</span></span></a></li></ul></div></div></div><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">Categories</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/C/"><span class="level-start"><span class="level-item">C++</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/CSAPP/"><span class="level-start"><span class="level-item">CSAPP</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/DRL/"><span class="level-start"><span class="level-item">DRL</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/GAN/"><span class="level-start"><span class="level-item">GAN</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li><li><a class="level is-mobile" href="/categories/GAN-RL/"><span class="level-start"><span class="level-item">GAN, RL</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/ML/"><span class="level-start"><span class="level-item">ML</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/NLP/"><span class="level-start"><span class="level-item">NLP</span></span><span class="level-end"><span class="level-item tag">14</span></span></a></li><li><a class="level is-mobile" href="/categories/TensorFlow/"><span class="level-start"><span class="level-item">TensorFlow</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/cs224d/"><span class="level-start"><span class="level-item">cs224d</span></span><span class="level-end"><span class="level-item tag">10</span></span></a></li><li><a class="level is-mobile" href="/categories/interview/"><span class="level-start"><span class="level-item">interview</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/machine-translation/"><span class="level-start"><span class="level-item">machine translation</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/python/"><span class="level-start"><span class="level-item">python</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/pytorch/"><span class="level-start"><span class="level-item">pytorch</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/reinforcement-learning/"><span class="level-start"><span class="level-item">reinforcement learning</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/transfer-learning/"><span class="level-start"><span class="level-item">transfer learning</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"><span class="level-start"><span class="level-item">数据结构与算法</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile" href="/categories/%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB/"><span class="level-start"><span class="level-item">文本分类</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"><span class="level-start"><span class="level-item">论文笔记</span></span><span class="level-end"><span class="level-item tag">34</span></span></a><ul><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/DL/"><span class="level-start"><span class="level-item">DL</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/ESA/"><span class="level-start"><span class="level-item">ESA</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/GAN/"><span class="level-start"><span class="level-item">GAN</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/MRC-and-QA/"><span class="level-start"><span class="level-item">MRC and QA</span></span><span class="level-end"><span class="level-item tag">7</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/Machine-Translation/"><span class="level-start"><span class="level-item">Machine Translation</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/NLP/"><span class="level-start"><span class="level-item">NLP</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/capsules/"><span class="level-start"><span class="level-item">capsules</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/data-augmentation/"><span class="level-start"><span class="level-item">data augmentation</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/dialogue-system/"><span class="level-start"><span class="level-item">dialogue system</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/language-model/"><span class="level-start"><span class="level-item">language model</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/machine-translation/"><span class="level-start"><span class="level-item">machine translation</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/open-set-recognition/"><span class="level-start"><span class="level-item">open set recognition</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/sentence-embedding/"><span class="level-start"><span class="level-item">sentence embedding</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/text-matching/"><span class="level-start"><span class="level-item">text matching</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li></ul></div></div></div><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">Recents</h3><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-05-05T02:03:16.000Z">2021-05-05</time></p><p class="title"><a href="/2021/05/05/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-contrastive-learning/">论文笔记-contrastive learning</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-04-29T01:07:08.000Z">2021-04-29</time></p><p class="title"><a href="/2021/04/29/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-video-transformer/">论文笔记-video transformer</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-04-29T01:05:10.000Z">2021-04-29</time></p><p class="title"><a href="/2021/04/29/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-dynamic-convolution-and-involution/">论文笔记-dynamic convolution and involution</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-04-16T07:48:48.000Z">2021-04-16</time></p><p class="title"><a href="/2021/04/16/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-unlikelihood-training/">论文笔记-unlikelihood training</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-04-12T08:16:35.000Z">2021-04-12</time></p><p class="title"><a href="/2021/04/12/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-Deformable-DETR/">论文笔记-DETR and Deformable DETR</a></p></div></article></div></div><div class="card widget" data-type="archives"><div class="card-content"><div class="menu"><h3 class="menu-label">Archives</h3><ul class="menu-list"><li><a class="level is-mobile" href="/archives/2021/05/"><span class="level-start"><span class="level-item">May 2021</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2021/04/"><span class="level-start"><span class="level-item">April 2021</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/archives/2019/11/"><span class="level-start"><span class="level-item">November 2019</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2019/10/"><span class="level-start"><span class="level-item">October 2019</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2019/08/"><span class="level-start"><span class="level-item">August 2019</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2019/06/"><span class="level-start"><span class="level-item">June 2019</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/archives/2019/05/"><span class="level-start"><span class="level-item">May 2019</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2019/04/"><span class="level-start"><span class="level-item">April 2019</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2019/03/"><span class="level-start"><span class="level-item">March 2019</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile" href="/archives/2019/02/"><span class="level-start"><span class="level-item">February 2019</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/archives/2019/01/"><span class="level-start"><span class="level-item">January 2019</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li><li><a class="level is-mobile" href="/archives/2018/12/"><span class="level-start"><span class="level-item">December 2018</span></span><span class="level-end"><span class="level-item tag">16</span></span></a></li><li><a class="level is-mobile" href="/archives/2018/11/"><span class="level-start"><span class="level-item">November 2018</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2018/10/"><span class="level-start"><span class="level-item">October 2018</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2018/09/"><span class="level-start"><span class="level-item">September 2018</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/archives/2018/08/"><span class="level-start"><span class="level-item">August 2018</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile" href="/archives/2018/07/"><span class="level-start"><span class="level-item">July 2018</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/archives/2018/06/"><span class="level-start"><span class="level-item">June 2018</span></span><span class="level-end"><span class="level-item tag">10</span></span></a></li><li><a class="level is-mobile" href="/archives/2018/05/"><span class="level-start"><span class="level-item">May 2018</span></span><span class="level-end"><span class="level-item tag">11</span></span></a></li><li><a class="level is-mobile" href="/archives/2018/04/"><span class="level-start"><span class="level-item">April 2018</span></span><span class="level-end"><span class="level-item tag">16</span></span></a></li><li><a class="level is-mobile" href="/archives/2018/03/"><span class="level-start"><span class="level-item">March 2018</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li></ul></div></div></div><div class="card widget" data-type="tags"><div class="card-content"><div class="menu"><h3 class="menu-label">Tags</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/C/"><span class="tag">C++</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/CSAPP/"><span class="tag">CSAPP</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/DL/"><span class="tag">DL</span><span class="tag">8</span></a></div><div class="control"><a class="tags has-addons" href="/tags/ESA/"><span class="tag">ESA</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/GAN/"><span class="tag">GAN</span><span class="tag">9</span></a></div><div class="control"><a class="tags has-addons" href="/tags/GAN%EF%BC%8CRL/"><span class="tag">GAN，RL</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/ML/"><span class="tag">ML</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/MRC-and-QA/"><span class="tag">MRC and QA</span><span class="tag">7</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Machine-Translation/"><span class="tag">Machine Translation</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/NLP/"><span class="tag">NLP</span><span class="tag">14</span></a></div><div class="control"><a class="tags has-addons" href="/tags/TensorFlow/"><span class="tag">TensorFlow</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Tensorflow/"><span class="tag">Tensorflow</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/ai-challenger/"><span class="tag">ai challenger</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/capsules/"><span class="tag">capsules</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/contrastive-learning/"><span class="tag">contrastive learning</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/cs224d/"><span class="tag">cs224d</span><span class="tag">10</span></a></div><div class="control"><a class="tags has-addons" href="/tags/data-augmentation/"><span class="tag">data augmentation</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/interview/"><span class="tag">interview</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/language-model/"><span class="tag">language model</span><span class="tag">6</span></a></div><div class="control"><a class="tags has-addons" href="/tags/machine-translation/"><span class="tag">machine translation</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/open-set-recognition/"><span class="tag">open set recognition</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/python/"><span class="tag">python</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/pytorch/"><span class="tag">pytorch</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/reinforcement-learning/"><span class="tag">reinforcement learning</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/sentence-embedding/"><span class="tag">sentence embedding</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/sentiment-classification/"><span class="tag">sentiment classification</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/text-matching/"><span class="tag">text matching</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/transfer-learning/"><span class="tag">transfer learning</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/vision-transformer/"><span class="tag">vision transformer</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"><span class="tag">数据结构与算法</span><span class="tag">6</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB/"><span class="tag">文本分类</span><span class="tag">8</span></a></div></div></div></div></div><div class="card widget" data-type="subscribe-email"><div class="card-content"><div class="menu"><h3 class="menu-label">Subscribe for updates</h3><form action="https://feedburner.google.com/fb/a/mailverify" method="post" target="popupwindow" onsubmit="window.open(&#039;https://feedburner.google.com/fb/a/mailverify?uri=&#039;,&#039;popupwindow&#039;,&#039;scrollbars=yes,width=550,height=520&#039;);return true"><input type="hidden" value="" name="uri"><input type="hidden" name="loc" value="en_US"><div class="field has-addons"><div class="control has-icons-left is-expanded"><input class="input" name="email" type="email" placeholder="Email"><span class="icon is-small is-left"><i class="fas fa-envelope"></i></span></div><div class="control"><input class="button" type="submit" value="Subscribe"></div></div></form></div></div></div></div><!--!--></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/logo.svg" alt="潘小榭" height="28"></a><p class="is-size-7"><span>&copy; 2021 Xie Pan</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("default");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "This website uses cookies to improve your experience.",
          dismiss: "Got it!",
          allow: "Allow cookies",
          deny: "Decline",
          link: "Learn more",
          policy: "Cookie Policy",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.5/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script></body></html>