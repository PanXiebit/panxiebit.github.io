<!doctype html>
<html lang="zh"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>从0开始GAN-6-pretraining for NLG - 潘小榭</title><link rel="manifest" href="/manifest.json"><meta name="theme-color" content="black"><meta name="application-name" content="潘晓榭"><meta name="msapplication-TileImage" content="/img/avatar.png"><meta name="msapplication-TileColor" content="black"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="潘晓榭"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="description" content="related papers BERT     BERT has a Mouth, and It Must Speak: BERT as a Markov Random Field Language Model      GPT&amp;#x2F;GPT-2.0    MASS: Masked Sequence to Sequence Pre-training for Language Generation"><meta property="og:type" content="blog"><meta property="og:title" content="潘晓榭"><meta property="og:url" content="https://github.com/PanXiebit"><meta property="og:site_name" content="潘晓榭"><meta property="og:description" content="related papers BERT     BERT has a Mouth, and It Must Speak: BERT as a Markov Random Field Language Model      GPT&amp;#x2F;GPT-2.0    MASS: Masked Sequence to Sequence Pre-training for Language Generation"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://www.qt86.com/cache/1625298592_187938.png"><meta property="article:published_time" content="2019-06-30T07:43:31.000Z"><meta property="article:modified_time" content="2021-06-29T08:12:08.539Z"><meta property="article:author" content="潘晓榭"><meta property="article:tag" content="GAN"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="https://www.qt86.com/cache/1625298592_187938.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"http://www.panxiaoxie.cn/2019/06/30/%E4%BB%8E0%E5%BC%80%E5%A7%8BGAN-6-pretraining-for-NLG/"},"headline":"从0开始GAN-6-pretraining for NLG","image":["http://www.panxiaoxie.cn/2019/06/30/%E4%BB%8E0%E5%BC%80%E5%A7%8BGAN-6-pretraining-for-NLG/sample_data.png","http://www.panxiaoxie.cn/2019/06/30/%E4%BB%8E0%E5%BC%80%E5%A7%8BGAN-6-pretraining-for-NLG/mlm.png","http://www.panxiaoxie.cn/2019/06/30/%E4%BB%8E0%E5%BC%80%E5%A7%8BGAN-6-pretraining-for-NLG/tlm.png","http://www.panxiaoxie.cn/2019/06/30/%E4%BB%8E0%E5%BC%80%E5%A7%8BGAN-6-pretraining-for-NLG/asymptotic_distill.png","http://www.panxiaoxie.cn/2019/06/30/%E4%BB%8E0%E5%BC%80%E5%A7%8BGAN-6-pretraining-for-NLG/switch.png","http://www.panxiaoxie.cn/2019/06/30/%E4%BB%8E0%E5%BC%80%E5%A7%8BGAN-6-pretraining-for-NLG/result.png"],"datePublished":"2019-06-30T07:43:31.000Z","dateModified":"2021-06-29T08:12:08.539Z","author":{"@type":"Person","name":"Xie Pan"},"publisher":{"@type":"Organization","name":"潘小榭","logo":{"@type":"ImageObject","url":"http://www.panxiaoxie.cn/img/panxiaoxie.png"}},"description":"related papers BERT     BERT has a Mouth, and It Must Speak: BERT as a Markov Random Field Language Model      GPT&#x2F;GPT-2.0    MASS: Masked Sequence to Sequence Pre-training for Language Generation"}</script><link rel="canonical" href="http://www.panxiaoxie.cn/2019/06/30/%E4%BB%8E0%E5%BC%80%E5%A7%8BGAN-6-pretraining-for-NLG/"><link rel="icon" href="/img/avatar.png"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/css/justifiedGallery.min.css"><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script><!--!--><!--!--><meta name="generator" content="Hexo 5.4.0"></head><body class="is-2-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/panxiaoxie.png" alt="潘小榭" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">主页</a><a class="navbar-item" href="/archives">归档</a><a class="navbar-item" href="/categories">分类</a><a class="navbar-item" href="/tags">标签</a><a class="navbar-item" href="/about">关于我</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/PanXiebit"><i class="fab fa-github"></i></a><a class="navbar-item search" title="搜索" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-8-widescreen"><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2019-06-30T07:43:31.000Z" title="2019/6/30 下午3:43:31">2019-06-30</time>发表</span><span class="level-item"><time dateTime="2021-06-29T08:12:08.539Z" title="2021/6/29 下午4:12:08">2021-06-29</time>更新</span><span class="level-item"><a class="link-muted" href="/categories/GAN/">GAN</a></span><span class="level-item">10 分钟读完 (大约1521个字)</span></div></div><h1 class="title is-3 is-size-4-mobile">从0开始GAN-6-pretraining for NLG</h1><div class="content"><h3 id="related-papers"><a href="#related-papers" class="headerlink" title="related papers"></a>related papers</h3><ul>
<li><p><a href>BERT</a>   </p>
</li>
<li><p><a href>BERT has a Mouth, and It Must Speak: BERT as a Markov Random Field Language Model</a>    </p>
</li>
<li><p><a href>GPT/GPT-2.0</a>  </p>
</li>
<li><p><a href>MASS: Masked Sequence to Sequence Pre-training for Language Generation</a>   </p>
</li>
<li><p><a href>Unified Language Model Pre-training for Natural Language Understanding and Generation</a>      </p>
</li>
<li><p><a href>Pretraining for Conditional Generation with Pseudo Self Attention</a>    </p>
</li>
<li><p><a href>Transformer-XL</a>       </p>
</li>
<li><p><a href>XLNet</a>     </p>
</li>
<li><p><a href>Defending Against Neural Fake News</a></p>
</li>
<li><p><a href>ERNIE</a>  </p>
</li>
<li><p><a href>WWM</a>  </p>
</li>
<li><p><a href>SpanBERT</a></p>
</li>
</ul>
<h3 id><a href="#" class="headerlink" title></a></h3><h3 id="cross-lingual-word-embedding"><a href="#cross-lingual-word-embedding" class="headerlink" title="cross-lingual word embedding"></a>cross-lingual word embedding</h3><p><a href>A survey of cross-lingual word embedding models, Ruder et al.2017</a>  </p>
<p><a href>Word translation without parallel data. Conneau et al.2017</a>  </p>
<p><a href>Massively multilingual sentence embeddings for zero-shot cross-lingual transfer and beyond. Artetxe et al.2018</a>  </p>
<h3 id="contextual-word-embedding"><a href="#contextual-word-embedding" class="headerlink" title="contextual word embedding"></a>contextual word embedding</h3><p><a href>ELMo</a>  </p>
<p><a href>Word2vec</a>  </p>
<p><a href>Glove</a>  </p>
<p><a href>GPT</a>  </p>
<p><a href>ULMFT: Universal language model fine-tuning for text classificatio</a>  </p>
<p><a href>Cross-lingual language model pretraining</a>  </p>
<p><a href>Polyglot contextual representations im- prove crosslingual transfer</a>  </p>
<h3 id="pre-trained-for-NMT"><a href="#pre-trained-for-NMT" class="headerlink" title="pre-trained for NMT"></a>pre-trained for NMT</h3><p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1908.05672">Towards Making the Most of BERT in Neural Machine Translation</a></p>
<p><a href>Unsupervised Pretraining for Sequence to Sequence Learning</a></p>
<p><a href>When and Why are Pre-trained Word Embeddings Useful for Neural Machine Translation?</a></p>
<p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1901.07291">Cross-lingual Language Model Pretraining</a>  </p>
<h1 id="XLM"><a href="#XLM" class="headerlink" title="XLM"></a>XLM</h1><p>paper: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1901.07291">Cross-lingual Language Model Pretraining</a>  </p>
<p>作者提出了两种方法来学习 cross-lingual 语言模型。其中一种是仅基于 monolingual data, 另一种是基于平行语料。在 cross-lingal 相关的任务上都有很大的提升。比如 XNLI，unsupervised machine translation, 以及 supervised machine tranlsation.</p>
<p>现有的在NLP领域的发展主要是围绕英文进行的，一些start-of-the-art或者NLP任务的benchmarks都是以英文为基础的。其他的一些语言受限于语料的问题，发展相对缓慢。近期随着cross-lingual sentence representation的发展，消除English-centric bias,并且构建一个通用的cross-lingual encoder来讲任何语言的sentence编码到共享的embedding空间成为可能。</p>
<p><strong>Shared sub-word vocabulary</strong></p>
<p>使用 bpe,并且不同的language共享词表.</p>
<blockquote>
<p>this greatly improves the alignment of embedding spaces across languages that share either the same alphabet or anchor tokens such as digits (Smith et al., 2017) or proper nouns.  </p>
</blockquote>
<p>共享词表能显著提升那些具有相同字母表或者anchor token(数字或专有名词)的语言之间的向量空间的对齐。</p>
<p>作者先从不同语言的monolingual data中筛选出部分data，然后学习bpe splits.</p>
<blockquote>
<p>Sentences are sampled according to a multinomial distribution with probabilities ${q_i}_{i=1…N}$, where:</p>
</blockquote>
<p><img src="/2019/06/30/%E4%BB%8E0%E5%BC%80%E5%A7%8BGAN-6-pretraining-for-NLG/sample_data.png"></p>
<p>其中 $n_i$ 表示第 i 中语言中sentence的总数。 $\sum_{k=1}^nn_k$ 表示N种语言所有的sentence的总数。$p_i$ 则表示第 i 中语言sample的概率。设定 $\alpha=0.5$，这样能增加 low-resource 的比例，从而减轻 bias to high-resource language.</p>
<p>作者总共提出了三种 language model. 接下来一一介绍：</p>
<p><strong>Causal Language Modeling (CLM)</strong>  </p>
<p>$p(w_t|w_1,…,w_{t-1},\theta)$</p>
<p>也就是普通的 aotu-regressive 语言模型。</p>
<p><a target="_blank" rel="noopener" href="https://www.aaai.org/ojs/index.php/AAAI/article/view/4182">Character-Level Language Modeling with Deeper Self-Attention</a> 这篇paper使用的self-attention, 我们知道self-attention 不像rnn那样具有hidden state的概率，这篇paper把上一个batch作为下一个batch的context，有点类似于 transformer-XL,但是这对于cross-lingual不太适合，所以这里的 CLM 与传统的language model完全一致。</p>
<p><strong>Masked Language Modeling (MLM)</strong></p>
<p><img src="/2019/06/30/%E4%BB%8E0%E5%BC%80%E5%A7%8BGAN-6-pretraining-for-NLG/mlm.png"></p>
<p>与 BERT 中MLM的区别：  </p>
<blockquote>
<p>Differences between our approach and the MLM of Devlin et al. (2018) include the use of text streams of an arbitrary number of sentences (truncated at 256 tokens) instead of pairs of sentences.  </p>
</blockquote>
<p>文本 stream 是任意数量的sentences，而不是pairs.（这里的pairs in BERT应该指的是 next sentence prediction.）</p>
<p>在筛选用来mask的词时，为了处理 rare word 和 frequent word(punctuation or stop words) 的不均衡问题:    </p>
<blockquote>
<p>tokens in a text stream are sampled according to a multinomial distribution, whose weights are proportional to the square root of their invert frequencies.</p>
</blockquote>
<p><strong>Translation Language Modeling (TLM)</strong></p>
<p><img src="/2019/06/30/%E4%BB%8E0%E5%BC%80%E5%A7%8BGAN-6-pretraining-for-NLG/tlm.png"></p>
<p>在预测一个 masked english word 的同时，不仅可以attend english context，也可以 attend franch translation.</p>
<p><strong>Cross-lingual Language Models</strong></p>
<p>如何使用这三种语言模型，CLM 和 MLM 在单语上进行训练。 TLM 在平行语料上训练。TLM 在使用时是联合 MLM 一起训练的，迭代优化两个目标函数。</p>
<blockquote>
<p>In this work, we consider cross-lingual language model pretraining with either CLM, MLM, or MLM used in combination with TLM. For the CLM and MLM objectives, we train the model with batches of 64 streams of continuous sentences composed of 256 tokens. At each iteration, a batch is composed of sentences coming from the same language, which is sampled from the distribution ${q_i}_{i=1…N}$ above, with α = 0.7. When TLM is used in combination with MLM, we alternate between these two objectives, and sample the language pairs with a similar approach.</p>
</blockquote>
<h1 id="CTNMT"><a href="#CTNMT" class="headerlink" title="CTNMT"></a>CTNMT</h1><p>paper: [Towards Making the Most of BERT in Neural Machine Translation</p>
<p>Jiacheng](<a target="_blank" rel="noopener" href="https://arxiv.org/abs/1908.05672">https://arxiv.org/abs/1908.05672</a>)</p>
<p>ByteDance 的一篇paper.</p>
<p>前人的研究中我们发现，BERT pretrian 对NMT几乎没有提升。作者认为其原因是，NMT 相对其他linguistic的任务，训练的steps会多很多，比如NMT一般是10万step，而 POS tagging只需要几百步。这使得在训练过程中，参数的更新太多导致 catastrophic forgetting problem. 也就是 BERT 训练得到的knowledge并不能给NMT代来提升。</p>
<p>于是乎，作者认为只是大家没有好好利用BERT而已，像我们这样搞, BERT还是能对NMT有提升的。然后提出了三种techniques:</p>
<p><strong>Asymptotic Distillation</strong>  </p>
<p><img src="/2019/06/30/%E4%BB%8E0%E5%BC%80%E5%A7%8BGAN-6-pretraining-for-NLG/asymptotic_distill.png"></p>
<p>渐近蒸馏，主要是用来解决 catastrophic forgetting 这一问题的，和这篇paper “<a href>Overcoming Catastrophic Forgetting During Domain Adaptation of Neural Machine Translation</a>“ 相似，也是采用的 Elastic Weight Consolidation(EWC) 的方法，对weight采用MSE的约束。</p>
<p>$$L_{kd}=-||\hat h^{lm}-h_l||^2_2$$</p>
<p>$$L=\alpha\cdot L_{nmt}+(1-\alpha)\cdot L_{kd}$$</p>
<p>其中 $L_{kd}$ 是正则化项，$\hat h^{lm}$ 是经过BERT编码之后的 sentence embedding. $h_l$ 则是NMT的encoded之后的 sentence embedding. 作者都使用的最后一层的表示。在后续实验中，作者也测试了不同层的表示进行约束。</p>
<p><strong>Dynamic Switch</strong></p>
<p>动态开关。</p>
<p><img src="/2019/06/30/%E4%BB%8E0%E5%BC%80%E5%A7%8BGAN-6-pretraining-for-NLG/switch.png"></p>
<p>就是GRU中的gate机制。</p>
<p>$$g = \sigma(Wh^{lm} + Uh^{nmt} + b)$$</p>
<p>$$h=g\odot h^{lm}+(1-g)\odot h^{nmt}$$</p>
<p><strong>Rate-scheduled learning</strong></p>
<p>slanted triangular learning, 斜三角学习率。最开始提出是在 <a href>ULMFT: Universal language model fine-tuning for text classificatio</a> 这篇论文中。</p>
<p>$$\theta_t=\theta_{t-1}-\eta\nabla_{\theta}L(\theta)$$</p>
<p>对 NMT 和 LM 对应的参数使用不同的学习率，但是都采用这种scheduled学习率.</p>
<p><strong>Result</strong></p>
<p><img src="/2019/06/30/%E4%BB%8E0%E5%BC%80%E5%A7%8BGAN-6-pretraining-for-NLG/result.png"></p>
</div><div class="article-licensing box"><div class="licensing-title"><p>从0开始GAN-6-pretraining for NLG</p><p><a href="http://www.panxiaoxie.cn/2019/06/30/从0开始GAN-6-pretraining-for-NLG/">http://www.panxiaoxie.cn/2019/06/30/从0开始GAN-6-pretraining-for-NLG/</a></p></div><div class="licensing-meta level is-mobile"><div class="level-left"><div class="level-item is-narrow"><div><h6>作者</h6><p>Xie Pan</p></div></div><div class="level-item is-narrow"><div><h6>发布于</h6><p>2019-06-30</p></div></div><div class="level-item is-narrow"><div><h6>更新于</h6><p>2021-06-29</p></div></div><div class="level-item is-narrow"><div><h6>许可协议</h6><p><a class="icons" rel="noopener" target="_blank" title="Creative Commons" href="https://creativecommons.org/"><i class="icon fab fa-creative-commons"></i></a><a class="icons" rel="noopener" target="_blank" title="Attribution" href="https://creativecommons.org/licenses/by/4.0/"><i class="icon fab fa-creative-commons-by"></i></a><a class="icons" rel="noopener" target="_blank" title="Noncommercial" href="https://creativecommons.org/licenses/by-nc/4.0/"><i class="icon fab fa-creative-commons-nc"></i></a></p></div></div></div></div></div><div class="article-tags is-size-7 mb-4"><span class="mr-2">#</span><a class="link-muted mr-2" rel="tag" href="/tags/GAN/">GAN</a></div><!--!--></article></div><!--!--><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/2019/08/12/UCB-cs294-policy-gradient/"><i class="level-item fas fa-chevron-left"></i><span class="level-item">UCB-cs294-policy gradient</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/2019/06/29/%E4%BB%8E0%E5%BC%80%E5%A7%8BGAN-5-decoding/"><span class="level-item">从0开始GAN-5-NAT Decoding</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><div class="card"><div class="card-content"><h3 class="title is-5">评论</h3><div id="disqus_thread"><noscript>Please enable JavaScript to view the <a target="_blank" rel="noopener" href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript></div><script>var disqus_config = function () {
            this.page.url = 'http://www.panxiaoxie.cn/2019/06/30/%E4%BB%8E0%E5%BC%80%E5%A7%8BGAN-6-pretraining-for-NLG/';
            this.page.identifier = '2019/06/30/从0开始GAN-6-pretraining-for-NLG/';
        };
        (function() {
            var d = document, s = d.createElement('script');  
            s.src = '//' + 'panxie' + '.disqus.com/embed.js';
            s.setAttribute('data-timestamp', +new Date());
            (d.head || d.body).appendChild(s);
        })();</script></div></div></div><div class="column column-left is-4-tablet is-4-desktop is-4-widescreen  order-1"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar" src="/img/avatar.png" alt="潘晓榭"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">潘晓榭</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Beijing, China</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">文章</p><a href="/archives"><p class="title">116</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">分类</p><a href="/categories"><p class="title">39</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">标签</p><a href="/tags"><p class="title">36</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/PanXiebit" target="_blank" rel="noopener">关注我</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/PanXiebit"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Email" href="/ftdpanxie@gmail.com"><i class="fa fa-envelope"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="RSS" href="/"><i class="fas fa-rss"></i></a></div></div></div><!--!--><div class="card widget" data-type="links"><div class="card-content"><div class="menu"><h3 class="menu-label">链接</h3><ul class="menu-list"><li><a class="level is-mobile" href="https://github.com/PanXiebit" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">github</span></span><span class="level-right"><span class="level-item tag">github.com</span></span></a></li><li><a class="level is-mobile" href="ftdpanxie@gmail.com" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">email</span></span><span class="level-right"><span class="level-item tag">ftdpanxie@gmail.com</span></span></a></li></ul></div></div></div><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">分类</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/C/"><span class="level-start"><span class="level-item">C++</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/CSAPP/"><span class="level-start"><span class="level-item">CSAPP</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/DRL/"><span class="level-start"><span class="level-item">DRL</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/GAN/"><span class="level-start"><span class="level-item">GAN</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li><li><a class="level is-mobile" href="/categories/GAN-RL/"><span class="level-start"><span class="level-item">GAN, RL</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/ML/"><span class="level-start"><span class="level-item">ML</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/NLP/"><span class="level-start"><span class="level-item">NLP</span></span><span class="level-end"><span class="level-item tag">14</span></span></a></li><li><a class="level is-mobile" href="/categories/TensorFlow/"><span class="level-start"><span class="level-item">TensorFlow</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/cs224d/"><span class="level-start"><span class="level-item">cs224d</span></span><span class="level-end"><span class="level-item tag">10</span></span></a></li><li><a class="level is-mobile" href="/categories/generation/"><span class="level-start"><span class="level-item">generation</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/interview/"><span class="level-start"><span class="level-item">interview</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/leetcode/"><span class="level-start"><span class="level-item">leetcode</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/machine-translation/"><span class="level-start"><span class="level-item">machine translation</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/python/"><span class="level-start"><span class="level-item">python</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/pytorch/"><span class="level-start"><span class="level-item">pytorch</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/reinforcement-learning/"><span class="level-start"><span class="level-item">reinforcement learning</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/sign-language-recognition/"><span class="level-start"><span class="level-item">sign language recognition</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/transfer-learning/"><span class="level-start"><span class="level-item">transfer learning</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"><span class="level-start"><span class="level-item">数据结构与算法</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile" href="/categories/%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB/"><span class="level-start"><span class="level-item">文本分类</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"><span class="level-start"><span class="level-item">论文笔记</span></span><span class="level-end"><span class="level-item tag">40</span></span></a><ul><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/DL/"><span class="level-start"><span class="level-item">DL</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/ESA/"><span class="level-start"><span class="level-item">ESA</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/GAN/"><span class="level-start"><span class="level-item">GAN</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/MRC-and-QA/"><span class="level-start"><span class="level-item">MRC and QA</span></span><span class="level-end"><span class="level-item tag">7</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/Machine-Translation/"><span class="level-start"><span class="level-item">Machine Translation</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/NLP/"><span class="level-start"><span class="level-item">NLP</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/Transformer/"><span class="level-start"><span class="level-item">Transformer</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/capsules/"><span class="level-start"><span class="level-item">capsules</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/computer-vision/"><span class="level-start"><span class="level-item">computer vision</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/constrast-learning/"><span class="level-start"><span class="level-item">constrast learning</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/data-augmentation/"><span class="level-start"><span class="level-item">data augmentation</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/dialogue-system/"><span class="level-start"><span class="level-item">dialogue system</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/language-model/"><span class="level-start"><span class="level-item">language model</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/machine-translation/"><span class="level-start"><span class="level-item">machine translation</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/open-set-recognition/"><span class="level-start"><span class="level-item">open set recognition</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/sentence-embedding/"><span class="level-start"><span class="level-item">sentence embedding</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/text-matching/"><span class="level-start"><span class="level-item">text matching</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/vision-language/"><span class="level-start"><span class="level-item">vision-language</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li></ul></div></div></div><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">最新文章</h3><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-09-12T10:38:37.000Z">2021-09-12</time></p><p class="title"><a href="/2021/09/12/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-Discrete-Latent-Variables-Based-Generation/">论文笔记-Discrete Latent Variables Based Generation</a></p><p class="categories"><a href="/categories/generation/">generation</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-08-22T03:28:02.000Z">2021-08-22</time></p><p class="title"><a href="/2021/08/22/leetcode/">leetcode</a></p><p class="categories"><a href="/categories/leetcode/">leetcode</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-07-23T11:13:20.000Z">2021-07-23</time></p><p class="title"><a href="/2021/07/23/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-Clip/">论文笔记-Clip!!!</a></p><p class="categories"><a href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/">论文笔记</a> / <a href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/vision-language/">vision-language</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-07-11T07:58:30.000Z">2021-07-11</time></p><p class="title"><a href="/2021/07/11/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-sign-language-recognition-and-translation/">论文笔记-sign language recognition and translation</a></p><p class="categories"><a href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/">论文笔记</a> / <a href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/computer-vision/">computer vision</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-07-02T04:37:58.000Z">2021-07-02</time></p><p class="title"><a href="/2021/07/02/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-constrast-learning-in-NLP/">论文笔记-constrast learning in NLP</a></p><p class="categories"><a href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/">论文笔记</a> / <a href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/constrast-learning/">constrast learning</a></p></div></article></div></div><div class="card widget" data-type="archives"><div class="card-content"><div class="menu"><h3 class="menu-label">归档</h3><ul class="menu-list"><li><a class="level is-mobile" href="/archives/2021/09/"><span class="level-start"><span class="level-item">九月 2021</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2021/08/"><span class="level-start"><span class="level-item">八月 2021</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2021/07/"><span class="level-start"><span class="level-item">七月 2021</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/archives/2021/05/"><span class="level-start"><span class="level-item">五月 2021</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2021/04/"><span class="level-start"><span class="level-item">四月 2021</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/archives/2020/09/"><span class="level-start"><span class="level-item">九月 2020</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2019/11/"><span class="level-start"><span class="level-item">十一月 2019</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2019/10/"><span class="level-start"><span class="level-item">十月 2019</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2019/08/"><span class="level-start"><span class="level-item">八月 2019</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2019/06/"><span class="level-start"><span class="level-item">六月 2019</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/archives/2019/05/"><span class="level-start"><span class="level-item">五月 2019</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2019/04/"><span class="level-start"><span class="level-item">四月 2019</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2019/03/"><span class="level-start"><span class="level-item">三月 2019</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile" href="/archives/2019/02/"><span class="level-start"><span class="level-item">二月 2019</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/archives/2019/01/"><span class="level-start"><span class="level-item">一月 2019</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li><li><a class="level is-mobile" href="/archives/2018/12/"><span class="level-start"><span class="level-item">十二月 2018</span></span><span class="level-end"><span class="level-item tag">16</span></span></a></li><li><a class="level is-mobile" href="/archives/2018/11/"><span class="level-start"><span class="level-item">十一月 2018</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2018/10/"><span class="level-start"><span class="level-item">十月 2018</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2018/09/"><span class="level-start"><span class="level-item">九月 2018</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/archives/2018/08/"><span class="level-start"><span class="level-item">八月 2018</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile" href="/archives/2018/07/"><span class="level-start"><span class="level-item">七月 2018</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/archives/2018/06/"><span class="level-start"><span class="level-item">六月 2018</span></span><span class="level-end"><span class="level-item tag">10</span></span></a></li><li><a class="level is-mobile" href="/archives/2018/05/"><span class="level-start"><span class="level-item">五月 2018</span></span><span class="level-end"><span class="level-item tag">11</span></span></a></li><li><a class="level is-mobile" href="/archives/2018/04/"><span class="level-start"><span class="level-item">四月 2018</span></span><span class="level-end"><span class="level-item tag">16</span></span></a></li><li><a class="level is-mobile" href="/archives/2018/03/"><span class="level-start"><span class="level-item">三月 2018</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li></ul></div></div></div><div class="card widget" data-type="tags"><div class="card-content"><div class="menu"><h3 class="menu-label">标签</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/C/"><span class="tag">C++</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/CSAPP/"><span class="tag">CSAPP</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/DL/"><span class="tag">DL</span><span class="tag">8</span></a></div><div class="control"><a class="tags has-addons" href="/tags/ESA/"><span class="tag">ESA</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/GAN/"><span class="tag">GAN</span><span class="tag">9</span></a></div><div class="control"><a class="tags has-addons" href="/tags/GAN%EF%BC%8CRL/"><span class="tag">GAN，RL</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/ML/"><span class="tag">ML</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/MRC-and-QA/"><span class="tag">MRC and QA</span><span class="tag">7</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Machine-Translation/"><span class="tag">Machine Translation</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/NLP/"><span class="tag">NLP</span><span class="tag">14</span></a></div><div class="control"><a class="tags has-addons" href="/tags/TensorFlow/"><span class="tag">TensorFlow</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Tensorflow/"><span class="tag">Tensorflow</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/ai-challenger/"><span class="tag">ai challenger</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/capsules/"><span class="tag">capsules</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/contrastive-learning/"><span class="tag">contrastive learning</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/cs224d/"><span class="tag">cs224d</span><span class="tag">10</span></a></div><div class="control"><a class="tags has-addons" href="/tags/data-augmentation/"><span class="tag">data augmentation</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/generation/"><span class="tag">generation</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/interview/"><span class="tag">interview</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/language-model/"><span class="tag">language model</span><span class="tag">6</span></a></div><div class="control"><a class="tags has-addons" href="/tags/leetcode/"><span class="tag">leetcode</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/machine-translation/"><span class="tag">machine translation</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/open-set-recognition/"><span class="tag">open set recognition</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/python/"><span class="tag">python</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/pytorch/"><span class="tag">pytorch</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/reinforcement-learning/"><span class="tag">reinforcement learning</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/sentence-embedding/"><span class="tag">sentence embedding</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/sentiment-classification/"><span class="tag">sentiment classification</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/sign-language/"><span class="tag">sign language</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/sign-language-recognition/"><span class="tag">sign language recognition</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/text-matching/"><span class="tag">text matching</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/transfer-learning/"><span class="tag">transfer learning</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/vision-transformer/"><span class="tag">vision transformer</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/vision-language/"><span class="tag">vision-language</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"><span class="tag">数据结构与算法</span><span class="tag">6</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB/"><span class="tag">文本分类</span><span class="tag">8</span></a></div></div></div></div></div><div class="card widget" data-type="subscribe-email"><div class="card-content"><div class="menu"><h3 class="menu-label">订阅更新</h3><form action="https://feedburner.google.com/fb/a/mailverify" method="post" target="popupwindow" onsubmit="window.open(&#039;https://feedburner.google.com/fb/a/mailverify?uri=&#039;,&#039;popupwindow&#039;,&#039;scrollbars=yes,width=550,height=520&#039;);return true"><input type="hidden" value="" name="uri"><input type="hidden" name="loc" value="en_US"><div class="field has-addons"><div class="control has-icons-left is-expanded"><input class="input" name="email" type="email" placeholder="Email"><span class="icon is-small is-left"><i class="fas fa-envelope"></i></span></div><div class="control"><input class="button" type="submit" value="订阅"></div></div></form></div></div></div></div><!--!--></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/panxiaoxie.png" alt="潘小榭" height="28"></a><p class="is-size-7"><span>&copy; 2021 Xie Pan</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("zh-CN");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="回到顶端" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "此网站使用Cookie来改善您的体验。",
          dismiss: "知道了！",
          allow: "允许使用Cookie",
          deny: "拒绝",
          link: "了解更多",
          policy: "Cookie政策",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.5/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="想要查找什么..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"想要查找什么...","untitled":"(无标题)","posts":"文章","pages":"页面","categories":"分类","tags":"标签"});
        });</script></body></html>