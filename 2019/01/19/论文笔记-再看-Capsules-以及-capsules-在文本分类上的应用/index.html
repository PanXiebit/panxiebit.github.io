<!doctype html>
<html lang="zh"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>论文笔记-再看 Capsules 以及 capsules 在文本分类上的应用 - 潘小榭</title><link rel="manifest" href="/manifest.json"><meta name="theme-color" content="black"><meta name="application-name" content="panxiaoxie"><meta name="msapplication-TileImage" content="/img/avatar.png"><meta name="msapplication-TileColor" content="black"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="panxiaoxie"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="description" content="参考：    blog: 苏剑林：揭开迷雾，来一顿美味的Capsule盛宴    paper：Investigating Capsule Networks with Dynamic Routing for Text Classification   再看 Capsules苏剑林同学在他的那篇博客中对 capsule 的理解很有道理，胶囊也就是用 “vector in vector out” 取代了"><meta property="og:type" content="blog"><meta property="og:title" content="panxiaoxie"><meta property="og:url" content="https://github.com/PanXiebit"><meta property="og:site_name" content="panxiaoxie"><meta property="og:description" content="参考：    blog: 苏剑林：揭开迷雾，来一顿美味的Capsule盛宴    paper：Investigating Capsule Networks with Dynamic Routing for Text Classification   再看 Capsules苏剑林同学在他的那篇博客中对 capsule 的理解很有道理，胶囊也就是用 “vector in vector out” 取代了"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://www.qt86.com/cache/1625298592_187938.png"><meta property="article:published_time" content="2019-01-19T13:28:17.000Z"><meta property="article:modified_time" content="2021-07-06T07:11:06.686Z"><meta property="article:author" content="panxiaoxie"><meta property="article:tag" content="capsules"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="https://www.qt86.com/cache/1625298592_187938.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"http://www.panxiaoxie.cn/2019/01/19/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-%E5%86%8D%E7%9C%8B-Capsules-%E4%BB%A5%E5%8F%8A-capsules-%E5%9C%A8%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E4%B8%8A%E7%9A%84%E5%BA%94%E7%94%A8/"},"headline":"论文笔记-再看 Capsules 以及 capsules 在文本分类上的应用","image":["http://www.panxiaoxie.cn/2019/01/19/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-%E5%86%8D%E7%9C%8B-Capsules-%E4%BB%A5%E5%8F%8A-capsules-%E5%9C%A8%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E4%B8%8A%E7%9A%84%E5%BA%94%E7%94%A8/09.png","http://www.panxiaoxie.cn/2019/01/19/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-%E5%86%8D%E7%9C%8B-Capsules-%E4%BB%A5%E5%8F%8A-capsules-%E5%9C%A8%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E4%B8%8A%E7%9A%84%E5%BA%94%E7%94%A8/02.png","http://www.panxiaoxie.cn/2019/01/19/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-%E5%86%8D%E7%9C%8B-Capsules-%E4%BB%A5%E5%8F%8A-capsules-%E5%9C%A8%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E4%B8%8A%E7%9A%84%E5%BA%94%E7%94%A8/03.png","http://www.panxiaoxie.cn/2019/01/19/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-%E5%86%8D%E7%9C%8B-Capsules-%E4%BB%A5%E5%8F%8A-capsules-%E5%9C%A8%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E4%B8%8A%E7%9A%84%E5%BA%94%E7%94%A8/01.png","http://www.panxiaoxie.cn/2019/01/19/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-%E5%86%8D%E7%9C%8B-Capsules-%E4%BB%A5%E5%8F%8A-capsules-%E5%9C%A8%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E4%B8%8A%E7%9A%84%E5%BA%94%E7%94%A8/04.png","http://www.panxiaoxie.cn/2019/01/19/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-%E5%86%8D%E7%9C%8B-Capsules-%E4%BB%A5%E5%8F%8A-capsules-%E5%9C%A8%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E4%B8%8A%E7%9A%84%E5%BA%94%E7%94%A8/05.png","http://www.panxiaoxie.cn/2019/01/19/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-%E5%86%8D%E7%9C%8B-Capsules-%E4%BB%A5%E5%8F%8A-capsules-%E5%9C%A8%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E4%B8%8A%E7%9A%84%E5%BA%94%E7%94%A8/06.png","http://www.panxiaoxie.cn/2019/01/19/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-%E5%86%8D%E7%9C%8B-Capsules-%E4%BB%A5%E5%8F%8A-capsules-%E5%9C%A8%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E4%B8%8A%E7%9A%84%E5%BA%94%E7%94%A8/07.png","http://www.panxiaoxie.cn/2019/01/19/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-%E5%86%8D%E7%9C%8B-Capsules-%E4%BB%A5%E5%8F%8A-capsules-%E5%9C%A8%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E4%B8%8A%E7%9A%84%E5%BA%94%E7%94%A8/08.png","http://www.panxiaoxie.cn/2019/01/19/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-%E5%86%8D%E7%9C%8B-Capsules-%E4%BB%A5%E5%8F%8A-capsules-%E5%9C%A8%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E4%B8%8A%E7%9A%84%E5%BA%94%E7%94%A8/10.png"],"datePublished":"2019-01-19T13:28:17.000Z","dateModified":"2021-07-06T07:11:06.686Z","author":{"@type":"Person","name":"Xie Pan"},"publisher":{"@type":"Organization","name":"潘小榭","logo":{"@type":"ImageObject","url":"http://www.panxiaoxie.cn/img/panxiaoxie.png"}},"description":"参考：    blog: 苏剑林：揭开迷雾，来一顿美味的Capsule盛宴    paper：Investigating Capsule Networks with Dynamic Routing for Text Classification   再看 Capsules苏剑林同学在他的那篇博客中对 capsule 的理解很有道理，胶囊也就是用 “vector in vector out” 取代了"}</script><link rel="canonical" href="http://www.panxiaoxie.cn/2019/01/19/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-%E5%86%8D%E7%9C%8B-Capsules-%E4%BB%A5%E5%8F%8A-capsules-%E5%9C%A8%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E4%B8%8A%E7%9A%84%E5%BA%94%E7%94%A8/"><link rel="icon" href="/img/avatar.png"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/css/justifiedGallery.min.css"><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script><!--!--><!--!--><meta name="generator" content="Hexo 5.4.0"></head><body class="is-2-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/panxiaoxie.png" alt="潘小榭" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">主页</a><a class="navbar-item" href="/archives">归档</a><a class="navbar-item" href="/categories">分类</a><a class="navbar-item" href="/tags">标签</a><a class="navbar-item" href="/about">关于我</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/PanXiebit"><i class="fab fa-github"></i></a><a class="navbar-item search" title="搜索" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-10-widescreen"><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2019-01-19T13:28:17.000Z" title="2019/1/19 下午9:28:17">2019-01-19</time>发表</span><span class="level-item"><time dateTime="2021-07-06T07:11:06.686Z" title="2021/7/6 下午3:11:06">2021-07-06</time>更新</span><span class="level-item"><a class="link-muted" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/">论文笔记</a><span> / </span><a class="link-muted" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/capsules/">capsules</a></span><span class="level-item">17 分钟读完 (大约2618个字)</span></div></div><h1 class="title is-3 is-size-4-mobile">论文笔记-再看 Capsules 以及 capsules 在文本分类上的应用</h1><div class="content"><p>参考：  </p>
<ul>
<li><p>blog: <a target="_blank" rel="noopener" href="https://spaces.ac.cn/archives/4819">苏剑林：揭开迷雾，来一顿美味的Capsule盛宴</a>  </p>
</li>
<li><p>paper：<a target="_blank" rel="noopener" href="https://www.paperweekly.site/papers/1811">Investigating Capsule Networks with Dynamic Routing for Text Classification</a></p>
</li>
</ul>
<h2 id="再看-Capsules"><a href="#再看-Capsules" class="headerlink" title="再看 Capsules"></a>再看 Capsules</h2><p>苏剑林同学在他的那篇博客中对 capsule 的理解很有道理，胶囊也就是用 “vector in vector out” 取代了 “scaler in scaler out”。</p>
<p>在我的上一篇 blog 中在 PrimaryCaps 模块中，将前一步通过卷积得到的输出是 [batch, 20, 20, 256]. 经过 PrimaryCaps 第一步 affine-transform 转换成 [batch, 6, 6, 32, 8]. 实际上就是在这一步将一个像素点的特征转换成了一个 8d-vector 的胶囊。</p>
<p>事实上，在 NLP 的任务中，这种用向量来表示一维特征的做法确实最基本的。比如 one-hot 向量，word2vec 将词转换成 dense vector.</p>
<p>在传统的神经网络中，从低层次的特征逐步抽象，归纳为高层次的特征，是通过权重加权求和得到的，比如卷积啊，全连接都是这样，然后通过梯度反向传播，更新这些权重参数。  </p>
<p>这个过程某种程度上模拟了人的层次分类做法，从而完成对最终目标的输出，并且具有比较好的泛化能力。的确，神经网络应该是这样做的，然而它并不能告诉我们它确确实实是这样做的，这就是神经网络的难解释性，也就是很多人会将深度学习视为黑箱的原因之一。</p>
<p>而 Hiton 提出了 Capsule 就具有很好的可解释性，那么其中的 “抛弃梯度下降” 又是怎么一回事呢？苏神在 blog 中给了很好的解释。</p>
<h3 id="胶囊的计算"><a href="#胶囊的计算" class="headerlink" title="胶囊的计算"></a>胶囊的计算</h3><p>在前面的 blog 中我们已经理解了什么是“胶囊”。神经元是标量，胶囊就是向量！Hinton的理解是：每一个胶囊表示一个属性，而胶囊的向量则表示这个属性的“标架”。也就是说，我们以前只是用一个标量表示有没有这个特征（比如有没有羽毛），现在我们用一个向量来表示，不仅仅表示有没有，还表示“有什么样的”（比如有什么颜色、什么纹理的羽毛），如果这样理解，就是说在对单个特征的表达上更丰富了。不仅如此，上一篇 blog 中有提到的 CNN 中的不足，主要在于两点，一是 max pooling 丢失了部分信息（这在低层次的layer中可能影响不大，但是在高层次的layer就会有比较大的影响），二是 CNN 不能提取低维特征与高维特征之间在空间中的相对位置信息。而胶囊的方向能表示这一部分信息。比如下面这张图就很明显的表示出来了。</p>
<p><img src="/2019/01/19/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-%E5%86%8D%E7%9C%8B-Capsules-%E4%BB%A5%E5%8F%8A-capsules-%E5%9C%A8%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E4%B8%8A%E7%9A%84%E5%BA%94%E7%94%A8/09.png"></p>
<p>从低层次胶囊到高层次胶囊的计算细节，主要分为 3 个步骤：  </p>
<ul>
<li><p>affine transform  </p>
</li>
<li><p>weighting and sum  </p>
</li>
<li><p>squash</p>
</li>
</ul>
<p><img src="/2019/01/19/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-%E5%86%8D%E7%9C%8B-Capsules-%E4%BB%A5%E5%8F%8A-capsules-%E5%9C%A8%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E4%B8%8A%E7%9A%84%E5%BA%94%E7%94%A8/02.png"></p>
<p><img src="/2019/01/19/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-%E5%86%8D%E7%9C%8B-Capsules-%E4%BB%A5%E5%8F%8A-capsules-%E5%9C%A8%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E4%B8%8A%E7%9A%84%E5%BA%94%E7%94%A8/03.png"></p>
<p>如果考虑更多的胶囊，可以抽象到下面这张图。</p>
<p><img src="/2019/01/19/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-%E5%86%8D%E7%9C%8B-Capsules-%E4%BB%A5%E5%8F%8A-capsules-%E5%9C%A8%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E4%B8%8A%E7%9A%84%E5%BA%94%E7%94%A8/01.png"></p>
<p>我们只关注其中的某一部分就是：</p>
<p><img src="/2019/01/19/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-%E5%86%8D%E7%9C%8B-Capsules-%E4%BB%A5%E5%8F%8A-capsules-%E5%9C%A8%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E4%B8%8A%E7%9A%84%E5%BA%94%E7%94%A8/04.png"></p>
<p>关于从低层次特征如何整合到高层次特征以及这样做的原因是啥，苏同学这里说的是相同透彻了。</p>
<p><img src="/2019/01/19/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-%E5%86%8D%E7%9C%8B-Capsules-%E4%BB%A5%E5%8F%8A-capsules-%E5%9C%A8%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E4%B8%8A%E7%9A%84%E5%BA%94%E7%94%A8/05.png"></p>
<h3 id="动态路由"><a href="#动态路由" class="headerlink" title="动态路由"></a>动态路由</h3><p>在前面的blog中我们差不多能理解：动态路由实际上就是 低层次的胶囊将部分的自己交付给高层次的胶囊，而这个部分的权重却又取决于 低层次胶囊和高层次胶囊的相关性。</p>
<p>我们原本也是可以通过反向传播来解决这个问题的（不显示的计算出相关性，而是直接用神经网络来代替，不知是否可用梯度下降来处理胶囊？），而 Hinton 使用的动态路由算法可解释更强。</p>
<p>动态路由算法就是来解决这个权重分配的问题。</p>
<p><img src="/2019/01/19/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-%E5%86%8D%E7%9C%8B-Capsules-%E4%BB%A5%E5%8F%8A-capsules-%E5%9C%A8%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E4%B8%8A%E7%9A%84%E5%BA%94%E7%94%A8/06.png"></p>
<p>对于动态路由的理解，苏同学给上了两道小菜。总的理解就是，高层胶囊在启动阶段，我们并不知道它是多少，那么前面的相似度也就没法计算。于是，我们只能初始化一个值，也就是取低层次胶囊的均值。如同上图中第二步将 $b_ij$ 设置成 0，那么低层次胶囊分配给高层次胶囊的权重 $c_{ij}$ 就都是相等的。</p>
<p>$$c_{ij}=\dfrac{exp(b_{ij})}{\sum_k exp(b_ik)}$$</p>
<p>然后反复迭代。说白了，输出是输入的聚类结果，而聚类通常都需要迭代算法，这个迭代算法就称为“动态路由”。至于这个动态路由的细节，其实是不固定的，取决于聚类的算法，比如关于Capsule的新文章《MATRIX CAPSULES WITH EM ROUTING》就使用了Gaussian Mixture Model来聚类。</p>
<h3 id="共享版-or-全连接版"><a href="#共享版-or-全连接版" class="headerlink" title="共享版 or 全连接版"></a>共享版 or 全连接版</h3><h4 id="全连接版"><a href="#全连接版" class="headerlink" title="全连接版"></a>全连接版</h4><p>在 Capsule 中，低层次特征是通过普通的卷积神经网络提取，然后通过一个矩阵变换得到的。其中的 $W$ 是需要学习的参数。$v_j$ 是作为输入 $u_i$ 的某种聚类中心出现的，而从不同角度看输入，得到的聚类结果显然是不一样的。那么为了实现“多角度看特征”，于是可以在每个胶囊传入下一个胶囊之前，都要先乘上一个矩阵做变换.</p>
<p>$$v_j = \text{squash}\sum_i\dfrac{e^{&lt;\hat u_{j|i}, v_j&gt;}}{\sum_k e^{&lt;\hat u_{k|i}, v_k&gt;}}\hat u_{j|i}, \hat u_{j|i}=W_{ij}u_i$$</p>
<p><img src="/2019/01/19/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-%E5%86%8D%E7%9C%8B-Capsules-%E4%BB%A5%E5%8F%8A-capsules-%E5%9C%A8%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E4%B8%8A%E7%9A%84%E5%BA%94%E7%94%A8/07.png"></p>
<h4 id="共享版"><a href="#共享版" class="headerlink" title="共享版"></a>共享版</h4><p>全连接层只能处理定长输入，全连接版的Capsule也不例外。而CNN处理的图像大小通常是不定的，提取的特征数目就不定了，这种情形下，全连接层的Capsule就不适用了。因为在前一图就可以看到，参数矩阵的个数等于输入胶囊数目乘以输出胶囊数目，既然输入数目不固定，那么就不能用全连接了。</p>
<p>所以跟CNN的权值共享一样，我们也需要一个权值共享版的Capsule。所谓共享版，是指对于固定的上层胶囊j，它与所有的底层胶囊的连接的变换矩阵是共用的，即 $W_{ji}≡W_j$.</p>
<p><img src="/2019/01/19/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-%E5%86%8D%E7%9C%8B-Capsules-%E4%BB%A5%E5%8F%8A-capsules-%E5%9C%A8%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E4%B8%8A%E7%9A%84%E5%BA%94%E7%94%A8/08.png"></p>
<p>采用 Hiton 论文中的参数来计算就是：  </p>
<ul>
<li><p>输入 [batch, 6, 6, 32, 8]=[batch, 1152, 8], 输入有 6x6x32=1152 个 capsules.  </p>
</li>
<li><p>输出 [batch, 16, 10]， 输出有 10 个 capsules.  </p>
</li>
</ul>
<p>对于全连接版，权重参数是 $1152\times 8\times 16\times N + 1152\times N + 1152\times N$. N 表示 low-level capsules 的数目。  </p>
<p>对于共享版， 权重参数是 $8\times 16\times 1152 + 1152 + 1152$.</p>
<h3 id="反向传播"><a href="#反向传播" class="headerlink" title="反向传播"></a>反向传播</h3><p>现在又有了 $W_{ji}$，那么这些参数怎么训练呢？答案是反向传播。读者也许比较晕的是：现在既有动态路由，又有反向传播了，究竟两者怎么配合？其实这个真的就最简单不过了。从形式上来看，就是往模型中添加了三层罢了，剩下的该做什么还是什么，最后构建一个loss来反向传播。</p>
<p>这样看来，Capsule里边不仅有反向传播，而且只有反向传播，因为动态路由已经作为了模型的一部分，都不算在迭代算法里边了。</p>
<h2 id="capsules-在文本分类上的应用"><a href="#capsules-在文本分类上的应用" class="headerlink" title="capsules 在文本分类上的应用"></a>capsules 在文本分类上的应用</h2><p><a target="_blank" rel="noopener" href="https://www.paperweekly.site/papers/1811">Investigating Capsule Networks with Dynamic Routing for Text Classification</a>  </p>
<h3 id="Model-Architecture"><a href="#Model-Architecture" class="headerlink" title="Model Architecture"></a>Model Architecture</h3><p><img src="/2019/01/19/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-%E5%86%8D%E7%9C%8B-Capsules-%E4%BB%A5%E5%8F%8A-capsules-%E5%9C%A8%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E4%B8%8A%E7%9A%84%E5%BA%94%E7%94%A8/10.png"></p>
<h4 id="N-gram-Convolutional-Layer"><a href="#N-gram-Convolutional-Layer" class="headerlink" title="N-gram Convolutional Layer"></a>N-gram Convolutional Layer</h4><p>普通的卷积操作。  </p>
<p>输入：[batch, L, embed_size, 1]  </p>
<p>输出：[batch, L-k1+1, 1, B]  </p>
<p>其中：  </p>
<ul>
<li><p>kernel: [k1, embed_size, 1, B]</p>
</li>
<li><p>B 表示卷积核的个数  </p>
</li>
<li><p>k1 是sentence 长度维度上的 sliding-window 尺寸</p>
</li>
</ul>
<h4 id="Primary-Capsule-Layer"><a href="#Primary-Capsule-Layer" class="headerlink" title="Primary Capsule Layer"></a>Primary Capsule Layer</h4><p>初始化成 capsules, 但依然只是简单的卷积操作。  </p>
<p>输入：[batch, L-k1+1, 1, B]  </p>
<p>输出：[batch, L-k1+1, 1, C, d]</p>
<p>其中：  </p>
<ul>
<li><p>d 表示 capsule 的维度</p>
</li>
<li><p>实际上依然是普通的卷积操作，不同的是，原本是从 channels B 到 channels C.现在每个 channels C 对应的有 d 个。也就是初始化的 capsules.  </p>
</li>
<li><p>kernel: [1, 1, B, C<em>d], 实现时先生成 C</em>d channels, 然后 split.  </p>
</li>
</ul>
<h4 id="Convolutional-Capsule-Layer"><a href="#Convolutional-Capsule-Layer" class="headerlink" title="Convolutional Capsule Layer"></a>Convolutional Capsule Layer</h4><p>从低层次 feature 到高层次 feature, 在 Hinton 中是capsules版的全连接，在这里是 capsules 版的卷积操作，其中涉及到动态路由算法。</p>
<p>输入：[batch, L-k1+1, 1, C, d]  </p>
<p>输出：[batch, L-k1-k2+2, 1, D, d]  </p>
<p>其中：  </p>
<ul>
<li><p>输出的 capsules 维度依旧是 d  </p>
</li>
<li><p>但是 capsules 的个数发生了变化，在 Hinton 论文中是通过全连接维度的变换，这里是通过卷积的操作来实现 capsules 个数的变换的。  </p>
</li>
</ul>
<p>与 Hinton 的论文类似，第一步是 affine transform 矩阵变换操作，在这篇 paper 中，作者提出了两种方式，实际上就是苏同学博客中的全连接版和共享版（低层次的 capsules 是否共享同样的矩阵变换参数）。  </p>
<ul>
<li><p>shared: $W\in R^{N\times d\times d}$. N 是 capsules 的个数  </p>
</li>
<li><p>no-shared: $W\in R^{H\times N\times d\times d}$.H 是低维的 capsules 的个数。</p>
</li>
</ul>
</div><div class="article-licensing box"><div class="licensing-title"><p>论文笔记-再看 Capsules 以及 capsules 在文本分类上的应用</p><p><a href="http://www.panxiaoxie.cn/2019/01/19/论文笔记-再看-Capsules-以及-capsules-在文本分类上的应用/">http://www.panxiaoxie.cn/2019/01/19/论文笔记-再看-Capsules-以及-capsules-在文本分类上的应用/</a></p></div><div class="licensing-meta level is-mobile"><div class="level-left"><div class="level-item is-narrow"><div><h6>作者</h6><p>Xie Pan</p></div></div><div class="level-item is-narrow"><div><h6>发布于</h6><p>2019-01-19</p></div></div><div class="level-item is-narrow"><div><h6>更新于</h6><p>2021-07-06</p></div></div><div class="level-item is-narrow"><div><h6>许可协议</h6><p><a class="icons" rel="noopener" target="_blank" title="Creative Commons" href="https://creativecommons.org/"><i class="icon fab fa-creative-commons"></i></a><a class="icons" rel="noopener" target="_blank" title="Attribution" href="https://creativecommons.org/licenses/by/4.0/"><i class="icon fab fa-creative-commons-by"></i></a><a class="icons" rel="noopener" target="_blank" title="Noncommercial" href="https://creativecommons.org/licenses/by-nc/4.0/"><i class="icon fab fa-creative-commons-nc"></i></a></p></div></div></div></div></div><div class="article-tags is-size-7 mb-4"><span class="mr-2">#</span><a class="link-muted mr-2" rel="tag" href="/tags/capsules/">capsules</a></div><!--!--></article></div><!--!--><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/2019/01/23/NLP%E7%AE%97%E6%B3%95-%E9%9D%A2%E8%AF%95%E7%BB%8F%E9%AA%8C/"><i class="level-item fas fa-chevron-left"></i><span class="level-item">NLP算法-实习面试经验</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/2019/01/17/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-Capsules-Network/"><span class="level-item">Dynamic Routing Between Capsules</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><div class="card"><div class="card-content"><h3 class="title is-5">评论</h3><div id="disqus_thread"><noscript>Please enable JavaScript to view the <a target="_blank" rel="noopener" href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript></div><script>var disqus_config = function () {
            this.page.url = 'http://www.panxiaoxie.cn/2019/01/19/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-%E5%86%8D%E7%9C%8B-Capsules-%E4%BB%A5%E5%8F%8A-capsules-%E5%9C%A8%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E4%B8%8A%E7%9A%84%E5%BA%94%E7%94%A8/';
            this.page.identifier = '2019/01/19/论文笔记-再看-Capsules-以及-capsules-在文本分类上的应用/';
        };
        (function() {
            var d = document, s = d.createElement('script');  
            s.src = '//' + 'panxie' + '.disqus.com/embed.js';
            s.setAttribute('data-timestamp', +new Date());
            (d.head || d.body).appendChild(s);
        })();</script></div></div></div><!--!--><div class="column column-right is-4-tablet is-4-desktop is-4-widescreen  order-3"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar" src="/img/avatar.png" alt="panxiaoxie"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">panxiaoxie</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Beijing, China</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">文章</p><a href="/archives"><p class="title">117</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">分类</p><a href="/categories"><p class="title">39</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">标签</p><a href="/tags"><p class="title">36</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/PanXiebit" target="_blank" rel="noopener">关注我</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/PanXiebit"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Email" href="/ftdpanxie@gmail.com"><i class="fa fa-envelope"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="RSS" href="/"><i class="fas fa-rss"></i></a></div></div></div><!--!--><div class="card widget" data-type="links"><div class="card-content"><div class="menu"><h3 class="menu-label">链接</h3><ul class="menu-list"><li><a class="level is-mobile" href="https://github.com/PanXiebit" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">github</span></span><span class="level-right"><span class="level-item tag">github.com</span></span></a></li><li><a class="level is-mobile" href="ftdpanxie@gmail.com" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">email</span></span><span class="level-right"><span class="level-item tag">ftdpanxie@gmail.com</span></span></a></li></ul></div></div></div><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">分类</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/C/"><span class="level-start"><span class="level-item">C++</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/CSAPP/"><span class="level-start"><span class="level-item">CSAPP</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/DRL/"><span class="level-start"><span class="level-item">DRL</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/GAN/"><span class="level-start"><span class="level-item">GAN</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li><li><a class="level is-mobile" href="/categories/GAN-RL/"><span class="level-start"><span class="level-item">GAN, RL</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/ML/"><span class="level-start"><span class="level-item">ML</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/NLP/"><span class="level-start"><span class="level-item">NLP</span></span><span class="level-end"><span class="level-item tag">14</span></span></a></li><li><a class="level is-mobile" href="/categories/TensorFlow/"><span class="level-start"><span class="level-item">TensorFlow</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/cs224d/"><span class="level-start"><span class="level-item">cs224d</span></span><span class="level-end"><span class="level-item tag">10</span></span></a></li><li><a class="level is-mobile" href="/categories/generation/"><span class="level-start"><span class="level-item">generation</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/interview/"><span class="level-start"><span class="level-item">interview</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/leetcode/"><span class="level-start"><span class="level-item">leetcode</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/machine-translation/"><span class="level-start"><span class="level-item">machine translation</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/python/"><span class="level-start"><span class="level-item">python</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/pytorch/"><span class="level-start"><span class="level-item">pytorch</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/reinforcement-learning/"><span class="level-start"><span class="level-item">reinforcement learning</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/sign-language-recognition/"><span class="level-start"><span class="level-item">sign language recognition</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/transfer-learning/"><span class="level-start"><span class="level-item">transfer learning</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"><span class="level-start"><span class="level-item">数据结构与算法</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile" href="/categories/%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB/"><span class="level-start"><span class="level-item">文本分类</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"><span class="level-start"><span class="level-item">论文笔记</span></span><span class="level-end"><span class="level-item tag">40</span></span></a><ul><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/DL/"><span class="level-start"><span class="level-item">DL</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/ESA/"><span class="level-start"><span class="level-item">ESA</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/GAN/"><span class="level-start"><span class="level-item">GAN</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/MRC-and-QA/"><span class="level-start"><span class="level-item">MRC and QA</span></span><span class="level-end"><span class="level-item tag">7</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/Machine-Translation/"><span class="level-start"><span class="level-item">Machine Translation</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/NLP/"><span class="level-start"><span class="level-item">NLP</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/Transformer/"><span class="level-start"><span class="level-item">Transformer</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/capsules/"><span class="level-start"><span class="level-item">capsules</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/computer-vision/"><span class="level-start"><span class="level-item">computer vision</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/constrast-learning/"><span class="level-start"><span class="level-item">constrast learning</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/data-augmentation/"><span class="level-start"><span class="level-item">data augmentation</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/dialogue-system/"><span class="level-start"><span class="level-item">dialogue system</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/language-model/"><span class="level-start"><span class="level-item">language model</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/machine-translation/"><span class="level-start"><span class="level-item">machine translation</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/open-set-recognition/"><span class="level-start"><span class="level-item">open set recognition</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/sentence-embedding/"><span class="level-start"><span class="level-item">sentence embedding</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/text-matching/"><span class="level-start"><span class="level-item">text matching</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/vision-language/"><span class="level-start"><span class="level-item">vision-language</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li></ul></div></div></div></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/panxiaoxie.png" alt="潘小榭" height="28"></a><p class="is-size-7"><span>&copy; 2021 Xie Pan</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("zh-CN");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="回到顶端" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "此网站使用Cookie来改善您的体验。",
          dismiss: "知道了！",
          allow: "允许使用Cookie",
          deny: "拒绝",
          link: "了解更多",
          policy: "Cookie政策",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.5/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="想要查找什么..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"想要查找什么...","untitled":"(无标题)","posts":"文章","pages":"页面","categories":"分类","tags":"标签"});
        });</script></body></html>