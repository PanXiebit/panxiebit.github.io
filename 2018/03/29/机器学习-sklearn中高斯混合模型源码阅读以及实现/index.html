<!doctype html>
<html lang="zh"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>代码实现高斯混合模型 - 潘小榭</title><link rel="manifest" href="/manifest.json"><meta name="theme-color" content="black"><meta name="application-name" content="panxiaoxie"><meta name="msapplication-TileImage" content="/img/avatar.png"><meta name="msapplication-TileColor" content="black"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="panxiaoxie"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="description" content="sklearn源码阅读，用em算法计算高斯混合模型GMM 代码实现高斯混合模型参考这篇博客Regularized Gaussian Covariance Estimation非常值得一读，同事这篇博客很深入的讲了协方差怎么求的问题，在前文中我也有提到～但我解释的很low。。 代码直接就看sklearn里面的源码吧～网上很多不靠谱。。。 github源码 类初始化123456789101112131"><meta property="og:type" content="blog"><meta property="og:title" content="panxiaoxie"><meta property="og:url" content="https://github.com/PanXiebit"><meta property="og:site_name" content="panxiaoxie"><meta property="og:description" content="sklearn源码阅读，用em算法计算高斯混合模型GMM 代码实现高斯混合模型参考这篇博客Regularized Gaussian Covariance Estimation非常值得一读，同事这篇博客很深入的讲了协方差怎么求的问题，在前文中我也有提到～但我解释的很low。。 代码直接就看sklearn里面的源码吧～网上很多不靠谱。。。 github源码 类初始化123456789101112131"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://www.qt86.com/cache/1625298592_187938.png"><meta property="article:published_time" content="2018-03-29T08:15:26.000Z"><meta property="article:modified_time" content="2021-06-29T08:12:08.200Z"><meta property="article:author" content="panxiaoxie"><meta property="article:tag" content="ML"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="https://www.qt86.com/cache/1625298592_187938.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"http://www.panxiaoxie.cn/2018/03/29/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-sklearn%E4%B8%AD%E9%AB%98%E6%96%AF%E6%B7%B7%E5%90%88%E6%A8%A1%E5%9E%8B%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB%E4%BB%A5%E5%8F%8A%E5%AE%9E%E7%8E%B0/"},"headline":"代码实现高斯混合模型","image":["http://www.panxiaoxie.cn/2018/03/29/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-sklearn%E4%B8%AD%E9%AB%98%E6%96%AF%E6%B7%B7%E5%90%88%E6%A8%A1%E5%9E%8B%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB%E4%BB%A5%E5%8F%8A%E5%AE%9E%E7%8E%B0/precision.png","http://www.panxiaoxie.cn/2018/03/29/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-sklearn%E4%B8%AD%E9%AB%98%E6%96%AF%E6%B7%B7%E5%90%88%E6%A8%A1%E5%9E%8B%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB%E4%BB%A5%E5%8F%8A%E5%AE%9E%E7%8E%B0/Figure_1.png"],"datePublished":"2018-03-29T08:15:26.000Z","dateModified":"2021-06-29T08:12:08.200Z","author":{"@type":"Person","name":"Xie Pan"},"publisher":{"@type":"Organization","name":"潘小榭","logo":{"@type":"ImageObject","url":"http://www.panxiaoxie.cn/img/panxiaoxie.png"}},"description":"sklearn源码阅读，用em算法计算高斯混合模型GMM 代码实现高斯混合模型参考这篇博客Regularized Gaussian Covariance Estimation非常值得一读，同事这篇博客很深入的讲了协方差怎么求的问题，在前文中我也有提到～但我解释的很low。。 代码直接就看sklearn里面的源码吧～网上很多不靠谱。。。 github源码 类初始化123456789101112131"}</script><link rel="canonical" href="http://www.panxiaoxie.cn/2018/03/29/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-sklearn%E4%B8%AD%E9%AB%98%E6%96%AF%E6%B7%B7%E5%90%88%E6%A8%A1%E5%9E%8B%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB%E4%BB%A5%E5%8F%8A%E5%AE%9E%E7%8E%B0/"><link rel="icon" href="/img/avatar.png"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/css/justifiedGallery.min.css"><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script><!--!--><!--!--><meta name="generator" content="Hexo 5.4.0"></head><body class="is-2-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/panxiaoxie.png" alt="潘小榭" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">主页</a><a class="navbar-item" href="/archives">归档</a><a class="navbar-item" href="/categories">分类</a><a class="navbar-item" href="/tags">标签</a><a class="navbar-item" href="/about">关于我</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/PanXiebit"><i class="fab fa-github"></i></a><a class="navbar-item search" title="搜索" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-10-widescreen"><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2018-03-29T08:15:26.000Z" title="2018/3/29 下午4:15:26">2018-03-29</time>发表</span><span class="level-item"><time dateTime="2021-06-29T08:12:08.200Z" title="2021/6/29 下午4:12:08">2021-06-29</time>更新</span><span class="level-item"><a class="link-muted" href="/categories/ML/">ML</a></span><span class="level-item">29 分钟读完 (大约4421个字)</span></div></div><h1 class="title is-3 is-size-4-mobile">代码实现高斯混合模型</h1><div class="content"><p>sklearn源码阅读，用em算法计算高斯混合模型GMM</p>
<h3 id="代码实现高斯混合模型"><a href="#代码实现高斯混合模型" class="headerlink" title="代码实现高斯混合模型"></a>代码实现高斯混合模型</h3><p>参考这篇博客<a target="_blank" rel="noopener" href="http://freemind.pluskid.org/machine-learning/regularized-gaussian-covariance-estimation/">Regularized Gaussian Covariance Estimation</a>非常值得一读，同事这篇博客很深入的讲了协方差怎么求的问题，在前文中我也有提到～但我解释的很low。。</p>
<p>代码直接就看sklearn里面的源码吧～网上很多不靠谱。。。</p>
<p><a target="_blank" rel="noopener" href="https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/mixture/gaussian_mixture.py">github源码</a></p>
<h3 id="类初始化"><a href="#类初始化" class="headerlink" title="类初始化"></a>类初始化</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">GaussianMixture</span>(<span class="params">BaseMixture</span>):</span></span><br><span class="line"></span><br><span class="line">  <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  Representation of a Gaussian mixture model probability distribution.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  This class allows to estimate the parameters of a Gaussian mixture</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  distribution. 对混合的高斯分布进行参数估计～</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, n_components=<span class="number">1</span>, covariance_type=<span class="string">&#x27;full&#x27;</span>, tol=<span class="number">1e-3</span>,</span></span></span><br><span class="line"><span class="params"><span class="function"></span></span></span><br><span class="line"><span class="params"><span class="function">             reg_covar=<span class="number">1e-6</span>, max_iter=<span class="number">100</span>, n_init=<span class="number">1</span>, init_params=<span class="string">&#x27;kmeans&#x27;</span>,</span></span></span><br><span class="line"><span class="params"><span class="function"></span></span></span><br><span class="line"><span class="params"><span class="function">             weights_init=<span class="literal">None</span>, means_init=<span class="literal">None</span>, precisions_init=<span class="literal">None</span>,</span></span></span><br><span class="line"><span class="params"><span class="function"></span></span></span><br><span class="line"><span class="params"><span class="function">             random_state=<span class="literal">None</span>, warm_start=<span class="literal">False</span>,</span></span></span><br><span class="line"><span class="params"><span class="function"></span></span></span><br><span class="line"><span class="params"><span class="function">             verbose=<span class="number">0</span>, verbose_interval=<span class="number">10</span></span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="built_in">super</span>(GaussianMixture, self).__init__(</span><br><span class="line"></span><br><span class="line">        n_components=n_components, tol=tol, reg_covar=reg_covar,</span><br><span class="line"></span><br><span class="line">        max_iter=max_iter, n_init=n_init, init_params=init_params,</span><br><span class="line"></span><br><span class="line">        random_state=random_state, warm_start=warm_start,</span><br><span class="line"></span><br><span class="line">        verbose=verbose, verbose_interval=verbose_interval)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 主要是针对3个要学习的参数的初始化</span></span><br><span class="line"></span><br><span class="line">    self.covariance_type = covariance_type <span class="comment"># 协方差矩阵形式</span></span><br><span class="line"></span><br><span class="line">    self.weights_init = weights_init <span class="comment"># 多项式分布，每一类的概率</span></span><br><span class="line"></span><br><span class="line">    self.means_init = means_init  <span class="comment"># 均值 (n_components, n_features)</span></span><br><span class="line"></span><br><span class="line">    self.precisions_init = precisions_init <span class="comment"># 协方差</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>先看初始化构造函数，参数是真的多。。。</p>
<ul>
<li><p><strong>n_components=1:</strong> The number of mixture components.表示混合类别的个数，也就是混合高斯分布的个数</p>
</li>
<li><p><strong>covariance_type=’full’:</strong> 协方差矩阵的类型。{‘full’, ‘tied’, ‘diag’, ‘spherical’} 分别对应完全协方差矩阵（元素都不为零），相同的完全协方差矩阵（HMM会用到），对角协方差矩阵（非对角为零，对角不为零），球面协方差矩阵（非对角为零，对角完全相同，球面特性），默认‘full’ 完全协方差矩阵</p>
</li>
<li><p><strong>tol=1e-3</strong> 收敛阈值，EM iterations will stop when the lower bound average gain is</p>
</li>
</ul>
<p>below this threshold.也就是当下界的平均增益小于阈值时，em迭代就停止。这里的下界指的是公式</p>
<p>（3）中的下界凸函数。我们知道em算法分两步，e step是期望，也就是不等式相等，m setp是最大化，</p>
<p>也就是下界凸函数最大化。这里的阈值平均增益就是指凸函数的最大化过程中的增益。</p>
<ul>
<li><strong>reg_covar=1e-6：</strong> Non-negative regularization added to the diagonal of</li>
</ul>
<p>covariance.Allows to assure that the covariance matrices are all positive.</p>
<p>非负正则化添加到协方差矩阵对角线上，保证协方差矩阵都是正定的。</p>
<ul>
<li><p><strong>max_iter=100:</strong> em算法的最大迭代次数</p>
</li>
<li><p><strong>n_init:</strong> int, defaults to 1.初始化的次数</p>
</li>
<li><p><strong>init_params:</strong> {‘kmeans’, ‘random’}, defaults to ‘kmeans’.</p>
</li>
</ul>
<p>The method used to initialize the weights, the means and the precisionsself.</p>
<p> Must be one of::</p>
<pre><code>-  &#39;kmeans&#39; : responsibilities are initialized using kmeans.

- &#39;random&#39; : responsibilities are initialized randomly.

- 这里对应的初始化，是指的隐藏变量z的分类所占比例，也就是weight_init，kmeans表示“hard”guess， &#123;0, 1&#125; or &#123;1, . . . , k&#125;)
</code></pre>
<p>  random应该就是”soft”guess吧。</p>
<ul>
<li>weights_init : shape (n_components, ), optional The user-provided initial weights, defaults to None. If it None, weights are initialized using the <code>init_params</code> method.</li>
</ul>
<p>  先验权重初始化，对应的就是隐藏变量有n_components类，而每一类所占的比例，也就是多项式分布的初始化～对应$\phi_i$</p>
<ul>
<li><strong>means_init :</strong> array-like, shape (n_components, n_features), optional. The user-provided initial means, defaults to None, If it None, means are initialized using the <code>init_params</code> method.混合高斯分布的均值初始化，注意shape=(n_components, n_features),有n_components这样的多维高斯分布，每个高斯分布有n_features维度</li>
</ul>
<ul>
<li><p><strong>precisions_init :</strong> The user-provided initial precisions (inverse of the covariance matrices), defaults to None. If it None, precisions are initialized using the ‘init_params’ method.The shape depends on ‘covariance_type’::</p>
<ul>
<li><p>(n_components,)                        if ‘spherical’,</p>
</li>
<li><p>(n_features, n_features)               if ‘tied’,</p>
</li>
<li><p>(n_components, n_features)             if ‘diag’,</p>
</li>
<li><p>(n_components, n_features, n_features) if ‘full’</p>
</li>
<li><p>用来初始化高斯分布中的协方差矩阵，协方差矩阵代表的是n_features维向量中每一维特征与其他维度特征的关系，对于一个高斯分布来说是n_features<em>n_features，n_components个混合也就是’full’。其中要学习的参数个数是(n_features+1)</em> n_features/2.具体关于协方差矩阵参考前面那篇博客</p>
</li>
</ul>
</li>
</ul>
<ul>
<li><strong>random_state :</strong> int, RandomState instance or None, optional (default=None) 随机数生成器</li>
</ul>
<ul>
<li><strong>warm_start :</strong> bool, default to False.If ‘warm_start’ is True, the solution of the last fitting is used as initialization for the next call of fit(). This can speed up convergence when fit is called several times on similar problems. 若为True，则fit（）调用会以上一次fit（）的结果作为初始化参数，适合相同问题多次fit的情况，能加速收敛，默认为False。</li>
</ul>
<ul>
<li><strong>verbose :</strong> int, default to 0. Enable verbose output. If 1 then it prints the current initialization and each iteration step. If greater than 1 then it prints also the log probability and the time needed for each step. 使能迭代信息显示，默认为0，可以为1或者大于1（显示的信息不同）</li>
</ul>
<ul>
<li><strong>verbose_interval:</strong> 与13挂钩，若使能迭代信息显示，设置多少次迭代后显示信息，默认10次。</li>
</ul>
<h3 id="E-step"><a href="#E-step" class="headerlink" title="E step"></a>E step</h3><p>就是求$w_j^i$</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_e_step</span>(<span class="params">self, X</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="string">&quot;&quot;&quot;E step.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Parameters</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    ----------</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    X : array-like, shape (n_samples, n_features)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    -------</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    log_prob_norm :</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    log_responsibility : 后验概率，样本i是j类的概率w_j^&#123;i&#125;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    log_prob_norm, log_resp = self._estimate_log_prob_resp(X)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> np.mean(log_prob_norm), log_resp</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>那么如何求$w_j^{i}$呢？</p>
<p>$$w_j^{(i)}:=p(z^{(i)}=j|x^{(i)};\phi,\mu,\Sigma)=\dfrac{p(x^{(i)}|z^{(i)}=j;\mu,\Sigma)p(z^{(i)}=j;\phi)}{\sum_{l=1}^kp(x^{(i)}|z^{(i)}=l;\mu,\Sigma)p(z^{(i)}=l;\phi)}$$</p>
<p><font size="4" color="#D2691E">要注意的是，为了计算方便，有以下几点：</font></p>
<ul>
<li><p>因为分子分母中设计到正态分布，即指数形式，故先计算其log形式。然后带入到M step中取回指数形式即可。</p>
</li>
<li><p>对于协方差矩阵，如果n_features很大的话，计算其逆矩阵和行列式就很复杂，因此可以先计算其precision矩阵，然后进行cholesky分解，以便优化计算。</p>
</li>
</ul>
<h4 id="先计算分子对数形式，两个对数相加："><a href="#先计算分子对数形式，两个对数相加：" class="headerlink" title="先计算分子对数形式，两个对数相加："></a>先计算分子对数形式，两个对数相加：</h4><p>$$logp(x^{(i)}|z^{(i)}=j;\mu,\Sigma)+logp(z^{(i)}=j;\phi)$$</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment"># 计算P(x|z)p(z)的对数形式</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_estimate_weighted_log_prob</span>(<span class="params">self, X</span>):</span></span><br><span class="line"></span><br><span class="line">        <span class="string">&quot;&quot;&quot;Estimate the weighted log-probabilities, log P(X | Z) + log weights.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Parameters</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        ----------</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        X : array-like, shape (n_samples, n_features)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Returns</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        -------</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        weighted_log_prob : array, shape (n_samples, n_component)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> self._estimate_log_prob(X) + self._estimate_log_weights()</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<ol>
<li>其中前者是高斯分布概率的对数,根据均值，协方差矩阵的cholesky分解可求得。</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_estimate_log_prob</span>(<span class="params">self, X</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> _estimate_log_gaussian_prob(</span><br><span class="line"></span><br><span class="line">            X, self.means_, self.precisions_cholesky_, self.covariance_type)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>这个函数，<code>_estimate_log_gaussian_prob</code>根据高斯分布的参数计算概率，涉及到协方差矩阵，要优化计算，很复杂，放在最后说。先把整个流程走完。</p>
<ol start="2">
<li>后者是每一类高斯分布所占的权重，也就是$\phi_j$</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_estimate_log_weights</span>(<span class="params">self</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 刚开始是初始值，后面随着m step而更新</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> np.log(self.weights_)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="再计算-w-j-i"><a href="#再计算-w-j-i" class="headerlink" title="再计算$w_j^i$"></a>再计算$w_j^i$</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_estimate_log_prob_resp</span>(<span class="params">self, X</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Estimate log probabilities and responsibilities for each sample.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Compute the log probabilities, weighted log probabilities per</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    component and responsibilities for each sample in X with respect to</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    the current state of the model.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Parameters</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    ----------</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    X : array-like, shape (n_samples, n_features)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    -------</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    log_prob_norm : array, shape (n_samples,)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        log p(X)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    log_responsibilities : array, shape (n_samples, n_components)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        logarithm of the responsibilities</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 计算分子log P(X | Z) + log weights.</span></span><br><span class="line"></span><br><span class="line">    weighted_log_prob = self._estimate_weighted_log_prob(X)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 计算分母log P(x)</span></span><br><span class="line"></span><br><span class="line">    log_prob_norm = logsumexp(weighted_log_prob, axis=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> np.errstate(under=<span class="string">&#x27;ignore&#x27;</span>):</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 忽略下溢，计算log(w_J^j)，也就是两个对数相减</span></span><br><span class="line"></span><br><span class="line">        log_resp = weighted_log_prob - log_prob_norm[:, np.newaxis]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> log_prob_norm, log_resp</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h3 id="M-setp"><a href="#M-setp" class="headerlink" title="M setp"></a>M setp</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_m_step</span>(<span class="params">self, X, log_resp</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="string">&quot;&quot;&quot;M step.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Parameters</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    ----------</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    X : array-like, shape (n_samples, n_features)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    log_resp : array-like, shape (n_samples, n_components)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Logarithm of the posterior probabilities (or responsibilities) of</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        the point of each sample in X.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    n_samples, _ = X.shape</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 根据E step中求得的log_resp,更新权重，均值和协方差</span></span><br><span class="line"></span><br><span class="line">    self.weights_, self.means_, self.covariances_ = (</span><br><span class="line"></span><br><span class="line">        _estimate_gaussian_parameters(X, np.exp(log_resp), self.reg_covar,</span><br><span class="line"></span><br><span class="line">                                      self.covariance_type))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 更新类别权重phi_j</span></span><br><span class="line"></span><br><span class="line">    self.weights_ /= n_samples</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 更新协方差矩阵的精度矩阵</span></span><br><span class="line"></span><br><span class="line">    self.precisions_cholesky_ = _compute_precision_cholesky(</span><br><span class="line"></span><br><span class="line">        self.covariances_, self.covariance_type)</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<p>具体怎么求，就是根据前面推导的公式了。根据前面的公式分别求对应的估计参数：</p>
<p>$$\Sigma_j:=\dfrac{\sum_{i=1}^mw_j^{(i)}(x^{(i)}-\mu_j)(x^{(i)}-\mu_j)^T}{\sum_{i=1}^mw_j^{(i)}}$$</p>
<h4 id="协方差矩阵：以‘full’为例"><a href="#协方差矩阵：以‘full’为例" class="headerlink" title="协方差矩阵：以‘full’为例"></a>协方差矩阵：以‘full’为例</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_estimate_gaussian_covariances_full</span>(<span class="params">resp, X, nk, means, reg_covar</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Estimate the full covariance matrices.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    resp:表示E step中猜测的w_j^&#123;i&#125;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    n_components, n_features = means.shape</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 协方差矩阵</span></span><br><span class="line"></span><br><span class="line">    covariances = np.empty((n_components, n_features, n_features))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(n_components):</span><br><span class="line"></span><br><span class="line">        diff = X - means[k]</span><br><span class="line"></span><br><span class="line">        covariances[k] = np.dot(resp[:, k] * diff.T, diff) / nk[k]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 正则化，flat表示展开成一维，然后每隔n_features取一个元素，单个协方差矩阵shape是</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># [n_features, n_features],所以就是对角线元素加上reg_covar</span></span><br><span class="line"></span><br><span class="line">        covariances[k].flat[::n_features + <span class="number">1</span>] += reg_covar</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> covariances</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="然后是正态分布的参数估计-u-j-phi-j"><a href="#然后是正态分布的参数估计-u-j-phi-j" class="headerlink" title="然后是正态分布的参数估计$u_j, \phi_j$"></a>然后是正态分布的参数估计$u_j, \phi_j$</h4><p>$$\phi_j:=\frac{1}{m}\sum_{i=1}^mw_j^{(i)}$$</p>
<p>$$\mu_j:=\dfrac{\sum_{i=1}^mw_j^{(i)}x^{(i)}}{\sum_{i=1}^mw_j^{(i)}}$$</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_estimate_gaussian_parameters</span>(<span class="params">X, resp, reg_covar, covariance_type</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Estimate the Gaussian distribution parameters.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Parameters</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    ----------</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    X : 样本数据 (n_samples, n_features)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    resp : Estep猜测的样本i是j类的概率w_i^&#123;j&#125;, shape (n_samples, n_components)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    reg_covar : 对角线正则化项</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    covariance_type : &#123;&#x27;full&#x27;, &#x27;tied&#x27;, &#x27;diag&#x27;, &#x27;spherical&#x27;&#125;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    -------</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    nk : 当前类别下的样本和 (n_components,) 也就是\sum_i^&#123;m&#125;(w_j^&#123;i&#125;)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    means : k个n维正态分布的均值, shape (n_components, n_features)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    covariances : 协方差矩阵</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 因为要做分母，避免为0</span></span><br><span class="line"></span><br><span class="line">    nk = resp.<span class="built_in">sum</span>(axis=<span class="number">0</span>) + <span class="number">10</span> * np.finfo(resp.dtype).eps</span><br><span class="line"></span><br><span class="line">    means = np.dot(resp.T, X) / nk[:, np.newaxis]</span><br><span class="line"></span><br><span class="line">    covariances = &#123;<span class="string">&quot;full&quot;</span>: _estimate_gaussian_covariances_full,</span><br><span class="line"></span><br><span class="line">                   <span class="string">&quot;tied&quot;</span>: _estimate_gaussian_covariances_tied,</span><br><span class="line"></span><br><span class="line">                   <span class="string">&quot;diag&quot;</span>: _estimate_gaussian_covariances_diag,</span><br><span class="line"></span><br><span class="line">                   <span class="string">&quot;spherical&quot;</span>: _estimate_gaussian_covariances_spherical</span><br><span class="line"></span><br><span class="line">                   &#125;[covariance_type](resp, X, nk, means, reg_covar)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> nk, means, covariances</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="迭代收敛，重复以上过程"><a href="#迭代收敛，重复以上过程" class="headerlink" title="迭代收敛，重复以上过程"></a>迭代收敛，重复以上过程</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">fit</span>(<span class="params">self, X, y=<span class="literal">None</span></span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Estimate model parameters with the EM algorithm.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    The method fit the model `n_init` times and set the parameters with</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    which the model has the largest likelihood or lower bound. Within each</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    trial, the method iterates between E-step and M-step for `max_iter`</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    times until the change of likelihood or lower bound is less than</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    `tol`, otherwise, a `ConvergenceWarning` is raised.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    迭代终止条件： 迭代次数ｎ_init，极大似然函数或下界函数的增益小于`tol`</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Parameters</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    ----------</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    X : array-like, shape (n_samples, n_features)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    -------</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    self</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    X = _check_X(X, self.n_components)</span><br><span class="line"></span><br><span class="line">    self._check_initial_parameters(X)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment"># if we enable warm_start, we will have a unique initialisation</span></span><br><span class="line"></span><br><span class="line">    do_init = <span class="keyword">not</span>(self.warm_start <span class="keyword">and</span> <span class="built_in">hasattr</span>(self, <span class="string">&#x27;converged_&#x27;</span>))</span><br><span class="line"></span><br><span class="line">    n_init = self.n_init <span class="keyword">if</span> do_init <span class="keyword">else</span> <span class="number">1</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    max_lower_bound = -np.infty</span><br><span class="line"></span><br><span class="line">    self.converged_ = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    random_state = check_random_state(self.random_state)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    n_samples, _ = X.shape</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 初始化次数</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> init <span class="keyword">in</span> <span class="built_in">range</span>(n_init):</span><br><span class="line"></span><br><span class="line">        self._print_verbose_msg_init_beg(init)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 先初始化参数</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> do_init:</span><br><span class="line"></span><br><span class="line">            self._initialize_parameters(X, random_state)</span><br><span class="line"></span><br><span class="line">            self.lower_bound_ = -np.infty</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 迭代次数</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> n_iter <span class="keyword">in</span> <span class="built_in">range</span>(self.max_iter):</span><br><span class="line"></span><br><span class="line">            prev_lower_bound = self.lower_bound_</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">            <span class="comment"># E step求出后验概率w_j^i或是Q分布</span></span><br><span class="line"></span><br><span class="line">            log_prob_norm, log_resp = self._e_step(X)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># Ｍ step更新参数</span></span><br><span class="line"></span><br><span class="line">            self._m_step(X, log_resp)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 求出下界函数的最大值</span></span><br><span class="line"></span><br><span class="line">            self.lower_bound_ = self._compute_lower_bound(</span><br><span class="line"></span><br><span class="line">                log_resp, log_prob_norm)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 下界函数的增益</span></span><br><span class="line"></span><br><span class="line">            change = self.lower_bound_ - prev_lower_bound</span><br><span class="line"></span><br><span class="line">            self._print_verbose_msg_iter_end(n_iter, change)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">            <span class="comment"># 比较下界函数增益与ｔｏｌ</span></span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">abs</span>(change) &lt; self.tol:</span><br><span class="line"></span><br><span class="line">                self.converged_ = <span class="literal">True</span></span><br><span class="line"></span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        self._print_verbose_msg_init_end(self.lower_bound_)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="comment">#</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> self.lower_bound_ &gt; max_lower_bound:</span><br><span class="line"></span><br><span class="line">            max_lower_bound = self.lower_bound_</span><br><span class="line"></span><br><span class="line">            best_params = self._get_parameters()</span><br><span class="line"></span><br><span class="line">            best_n_iter = n_iter</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> self.converged_:</span><br><span class="line"></span><br><span class="line">        warnings.warn(<span class="string">&#x27;Initialization %d did not converge. &#x27;</span></span><br><span class="line"></span><br><span class="line">                      <span class="string">&#x27;Try different init parameters, &#x27;</span></span><br><span class="line"></span><br><span class="line">                      <span class="string">&#x27;or increase max_iter, tol &#x27;</span></span><br><span class="line"></span><br><span class="line">                      <span class="string">&#x27;or check for degenerate data.&#x27;</span></span><br><span class="line"></span><br><span class="line">                      % (init + <span class="number">1</span>), ConvergenceWarning)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    self._set_parameters(best_params)</span><br><span class="line"></span><br><span class="line">    self.n_iter_ = best_n_iter</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> self</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="E-step中p-x-z-j"><a href="#E-step中p-x-z-j" class="headerlink" title="E step中p(x|z=j)"></a>E step中p(x|z=j)</h3><p>根据高斯分布的参数计算概率,优化的计算方法。</p>
<p>先计算协方差矩阵的precision矩阵，并进行cholesky分解</p>
<p>Precision matrix 协方差矩阵的逆矩阵：<a target="_blank" rel="noopener" href="https://www.statlect.com/glossary/precision-matrix">https://www.statlect.com/glossary/precision-matrix</a></p>
<p><img src="/2018/03/29/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-sklearn%E4%B8%AD%E9%AB%98%E6%96%AF%E6%B7%B7%E5%90%88%E6%A8%A1%E5%9E%8B%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB%E4%BB%A5%E5%8F%8A%E5%AE%9E%E7%8E%B0/precision.png"></p>
<p>然后根据精度矩阵的cholesky分解形式,这样可以优化矩阵运算</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_compute_precision_cholesky</span>(<span class="params">covariances, covariance_type</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Compute the Cholesky decomposition of the precisions.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Parameters</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    ----------</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    covariances : array-like</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        The covariance matrix of the current components.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        The shape depends of the covariance_type.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    covariance_type : &#123;&#x27;full&#x27;, &#x27;tied&#x27;, &#x27;diag&#x27;, &#x27;spherical&#x27;&#125;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        The type of precision matrices.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    -------</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    precisions_cholesky : array-like</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        The cholesky decomposition of sample precisions of the current</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        components. The shape depends of the covariance_type.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> covariance_type <span class="keyword">in</span> <span class="string">&#x27;full&#x27;</span>:</span><br><span class="line"></span><br><span class="line">        n_components, n_features, _ = covariances.shape</span><br><span class="line"></span><br><span class="line">        precisions_chol = np.empty((n_components, n_features, n_features))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> k, covariance <span class="keyword">in</span> <span class="built_in">enumerate</span>(covariances):</span><br><span class="line"></span><br><span class="line">            <span class="keyword">try</span>:</span><br><span class="line"></span><br><span class="line">                cov_chol = linalg.cholesky(covariance, lower=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">            <span class="keyword">except</span> linalg.LinAlgError:</span><br><span class="line"></span><br><span class="line">                <span class="keyword">raise</span> ValueError(estimate_precision_error_message)</span><br><span class="line"></span><br><span class="line">            precisions_chol[k] = linalg.solve_triangular(cov_chol,</span><br><span class="line"></span><br><span class="line">                                                         np.eye(n_features),</span><br><span class="line"></span><br><span class="line">                                                         lower=<span class="literal">True</span>).T</span><br><span class="line"></span><br><span class="line">    <span class="keyword">elif</span> covariance_type == <span class="string">&#x27;tied&#x27;</span>:</span><br><span class="line"></span><br><span class="line">        _, n_features = covariances.shape</span><br><span class="line"></span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line"></span><br><span class="line">            cov_chol = linalg.cholesky(covariances, lower=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">except</span> linalg.LinAlgError:</span><br><span class="line"></span><br><span class="line">            <span class="keyword">raise</span> ValueError(estimate_precision_error_message)</span><br><span class="line"></span><br><span class="line">        precisions_chol = linalg.solve_triangular(cov_chol, np.eye(n_features),</span><br><span class="line"></span><br><span class="line">                                                  lower=<span class="literal">True</span>).T</span><br><span class="line"></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> np.<span class="built_in">any</span>(np.less_equal(covariances, <span class="number">0.0</span>)):</span><br><span class="line"></span><br><span class="line">            <span class="keyword">raise</span> ValueError(estimate_precision_error_message)</span><br><span class="line"></span><br><span class="line">        precisions_chol = <span class="number">1.</span> / np.sqrt(covariances)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> precisions_chol</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h4 id="计算cholesky分解的行列式"><a href="#计算cholesky分解的行列式" class="headerlink" title="计算cholesky分解的行列式"></a>计算cholesky分解的行列式</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment"># Gaussian mixture probability estimators</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 根据cholesky分解计算行列式的log</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_compute_log_det_cholesky</span>(<span class="params">matrix_chol, covariance_type, n_features</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Compute the log-det of the cholesky decomposition of matrices.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Parameters</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    ----------</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    matrix_chol : 协方差矩阵的cholesky分解</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    covariance_type : &#123;&#x27;full&#x27;, &#x27;tied&#x27;, &#x27;diag&#x27;, &#x27;spherical&#x27;&#125;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    n_features : int</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Number of features.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    -------</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    log_det_precision_chol : array-like, shape (n_components,)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        The determinant of the precision matrix for each component.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> covariance_type == <span class="string">&#x27;full&#x27;</span>:</span><br><span class="line"></span><br><span class="line">        n_components, _, _ = matrix_chol.shape</span><br><span class="line"></span><br><span class="line">        log_det_chol = (np.<span class="built_in">sum</span>(np.log(</span><br><span class="line"></span><br><span class="line">            matrix_chol.reshape(</span><br><span class="line"></span><br><span class="line">                n_components, -<span class="number">1</span>)[:, ::n_features + <span class="number">1</span>]), <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">elif</span> covariance_type == <span class="string">&#x27;tied&#x27;</span>:</span><br><span class="line"></span><br><span class="line">        log_det_chol = (np.<span class="built_in">sum</span>(np.log(np.diag(matrix_chol))))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">elif</span> covariance_type == <span class="string">&#x27;diag&#x27;</span>:</span><br><span class="line"></span><br><span class="line">        log_det_chol = (np.<span class="built_in">sum</span>(np.log(matrix_chol), axis=<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line"></span><br><span class="line">        log_det_chol = n_features * (np.log(matrix_chol))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> log_det_chol</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h4 id="计算分子-logp-x-i-z-i-j-mu-Sigma"><a href="#计算分子-logp-x-i-z-i-j-mu-Sigma" class="headerlink" title="计算分子: $logp(x^{(i)}|z^{(i)}=j;\mu,\Sigma)$"></a>计算分子: $logp(x^{(i)}|z^{(i)}=j;\mu,\Sigma)$</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_estimate_log_gaussian_prob</span>(<span class="params">X, means, precisions_chol, covariance_type</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Estimate the log Gaussian probability.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Parameters</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    ----------</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    X : 样本数据(n_samples, n_features)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    means : k个n维正态分布的均值(n_components, n_features)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    precisions_chol : 精度矩阵的Cholesky分解</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    covariance_type : &#123;&#x27;full&#x27;, &#x27;tied&#x27;, &#x27;diag&#x27;, &#x27;spherical&#x27;&#125;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    -------</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    log_prob : (n_samples, n_components)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    n_samples, n_features = X.shape</span><br><span class="line"></span><br><span class="line">    n_components, _ = means.shape</span><br><span class="line"></span><br><span class="line">    <span class="comment"># det(precision_chol) is half of det(precision)</span></span><br><span class="line"></span><br><span class="line">    log_det = _compute_log_det_cholesky(</span><br><span class="line"></span><br><span class="line">        precisions_chol, covariance_type, n_features)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> covariance_type == <span class="string">&#x27;full&#x27;</span>:</span><br><span class="line"></span><br><span class="line">        log_prob = np.empty((n_samples, n_components))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> k, (mu, prec_chol) <span class="keyword">in</span> <span class="built_in">enumerate</span>(<span class="built_in">zip</span>(means, precisions_chol)):</span><br><span class="line"></span><br><span class="line">            y = np.dot(X, prec_chol) - np.dot(mu, prec_chol)</span><br><span class="line"></span><br><span class="line">            log_prob[:, k] = np.<span class="built_in">sum</span>(np.square(y), axis=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">elif</span> covariance_type == <span class="string">&#x27;tied&#x27;</span>:</span><br><span class="line"></span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">elif</span> covariance_type == <span class="string">&#x27;diag&#x27;</span>:</span><br><span class="line"></span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">elif</span> covariance_type == <span class="string">&#x27;spherical&#x27;</span>:</span><br><span class="line"></span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> -<span class="number">.5</span> * (n_features * np.log(<span class="number">2</span> * np.pi) + log_prob) + log_det</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h3 id="sklearn中实例"><a href="#sklearn中实例" class="headerlink" title="sklearn中实例"></a>sklearn中实例</h3><p>Although GMM are often used for clustering, we can compare the obtained clusters with the actual classes from the dataset. We initialize the means of the Gaussians with the means of the classes from the training set to make this comparison valid.</p>
<p>We plot predicted labels on both training and held out test data using a variety of GMM covariance types on the iris dataset. We compare GMMs with spherical, diagonal, full, and tied covariance matrices in increasing order of performance. Although one would expect full covariance to perform best in general, it is prone to overfitting on small datasets and does not generalize well to held out test data.</p>
<p>On the plots, train data is shown as dots, while test data is shown as crosses. The iris dataset is four-dimensional. Only the first two dimensions are shown here, and thus some points are separated in other dimensions.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">import</span> matplotlib <span class="keyword">as</span> mpl</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.mixture <span class="keyword">import</span> GaussianMixture</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> StratifiedKFold</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(__doc__)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">colors = [<span class="string">&#x27;navy&#x27;</span>, <span class="string">&#x27;turquoise&#x27;</span>, <span class="string">&#x27;darkorange&#x27;</span>]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">iris = datasets.load_iris()  <span class="comment"># data, target</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Break up the dataset into non-overlapping training (75%) and testing</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># (25%) sets.</span></span><br><span class="line"></span><br><span class="line">skf = StratifiedKFold(n_splits=<span class="number">4</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Only take the first fold.</span></span><br><span class="line"></span><br><span class="line">train_index, test_index = <span class="built_in">next</span>(<span class="built_in">iter</span>(skf.split(iris.data, iris.target)))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">X_train = iris.data[train_index]     <span class="comment"># (111, 4)</span></span><br><span class="line"></span><br><span class="line">y_train = iris.target[train_index]   <span class="comment"># (111,)</span></span><br><span class="line"></span><br><span class="line">X_test = iris.data[test_index]       <span class="comment"># (39, 4)</span></span><br><span class="line"></span><br><span class="line">y_test = iris.target[test_index]     <span class="comment"># (39,)</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">n_classes = <span class="built_in">len</span>(np.unique(y_train))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Try GMMs using different types of covariances. 根据协方差矩阵，有4中不同的GMM模型</span></span><br><span class="line"></span><br><span class="line">estimators = <span class="built_in">dict</span>((cov_type, GaussianMixture(n_components=n_classes,</span><br><span class="line"></span><br><span class="line">                   covariance_type=cov_type, max_iter=<span class="number">20</span>, random_state=<span class="number">0</span>))</span><br><span class="line"></span><br><span class="line">                  <span class="keyword">for</span> cov_type <span class="keyword">in</span> [<span class="string">&#x27;spherical&#x27;</span>, <span class="string">&#x27;diag&#x27;</span>, <span class="string">&#x27;tied&#x27;</span>, <span class="string">&#x27;full&#x27;</span>])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">n_estimators = <span class="built_in">len</span>(estimators)  <span class="comment"># 4</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># figsize表示图像的尺寸（width, height in inches）</span></span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">3</span> * <span class="number">5</span> // <span class="number">2</span>, <span class="number">6</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 图像之间的间距</span></span><br><span class="line"></span><br><span class="line">plt.subplots_adjust(bottom=<span class="number">.01</span>, top=<span class="number">0.95</span>, hspace=<span class="number">.15</span>, wspace=<span class="number">.05</span>,</span><br><span class="line"></span><br><span class="line">                    left=<span class="number">.01</span>, right=<span class="number">.99</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 椭圆</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">make_ellipses</span>(<span class="params">gmm, ax</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> n, color <span class="keyword">in</span> <span class="built_in">enumerate</span>(colors):</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> gmm.covariance_type == <span class="string">&#x27;full&#x27;</span>:</span><br><span class="line"></span><br><span class="line">            covariances = gmm.covariances_[n][:<span class="number">2</span>, :<span class="number">2</span>]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">elif</span> gmm.covariance_type == <span class="string">&#x27;tied&#x27;</span>:</span><br><span class="line"></span><br><span class="line">            covariances = gmm.covariances_[:<span class="number">2</span>, :<span class="number">2</span>]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">elif</span> gmm.covariance_type == <span class="string">&#x27;diag&#x27;</span>:</span><br><span class="line"></span><br><span class="line">            covariances = np.diag(gmm.covariances_[n][:<span class="number">2</span>])</span><br><span class="line"></span><br><span class="line">        <span class="keyword">elif</span> gmm.covariance_type == <span class="string">&#x27;spherical&#x27;</span>:</span><br><span class="line"></span><br><span class="line">            covariances = np.eye(gmm.means_.shape[<span class="number">1</span>]) * gmm.covariances_[n]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 参数估计得到的混合二维高斯分布，将其用椭圆表示出来～</span></span><br><span class="line"></span><br><span class="line">        v, w = np.linalg.eigh(covariances) <span class="comment"># 返回协方差矩阵的特征值和列向量由特征矩阵构成的矩阵</span></span><br><span class="line"></span><br><span class="line">        u = w[<span class="number">0</span>] / np.linalg.norm(w[<span class="number">0</span>]) <span class="comment"># order=None 表示 Frobenius norm，2-norm</span></span><br><span class="line"></span><br><span class="line">        angle = np.arctan2(u[<span class="number">1</span>], u[<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line">        angle = <span class="number">180</span> * angle / np.pi  <span class="comment"># 转换为角度</span></span><br><span class="line"></span><br><span class="line">        v = <span class="number">2.</span> * np.sqrt(<span class="number">2.</span>) * np.sqrt(v)</span><br><span class="line"></span><br><span class="line">        ell = mpl.patches.Ellipse(gmm.means_[n, :<span class="number">2</span>], v[<span class="number">0</span>], v[<span class="number">1</span>],</span><br><span class="line"></span><br><span class="line">                                  <span class="number">180</span> + angle, color=color)</span><br><span class="line"></span><br><span class="line">        ell.set_clip_box(ax.bbox)</span><br><span class="line"></span><br><span class="line">        ell.set_alpha(<span class="number">0.5</span>)</span><br><span class="line"></span><br><span class="line">        ax.add_artist(ell)  <span class="comment"># 增加文字</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> index, (name, estimator) <span class="keyword">in</span> <span class="built_in">enumerate</span>(estimators.items()):</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Since we have class labels for the training data, we can</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># initialize the GMM parameters in a supervised manner.</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 这里因为有类标签，所以直接用真实均值来初始化GMM的均值。在无标签或者标签较少的情况下，则需要随机初始化</span></span><br><span class="line"></span><br><span class="line">    estimator.means_init = np.array([X_train[y_train == i].mean(axis=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">                                    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n_classes)])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Train the other parameters using the EM algorithm.</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 用em算法来估计其他参数</span></span><br><span class="line"></span><br><span class="line">    estimator.fit(X_train)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 画椭圆</span></span><br><span class="line"></span><br><span class="line">    h = plt.subplot(<span class="number">2</span>, n_estimators // <span class="number">2</span>, index + <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    make_ellipses(estimator, h)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> n, color <span class="keyword">in</span> <span class="built_in">enumerate</span>(colors):</span><br><span class="line"></span><br><span class="line">        data = iris.data[iris.target == n]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 不同的种类数据用不同的点表示</span></span><br><span class="line"></span><br><span class="line">        plt.scatter(data[:, <span class="number">0</span>], data[:, <span class="number">1</span>], s=<span class="number">0.8</span>, color=color,</span><br><span class="line"></span><br><span class="line">                    label=iris.target_names[n])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 用xx表示测试集</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> n, color <span class="keyword">in</span> <span class="built_in">enumerate</span>(colors):</span><br><span class="line"></span><br><span class="line">        data = X_test[y_test == n]</span><br><span class="line"></span><br><span class="line">        plt.scatter(data[:, <span class="number">0</span>], data[:, <span class="number">1</span>], marker=<span class="string">&#x27;x&#x27;</span>, color=color)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 训练集的准确率</span></span><br><span class="line"></span><br><span class="line">    y_train_pred = estimator.predict(X_train) <span class="comment"># 预测是选取概率最大的一类</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 当无标签时是没有办法计算准确率的。但是这里有标签，</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># y_train_pred返回的是概率最大的索引，　y_train的元素是[0,1,2,3]中的一个</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 因此可以求得准确率</span></span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(y_train_pred[:<span class="number">5</span>])</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(y_train[:<span class="number">5</span>])</span><br><span class="line"></span><br><span class="line">    train_accuracy = np.mean(y_train_pred.ravel() == y_train.ravel()) * <span class="number">100</span></span><br><span class="line"></span><br><span class="line">    plt.text(<span class="number">0.05</span>, <span class="number">0.9</span>, <span class="string">&#x27;Train accuracy: %.1f&#x27;</span> % train_accuracy,</span><br><span class="line"></span><br><span class="line">             transform=h.transAxes)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    y_test_pred = estimator.predict(X_test)</span><br><span class="line"></span><br><span class="line">    test_accuracy = np.mean(y_test_pred.ravel() == y_test.ravel()) * <span class="number">100</span></span><br><span class="line"></span><br><span class="line">    plt.text(<span class="number">0.05</span>, <span class="number">0.8</span>, <span class="string">&#x27;Test accuracy: %.1f&#x27;</span> % test_accuracy,</span><br><span class="line"></span><br><span class="line">             transform=h.transAxes)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    plt.xticks(())</span><br><span class="line"></span><br><span class="line">    plt.yticks(())</span><br><span class="line"></span><br><span class="line">    plt.title(name)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">plt.legend(scatterpoints=<span class="number">1</span>, loc=<span class="string">&#x27;lower right&#x27;</span>, prop=<span class="built_in">dict</span>(size=<span class="number">12</span>))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">plt.show()</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><img src="/2018/03/29/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-sklearn%E4%B8%AD%E9%AB%98%E6%96%AF%E6%B7%B7%E5%90%88%E6%A8%A1%E5%9E%8B%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB%E4%BB%A5%E5%8F%8A%E5%AE%9E%E7%8E%B0/Figure_1.png"></p>
</div><div class="article-licensing box"><div class="licensing-title"><p>代码实现高斯混合模型</p><p><a href="http://www.panxiaoxie.cn/2018/03/29/机器学习-sklearn中高斯混合模型源码阅读以及实现/">http://www.panxiaoxie.cn/2018/03/29/机器学习-sklearn中高斯混合模型源码阅读以及实现/</a></p></div><div class="licensing-meta level is-mobile"><div class="level-left"><div class="level-item is-narrow"><div><h6>作者</h6><p>Xie Pan</p></div></div><div class="level-item is-narrow"><div><h6>发布于</h6><p>2018-03-29</p></div></div><div class="level-item is-narrow"><div><h6>更新于</h6><p>2021-06-29</p></div></div><div class="level-item is-narrow"><div><h6>许可协议</h6><p><a class="icons" rel="noopener" target="_blank" title="Creative Commons" href="https://creativecommons.org/"><i class="icon fab fa-creative-commons"></i></a><a class="icons" rel="noopener" target="_blank" title="Attribution" href="https://creativecommons.org/licenses/by/4.0/"><i class="icon fab fa-creative-commons-by"></i></a><a class="icons" rel="noopener" target="_blank" title="Noncommercial" href="https://creativecommons.org/licenses/by-nc/4.0/"><i class="icon fab fa-creative-commons-nc"></i></a></p></div></div></div></div></div><div class="article-tags is-size-7 mb-4"><span class="mr-2">#</span><a class="link-muted mr-2" rel="tag" href="/tags/ML/">ML</a></div><!--!--></article></div><!--!--><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/2018/04/06/chapter9-%E9%9A%90%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E6%A8%A1%E5%9E%8B-standford/"><i class="level-item fas fa-chevron-left"></i><span class="level-item">chapter9 隐马尔可夫模型</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/2018/03/29/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B%E5%88%B0%E9%AB%98%E6%96%AF%E5%88%A4%E5%88%AB%E5%88%86%E6%9E%90%E5%86%8D%E5%88%B0GMM%E5%92%8CEM%E7%AE%97%E6%B3%95/"><span class="level-item">机器学习-生成模型到高斯判别分析再到GMM和EM算法</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><div class="card"><div class="card-content"><h3 class="title is-5">评论</h3><div id="disqus_thread"><noscript>Please enable JavaScript to view the <a target="_blank" rel="noopener" href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript></div><script>var disqus_config = function () {
            this.page.url = 'http://www.panxiaoxie.cn/2018/03/29/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-sklearn%E4%B8%AD%E9%AB%98%E6%96%AF%E6%B7%B7%E5%90%88%E6%A8%A1%E5%9E%8B%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB%E4%BB%A5%E5%8F%8A%E5%AE%9E%E7%8E%B0/';
            this.page.identifier = '2018/03/29/机器学习-sklearn中高斯混合模型源码阅读以及实现/';
        };
        (function() {
            var d = document, s = d.createElement('script');  
            s.src = '//' + 'panxie' + '.disqus.com/embed.js';
            s.setAttribute('data-timestamp', +new Date());
            (d.head || d.body).appendChild(s);
        })();</script></div></div></div><!--!--><div class="column column-right is-4-tablet is-4-desktop is-4-widescreen  order-3"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar" src="/img/avatar.png" alt="panxiaoxie"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">panxiaoxie</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Beijing, China</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">文章</p><a href="/archives"><p class="title">116</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">分类</p><a href="/categories"><p class="title">38</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">标签</p><a href="/tags"><p class="title">35</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/PanXiebit" target="_blank" rel="noopener">关注我</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/PanXiebit"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Email" href="/ftdpanxie@gmail.com"><i class="fa fa-envelope"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="RSS" href="/"><i class="fas fa-rss"></i></a></div></div></div><!--!--><div class="card widget" data-type="links"><div class="card-content"><div class="menu"><h3 class="menu-label">链接</h3><ul class="menu-list"><li><a class="level is-mobile" href="https://github.com/PanXiebit" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">github</span></span><span class="level-right"><span class="level-item tag">github.com</span></span></a></li><li><a class="level is-mobile" href="ftdpanxie@gmail.com" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">email</span></span><span class="level-right"><span class="level-item tag">ftdpanxie@gmail.com</span></span></a></li></ul></div></div></div><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">分类</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/C/"><span class="level-start"><span class="level-item">C++</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/CSAPP/"><span class="level-start"><span class="level-item">CSAPP</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/DRL/"><span class="level-start"><span class="level-item">DRL</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/GAN/"><span class="level-start"><span class="level-item">GAN</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li><li><a class="level is-mobile" href="/categories/GAN-RL/"><span class="level-start"><span class="level-item">GAN, RL</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/ML/"><span class="level-start"><span class="level-item">ML</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/NLP/"><span class="level-start"><span class="level-item">NLP</span></span><span class="level-end"><span class="level-item tag">14</span></span></a></li><li><a class="level is-mobile" href="/categories/TensorFlow/"><span class="level-start"><span class="level-item">TensorFlow</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/cs224d/"><span class="level-start"><span class="level-item">cs224d</span></span><span class="level-end"><span class="level-item tag">10</span></span></a></li><li><a class="level is-mobile" href="/categories/generation/"><span class="level-start"><span class="level-item">generation</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/interview/"><span class="level-start"><span class="level-item">interview</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/machine-translation/"><span class="level-start"><span class="level-item">machine translation</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/python/"><span class="level-start"><span class="level-item">python</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/pytorch/"><span class="level-start"><span class="level-item">pytorch</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/reinforcement-learning/"><span class="level-start"><span class="level-item">reinforcement learning</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/sign-language-recognition/"><span class="level-start"><span class="level-item">sign language recognition</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/transfer-learning/"><span class="level-start"><span class="level-item">transfer learning</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"><span class="level-start"><span class="level-item">数据结构与算法</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile" href="/categories/%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB/"><span class="level-start"><span class="level-item">文本分类</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"><span class="level-start"><span class="level-item">论文笔记</span></span><span class="level-end"><span class="level-item tag">40</span></span></a><ul><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/DL/"><span class="level-start"><span class="level-item">DL</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/ESA/"><span class="level-start"><span class="level-item">ESA</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/GAN/"><span class="level-start"><span class="level-item">GAN</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/MRC-and-QA/"><span class="level-start"><span class="level-item">MRC and QA</span></span><span class="level-end"><span class="level-item tag">7</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/Machine-Translation/"><span class="level-start"><span class="level-item">Machine Translation</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/NLP/"><span class="level-start"><span class="level-item">NLP</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/Transformer/"><span class="level-start"><span class="level-item">Transformer</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/capsules/"><span class="level-start"><span class="level-item">capsules</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/computer-vision/"><span class="level-start"><span class="level-item">computer vision</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/constrast-learning/"><span class="level-start"><span class="level-item">constrast learning</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/data-augmentation/"><span class="level-start"><span class="level-item">data augmentation</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/dialogue-system/"><span class="level-start"><span class="level-item">dialogue system</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/language-model/"><span class="level-start"><span class="level-item">language model</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/machine-translation/"><span class="level-start"><span class="level-item">machine translation</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/open-set-recognition/"><span class="level-start"><span class="level-item">open set recognition</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/sentence-embedding/"><span class="level-start"><span class="level-item">sentence embedding</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/text-matching/"><span class="level-start"><span class="level-item">text matching</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/vision-language/"><span class="level-start"><span class="level-item">vision-language</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li></ul></div></div></div></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/panxiaoxie.png" alt="潘小榭" height="28"></a><p class="is-size-7"><span>&copy; 2021 Xie Pan</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("zh-CN");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="回到顶端" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "此网站使用Cookie来改善您的体验。",
          dismiss: "知道了！",
          allow: "允许使用Cookie",
          deny: "拒绝",
          link: "了解更多",
          policy: "Cookie政策",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.5/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="想要查找什么..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"想要查找什么...","untitled":"(无标题)","posts":"文章","pages":"页面","categories":"分类","tags":"标签"});
        });</script></body></html>