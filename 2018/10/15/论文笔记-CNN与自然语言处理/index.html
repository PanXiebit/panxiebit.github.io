<!doctype html>
<html lang="de"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>论文笔记-CNN与自然语言处理 - 潘小榭</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="潘小榭"><meta name="msapplication-TileImage" content="/img/favicon.svg"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="潘小榭"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="description" content="最近在参加 AI challenge 观点型阅读理解的比赛。数据集形式如下：  最开始尝试的模型主要包括几个部分：  Embedding: 使用预训练的中文词向量。    Encoder: 基于 Bi-GRU 对 passage,query 和 alternatives 进行编码处理。    Attention: 用 trilinear 的方式，并 mask 之后得到相似矩阵，然后采用类似于 Bi"><meta property="og:type" content="blog"><meta property="og:title" content="论文笔记-CNN与自然语言处理"><meta property="og:url" content="http://www.panxiaoxie.cn/2018/10/15/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-CNN%E4%B8%8E%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/"><meta property="og:site_name" content="潘小榭"><meta property="og:description" content="最近在参加 AI challenge 观点型阅读理解的比赛。数据集形式如下：  最开始尝试的模型主要包括几个部分：  Embedding: 使用预训练的中文词向量。    Encoder: 基于 Bi-GRU 对 passage,query 和 alternatives 进行编码处理。    Attention: 用 trilinear 的方式，并 mask 之后得到相似矩阵，然后采用类似于 Bi"><meta property="og:image" content="http://www.panxiaoxie.cn/2018/10/15/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-CNN%E4%B8%8E%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/01.png"><meta property="og:image" content="http://www.panxiaoxie.cn/2018/10/15/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-CNN%E4%B8%8E%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/02.png"><meta property="og:image" content="http://www.panxiaoxie.cn/2018/10/15/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-CNN%E4%B8%8E%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/05.png"><meta property="og:image" content="http://www.panxiaoxie.cn/2018/10/15/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-CNN%E4%B8%8E%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/03.png"><meta property="og:image" content="http://www.panxiaoxie.cn/2018/10/15/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-CNN%E4%B8%8E%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/06.png"><meta property="og:image" content="http://www.panxiaoxie.cn/2018/10/15/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-CNN%E4%B8%8E%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/07.png"><meta property="og:image" content="http://www.panxiaoxie.cn/2018/10/15/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-CNN%E4%B8%8E%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/09.jpg"><meta property="og:image" content="http://www.panxiaoxie.cn/2018/10/15/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-CNN%E4%B8%8E%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/10.jpg"><meta property="og:image" content="http://www.panxiaoxie.cn/2018/10/15/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-CNN%E4%B8%8E%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/08.gif"><meta property="og:image" content="http://www.panxiaoxie.cn/2018/10/15/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-CNN%E4%B8%8E%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/11.png"><meta property="og:image" content="http://www.panxiaoxie.cn/2018/10/15/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-CNN%E4%B8%8E%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/12.png"><meta property="og:image" content="http://www.panxiaoxie.cn/2018/10/15/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-CNN%E4%B8%8E%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/13.png"><meta property="article:published_time" content="2018-10-15T11:34:48.000Z"><meta property="article:modified_time" content="2021-06-29T08:12:09.158Z"><meta property="article:author" content="Xie Pan"><meta property="article:tag" content="MRC and QA"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="/2018/10/15/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-CNN%E4%B8%8E%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/01.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"http://www.panxiaoxie.cn/2018/10/15/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-CNN%E4%B8%8E%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/"},"headline":"论文笔记-CNN与自然语言处理","image":["http://www.panxiaoxie.cn/2018/10/15/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-CNN%E4%B8%8E%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/01.png","http://www.panxiaoxie.cn/2018/10/15/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-CNN%E4%B8%8E%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/02.png","http://www.panxiaoxie.cn/2018/10/15/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-CNN%E4%B8%8E%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/05.png","http://www.panxiaoxie.cn/2018/10/15/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-CNN%E4%B8%8E%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/03.png","http://www.panxiaoxie.cn/2018/10/15/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-CNN%E4%B8%8E%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/06.png","http://www.panxiaoxie.cn/2018/10/15/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-CNN%E4%B8%8E%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/07.png","http://www.panxiaoxie.cn/2018/10/15/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-CNN%E4%B8%8E%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/09.jpg","http://www.panxiaoxie.cn/2018/10/15/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-CNN%E4%B8%8E%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/10.jpg","http://www.panxiaoxie.cn/2018/10/15/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-CNN%E4%B8%8E%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/08.gif","http://www.panxiaoxie.cn/2018/10/15/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-CNN%E4%B8%8E%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/11.png","http://www.panxiaoxie.cn/2018/10/15/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-CNN%E4%B8%8E%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/12.png","http://www.panxiaoxie.cn/2018/10/15/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-CNN%E4%B8%8E%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/13.png"],"datePublished":"2018-10-15T11:34:48.000Z","dateModified":"2021-06-29T08:12:09.158Z","author":{"@type":"Person","name":"Xie Pan"},"publisher":{"@type":"Organization","name":"潘小榭","logo":{"@type":"ImageObject","url":"http://www.panxiaoxie.cn/img/logo.svg"}},"description":"最近在参加 AI challenge 观点型阅读理解的比赛。数据集形式如下：  最开始尝试的模型主要包括几个部分：  Embedding: 使用预训练的中文词向量。    Encoder: 基于 Bi-GRU 对 passage,query 和 alternatives 进行编码处理。    Attention: 用 trilinear 的方式，并 mask 之后得到相似矩阵，然后采用类似于 Bi"}</script><link rel="canonical" href="http://www.panxiaoxie.cn/2018/10/15/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-CNN%E4%B8%8E%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/"><link rel="icon" href="/img/favicon.svg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/css/justifiedGallery.min.css"><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script><!--!--><!--!--><meta name="generator" content="Hexo 5.4.0"></head><body class="is-2-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/logo.svg" alt="潘小榭" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-8-widescreen"><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2018-10-15T11:34:48.000Z" title="2018/10/15 下午7:34:48">2018-10-15</time></span><span class="level-item">Updated&nbsp;<time dateTime="2021-06-29T08:12:09.158Z" title="2021/6/29 下午4:12:09">2021-06-29</time></span><span class="level-item"><a class="link-muted" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/">论文笔记</a><span> / </span><a class="link-muted" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/MRC-and-QA/">MRC and QA</a></span><span class="level-item">21 minutes read (About 3214 words)</span></div></div><h1 class="title is-3 is-size-4-mobile">论文笔记-CNN与自然语言处理</h1><div class="content"><p>最近在参加 AI challenge 观点型阅读理解的比赛。数据集形式如下：</p>
<p><img src="/2018/10/15/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-CNN%E4%B8%8E%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/01.png"></p>
<p>最开始尝试的模型主要包括几个部分：</p>
<ul>
<li><p><strong>Embedding:</strong> 使用预训练的中文词向量。  </p>
</li>
<li><p><strong>Encoder:</strong> 基于 Bi-GRU 对 passage,query 和 alternatives 进行编码处理。  </p>
</li>
<li><p><strong>Attention:</strong> 用 trilinear 的方式，并 mask 之后得到相似矩阵，然后采用类似于 <a target="_blank" rel="noopener" href="https://panxiaoxie.cn/2018/08/07/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-QA%20BiDAF/">BiDAF</a> 中的形式 bi-attention flow 得到 attened passage.  </p>
</li>
<li><p><strong>contextual:</strong> 用 Bi-GRU 对 attened passage 进行编码，得到 fusion.  </p>
</li>
<li><p><strong>match</strong> 使用 attention pooling 的方式将 fusion 和 enc_answer 转换为单个 vector. 然后使用 cosin 进行匹配计算得到最相似的答案。  </p>
</li>
</ul>
<p>目前能得到的准确率是 0.687. 距离第一名差了 0.1…其实除了换模型，能提升和改进的地方是挺多的。</p>
<ul>
<li><p>可以用 ELMO 或 wordvec 先对训练集进行预训练得到自己的词向量。  </p>
</li>
<li><p>attention 层可以使用更丰富的方式，很多paper 中也有提到。甚至可以加上人工提取的特征。比如苏剑林 <a target="_blank" rel="noopener" href="https://kexue.fm/archives/5409">blog</a> 中提到的。</p>
</li>
<li><p>还有个很重要的就是 match 部分， attention pooling 是否可以换成其他更好的方式？</p>
</li>
</ul>
<p>但是，不断尝试各种模型的前提也要考虑速度吧。。rnn 实在是太慢了，所以决定试试 CNN 的方式来处理 NLP 的任务。</p>
<p>关于使用 CNN 来处理阅读理解的任务的大作还是挺多的，这里主要介绍这两篇：  </p>
<ul>
<li><p>Facebook: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1705.03122">Convolutional Sequence to Sequence Learning</a>  </p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1711.04352">Fast Reading Comprehension with ConvNets</a></p>
</li>
</ul>
<h1 id="ConvS2S"><a href="#ConvS2S" class="headerlink" title="ConvS2S"></a>ConvS2S</h1><p>paper: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1705.03122">Convolutional Sequence to Sequence Learning</a></p>
<p>这篇 paper 对应的 NLP 任务是机器翻译，除了用 CNN 对 sentence 进行编码之外，其核心是在 decoder 的时候也使用 CNN. 对于阅读理解来说，能够借用的是其编码 sentence 的方式。但这里作为学习，也多了解一下 decoder 吧～</p>
<p>对文本来说，看到 CNN 我们首先想到的是 cnn 能有效利用局部信息，提取出局部特征，所以适合做文本分类。但是对于 机器翻译、阅读理解这样的需要考虑全局信息的任务，CNN 似乎看起来并不那么有效。而且在 decoder 的时候，词的生成是 one by one 的，下一个词的生成是依赖于上一个词的。所以在 decoder 中使用 RNN 也是很自然而然的。</p>
<p>Facebook 的这篇 paper 就改变了这些传统的思维，不仅用 CNN 编码全局信息，而且还能 decoder.</p>
<h2 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h2><blockquote>
<p>Multi-layer convolutional neural networks create hierarchical representations over the input sequence in which nearby input elements interact at lower layers while distant elements interact at higher layers.  </p>
</blockquote>
<p>多层 CNN 具有层级表示结构，相邻的词之间在较低层的 layer 交互，距离较远的词在较高层的 layer 交互（交互的目的就是语义消歧）。</p>
<blockquote>
<p>Hierarchical structure provides a shorter path to capture long-range dependencies compared to the chain structure modeled by recurrent networks, e.g. we can obtain a feature representation capturing relationships within a window of n words by applying only O(n/k) convolutional operations for kernels of width k, compared to a linear number O(n) for recurrent neural networks.  </p>
</blockquote>
<p>层级结构提供了一个更短的路径来获取长期依赖。比如相距为 n 的两个词，在 rnn 中交互需要的步数是 O(n),在层级 CNN 中需要 O(n/k).这样减少了非线性的操作，降低了梯度消失的情况。所以这两个词的交互效果会更好～</p>
<blockquote>
<p>Inputs to a convolutional network are fed through a constant number of kernels and non-linearities, whereas recurrent networks apply up to n operations and non-linearities to the first word and only a single set of operations to the last word. Fixing the number of nonlinearities applied to the inputs also eases learning.  </p>
</blockquote>
<p>输入到 CNN 中每个词都会经历固定的 kernel 和 非线性操作。而输入到 RNN 的，第一个词需要经过 n 个 operations，最后一个词只经历了一个 operations. 作者认为固定的操作更容易学习。  </p>
<p>这一点我个人认为并不一定就是合理的，本来一个句子中不同词的重要性就是不一样的。  </p>
<h2 id="Model-Architecture"><a href="#Model-Architecture" class="headerlink" title="Ｍodel Architecture"></a>Ｍodel Architecture</h2><p><img src="/2018/10/15/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-CNN%E4%B8%8E%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/02.png"></p>
<p>模型分为以下几个部分：  </p>
<ul>
<li><p>position embedding  </p>
</li>
<li><p>convolution block structure  </p>
</li>
<li><p>Multi-step attention  </p>
</li>
</ul>
<h3 id="position-encoding"><a href="#position-encoding" class="headerlink" title="position encoding"></a>position encoding</h3><p><img src="/2018/10/15/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-CNN%E4%B8%8E%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/05.png"></p>
<p>这部分在很多地方都出现过了，在没有 rnn 的情况下，都会用 PE 来编码位置信息。但是在这篇 paper 中，作者通过实验发现，PE 作用似乎并不是很重要。  </p>
<p><img src="/2018/10/15/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-CNN%E4%B8%8E%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/03.png"></p>
<h3 id="convolution-blocks"><a href="#convolution-blocks" class="headerlink" title="convolution blocks"></a>convolution blocks</h3><p>作者使用的是门激活机制， GLU, gate linear units.  </p>
<blockquote>
<p>来自于 paper: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1612.08083">Language modeling with gated convolutional networks</a>  </p>
</blockquote>
<p>在这篇 paper 中，作者用无监督的方式，来训练语言模型，将 CNN 得到的语言模型与 LSTM 进行对比。</p>
<p><img src="/2018/10/15/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-CNN%E4%B8%8E%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/06.png"></p>
<p>也就是:</p>
<p>$$h_l=(X<em>W+b)\otimes \sigma(X</em>V+c)$$</p>
<blockquote>
<p>The output of each layer is a linear projection X ∗ W + b modulated by the gates σ(X ∗ V + c). Similar to LSTMs, these gates multiply each element of the matrix X ∗W+b</p>
</blockquote>
<p>and control the information passed on in the hierarchy.</p>
<p>如果是 LSTM-style，应该是 GTU：</p>
<p>$$h_i^l=tanh(X<em>W+b)\otimes \sigma(X</em>V+c)$$</p>
<p>作者将两者进行了对比，发现 GLU 效果更好。</p>
<p><strong>residual connection:</strong> 为了得到更 deep 的卷积神经网络，作者增加了残差链接。</p>
<p>$$h_i^l=v(W^l[h_{i-k/2}^{l-1},…,h_{i+k/2}^{l-1}]+b_w^l)+h_i^{l-1}$$</p>
<p>卷积的整个过程：  </p>
<p><img src="/2018/10/15/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-CNN%E4%B8%8E%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/07.png"></p>
<p>论文中举了这样一个例子：  </p>
<blockquote>
<p>For instance, stacking 6 blocks with k = 5 results in an input field of 25 elements, i.e. each output depends on 25 inputs. Non-linearities allow the networks to exploit the full input field, or to focus on fewer elements if needed.  </p>
</blockquote>
<p>这个怎么算的呢？看下图：</p>
<p><img src="/2018/10/15/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-CNN%E4%B8%8E%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/09.jpg"></p>
<p><img src="/2018/10/15/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-CNN%E4%B8%8E%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/10.jpg"></p>
<p>从上图中可以看到，当 k=3 时，3 个 blocks，第三层中的每一个输入都与输入中的 7 列有关。所以计算方式是 k + (k-1)* (blocks-1).</p>
<p>一维卷积和二维卷积的区别：</p>
<ul>
<li><p>ConvS2S 是 1D 卷积，kernel 只是在时间维度上平移，且 stride 的固定 size 为1,这是因为语言不具备图像的可伸缩性，图像在均匀的进行降采样后不改变图像的特征，而一个句子间隔着取词，意思就会改变很多了。  </p>
</li>
<li><p>在图像中一个卷积层往往有多个 filter，以获取图像不同的 pattern，但是在 ConvS2S 中，每一层只有一个 filter。一个句子进入 filter 的数据形式是 [1, n, d]. 其中 n 为句子长度， filter 对数据进行 n 方向上卷积，而 d 是词的向量维度，可以理解为 channel，与彩色图片中的 rgb 三个 channel 类似。</p>
</li>
</ul>
<blockquote>
<p>Facebook 在设计时，并没有像图像中常做的那样，每一层只设置一个 filter。这样做的原因，一是为了简化模型，加速模型收敛，二是他们认为一个句子的 pattern 要较图像简单很多，通过每层设置一个 filter，逐层堆叠后便能抓到所有的 pattern. 更有可能的原因是前者。因为在 transorfmer 中，multi-head attention 多头聚焦取得了很好的效果，说明一个句子的 pattern 是有多个的.  </p>
</blockquote>
<p>这段话是有问题的吧？ filter 的个数难道不是 2d吗？ 只不过这里说的 transorfmer 的多头聚焦是值得聚焦到一个词向量中的部分维度。记得在 cs224d 中 manning 曾经讲过一个例子，经过训练或词与词之间的交互后，词向量中的部分维度发生了变化。</p>
<p>在 paper 中，卷积核的尺寸大小是 $W\in R^{2d\times kd}$.</p>
<blockquote>
<p>For encoder networks we ensure that the output of the convolutional layers matches the input length by padding the input at each layer. However, for decoder networks we have to take care that no future information is available to the decoder (Oord et al., 2016a). Specifically, we pad the input by k − 1 elements on both the left and right side by zero vectors, and then remove k elements from the end of the convolution output.</p>
</blockquote>
<p>在 encoder 和 decoder 网络中，padding 的方式是不一样的。因为在 decoder 的时候不能考虑未来信息.  </p>
<p>在 encoder 时，将 (k-1) pad 到左右两边，保证卷积层的长度不变。  </p>
<p>在 decoder 中，将 (k-1) pad 到句子的左边。因此生成的词依旧是 one by one.</p>
<h3 id="Multi-step-Attention"><a href="#Multi-step-Attention" class="headerlink" title="Multi-step Attention"></a>Multi-step Attention</h3><p><img src="/2018/10/15/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-CNN%E4%B8%8E%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/08.gif"></p>
<p>$$d_i^l=W_d^lh_i^l+b_d^l+g_i$$</p>
<p>$$a_{ij}^l=\dfrac{exp(d_i^l\cdot z_j^u)}{\sum_{t=1}^mexp(d_i^l\cdot z_j^u)}$$</p>
<p>$$c_i^l=\sum_{j=1}^ma_{ij}^l(z_j^u+e_j)$$</p>
<p>上式中，l 表示 decoder 中卷积层的层数，i 表示时间步。  </p>
<p>实际上跟 rnn 的 decoder 还是比较接近的。  </p>
<ul>
<li><p>在训练阶段是 teacher forcing, 卷积核 $W_d^l$ 在 target sentence $h^l$ 上移动做卷积得到 $(W_d^lh_i^l + b_d^l)$，类似与 rnn-decoder 中的隐藏状态。然后加上上一个词的 embedding $g_i$,得到 $d_i^l$.  </p>
</li>
<li><p>与 encdoer 得到的 source sentence 做交互，通过 softmax 得到 attention weights $a_{ij}^l$.  </p>
</li>
<li><p>得到 attention vector 跟 rnn-decoder 有所不同，这里加上了 input element embedding $e_j$.</p>
</li>
</ul>
<p><strong>至于这里为什么要加 $e_j$?</strong>  </p>
<blockquote>
<p>We found adding e_j to be beneficial and it resembles key-value memory networks where the keys are the z_j^u and the values are the z^u_j + e_j (Miller et al., 2016). Encoder outputs z_j^u represent potentially large input contexts and e_j provides point information about a specific input element that is useful when making a prediction. Once c^l_i has been computed, it is simply added to the output of the corresponding decoder layer h^l_i.</p>
</blockquote>
<p>$z_j^u$ 表示更丰富的信息，而 $e_j$ 能够能具体的指出输入中对预测有用的信息。还是谁用谁知道吧。。</p>
<p><strong>关于 multi-hop attention:</strong>  </p>
<blockquote>
<p>This can be seen as attention with multiple ’hops’ (Sukhbaatar et al., 2015) compared to single step attention (Bahdanau et al., 2014; Luong et al., 2015; Zhou et al., 2016; Wu et al., 2016). In particular, the attention of the first layer determines a useful source context which is then fed to the second layer that takes this information into account when computing attention etc. The decoder also has immediate access to the attention history of the k − 1 previous time steps because the conditional inputs $c^{l-1}_{i−k}, . . . , c^{l-1}<em>i$ are part of $h^{l-1}</em>{i-k}, . . . , h^{l-1}_i$ which are input to $h^l_i$. This makes it easier for the model to take into account which previous inputs have been attended to already compared to recurrent nets where this information is in the recurrent state and needs to survive several non-linearities. Overall, our attention mechanism considers which words we previously attended to (Yang et al., 2016) and performs multiple attention ’hops’ per time step. In Appendix §C, we plot attention scores for a deep decoder and show that at different layers, different portions of the source are attended to.</p>
</blockquote>
<p>这个跟 memory networks 中的 multi-hop 是有点类似。</p>
<h1 id="FAST-READING-COMPREHENSION-WITH-CONVNETS"><a href="#FAST-READING-COMPREHENSION-WITH-CONVNETS" class="headerlink" title="FAST READING COMPREHENSION WITH CONVNETS"></a>FAST READING COMPREHENSION WITH CONVNETS</h1><p>Gated Linear Dilated Residual Network (GLDR):   </p>
<p>a combination of <strong>residual networks</strong> (He et al., 2016), <strong>dilated convolutions</strong> (Yu &amp; Koltun, 2016) and <strong>gated linear units (Dauphin et al., 2017)</strong>.</p>
<h2 id="text-understanding-with-dilated-convolution"><a href="#text-understanding-with-dilated-convolution" class="headerlink" title="text understanding with dilated convolution"></a>text understanding with dilated convolution</h2><p><img src="/2018/10/15/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-CNN%E4%B8%8E%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/11.png"></p>
<p>kernel:$k=[k_{-l},k_{-l+1},…,k_l]$, size=$2l+1$    </p>
<p>input: $x=[x_1,x_2,…,x_n]$  </p>
<p>dilation: d</p>
<p>卷积可以表示为：</p>
<p>$$(k*x)_ t=\sum_{i=-l}^lk_i\cdot x_{t + d\cdot i}$$</p>
<p><strong>为什么要使用膨胀卷积呢？ Why Dilated convolution?</strong>  </p>
<blockquote>
<p>Repeated dilated convolution (Yu &amp; Koltun, 2016) increases the receptive region of ConvNet outputs exponentially with respect to the network depth, which results in drastically shortened computation paths.   </p>
</blockquote>
<p>能够显著缩短两个词之间的计算路径。</p>
<p><img src="/2018/10/15/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-CNN%E4%B8%8E%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/12.png"></p>
<p>作者将 GLDR 和 self-attention,以及 RNN 进行了对比，<strong>input sequence length n, network width w, kernel size k, and network depth D</strong>.</p>
<h2 id="model-Architecture"><a href="#model-Architecture" class="headerlink" title="model Architecture"></a>model Architecture</h2><p>作者与 BiDAF 和 DrQA 进行了对比，将 BiDAF 和 DrQA 中的 BiLSTM 部分替换成 GLDR Convolution.</p>
<p><img src="/2018/10/15/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-CNN%E4%B8%8E%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/13.png"></p>
<blockquote>
<p>The receptive field of this convolutional network grows</p>
</blockquote>
<p>exponentially with depth and soon encompasses a long sequence, essentially enabling it to capture</p>
<p>similar long-term dependencies as an actual sequential model.  </p>
<p>感受野的尺寸大小指数增加，能够迅速压缩 long sentence,并 capture 长期依赖。</p>
<blockquote>
<p>Convolutional BiDAF. In our convolutional version of BiDAF, we replaced all bidirectional LSTMs with GLDRs . We have two 5-layer GLDRs in the contextual layer whose weights are un-tied. In the modeling layer, a 17-layer GLDR with dilation 1, 2, 4, 8, 16 in the first 5 residual blocks is used, which results in a reception region of 65 words. A 3-layer GLDR replaces the bidirectional LSTM in the output layer. For simplicity, we use same-padding and kernel size 3 for all convolutions unless specified. The hidden size of all GLDRs is 100 which is the same as the LSTMs in BiDAF.  </p>
</blockquote>
<p>具体网络结构，实际参数可以看 paper 实验部分。</p>
</div><div class="article-licensing box"><div class="licensing-title"><p>论文笔记-CNN与自然语言处理</p><p><a href="http://www.panxiaoxie.cn/2018/10/15/论文笔记-CNN与自然语言处理/">http://www.panxiaoxie.cn/2018/10/15/论文笔记-CNN与自然语言处理/</a></p></div><div class="licensing-meta level is-mobile"><div class="level-left"><div class="level-item is-narrow"><div><h6>Author</h6><p>Xie Pan</p></div></div><div class="level-item is-narrow"><div><h6>Posted on</h6><p>2018-10-15</p></div></div><div class="level-item is-narrow"><div><h6>Updated on</h6><p>2021-06-29</p></div></div><div class="level-item is-narrow"><div><h6>Licensed under</h6><p><a class="icons" rel="noopener" target="_blank" title="Creative Commons" href="https://creativecommons.org/"><i class="icon fab fa-creative-commons"></i></a><a class="icons" rel="noopener" target="_blank" title="Attribution" href="https://creativecommons.org/licenses/by/4.0/"><i class="icon fab fa-creative-commons-by"></i></a><a class="icons" rel="noopener" target="_blank" title="Noncommercial" href="https://creativecommons.org/licenses/by-nc/4.0/"><i class="icon fab fa-creative-commons-nc"></i></a></p></div></div></div></div></div><div class="article-tags is-size-7 mb-4"><span class="mr-2">#</span><a class="link-muted mr-2" rel="tag" href="/tags/MRC-and-QA/">MRC and QA</a></div><!--!--></article></div><!--!--><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/2018/11/04/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-Multi-cast-Attention-Networks/"><i class="level-item fas fa-chevron-left"></i><span class="level-item">论文笔记-Multi-cast Attention Networks</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/2018/10/01/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-batch-layer-weights-normalization/"><span class="level-item">论文笔记-batch,layer,weights normalization</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><div class="card"><div class="card-content"><h3 class="title is-5">Comments</h3><div id="disqus_thread"><noscript>Please enable JavaScript to view the <a target="_blank" rel="noopener" href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript></div><script>var disqus_config = function () {
            this.page.url = 'http://www.panxiaoxie.cn/2018/10/15/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-CNN%E4%B8%8E%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/';
            this.page.identifier = '2018/10/15/论文笔记-CNN与自然语言处理/';
        };
        (function() {
            var d = document, s = d.createElement('script');  
            s.src = '//' + 'panxie' + '.disqus.com/embed.js';
            s.setAttribute('data-timestamp', +new Date());
            (d.head || d.body).appendChild(s);
        })();</script></div></div></div><div class="column column-left is-4-tablet is-4-desktop is-4-widescreen  order-1"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar" src="/img/avatar.png" alt="潘小榭"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">潘小榭</p><p class="is-size-6 is-block">Blogging is happier than writing essays!</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Beijing</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">Posts</p><a href="/archives"><p class="title">110</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Categories</p><a href="/categories"><p class="title">32</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Tags</p><a href="/tags"><p class="title">31</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/ppoffice" target="_blank" rel="noopener">Follow</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/ppoffice"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Facebook" href="https://facebook.com"><i class="fab fa-facebook"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Twitter" href="https://twitter.com"><i class="fab fa-twitter"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Dribbble" href="https://dribbble.com"><i class="fab fa-dribbble"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="RSS" href="/"><i class="fas fa-rss"></i></a></div></div></div><!--!--><div class="card widget" data-type="links"><div class="card-content"><div class="menu"><h3 class="menu-label">Links</h3><ul class="menu-list"><li><a class="level is-mobile" href="https://github.com/PanXiebit" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">github</span></span><span class="level-right"><span class="level-item tag">github.com</span></span></a></li></ul></div></div></div><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">Categories</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/C/"><span class="level-start"><span class="level-item">C++</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/CSAPP/"><span class="level-start"><span class="level-item">CSAPP</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/DRL/"><span class="level-start"><span class="level-item">DRL</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/GAN/"><span class="level-start"><span class="level-item">GAN</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li><li><a class="level is-mobile" href="/categories/GAN-RL/"><span class="level-start"><span class="level-item">GAN, RL</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/ML/"><span class="level-start"><span class="level-item">ML</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/NLP/"><span class="level-start"><span class="level-item">NLP</span></span><span class="level-end"><span class="level-item tag">14</span></span></a></li><li><a class="level is-mobile" href="/categories/TensorFlow/"><span class="level-start"><span class="level-item">TensorFlow</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/cs224d/"><span class="level-start"><span class="level-item">cs224d</span></span><span class="level-end"><span class="level-item tag">10</span></span></a></li><li><a class="level is-mobile" href="/categories/interview/"><span class="level-start"><span class="level-item">interview</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/machine-translation/"><span class="level-start"><span class="level-item">machine translation</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/python/"><span class="level-start"><span class="level-item">python</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/pytorch/"><span class="level-start"><span class="level-item">pytorch</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/reinforcement-learning/"><span class="level-start"><span class="level-item">reinforcement learning</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/transfer-learning/"><span class="level-start"><span class="level-item">transfer learning</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"><span class="level-start"><span class="level-item">数据结构与算法</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile" href="/categories/%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB/"><span class="level-start"><span class="level-item">文本分类</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"><span class="level-start"><span class="level-item">论文笔记</span></span><span class="level-end"><span class="level-item tag">34</span></span></a><ul><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/DL/"><span class="level-start"><span class="level-item">DL</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/ESA/"><span class="level-start"><span class="level-item">ESA</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/GAN/"><span class="level-start"><span class="level-item">GAN</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/MRC-and-QA/"><span class="level-start"><span class="level-item">MRC and QA</span></span><span class="level-end"><span class="level-item tag">7</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/Machine-Translation/"><span class="level-start"><span class="level-item">Machine Translation</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/NLP/"><span class="level-start"><span class="level-item">NLP</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/capsules/"><span class="level-start"><span class="level-item">capsules</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/data-augmentation/"><span class="level-start"><span class="level-item">data augmentation</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/dialogue-system/"><span class="level-start"><span class="level-item">dialogue system</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/language-model/"><span class="level-start"><span class="level-item">language model</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/machine-translation/"><span class="level-start"><span class="level-item">machine translation</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/open-set-recognition/"><span class="level-start"><span class="level-item">open set recognition</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/sentence-embedding/"><span class="level-start"><span class="level-item">sentence embedding</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/text-matching/"><span class="level-start"><span class="level-item">text matching</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li></ul></div></div></div><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">Recents</h3><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-05-05T02:03:16.000Z">2021-05-05</time></p><p class="title"><a href="/2021/05/05/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-contrastive-learning/">论文笔记-contrastive learning</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-04-29T01:07:08.000Z">2021-04-29</time></p><p class="title"><a href="/2021/04/29/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-video-transformer/">论文笔记-video transformer</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-04-29T01:05:10.000Z">2021-04-29</time></p><p class="title"><a href="/2021/04/29/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-dynamic-convolution-and-involution/">论文笔记-dynamic convolution and involution</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-04-16T07:48:48.000Z">2021-04-16</time></p><p class="title"><a href="/2021/04/16/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-unlikelihood-training/">论文笔记-unlikelihood training</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-04-12T08:16:35.000Z">2021-04-12</time></p><p class="title"><a href="/2021/04/12/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-Deformable-DETR/">论文笔记-DETR and Deformable DETR</a></p></div></article></div></div><div class="card widget" data-type="archives"><div class="card-content"><div class="menu"><h3 class="menu-label">Archives</h3><ul class="menu-list"><li><a class="level is-mobile" href="/archives/2021/05/"><span class="level-start"><span class="level-item">May 2021</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2021/04/"><span class="level-start"><span class="level-item">April 2021</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/archives/2019/11/"><span class="level-start"><span class="level-item">November 2019</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2019/10/"><span class="level-start"><span class="level-item">October 2019</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2019/08/"><span class="level-start"><span class="level-item">August 2019</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2019/06/"><span class="level-start"><span class="level-item">June 2019</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/archives/2019/05/"><span class="level-start"><span class="level-item">May 2019</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2019/04/"><span class="level-start"><span class="level-item">April 2019</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2019/03/"><span class="level-start"><span class="level-item">March 2019</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile" href="/archives/2019/02/"><span class="level-start"><span class="level-item">February 2019</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/archives/2019/01/"><span class="level-start"><span class="level-item">January 2019</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li><li><a class="level is-mobile" href="/archives/2018/12/"><span class="level-start"><span class="level-item">December 2018</span></span><span class="level-end"><span class="level-item tag">16</span></span></a></li><li><a class="level is-mobile" href="/archives/2018/11/"><span class="level-start"><span class="level-item">November 2018</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2018/10/"><span class="level-start"><span class="level-item">October 2018</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2018/09/"><span class="level-start"><span class="level-item">September 2018</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/archives/2018/08/"><span class="level-start"><span class="level-item">August 2018</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile" href="/archives/2018/07/"><span class="level-start"><span class="level-item">July 2018</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/archives/2018/06/"><span class="level-start"><span class="level-item">June 2018</span></span><span class="level-end"><span class="level-item tag">10</span></span></a></li><li><a class="level is-mobile" href="/archives/2018/05/"><span class="level-start"><span class="level-item">May 2018</span></span><span class="level-end"><span class="level-item tag">11</span></span></a></li><li><a class="level is-mobile" href="/archives/2018/04/"><span class="level-start"><span class="level-item">April 2018</span></span><span class="level-end"><span class="level-item tag">16</span></span></a></li><li><a class="level is-mobile" href="/archives/2018/03/"><span class="level-start"><span class="level-item">March 2018</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li></ul></div></div></div><div class="card widget" data-type="tags"><div class="card-content"><div class="menu"><h3 class="menu-label">Tags</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/C/"><span class="tag">C++</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/CSAPP/"><span class="tag">CSAPP</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/DL/"><span class="tag">DL</span><span class="tag">8</span></a></div><div class="control"><a class="tags has-addons" href="/tags/ESA/"><span class="tag">ESA</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/GAN/"><span class="tag">GAN</span><span class="tag">9</span></a></div><div class="control"><a class="tags has-addons" href="/tags/GAN%EF%BC%8CRL/"><span class="tag">GAN，RL</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/ML/"><span class="tag">ML</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/MRC-and-QA/"><span class="tag">MRC and QA</span><span class="tag">7</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Machine-Translation/"><span class="tag">Machine Translation</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/NLP/"><span class="tag">NLP</span><span class="tag">14</span></a></div><div class="control"><a class="tags has-addons" href="/tags/TensorFlow/"><span class="tag">TensorFlow</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Tensorflow/"><span class="tag">Tensorflow</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/ai-challenger/"><span class="tag">ai challenger</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/capsules/"><span class="tag">capsules</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/contrastive-learning/"><span class="tag">contrastive learning</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/cs224d/"><span class="tag">cs224d</span><span class="tag">10</span></a></div><div class="control"><a class="tags has-addons" href="/tags/data-augmentation/"><span class="tag">data augmentation</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/interview/"><span class="tag">interview</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/language-model/"><span class="tag">language model</span><span class="tag">6</span></a></div><div class="control"><a class="tags has-addons" href="/tags/machine-translation/"><span class="tag">machine translation</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/open-set-recognition/"><span class="tag">open set recognition</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/python/"><span class="tag">python</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/pytorch/"><span class="tag">pytorch</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/reinforcement-learning/"><span class="tag">reinforcement learning</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/sentence-embedding/"><span class="tag">sentence embedding</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/sentiment-classification/"><span class="tag">sentiment classification</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/text-matching/"><span class="tag">text matching</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/transfer-learning/"><span class="tag">transfer learning</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/vision-transformer/"><span class="tag">vision transformer</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"><span class="tag">数据结构与算法</span><span class="tag">6</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB/"><span class="tag">文本分类</span><span class="tag">8</span></a></div></div></div></div></div><div class="card widget" data-type="subscribe-email"><div class="card-content"><div class="menu"><h3 class="menu-label">Subscribe for updates</h3><form action="https://feedburner.google.com/fb/a/mailverify" method="post" target="popupwindow" onsubmit="window.open(&#039;https://feedburner.google.com/fb/a/mailverify?uri=&#039;,&#039;popupwindow&#039;,&#039;scrollbars=yes,width=550,height=520&#039;);return true"><input type="hidden" value="" name="uri"><input type="hidden" name="loc" value="en_US"><div class="field has-addons"><div class="control has-icons-left is-expanded"><input class="input" name="email" type="email" placeholder="Email"><span class="icon is-small is-left"><i class="fas fa-envelope"></i></span></div><div class="control"><input class="button" type="submit" value="Subscribe"></div></div></form></div></div></div></div><!--!--></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/logo.svg" alt="潘小榭" height="28"></a><p class="is-size-7"><span>&copy; 2021 Xie Pan</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("default");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "This website uses cookies to improve your experience.",
          dismiss: "Got it!",
          allow: "Allow cookies",
          deny: "Decline",
          link: "Learn more",
          policy: "Cookie Policy",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.5/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script></body></html>