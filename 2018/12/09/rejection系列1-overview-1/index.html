<!doctype html>
<html lang="zh"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>rejection系列1-overview - 潘小榭</title><link rel="manifest" href="/manifest.json"><meta name="theme-color" content="black"><meta name="application-name" content="panxiaoxie"><meta name="msapplication-TileImage" content="/img/avatar.png"><meta name="msapplication-TileColor" content="black"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="panxiaoxie"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="description" content="关于 open set recognition 的一片综述。   paper: Recent Advances in Open Set Recognition: A Survey Motivation In real-world recognition&amp;#x2F;classification tasks, limited by various objective factors, it is usually"><meta property="og:type" content="blog"><meta property="og:title" content="panxiaoxie"><meta property="og:url" content="https://github.com/PanXiebit"><meta property="og:site_name" content="panxiaoxie"><meta property="og:description" content="关于 open set recognition 的一片综述。   paper: Recent Advances in Open Set Recognition: A Survey Motivation In real-world recognition&amp;#x2F;classification tasks, limited by various objective factors, it is usually"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://www.qt86.com/cache/1625298592_187938.png"><meta property="article:published_time" content="2018-12-09T01:00:08.000Z"><meta property="article:modified_time" content="2021-06-29T08:12:08.539Z"><meta property="article:author" content="panxiaoxie"><meta property="article:tag" content="open set recognition"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="https://www.qt86.com/cache/1625298592_187938.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"http://www.panxiaoxie.cn/2018/12/09/rejection%E7%B3%BB%E5%88%971-overview-1/"},"headline":"rejection系列1-overview","image":["http://www.panxiaoxie.cn/2018/12/09/rejection%E7%B3%BB%E5%88%971-overview-1/01.png","http://www.panxiaoxie.cn/2018/12/09/rejection%E7%B3%BB%E5%88%971-overview-1/02.png","http://www.panxiaoxie.cn/2018/12/09/rejection%E7%B3%BB%E5%88%971-overview-1/03.png","http://www.panxiaoxie.cn/2018/12/09/rejection%E7%B3%BB%E5%88%971-overview-1/04.png","http://www.panxiaoxie.cn/2018/12/09/rejection%E7%B3%BB%E5%88%971-overview-1/05.png","http://www.panxiaoxie.cn/2018/12/09/rejection%E7%B3%BB%E5%88%971-overview-1/06.png","http://www.panxiaoxie.cn/2018/12/09/rejection%E7%B3%BB%E5%88%971-overview-1/07.png","http://www.panxiaoxie.cn/2018/12/09/rejection%E7%B3%BB%E5%88%971-overview-1/08.png","http://www.panxiaoxie.cn/2018/12/09/rejection%E7%B3%BB%E5%88%971-overview-1/09.png","http://www.panxiaoxie.cn/2018/12/09/rejection%E7%B3%BB%E5%88%971-overview-1/11.png","http://www.panxiaoxie.cn/2018/12/09/rejection%E7%B3%BB%E5%88%971-overview-1/12.png","http://www.panxiaoxie.cn/2018/12/09/rejection%E7%B3%BB%E5%88%971-overview-1/21.png","http://www.panxiaoxie.cn/2018/12/09/rejection%E7%B3%BB%E5%88%971-overview-1/15.png","http://www.panxiaoxie.cn/2018/12/09/rejection%E7%B3%BB%E5%88%971-overview-1/13.png","http://www.panxiaoxie.cn/2018/12/09/rejection%E7%B3%BB%E5%88%971-overview-1/14.png","http://www.panxiaoxie.cn/2018/12/09/rejection%E7%B3%BB%E5%88%971-overview-1/16.png","http://www.panxiaoxie.cn/2018/12/09/rejection%E7%B3%BB%E5%88%971-overview-1/17.png","http://www.panxiaoxie.cn/2018/12/09/rejection%E7%B3%BB%E5%88%971-overview-1/18.png","http://www.panxiaoxie.cn/2018/12/09/rejection%E7%B3%BB%E5%88%971-overview-1/19.png","http://www.panxiaoxie.cn/2018/12/09/rejection%E7%B3%BB%E5%88%971-overview-1/20.png","http://www.panxiaoxie.cn/2018/12/09/rejection%E7%B3%BB%E5%88%971-overview-1/22.png","http://www.panxiaoxie.cn/2018/12/09/rejection%E7%B3%BB%E5%88%971-overview-1/23.png","http://www.panxiaoxie.cn/2018/12/09/rejection%E7%B3%BB%E5%88%971-overview-1/24.png","http://www.panxiaoxie.cn/2018/12/09/rejection%E7%B3%BB%E5%88%971-overview-1/25.png","http://www.panxiaoxie.cn/2018/12/09/rejection%E7%B3%BB%E5%88%971-overview-1/27.png","http://www.panxiaoxie.cn/2018/12/09/rejection%E7%B3%BB%E5%88%971-overview-1/28.png","http://www.panxiaoxie.cn/2018/12/09/rejection%E7%B3%BB%E5%88%971-overview-1/26.png","http://www.panxiaoxie.cn/2018/12/09/rejection%E7%B3%BB%E5%88%971-overview-1/29.png","http://www.panxiaoxie.cn/2018/12/09/rejection%E7%B3%BB%E5%88%971-overview-1/30.png","http://www.panxiaoxie.cn/2018/12/09/rejection%E7%B3%BB%E5%88%971-overview-1/31.png","http://www.panxiaoxie.cn/2018/12/09/rejection%E7%B3%BB%E5%88%971-overview-1/32.png","http://www.panxiaoxie.cn/2018/12/09/rejection%E7%B3%BB%E5%88%971-overview-1/33.png","http://www.panxiaoxie.cn/2018/12/09/rejection%E7%B3%BB%E5%88%971-overview-1/34.png","http://www.panxiaoxie.cn/2018/12/09/rejection%E7%B3%BB%E5%88%971-overview-1/35.png"],"datePublished":"2018-12-09T01:00:08.000Z","dateModified":"2021-06-29T08:12:08.539Z","author":{"@type":"Person","name":"Xie Pan"},"publisher":{"@type":"Organization","name":"潘小榭","logo":{"@type":"ImageObject","url":"http://www.panxiaoxie.cn/img/panxiaoxie.png"}},"description":"关于 open set recognition 的一片综述。   paper: Recent Advances in Open Set Recognition: A Survey Motivation In real-world recognition&#x2F;classification tasks, limited by various objective factors, it is usually"}</script><link rel="canonical" href="http://www.panxiaoxie.cn/2018/12/09/rejection%E7%B3%BB%E5%88%971-overview-1/"><link rel="icon" href="/img/avatar.png"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/css/justifiedGallery.min.css"><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script><!--!--><!--!--><meta name="generator" content="Hexo 5.4.0"></head><body class="is-2-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/panxiaoxie.png" alt="潘小榭" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">主页</a><a class="navbar-item" href="/archives">归档</a><a class="navbar-item" href="/categories">分类</a><a class="navbar-item" href="/tags">标签</a><a class="navbar-item" href="/about">关于我</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/PanXiebit"><i class="fab fa-github"></i></a><a class="navbar-item search" title="搜索" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-10-widescreen"><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2018-12-09T01:00:08.000Z" title="2018/12/9 上午9:00:08">2018-12-09</time>发表</span><span class="level-item"><time dateTime="2021-06-29T08:12:08.539Z" title="2021/6/29 下午4:12:08">2021-06-29</time>更新</span><span class="level-item"><a class="link-muted" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/">论文笔记</a><span> / </span><a class="link-muted" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/open-set-recognition/">open set recognition</a></span><span class="level-item">34 分钟读完 (大约5074个字)</span></div></div><h1 class="title is-3 is-size-4-mobile">rejection系列1-overview</h1><div class="content"><p>关于 open set recognition 的一片综述。  </p>
<p>paper: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1811.08581">Recent Advances in Open Set Recognition: A Survey</a></p>
<h2 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h2><blockquote>
<p>In real-world recognition/classification tasks, limited by various objective factors, it is usually difficult to collect training samples to exhaust all classes when training a recognizer or classifier. A more realistic scenario is open set recognition (OSR), where incomplete knowledge of the world exists at training time, and unknown classes can be submitted to an algorithm during testing, requiring the classifiers not only to accurately classify the seen classes, but also to effectively deal with the unseen ones.  </p>
</blockquote>
<p>现实中对于分类任务，不可能在训练集中穷尽所有类别。更实际的情况是 open set recognition (OSR). 在训练阶段包含的是不完整的 knowledge of world. 在测试阶段会出现 unknown 类别。这需要分类器不仅能准确的识别在训练阶段已经见到过的类别，也能有效的处理没有见过的类别, 比如 rejection 或者归类为 unknown.</p>
<blockquote>
<p>This paper provides a comprehensive survey of existing open set recognition techniques covering various aspects ranging from related definitions, representations of models, datasets, experiment setup and evaluation metrics. Furthermore, we briefly analyze the relationships between OSR and its related tasks including zero-shot, one-shot (few-shot) recognition/learning techniques, classification with reject option, and so forth. Additionally, we also overview the open world recognition which can be seen as a natural extension of OSR. Importantly, we highlight the limitations of existing approaches and point out some promising subsequent research directions in this field.  </p>
</blockquote>
<p>这篇综述覆盖了相关的定义、模型、实验以及验证指标。更多地，还分析了 与OSR 相关的任务 zero-shot, one-shot 识别，以及 rejection. 额外地，还概述了 open world recognition 可以看作 OSR 的扩展。更重要的是，作者说明了当前一些方法的限制，并指出了未来研究的一些方向。</p>
<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><blockquote>
<p>a more realistic scenario is usually open and non-stationary such as driverless, fault/medical diagnosis, etc., where unseen situations can emerge unexpectedly, which drastically weakens the robustness of these existing methods.  </p>
</blockquote>
<p>更现实的场景是 <strong>开放的和非静态</strong> 的。</p>
<blockquote>
<p>To meet this challenge, several related research directions actually have been explored including lifelong learning [1], [2], transfer learning [3]–[5], domain adaptation [6], zero-shot [7]–[9], one-shot (few-shot) [10]–[16] recognition/learning and open set recognition/classification [17]–[19], and so forth.  </p>
</blockquote>
<p>涉及到的领域： lifelong learning, transfer learning, domain adaption, zero-shot, one-shot, open set recogntion.</p>
<p>recognition should consider four basic categories of classes as follows:  </p>
<p><img src="/2018/12/09/rejection%E7%B3%BB%E5%88%971-overview-1/01.png"></p>
<ul>
<li><p>known known: train/dev 中有标签的样本，包括正负类别，并且有相关的语义信息。  </p>
</li>
<li><p>known unknown: train/dev 中有标签的样本，负类，没有相关的语义信息。  </p>
</li>
<li><p>unknown known: test 中没有出现在 train 中的样本，但是有相关的语义信息。比如，train 中有猫，然后 test 中有另外一种猫科动物，那么动物这个样本是有意义的吧？？？  </p>
</li>
<li><p>unknown unknown: test 中没有出现在 train 中的样本，并且没有任何相关的语义信息。  </p>
</li>
</ul>
<blockquote>
<p>Unlike the traditional classification, zero-shot learning (ZSL) can identify unseen classes which have no available observations in training. However, the available semantic/attribute information shared among all classes including seen and unseen ones are needed.  </p>
</blockquote>
<p>zero-shot 是针对 unknown known, 也就是包含了语义信息。</p>
<blockquote>
<p>The ZSL mainly focuses on the recognition of the unknown known classes defined above. Actually, such a setting is rather restrictive and impractical, since we usually know nothing about the testing samples which may come from known known classes or not.  </p>
</blockquote>
<p>unknown known 这种设定很有限，并且不切实际。因为我们很难知道 test 中的样本是否是包含了语义信息，无法判断是 unknown known or unknown unknown.  </p>
<p><strong>comparision between open set recognition and traditional classification</strong></p>
<p><img src="/2018/12/09/rejection%E7%B3%BB%E5%88%971-overview-1/02.png"></p>
<p>Via these decision boundaries, samples from an unknown unknown class are labeled as ”unknown” or rejected rather than misclassified as known known classes.</p>
<h2 id="Basic-notation-and-related-definition"><a href="#Basic-notation-and-related-definition" class="headerlink" title="Basic notation and related definition"></a>Basic notation and related definition</h2><p>经验风险函数：  </p>
<p><img src="/2018/12/09/rejection%E7%B3%BB%E5%88%971-overview-1/03.png"></p>
<p>$L(x, y, f(x)) \ge 0$ 是 loss function. P(x,y) 是对应样本 (x, y) 的概率，通常这个联合分布的概率我们是不知道的，因为我们无法确定自然界中样本空间(label space)到底是个什么分布。</p>
<p><strong>[李航，机器学习] 中关于风险函数的定义：</strong>  </p>
<blockquote>
<p> 损失函数度量一次模型预测的好坏，风险函数度量平均意义下模型预测的好坏。  </p>
</blockquote>
<p><img src="/2018/12/09/rejection%E7%B3%BB%E5%88%971-overview-1/04.png"></p>
<p><img src="/2018/12/09/rejection%E7%B3%BB%E5%88%971-overview-1/05.png"></p>
<p><img src="/2018/12/09/rejection%E7%B3%BB%E5%88%971-overview-1/06.png"></p>
<p><img src="/2018/12/09/rejection%E7%B3%BB%E5%88%971-overview-1/07.png"></p>
<p>以前看不懂这一部分，现在只想说： <strong>Perfect!</strong></p>
<blockquote>
<p>Therefore, traditional recognition/classification approaches minimize the empirical risk instead of the ideal risk RI by using other knowledge, such as assuming that the label space is at least locally smooth and regularizing the empirical risk minimization.  </p>
</blockquote>
<p>传统的分类方法是根据其他的外部知识来最小化经验风险，比如 label space 是光滑的，然后使用正则化最小经验风险（也就是上面所说的结构风险函数）。</p>
<blockquote>
<p>Note that traditional recognition problem is usually performed under the closed set assumption. When the assumption switches to open environment/set scenario with the open space, other things should be added since intuitively there is some risk in labeling sample in the open space as any known known classes. This gives such an insight for OSR that <strong>we do know something else: we do know where known known classes exist, and we know that in open space we do not have a good basis for assigning labels for the unknown unknown classes.</strong>  </p>
</blockquote>
<p>传统的识别是假设在固定的样本空间下(known known). 当转换到开放式场景下，我们很敏感的意识到需要给 label space 加点 risk。。我们知道 known known classes 是存在的，我们也知道我们并没有这样一个 basis 去给 unknown unknown 打标签。</p>
<h3 id="open-space-risk"><a href="#open-space-risk" class="headerlink" title="open space risk"></a>open space risk</h3><p>这部分的内容主要引自这篇 paper: <a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/document/6365193/">17. Toward Open Set Recognition</a></p>
<p>这篇 paper 是把 class of interest 当作一个类，然后所有的 unknown/known 当作很多 classes, 也就是  1-vs-set.</p>
<p><img src="/2018/12/09/rejection%E7%B3%BB%E5%88%971-overview-1/08.png"></p>
<blockquote>
<p>To improve the overall open set recognition error, our 1-vs-set formulation balances the unknown classes by obtaining a core margin around the decision boundary A from the base SVM, specializing the resulting half-space by adding another plane $\Omega$ and then generalizing or specializing the two planes (shown in Fig. 2) to optimize empirical and open space risk. This process uses the open set training data and the risk model to define a new “open set margin.” The second plane $\Omega$ allows the 1-vs-set machine to avoid the overgeneralization that would misclassify the raccoon in Fig. 2. The overall optimization can also adjust the original margin with respect to A to reduce open space risk, which can avoid negatives such as the owl.  </p>
</blockquote>
<p>使用了两个超平面，去分隔 Negatives/positivecs/unknown.</p>
<blockquote>
<p>While we do not know the joint distribution $P(x, y)$ in, one way to look at the open space risk is as a weak assumption: Far from the known data the Principle of Indifference [8] suggests that if there is no known reason to assign a probability, alternatives should be given equal probability. In our case, this means that at all points in open space, all labels (both known and unknown) are equally</p>
</blockquote>
<p>likely, and risk should be computed accordingly. However, we cannot have constant value probabilities over infinite spaces—the distribution must be integrable and integrate to 1. We must formalize open space differently (e.g., by ensuring the problem is well posed and then assuming the probability is proportional to relative Lebesgue measure [9]). Thus, we can consider the measure of the open space to the full space, and define our risk penalty proportional to such a ratio.  </p>
<p>无法知道联合分布 $P(x, y)$, 作者假设所有的样本概率是相等的，但是向量空间中样本总数是不确定的，所以作者定义一个比例来描述 在 open space 中出现 unknown 的危险惩罚系数。</p>
<p><img src="/2018/12/09/rejection%E7%B3%BB%E5%88%971-overview-1/09.png"></p>
<blockquote>
<p>where open space risk is considered to be the fraction (in terms of Lebesgue measure) of positively labeled open space compared to the overall measure of positively labeled space (which includes the space near the positive examples).  </p>
</blockquote>
<p><strong>open space risk</strong> 是开放空间中 positive label 的总数与总体空间中 positive label 的总体度量。</p>
<p>不太懂。。问题还是不知道怎么度量？ unknown 的类别能确定？？？</p>
<h3 id="openness"><a href="#openness" class="headerlink" title="openness"></a>openness</h3><p>openness，用来表征数据集的开放程度：</p>
<p><img src="/2018/12/09/rejection%E7%B3%BB%E5%88%971-overview-1/11.png"></p>
<ul>
<li><p>$C_{TR}$ 是训练集中的类别数，越大，开放程度越小。   </p>
</li>
<li><p>$C_{TE}$ 测试集中的类别数。  </p>
</li>
</ul>
<h3 id="The-Open-Set-Recognition-Problem"><a href="#The-Open-Set-Recognition-Problem" class="headerlink" title="The Open Set Recognition Problem"></a>The Open Set Recognition Problem</h3><blockquote>
<p>our goal is to balance the risk of the unknown in open space with the empirical (known) risk. In this sense, we formally define the open set recognition problem as follows:  </p>
</blockquote>
<p>我们的目的是平衡 the risk of unknown 出现在基于 known classes 计算的到的 open space 的 empirical risk。  </p>
<p>怎么理解呢？就是传统的风险函数都是只考虑了经验风险，也就是完全基于训练数据的。但是在 open space 里面，我们还要测试时会出现的 unknown，所以在 风险函数的设置的同时，就要考虑到 unknown 的存在。也就是前面的 open space risk.</p>
<p><img src="/2018/12/09/rejection%E7%B3%BB%E5%88%971-overview-1/12.png"></p>
<h2 id="a-categorization-of-OSR-techniques"><a href="#a-categorization-of-OSR-techniques" class="headerlink" title="a categorization of OSR techniques"></a>a categorization of OSR techniques</h2><p>问题的关键在于如何将 公式（4）open space risk 合并到模型中去。然后大佬们提出各式各样的模型，主要分为 discriminative model and generative models.</p>
<p>更进一步，可以分为：five categories (Table II):   </p>
<ul>
<li><p>Traditional ML-based  </p>
</li>
<li><p>Deep Network-based  </p>
</li>
<li><p>Adversarial Learning-based  </p>
</li>
<li><p>EVT-based  </p>
</li>
<li><p>Dirichlet Process-based OSR models</p>
</li>
</ul>
<p><img src="/2018/12/09/rejection%E7%B3%BB%E5%88%971-overview-1/21.png"></p>
<h3 id="Deep-Neural-Network-based-OSR-Models"><a href="#Deep-Neural-Network-based-OSR-Models" class="headerlink" title="Deep Neural Network-based OSR Models"></a>Deep Neural Network-based OSR Models</h3><p>大佬们的杰作，感觉都挺新的，新坑？</p>
<p><img src="/2018/12/09/rejection%E7%B3%BB%E5%88%971-overview-1/15.png"></p>
<p><img src="/2018/12/09/rejection%E7%B3%BB%E5%88%971-overview-1/13.png"></p>
<p><img src="/2018/12/09/rejection%E7%B3%BB%E5%88%971-overview-1/14.png"></p>
<p><img src="/2018/12/09/rejection%E7%B3%BB%E5%88%971-overview-1/16.png"></p>
<p>提出了 OpenMax,使用 deep networks, 还是用 softmax 损失函数来最小化 交叉熵 cross entropy loss. 然后在网络的倒数第二层（softmax 的前一层？）得到每一个正分类的 <strong>mean activate vector(MAV)</strong>.  </p>
<p>然后是根据 Weibull districution 去 redistribution 以及重新分类等等接下来的操作还是看相应 的 paper 吧。</p>
<blockquote>
<p>the OpenMax effectively addressed the challenge of the recognition for fooling/rubbish and unrelated open set images. However, as discussed in [71], the OpenMax fails to recognize the adversarial images which are visually indistinguishable from training samples but are designed to make deep networks produce high confidence but incorrect answers [96], [98].  </p>
</blockquote>
<p>OpenMax 有效的解决了 不相关的 open set images 的问题，但是却无法有效区分对抗生成样本。</p>
<blockquote>
<p>Actually, the authors in [72] have indicated that the OpenMax is susceptible to the adversarial generation techniques directly working on deep representations. Therefore, the adversarial samples are still a serious challenge for open set recognition. Furthermore, using the distance from MAV, the cross entropy loss function in OpenMax does not directly incentivize projecting class samples around the MAV. In addition to that, the distance function used in testing is not used in training, possibly resulting in inaccurate measurement in that space [73]. To address this limitation, Hassen and Chan [73] learned a neural network based representation for open set recognition, which is similar in spirit to the Fisher Discriminant, where samples from the same class are closed to each other while the ones from different classes are further apart, leading to larger space among known known classes for unknown unknown classes’ samples to occupy.  </p>
</blockquote>
<p>交叉熵并不能有效的将类别映射到相应的 MAV 中，因为在测试集中的 distence function 跟在 training set 里面是不一样的，这会导致不准确的判别。基于此，[73]提出了 Fisher 判别，从同一个类别中采样，使得unknown unknown 和 known known 的间距很大。</p>
<p><img src="/2018/12/09/rejection%E7%B3%BB%E5%88%971-overview-1/17.png"></p>
<ul>
<li><p>OpenMax to text classification  </p>
</li>
<li><p>Deep Open classifier  </p>
</li>
<li><p>tWiSARD  </p>
</li>
<li><p>hidden unknown unknown classes  </p>
</li>
</ul>
<h3 id="Adversarial-Learning-based-OSR-Models"><a href="#Adversarial-Learning-based-OSR-Models" class="headerlink" title="Adversarial Learning-based OSR Models"></a>Adversarial Learning-based OSR Models</h3><p><img src="/2018/12/09/rejection%E7%B3%BB%E5%88%971-overview-1/18.png"></p>
<blockquote>
<p>Note that the main challenge for open set recognition is the incomplete class knowledge existing in training, leading to the open space risk when classifiers encounter unknown unknown classes during testing. Fortunately, the adversarial learning technique can account for open space to some extent by adversarially generating the unknown unknown class data according to the known known class knowledge, which undoubtedly provides another way to tackle the challenging multiclass OSR problem.  </p>
</blockquote>
<p>open set recognition 最大的挑战是 training 中不完整的 knowledge， 在 testing 中遇到 unknown unknown 导致 open space risk.  </p>
<p>而对抗训练网络在某种程度上根据 known known 生成 unknown unknown，提供了另外一种方式解决 OSR 问题。</p>
<h3 id="EVT-based-OSR-Models"><a href="#EVT-based-OSR-Models" class="headerlink" title="EVT-based OSR Models"></a>EVT-based OSR Models</h3><blockquote>
<p>As a powerful tool to increase the classification performance, the <strong>statistical Extreme Value Theory (EVT)</strong> has recently achieved great success due to the fact that EVT can effectively model the tails of the distribution of distances between training observations using the asymptotic theory[100].  </p>
</blockquote>
<p>不是很懂这个理论，给出几篇 paper 吧</p>
<p><img src="/2018/12/09/rejection%E7%B3%BB%E5%88%971-overview-1/19.png"></p>
<p><img src="/2018/12/09/rejection%E7%B3%BB%E5%88%971-overview-1/20.png"></p>
<p><strong>Remark:</strong> As mentioned above, almost all existing OSR methods adopt the threshold-based classification scheme, where recognizers in decision either reject or categorize the input samples to some known known class using <strong>empirically set threshold</strong>. Thus the threshold plays a key role. However, the selection for it usually depends on the knowledge of known known classes, inevitably incurring risks due to lacking available information from unknown unknown classes [57]. This indicates the threshold-based OSR methods still face serious challenges.  </p>
<p>基于 known known 得到的 threshold 因为缺乏 unknown unknown 的信息，不可避免的会造成 risk, 这也是基于 threshold 这类方法所面临的困难。</p>
<h3 id="Dirichlet-Process-based-OSR-Models-生成模型"><a href="#Dirichlet-Process-based-OSR-Models-生成模型" class="headerlink" title="Dirichlet Process-based OSR Models (生成模型)"></a>Dirichlet Process-based OSR Models (生成模型)</h3><blockquote>
<p>Dirichlet process (DP) [104]–[108] considered as a distribution over distributions is a stochastic process, which has been widely applied in clustering and density estimation problems as a nonparametric prior defined over the number of mixture components. Furthermore, this model does not overly depend on training samples and can achieve adaptive change as the data changes, making it naturally adapt to the open set recognition scenario. In fact, researchers have begun the related research  </p>
</blockquote>
<p>Dirichlet 过程作为一种基于混合模型的非参数方法广泛用于聚类，参数估计。这种模型不需要依赖于 training，可以随着 dataset 的变化而自适应的变化，这使得它能有效的适用于 open set 的场景。</p>
<p>对生成模型不是很熟。。</p>
<p><strong>Remark:</strong> Instead of addressing the OSR problem from the discriminative model perspective, CD-OSR actually reconsiders this problem from the generative model perspective due to the use of HDP, which provides another research direction for open set recognition. Furthermore, the collective decision strategy for OSR is also worth further exploring since <strong>it not only takes the correlations among the testing samples into account but also provides a possibility for new class discovery,</strong> whereas single-sample decision strategy2 adopted by other existing OSR methods can not do such a work since it can not directly tell whether the single rejected sample is an outlier or from new class.  </p>
<h2 id="Beyond-open-set-Recognition"><a href="#Beyond-open-set-Recognition" class="headerlink" title="Beyond open set Recognition"></a>Beyond open set Recognition</h2><p>关于 open set recognition 如果仅仅考虑静态的 set，意义不是很大。以及，只对 unknown unknown 进行 rejection 也是不够的。为此，有人提出 open world recognition.</p>
<p>open world recognition (OWR), where a recognition system should perform four tasks:  </p>
<ul>
<li><p>detecting unknown unknown classes  </p>
</li>
<li><p>choosing which samples to label for addition to the model  </p>
</li>
<li><p>labelling those samples  </p>
</li>
<li><p>updating the classifier</p>
</li>
</ul>
<p><strong>Remark:</strong> As a natural extension of OSR, the OWR faces more serious challenges which require it not only to have the ability to handle the OSR task, but also to have minimal</p>
<p>downtime, even to continuously learn, which seems to have the flavor of lifelong learning to some extent. Besides, although some progress regarding the OWR has been made, there is still a long way to go.  </p>
<p>终身学习。。666</p>
<h2 id="Dataset-and-evalution-metrics"><a href="#Dataset-and-evalution-metrics" class="headerlink" title="Dataset and evalution metrics"></a>Dataset and evalution metrics</h2><h3 id="dataset"><a href="#dataset" class="headerlink" title="dataset"></a>dataset</h3><ul>
<li><p><a target="_blank" rel="noopener" href="https://dx.doi.org/10.6084/m9.figshare.1097614">https://dx.doi.org/10.6084/m9.figshare.1097614</a>  </p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://www.csie.ntu.edu.tw/%E2%88%BCcjlin/libsvmtools/datasets/multi-class.html">https://www.csie.ntu.edu.tw/∼cjlin/libsvmtools/datasets/multi-class.html</a></p>
</li>
</ul>
<p><img src="/2018/12/09/rejection%E7%B3%BB%E5%88%971-overview-1/22.png"></p>
<blockquote>
<p> Experiment Setup: In open set recognition, most existing experiments are carried out on a variety of recastes multi-class benchmark datasets. Specifically, taking the Usps dataset as an example, when it is used for OSR problem, one can randomly choose S distinct labels as the known known classes, and vary openness by adding a subset of the remaining labels.  </p>
</blockquote>
<p>可以增加减少类别数来改变 openness.</p>
<h3 id="Evaluation-Metrics-for-Open-Set-Recognition"><a href="#Evaluation-Metrics-for-Open-Set-Recognition" class="headerlink" title="Evaluation Metrics for Open Set Recognition"></a>Evaluation Metrics for Open Set Recognition</h3><ul>
<li><p>TP： true positive  </p>
</li>
<li><p>FP: false positive</p>
</li>
<li><p>TN: true negative  </p>
</li>
<li><p>FN: false negative  </p>
</li>
<li><p>TU: true unknown  </p>
</li>
<li><p>FU: false unknown</p>
</li>
</ul>
<h4 id="accuracy"><a href="#accuracy" class="headerlink" title="accuracy"></a>accuracy</h4><p>对于 closed set :</p>
<p>$$\text{accuracy}=\dfrac{TP+TN}{TP+TN+FP+FN}$$</p>
<p>对于 open set:</p>
<p>$$\text{accuracy}_O=\dfrac{(TP+TN)+TU}{(TP+TN+FP+FN)+(TU+FU)}$$</p>
<p>对于不均衡情况，accuracy 并不能客观的评价模型好坏。比如在testing 中，unknown unknown 样本数量很多,那么如果分类器把所有的类别都判为 unknown unknown，它的准确率依旧很高。</p>
<p>于是，有人提出了 <strong>normalized accuracy(NA)</strong>.</p>
<p><img src="/2018/12/09/rejection%E7%B3%BB%E5%88%971-overview-1/23.png"></p>
<p>$0\le \lambda \le 1$ 是正则化常数。</p>
<h4 id="F-measure"><a href="#F-measure" class="headerlink" title="F-measure"></a>F-measure</h4><p>F1:  </p>
<p>$$F1=\dfrac{2<em>\text{precision}</em> \text{recall}}{\text{precision}+\text{recall}}$$</p>
<p>$$precision=\dfrac{TP}{TP+FP}$$</p>
<p>精度： 预测得到的 positive 中真正是 positive 的概率。</p>
<p>$$recall=\dfrac{TP}{TP+FN}$$</p>
<p>召回： 所有真正 positive 的样本被预测为 positive 的概率。</p>
<p>在 open set 场景下，F1 值无法考虑 unknown unknown.</p>
<blockquote>
<p>Instead, the computations of Precision and Recall in it are only for available known known classes. Additionally, the work [67] has indicated that although the computations of Precision and Recall are only for available known known classes, the FN and FP also consider the false unknown unknown classes and false known known classes by taking into account the false negative and the false positive, and we refer the reader to [67] for more details.  </p>
</blockquote>
<p>事实上，在 FP 和 FN 中可能也包括 false unknown unknown, 这就有问题了是吧。。</p>
<p>详细参考这篇 paper <a target="_blank" rel="noopener" href="https://link.springer.com/content/pdf/10.1007%2Fs10994-016-5610-8.pdf">Nearest neighbors distance ratio open-set classifier</a></p>
<blockquote>
<p>Note that the Precision</p>
</blockquote>
<p>contains the <strong>macro-Precision and micro-Precision</strong> while Recall includes the macro-Recall and micro-Recall, which leads to the corresponding <strong>macro-F-measure and micro-F-measure</strong>. Nevertheless, whether it is macro-F-measure or micro-F-measure, the higher their values, the better the performance of the corresponding OSR model.</p>
<h4 id="Youden’s-index-for-OSR"><a href="#Youden’s-index-for-OSR" class="headerlink" title="Youden’s index for OSR"></a>Youden’s index for OSR</h4><p>$$J= \text{Recall}+S-1$$</p>
<p>其中 S 是真负类率： $S=\dfrac{TN}{TN+FP}$</p>
<h2 id="future-research-directions"><a href="#future-research-directions" class="headerlink" title="future research directions"></a>future research directions</h2><h3 id="About-modeling"><a href="#About-modeling" class="headerlink" title="About modeling"></a>About modeling</h3><ul>
<li><p>大部分工作都是基于判别模型来做的，只有少部分是基于生成模型，也许生成模型会更有探索空间。</p>
</li>
<li><p>OSR 的主要挑战是传统的分类器是在 closed-set 场景下获得的，一旦 unknown unknown class 落入这个空间，将永远无法被正确的分类。</p>
</li>
</ul>
<h4 id="modeling-known-known-classes"><a href="#modeling-known-known-classes" class="headerlink" title="modeling known known classes"></a>modeling known known classes</h4><p>如果得到的 known known class 没有被过拟合，那么这样的分类器就能有效的区分出 unknown unknown. 所以聚类和分类算法的结合会是不错的方向。关于 clustering 和  classification 的 unified learning framework:</p>
<p><img src="/2018/12/09/rejection%E7%B3%BB%E5%88%971-overview-1/24.png"></p>
<p>这两篇 paper 依旧是在 closed-set 下做的，所以需要你去尝试。。。</p>
<h4 id="modeling-unknown-unknown-classes"><a href="#modeling-unknown-unknown-classes" class="headerlink" title="modeling unknown unknown classes"></a>modeling unknown unknown classes</h4><p>似乎在只有 known known classes 的情况下是很难去学习 unknown unknown 的类的性质的。但是可以通过对抗学习来生成 unknown unknown 也是不错的方向。</p>
<p>顺便作者还提了下 transductive leanring，以及基于 Dirichlet process 的自适应行，CD-OSR、Dirichlet processed-based OSR 也是值得探索的。</p>
<h3 id="About-rejecting"><a href="#About-rejecting" class="headerlink" title="About rejecting"></a>About rejecting</h3><p>大部分的工作都是 reject unknown unknown classes，而没有后续的工作了。只有少量的 [66][67]进行了后续的工作，比如 new classes discovery.</p>
<p><img src="/2018/12/09/rejection%E7%B3%BB%E5%88%971-overview-1/25.png"></p>
<h3 id="About-the-decision"><a href="#About-the-decision" class="headerlink" title="About the decision"></a>About the decision</h3><p>所有的 OSR 模型都是用来识别单个样本的，但是一个决策的决定并没有考虑样本之间的相关性。所以 <strong>collective decision</strong> 不仅在 testing 时考虑相关性，同时还能发现 new classes.</p>
<p><img src="/2018/12/09/rejection%E7%B3%BB%E5%88%971-overview-1/27.png"></p>
<p><img src="/2018/12/09/rejection%E7%B3%BB%E5%88%971-overview-1/28.png"></p>
<h3 id="Open-set-‘sth’"><a href="#Open-set-‘sth’" class="headerlink" title="Open set + ‘sth’"></a>Open set + ‘sth’</h3><p>As open set scenario is a more practical assumption for the real-world classification/recognition tasks, it can naturally be combined with various fields involving classification/recognition such as <strong>semi-supervised learning, domain adaptation, active learning, multi-task learning, multi-label learning, multi-view learning,</strong> and so forth. For example, [124]–[126] recently introduced this scenario into domain adaptation, while [127] explored the open set classification in active learning field. Therefore, many interesting works are worth looking forward to.  </p>
<p>看起来是个不错的方向。。</p>
<p><img src="/2018/12/09/rejection%E7%B3%BB%E5%88%971-overview-1/26.png"></p>
<h3 id="Generalized-Open-Set-Recognition"><a href="#Generalized-Open-Set-Recognition" class="headerlink" title="Generalized Open Set Recognition"></a>Generalized Open Set Recognition</h3><p>利用 side-information,比如 unknown unknwon 和 known known 会有共同的语义信息(semantic/attribute information).</p>
<h4 id="Appending-semantic-attribute-information"><a href="#Appending-semantic-attribute-information" class="headerlink" title="Appending semantic/attribute information"></a>Appending semantic/attribute information</h4><blockquote>
<p>In fact, a lot</p>
</blockquote>
<p>of semantic/attibute information is shared between the known known and the unknown unknown classes. Therefore, we can fully utilize this kind of information to ’cognize’ the unknown unknown classes, or at least to provide a rough semantic/attribute description for the corresponding unknown unknown classes instead of simply rejecting them.  </p>
<p>利用语义信息去意识到 unknown unknwon，而不是简单的 reject.</p>
<p>但是要注意区分 open set recognition 和 ZSL(zero-shot learning) 的区别：</p>
<p><img src="/2018/12/09/rejection%E7%B3%BB%E5%88%971-overview-1/29.png"></p>
<p>The $\text{side-information}^1$ in ZSL denotes the semantic/attribute information shared among all classes including known known and unknown known classes.</p>
<p>where the $\text{side-information}^4$ denotes the available semantic/attribute information only for known known classes</p>
<p>感觉这个 side-information 的界限很难确定啊？Generalized Open Set Recognition 的这个范围似乎很难实现， 怎么可能出现在 training 中的 semantice information 完全不出现在 unknown unknown 中呢。。</p>
<p><img src="/2018/12/09/rejection%E7%B3%BB%E5%88%971-overview-1/30.png"></p>
<p><img src="/2018/12/09/rejection%E7%B3%BB%E5%88%971-overview-1/31.png"></p>
<p><img src="/2018/12/09/rejection%E7%B3%BB%E5%88%971-overview-1/32.png"></p>
<p>还有一些相似的工作：</p>
<p><img src="/2018/12/09/rejection%E7%B3%BB%E5%88%971-overview-1/33.png"></p>
<h4 id="Using-other-available-side-information"><a href="#Using-other-available-side-information" class="headerlink" title="Using other available side-information"></a>Using other available side-information</h4><blockquote>
<p>**The main reason for open space risk is that the traditional classifiers trained under closed set scenario usually divide over-occupied space for known known classes, thus inevitably resulting in misclassifications once the unknown unknown class samples</p>
</blockquote>
<p>fall into the space divided for some known known class.** From this perspective, the open space risk will be reduced as the space divided for those known known classes decreases by</p>
<p>using other side-information like universum [135], [136] to shrink their regions as much as possible.  </p>
<p>虽然感觉很扯淡。。但是还是有人做啊，不过关于 open space risk 的定义可以在看一遍。。</p>
<h3 id="Relative-Open-Set-Recognition"><a href="#Relative-Open-Set-Recognition" class="headerlink" title="Relative Open Set Recognition"></a>Relative Open Set Recognition</h3><p>感觉这个还挺有意思的。疾病的诊断，所有的样本空间都可以区分为 sick or no sick, 所以仅仅是判断有没有病，那么这是个 closed set 问题。但是如果我们要进一步判断疾病的类型，那么有可能出现 unseen disease in training.</p>
<h3 id="Knowledge-Integration-for-Open-Set-Recognition"><a href="#Knowledge-Integration-for-Open-Set-Recognition" class="headerlink" title="Knowledge Integration for Open Set Recognition"></a>Knowledge Integration for Open Set Recognition</h3><blockquote>
<p>In fact, the incomplete knowledge of the world is universal, especially for the single individuals: something you know does not mean I also know.  </p>
</blockquote>
<blockquote>
<p>how to integrate the classifiers trained on each sub-knowledge set to further reduce the open space risk will be an interesting yet challenging topic in the future work, especially for such a situation: we can only obtain the classifiers trained on corresponding sub-knowledge sets, yet these sub-knowledge sets are not available due to the privacy protection of data.  </p>
</blockquote>
<p>利用知识库来减小 open space risk。</p>
<p>似乎这个看起来比较靠谱，因为 unknown 范围确实很难定义，如果给个外部知识库给你，把跟知识库相关的 unknown 识别出来，就很棒了吧</p>
<p><img src="/2018/12/09/rejection%E7%B3%BB%E5%88%971-overview-1/34.png"></p>
<p>相关的一些开源工具和代码：</p>
<p><img src="/2018/12/09/rejection%E7%B3%BB%E5%88%971-overview-1/35.png"></p>
</div><div class="article-licensing box"><div class="licensing-title"><p>rejection系列1-overview</p><p><a href="http://www.panxiaoxie.cn/2018/12/09/rejection系列1-overview-1/">http://www.panxiaoxie.cn/2018/12/09/rejection系列1-overview-1/</a></p></div><div class="licensing-meta level is-mobile"><div class="level-left"><div class="level-item is-narrow"><div><h6>作者</h6><p>Xie Pan</p></div></div><div class="level-item is-narrow"><div><h6>发布于</h6><p>2018-12-09</p></div></div><div class="level-item is-narrow"><div><h6>更新于</h6><p>2021-06-29</p></div></div><div class="level-item is-narrow"><div><h6>许可协议</h6><p><a class="icons" rel="noopener" target="_blank" title="Creative Commons" href="https://creativecommons.org/"><i class="icon fab fa-creative-commons"></i></a><a class="icons" rel="noopener" target="_blank" title="Attribution" href="https://creativecommons.org/licenses/by/4.0/"><i class="icon fab fa-creative-commons-by"></i></a><a class="icons" rel="noopener" target="_blank" title="Noncommercial" href="https://creativecommons.org/licenses/by-nc/4.0/"><i class="icon fab fa-creative-commons-nc"></i></a></p></div></div></div></div></div><div class="article-tags is-size-7 mb-4"><span class="mr-2">#</span><a class="link-muted mr-2" rel="tag" href="/tags/open-set-recognition/">open set recognition</a></div><!--!--></article></div><!--!--><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/2018/12/11/rejection%E7%B3%BB%E5%88%973-OpenMax/"><i class="level-item fas fa-chevron-left"></i><span class="level-item">rejection系列3 OpenMax</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/2018/12/07/pytorch-%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/"><span class="level-item">pytorch-损失函数</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><div class="card"><div class="card-content"><h3 class="title is-5">评论</h3><div id="disqus_thread"><noscript>Please enable JavaScript to view the <a target="_blank" rel="noopener" href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript></div><script>var disqus_config = function () {
            this.page.url = 'http://www.panxiaoxie.cn/2018/12/09/rejection%E7%B3%BB%E5%88%971-overview-1/';
            this.page.identifier = '2018/12/09/rejection系列1-overview-1/';
        };
        (function() {
            var d = document, s = d.createElement('script');  
            s.src = '//' + 'panxie' + '.disqus.com/embed.js';
            s.setAttribute('data-timestamp', +new Date());
            (d.head || d.body).appendChild(s);
        })();</script></div></div></div><!--!--><div class="column column-right is-4-tablet is-4-desktop is-4-widescreen  order-3"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar" src="/img/avatar.png" alt="panxiaoxie"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">panxiaoxie</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Beijing, China</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">文章</p><a href="/archives"><p class="title">121</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">分类</p><a href="/categories"><p class="title">40</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">标签</p><a href="/tags"><p class="title">38</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/PanXiebit" target="_blank" rel="noopener">关注我</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/PanXiebit"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Email" href="/ftdpanxie@gmail.com"><i class="fa fa-envelope"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="RSS" href="/"><i class="fas fa-rss"></i></a></div></div></div><!--!--><div class="card widget" data-type="links"><div class="card-content"><div class="menu"><h3 class="menu-label">链接</h3><ul class="menu-list"><li><a class="level is-mobile" href="https://github.com/PanXiebit" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">github</span></span><span class="level-right"><span class="level-item tag">github.com</span></span></a></li><li><a class="level is-mobile" href="ftdpanxie@gmail.com" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">email</span></span><span class="level-right"><span class="level-item tag">ftdpanxie@gmail.com</span></span></a></li></ul></div></div></div><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">分类</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/C/"><span class="level-start"><span class="level-item">C++</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/CSAPP/"><span class="level-start"><span class="level-item">CSAPP</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/DRL/"><span class="level-start"><span class="level-item">DRL</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/GAN/"><span class="level-start"><span class="level-item">GAN</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li><li><a class="level is-mobile" href="/categories/GAN-RL/"><span class="level-start"><span class="level-item">GAN, RL</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/ML/"><span class="level-start"><span class="level-item">ML</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/NLP/"><span class="level-start"><span class="level-item">NLP</span></span><span class="level-end"><span class="level-item tag">14</span></span></a></li><li><a class="level is-mobile" href="/categories/TensorFlow/"><span class="level-start"><span class="level-item">TensorFlow</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/cs224d/"><span class="level-start"><span class="level-item">cs224d</span></span><span class="level-end"><span class="level-item tag">10</span></span></a></li><li><a class="level is-mobile" href="/categories/generation/"><span class="level-start"><span class="level-item">generation</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/generative-models/"><span class="level-start"><span class="level-item">generative models</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/interview/"><span class="level-start"><span class="level-item">interview</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/machine-translation/"><span class="level-start"><span class="level-item">machine translation</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/python/"><span class="level-start"><span class="level-item">python</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/pytorch/"><span class="level-start"><span class="level-item">pytorch</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/reinforcement-learning/"><span class="level-start"><span class="level-item">reinforcement learning</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/sign-language-recognition/"><span class="level-start"><span class="level-item">sign language recognition</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/transfer-learning/"><span class="level-start"><span class="level-item">transfer learning</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/transformer/"><span class="level-start"><span class="level-item">transformer</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"><span class="level-start"><span class="level-item">数据结构与算法</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile" href="/categories/%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB/"><span class="level-start"><span class="level-item">文本分类</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"><span class="level-start"><span class="level-item">论文笔记</span></span><span class="level-end"><span class="level-item tag">40</span></span></a><ul><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/DL/"><span class="level-start"><span class="level-item">DL</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/ESA/"><span class="level-start"><span class="level-item">ESA</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/GAN/"><span class="level-start"><span class="level-item">GAN</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/MRC-and-QA/"><span class="level-start"><span class="level-item">MRC and QA</span></span><span class="level-end"><span class="level-item tag">7</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/Machine-Translation/"><span class="level-start"><span class="level-item">Machine Translation</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/NLP/"><span class="level-start"><span class="level-item">NLP</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/Transformer/"><span class="level-start"><span class="level-item">Transformer</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/capsules/"><span class="level-start"><span class="level-item">capsules</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/computer-vision/"><span class="level-start"><span class="level-item">computer vision</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/constrast-learning/"><span class="level-start"><span class="level-item">constrast learning</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/data-augmentation/"><span class="level-start"><span class="level-item">data augmentation</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/dialogue-system/"><span class="level-start"><span class="level-item">dialogue system</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/language-model/"><span class="level-start"><span class="level-item">language model</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/machine-translation/"><span class="level-start"><span class="level-item">machine translation</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/open-set-recognition/"><span class="level-start"><span class="level-item">open set recognition</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/sentence-embedding/"><span class="level-start"><span class="level-item">sentence embedding</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/text-matching/"><span class="level-start"><span class="level-item">text matching</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/vision-language/"><span class="level-start"><span class="level-item">vision-language</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li></ul></div></div></div></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/panxiaoxie.png" alt="潘小榭" height="28"></a><p class="is-size-7"><span>&copy; 2022 Xie Pan</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("zh-CN");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="回到顶端" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "此网站使用Cookie来改善您的体验。",
          dismiss: "知道了！",
          allow: "允许使用Cookie",
          deny: "拒绝",
          link: "了解更多",
          policy: "Cookie政策",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.5/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="想要查找什么..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"想要查找什么...","untitled":"(无标题)","posts":"文章","pages":"页面","categories":"分类","tags":"标签"});
        });</script></body></html>