<!doctype html>
<html lang="zh"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>cs224d-lecture10 机器翻译和注意力机制 - 潘小榭</title><link rel="manifest" href="/manifest.json"><meta name="theme-color" content="black"><meta name="application-name" content="panxiaoxie"><meta name="msapplication-TileImage" content="/img/avatar.png"><meta name="msapplication-TileColor" content="black"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="panxiaoxie"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="description" content="主要内容：  Seq2Seq 基础模型  seq2seq encoder and decoder   Attention Mechanisms: 介绍了三种attention  Bahdanau et al. NMT model: 重点是怎么计算 context vector $c_i$"><meta property="og:type" content="blog"><meta property="og:title" content="panxiaoxie"><meta property="og:url" content="https://github.com/PanXiebit"><meta property="og:site_name" content="panxiaoxie"><meta property="og:description" content="主要内容：  Seq2Seq 基础模型  seq2seq encoder and decoder   Attention Mechanisms: 介绍了三种attention  Bahdanau et al. NMT model: 重点是怎么计算 context vector $c_i$"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://www.qt86.com/cache/1625298592_187938.png"><meta property="article:published_time" content="2018-05-08T02:18:54.000Z"><meta property="article:modified_time" content="2021-06-29T08:12:08.269Z"><meta property="article:author" content="panxiaoxie"><meta property="article:tag" content="cs224d"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="https://www.qt86.com/cache/1625298592_187938.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"http://www.panxiaoxie.cn/2018/05/08/cs224d-lecture10-%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91%E5%92%8C%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/"},"headline":"cs224d-lecture10 机器翻译和注意力机制","image":["http://www.panxiaoxie.cn/2018/05/08/cs224d-lecture10-%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91%E5%92%8C%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/att08.png","http://www.panxiaoxie.cn/2018/05/08/cs224d-lecture10-%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91%E5%92%8C%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/att09.png","http://www.panxiaoxie.cn/2018/05/08/cs224d-lecture10-%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91%E5%92%8C%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/att10.png","http://www.panxiaoxie.cn/2018/05/08/cs224d-lecture10-%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91%E5%92%8C%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/att11.png","http://www.panxiaoxie.cn/2018/05/08/cs224d-lecture10-%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91%E5%92%8C%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/att12.png","http://www.panxiaoxie.cn/2018/05/08/cs224d-lecture10-%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91%E5%92%8C%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/att13.png","http://www.panxiaoxie.cn/2018/05/08/cs224d-lecture10-%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91%E5%92%8C%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/att14.png"],"datePublished":"2018-05-08T02:18:54.000Z","dateModified":"2021-06-29T08:12:08.269Z","author":{"@type":"Person","name":"Xie Pan"},"publisher":{"@type":"Organization","name":"潘小榭","logo":{"@type":"ImageObject","url":"http://www.panxiaoxie.cn/img/panxiaoxie.png"}},"description":"主要内容：  Seq2Seq 基础模型  seq2seq encoder and decoder   Attention Mechanisms: 介绍了三种attention  Bahdanau et al. NMT model: 重点是怎么计算 context vector $c_i$"}</script><link rel="canonical" href="http://www.panxiaoxie.cn/2018/05/08/cs224d-lecture10-%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91%E5%92%8C%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/"><link rel="icon" href="/img/avatar.png"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/css/justifiedGallery.min.css"><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script><!--!--><!--!--><meta name="generator" content="Hexo 5.4.0"></head><body class="is-2-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/panxiaoxie.png" alt="潘小榭" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">主页</a><a class="navbar-item" href="/archives">归档</a><a class="navbar-item" href="/categories">分类</a><a class="navbar-item" href="/tags">标签</a><a class="navbar-item" href="/about">关于我</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/PanXiebit"><i class="fab fa-github"></i></a><a class="navbar-item search" title="搜索" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-10-widescreen"><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2018-05-08T02:18:54.000Z" title="2018/5/8 上午10:18:54">2018-05-08</time>发表</span><span class="level-item"><time dateTime="2021-06-29T08:12:08.269Z" title="2021/6/29 下午4:12:08">2021-06-29</time>更新</span><span class="level-item"><a class="link-muted" href="/categories/cs224d/">cs224d</a></span><span class="level-item">17 分钟读完 (大约2500个字)</span></div></div><h1 class="title is-3 is-size-4-mobile">cs224d-lecture10 机器翻译和注意力机制</h1><div class="content"><p>主要内容：</p>
<ul>
<li><p>Seq2Seq 基础模型</p>
<ul>
<li>seq2seq encoder and decoder</li>
</ul>
</li>
<li><p>Attention Mechanisms: 介绍了三种attention</p>
<ul>
<li>Bahdanau et al. NMT model: 重点是怎么计算 context vector $c_i$</li>
</ul>
</li>
</ul>
<span id="more"></span>



<h3 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h3><p>对于NER标注，是通过previous words预测下一个word.还有一类NLP任务，是针对sequential output or outputs that are sequences of potentially varying length. 比如：</p>
<ul>
<li><strong>Translation:</strong> taking a sentence in one language as input and outputting the same sentence in another language</li>
</ul>
<ul>
<li><strong>Conversation:</strong> taking a statement or question as input and responding to it.</li>
</ul>
<ul>
<li><strong>Summarization:</strong> taking a large body of text as input and outputting a summary of it.</li>
</ul>
<p>这一节内容讲的就是根据一个基于深度学习的框架sequence-tosequence模型，用来处理序列生成的问题。</p>
<p>序列生成的历史方法:</p>
<ul>
<li><p>word-based system: 无法capture句子中的词序</p>
</li>
<li><p>phrase-based system: 无法解决长时间依赖的问题</p>
</li>
<li><p>Seq2Seq模型：can generate arbitrary output sequences after seeing the entire input. They can even focus in on specific parts of the input automatically to help generate a useful translation.</p>
</li>
</ul>
<h3 id="sequence-to-sequence-Basics"><a href="#sequence-to-sequence-Basics" class="headerlink" title="sequence-to-sequence Basics"></a>sequence-to-sequence Basics</h3><p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1409.3215"> Sutskever et al. 2014, “Sequence to Sequence Learning with Neural Networks”</a></p>
<h4 id="Seq2Seq-encoder"><a href="#Seq2Seq-encoder" class="headerlink" title="Seq2Seq-encoder"></a>Seq2Seq-encoder</h4><p><img src="/2018/05/08/cs224d-lecture10-%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91%E5%92%8C%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/att08.png"></p>
<p>encoder的目的就是将input sentence读入到模型中，并生成一个固定维度 context vector C. 显然，就一个任意长度的句子的信息压缩到一个固定维度的向量中，这是很困难的。所以encoder通常使用 <strong>stacked LSTMs.</strong></p>
<p>通常会将sentence翻转作为输入，以机器翻译为例，翻转后输入的最后一个词对应的翻译，也就是output的第一个词。</p>
<blockquote>
<p>明显感觉效果会不太好对吧，所以也就有了后来的attention</p>
</blockquote>
<p>举个例子：</p>
<p>input sentence：”what is your name”</p>
<p>那么得到的context vector 就是 a vector space representation of the notion of asking someone for their name.</p>
<h4 id="Seq2Seq-decoder"><a href="#Seq2Seq-decoder" class="headerlink" title="Seq2Seq-decoder"></a>Seq2Seq-decoder</h4><p><img src="/2018/05/08/cs224d-lecture10-%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91%E5%92%8C%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/att09.png"></p>
<p>decoder的目的是生成sentence，在最上面一层LSTM上接着softmax用来生成当前时间步的output词。然后用这个词作为下一个时间步的input word.</p>
<p>一旦得到output sentence,通过最小化交叉熵损失函数，来训练encoder和decoder中的参数。</p>
<h4 id="Bidirectional-RNNs"><a href="#Bidirectional-RNNs" class="headerlink" title="Bidirectional RNNs"></a>Bidirectional RNNs</h4><p><img src="/2018/05/08/cs224d-lecture10-%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91%E5%92%8C%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/att10.png"></p>
<h3 id="Attention-Mechanism"><a href="#Attention-Mechanism" class="headerlink" title="Attention Mechanism"></a>Attention Mechanism</h3><h4 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h4><p>在seq2seq模型中，使用单一的 context vector：different parts of an input have different levels of significance. Moreover, different parts of the output may even consider different parts of the input “important.”</p>
<ul>
<li>也就是说输入sentence中，每个词并不是具有同样的重要程度的。比如 “the ball is on the field”,显然”ball” “on” “field”比较重要。</li>
</ul>
<ul>
<li>而且，在输出的某一部分也可能更看中input中的某一部分。通常output中的前几个词主要却取决于input中的前几个词，output中的后几个词主要取决于input中的后几个词。</li>
</ul>
<p>那么Attention mechanisms采用的方法是： providing the decoder network with a look at the entire input sequence at every decoding step; the decoder can then decide what input words are important at any point in time. 在decoder时采用注意力机制，确定在任何时刻生成词时输入序列中每个词的权重。</p>
<h4 id="Bahdanau-et-al-NMT-model"><a href="#Bahdanau-et-al-NMT-model" class="headerlink" title="Bahdanau et al. NMT model"></a>Bahdanau et al. NMT model</h4><p>原论文： <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1409.0473">Bahdanau et al. Neural Machine Translation by Jointly Learning to Align and Translate</a></p>
<h5 id="Decoder-General-description"><a href="#Decoder-General-description" class="headerlink" title="Decoder: General description"></a>Decoder: General description</h5><p><img src="/2018/05/08/cs224d-lecture10-%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91%E5%92%8C%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/att11.png"></p>
<p>decoder中生成下一个词的条件概率：</p>
<p>$$P(y_i|y_1,…,y_{i-1},X)=g(y_{i-1},s_i,c_i)$$</p>
<p>其中，当前时间步的隐藏状态 $s_i$ 表示为：</p>
<p>$$s_i=f(s_{i-1},y_{i-1},c_i)$$</p>
<p>也就是： i时刻生成此 $y_i$ 取决于 上一个生成词 $y_{i-1}$ (在生成序列时上一个时间步的输出是下一个时间步的输入) 和 i-1时刻的隐藏状态 $s_{i-1}$ 以及context vector对应的值 $c_i$.</p>
<p><strong>重点是怎么计算每个时间步的context vector $c_i$：</strong></p>
<p>在标准的seq2seq模型中，context vector只有一个，但在attention模型中，每个时间步都有单独的context vector $c_i$,它依赖于输入序列中的所有annotation $(h_1; · ·· ; h_{T_x})$,并赋予他们一定的权重。也就是：</p>
<p>$$c_i=\sum_{j=1}^{T_x}\alpha_{ij}h_j$$</p>
<p>其中i表示输出序列的第i时刻，j表示输入序列的第j个word的annotation.</p>
<p>其中对于每个输入词的annotation即 $h_j$ 的权重 $a_{ij}$ 是这么计算的：</p>
<p>$$\alpha_{ij}=\dfrac{exp(e_{ij})}{\sum_{k=1}^{T_x}exp(e_{ik})}$$</p>
<p>其中：</p>
<p>$$e_{ij}=a(s_{i-1},h_j)$$</p>
<p>是对其模型(alignment model),$s_{i-1}$ 表示输出序列的隐藏状态， $h_j$ 表示输入序列的隐藏状态，所以用来计算输入sentence中第j个位置和输出序列中第i个位置匹配的得分(score).这个得分是基于decoder中的前一个时刻的隐藏状态 $s_{i-1}$, 和输入序列中的第j个annotation $h_j$。 a是任意函数，且得到的值是R。比如可以是一个单层的全连接神经网络，得到了序列 $e_{i,1},…,e_{i,n}$， 然后使用softmax得到 $\alpha_i=(\alpha_{i,1},…,\alpha_{i,n})$.</p>
<p>疑问：知道了 $e_{ij}$ 的意义，但不太明白怎么计算。。还没看论文，猜想既然a是任意函数，那么应该就是用神经网络来表示了。</p>
<p><strong>总结下来：</strong></p>
<p>Let $\alpha_{ij}$ be a probability that the target word yi is aligned to, or translated from, a source word $x_j$. Then, the i-th context vector $c_i$ is the expected annotation over all the annotations with probabilities $\alpha_{ij}$.</p>
<p>所以 $\alpha_{ij}$ 表示的就是从词 $x_j$ translate to (or align to) 词 $y_i$ 的概率。也就是说 output中第i个词 $y_i$ 可能由 input中的任意一个词对齐而来的，也不一定就是翻译，就是 翻译 $y_i$ 的时候，input中每一个对它的影响程度，也就是这个权重值 $\alpha_{ij}$.  </p>
<p>而这个概率 $\alpha_{ij}$ 以及其 associated energy $e_{ij}$ 反映了 $s_{i-1}$ 和 $h_j$ 对生成下一个word的重要性。</p>
<p>疑问：在训练的时候可以通过反向传播，得到参数 $c_i$，但是这个权重也只能用于当前的序列吧。。测试的时候，这些训练的参数还能用么？</p>
<h5 id="Encoder-bidirectional-RNN-for-annotation-sequences"><a href="#Encoder-bidirectional-RNN-for-annotation-sequences" class="headerlink" title="Encoder: bidirectional RNN for annotation sequences"></a>Encoder: bidirectional RNN for annotation sequences</h5><p>在encoder时，将输入序列编码为annotation $(h_1,h_2,…,h_{T_x})$. 为了既考虑preceding words，又考虑 following words，采用双向RNN（BiRNN）.</p>
<p>forward RNN $\overrightarrow f$ reads input sentence (from $x_1$ to $x_{T_x}$):</p>
<p>$$(\overrightarrow h_1,…,\overrightarrow h_{T_x})$$</p>
<p>backward RNN $\overleftarrow f$ reads input sentence in the reverse order (from $x_{T_x}$ to $x_1$):</p>
<p>$$(\overleftarrow h_1,…,\overleftarrow h_{T_x})$$</p>
<p>annotation for $x_j$:</p>
<p>$$h_j=[\overrightarrow {h_{T_j}^T},\overleftarrow {h_{T_j}^T}]$$</p>
<h5 id="Connection-with-translation-alignment"><a href="#Connection-with-translation-alignment" class="headerlink" title="Connection with translation alignment"></a>Connection with translation alignment</h5><p>在训练的decoder过程中，可以得到这样的一个alignment table, a table mapping words in the source to corresponding words in the target sentence.使用attention score $\alpha_{i,j}$ 填充这个表格。</p>
<p><img src="/2018/05/08/cs224d-lecture10-%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91%E5%92%8C%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/att12.png"></p>
<p>这就解决了之前的疑惑了，在测试的时候，context vector的权重 $\alpha_i$ 直接通过查表得到～</p>
<h3 id="Huong-et-al-NMT-model"><a href="#Huong-et-al-NMT-model" class="headerlink" title="Huong et al. NMT model"></a>Huong et al. NMT model</h3><p>原论文： <a target="_blank" rel="noopener" href="http://aclweb.org/anthology/D15-1166"> Effective Approaches to Attentionbased Neural Machine Translation by Minh-Thang Luong, Hieu Pham an Christopher D. Manning</a></p>
<h4 id="Global-attention"><a href="#Global-attention" class="headerlink" title="Global attention"></a>Global attention</h4><p>encoder 隐藏状态序列： $h_1,…,h_n$ ，n表示序列长度</p>
<p>decoder 隐藏状态序列： $\overline h_1,…,\overline h_n$</p>
<p>对于每一个decoder中的隐藏状态 $\overline h_i$，计算其基于所有encoder隐藏状态的attention vector $c_i$.</p>
<p>$$</p>
<p>score(h_i^T\overline h_j)=\begin{cases} h_i^T\overline h_j \</p>
<p>h_i^TW\overline h_j \quad &amp; \text{$\in R$}\</p>
<p>W[h_i,\overline h_j]</p>
<p>\end{cases}  </p>
<p>$$</p>
<p>类似于Bahdanau et al. NMT model中的 $e_{ij}$, 同样的需要得到的权重 $\alpha_{ij}$ 是概率，也就是encoder中的 $h_i$ 与 decoder中的 $h_j$ 匹配的概率, attention vector $\alpha_{i,j}$：</p>
<p>$$\alpha_{i,j}=\dfrac{exp(score(h_i^T\overline h_j))}{\sum_{k=1}^nexp(score(h_k^T\overline h_j))}$$</p>
<p>那么context vector:</p>
<p>$$c_i=\sum_{j=1}^n \alpha_{i,j}h_j$$</p>
<p>那么使用context vector和隐藏状态 $\overline h_i$ 生成新的decoder中第i时间步的新的 vector</p>
<p>$$\tilde h_i=f[\overline h_i,c_i]$$</p>
<h4 id="Local-Attention"><a href="#Local-Attention" class="headerlink" title="Local Attention"></a>Local Attention</h4><p>the model predicts an aligned position in the input sequence. Then, it computes a context vector <strong>using a window centered on this position</strong>. The computational cost of this attention step is constant and does not explode with the length of the sentence.</p>
<p>window怎么选？？  Christopher 好像说用强化学习。。</p>
<p><img src="/2018/05/08/cs224d-lecture10-%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91%E5%92%8C%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/att13.png"></p>
<h3 id="Google’s-new-NMT"><a href="#Google’s-new-NMT" class="headerlink" title="Google’s new NMT"></a>Google’s new NMT</h3><p><a target="_blank" rel="noopener" href="https://www.aclweb.org/anthology/Q/Q17/Q17-1024.pdf">6 Johnson et el. 2016, “Google’s Multilingual Neural Machine Translation System: Enabling Zero-Shot Translation”</a></p>
<p>The new multilingual model not only improved their translation performance, it also enabled <strong>“zero-shot translation,”</strong> in which we can translate between two languages for which we have no translation training data. For instance, if we only had examples of Japanese-English translations and Korean-English translations, Google’s team found that the multilingual NMT system trained on this data could actually generate reasonable Japanese-Korean translations. The powerful implication of this finding is that part of the decoding process is not language-specific, and the model is in fact <strong>maintaining an internal representation</strong> of the input/output sentences independent of the actual languages involved.</p>
<h3 id="More-advanced-papers-using-attention"><a href="#More-advanced-papers-using-attention" class="headerlink" title="More advanced papers using attention"></a>More advanced papers using attention</h3><ul>
<li>Show, Attend and Tell: Neural Image Caption Generation with Visual Attention by Kelvin Xu, Jimmy Lei Ba,Ryan Kiros, Kyunghyun Cho, Aaron Courville, Ruslan Salakhutdinov, Richard S. Zemel</li>
</ul>
<p>and Yoshua Bengio. This paper learns words/image alignment.</p>
<ul>
<li>Modeling Coverage for Neural Machine Translation by Zhaopeng Tu, Zhengdong Lu, Yang Liu, Xiaohua Liu and Hang Li. Their model</li>
</ul>
<p>uses a coverage vector that takes into account the attention history to help future attention.</p>
<ul>
<li>Incorporating Structural Alignment Biases into an Attentional Neural Translation Model by Cohn, Hoang, Vymolova, Yao, Dyer, Haffari. This paper improves the attention by incorporating other traditional linguistic ideas.</li>
</ul>
<h3 id="Sequence-model-decoders"><a href="#Sequence-model-decoders" class="headerlink" title="Sequence model decoders"></a>Sequence model decoders</h3><p>使用统计的方法找到最合适的sequence $\hat s*$：</p>
<p>$$\hat s* = argmax_{\hat s}(P(\hat s|s))$$</p>
<ul>
<li>Exhaustive search: NP问题</li>
</ul>
<ul>
<li>Ancestral sampling</li>
</ul>
<p>$$x_t \sim P(x_t|x_1,..,x_n)$$</p>
<ul>
<li>Greedy search</li>
</ul>
<p>$$x_t=argmax_{\tilde x_t}P(\tilde x_t|x_1,…,x_n)$$</p>
<p>如果其中一步错了，对接下来的序列影响很大。</p>
<ul>
<li>Beam search： the idea is to maintain K candidates at each time</li>
</ul>
<p>step.</p>
<p><img src="/2018/05/08/cs224d-lecture10-%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91%E5%92%8C%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/att14.png"></p>
<h3 id="Presentation"><a href="#Presentation" class="headerlink" title="Presentation"></a>Presentation</h3><p>Google’s Multilingual Neural Machine Translation System: Enabling zero-short Translation</p>
</div><div class="article-licensing box"><div class="licensing-title"><p>cs224d-lecture10 机器翻译和注意力机制</p><p><a href="http://www.panxiaoxie.cn/2018/05/08/cs224d-lecture10-机器翻译和注意力机制/">http://www.panxiaoxie.cn/2018/05/08/cs224d-lecture10-机器翻译和注意力机制/</a></p></div><div class="licensing-meta level is-mobile"><div class="level-left"><div class="level-item is-narrow"><div><h6>作者</h6><p>Xie Pan</p></div></div><div class="level-item is-narrow"><div><h6>发布于</h6><p>2018-05-08</p></div></div><div class="level-item is-narrow"><div><h6>更新于</h6><p>2021-06-29</p></div></div><div class="level-item is-narrow"><div><h6>许可协议</h6><p><a class="icons" rel="noopener" target="_blank" title="Creative Commons" href="https://creativecommons.org/"><i class="icon fab fa-creative-commons"></i></a><a class="icons" rel="noopener" target="_blank" title="Attribution" href="https://creativecommons.org/licenses/by/4.0/"><i class="icon fab fa-creative-commons-by"></i></a><a class="icons" rel="noopener" target="_blank" title="Noncommercial" href="https://creativecommons.org/licenses/by-nc/4.0/"><i class="icon fab fa-creative-commons-nc"></i></a></p></div></div></div></div></div><div class="article-tags is-size-7 mb-4"><span class="mr-2">#</span><a class="link-muted mr-2" rel="tag" href="/tags/cs224d/">cs224d</a></div><!--!--></article></div><!--!--><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/2018/05/11/cs224d-lecture11-%E5%86%8D%E7%9C%8BGRU%E5%92%8CNMT/"><i class="level-item fas fa-chevron-left"></i><span class="level-item">cs224d-lecture11 再看GRU和NMT</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/2018/05/07/cs224d-lecture9-machine-translation/"><span class="level-item">cs224d-lecture9 机器翻译</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><div class="card"><div class="card-content"><h3 class="title is-5">评论</h3><div id="disqus_thread"><noscript>Please enable JavaScript to view the <a target="_blank" rel="noopener" href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript></div><script>var disqus_config = function () {
            this.page.url = 'http://www.panxiaoxie.cn/2018/05/08/cs224d-lecture10-%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91%E5%92%8C%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/';
            this.page.identifier = '2018/05/08/cs224d-lecture10-机器翻译和注意力机制/';
        };
        (function() {
            var d = document, s = d.createElement('script');  
            s.src = '//' + 'panxie' + '.disqus.com/embed.js';
            s.setAttribute('data-timestamp', +new Date());
            (d.head || d.body).appendChild(s);
        })();</script></div></div></div><!--!--><div class="column column-right is-4-tablet is-4-desktop is-4-widescreen  order-3"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar" src="/img/avatar.png" alt="panxiaoxie"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">panxiaoxie</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Beijing, China</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">文章</p><a href="/archives"><p class="title">120</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">分类</p><a href="/categories"><p class="title">40</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">标签</p><a href="/tags"><p class="title">37</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/PanXiebit" target="_blank" rel="noopener">关注我</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/PanXiebit"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Email" href="/ftdpanxie@gmail.com"><i class="fa fa-envelope"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="RSS" href="/"><i class="fas fa-rss"></i></a></div></div></div><!--!--><div class="card widget" data-type="links"><div class="card-content"><div class="menu"><h3 class="menu-label">链接</h3><ul class="menu-list"><li><a class="level is-mobile" href="https://github.com/PanXiebit" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">github</span></span><span class="level-right"><span class="level-item tag">github.com</span></span></a></li><li><a class="level is-mobile" href="ftdpanxie@gmail.com" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">email</span></span><span class="level-right"><span class="level-item tag">ftdpanxie@gmail.com</span></span></a></li></ul></div></div></div><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">分类</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/C/"><span class="level-start"><span class="level-item">C++</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/CSAPP/"><span class="level-start"><span class="level-item">CSAPP</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/DRL/"><span class="level-start"><span class="level-item">DRL</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/GAN/"><span class="level-start"><span class="level-item">GAN</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li><li><a class="level is-mobile" href="/categories/GAN-RL/"><span class="level-start"><span class="level-item">GAN, RL</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/ML/"><span class="level-start"><span class="level-item">ML</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/NLP/"><span class="level-start"><span class="level-item">NLP</span></span><span class="level-end"><span class="level-item tag">14</span></span></a></li><li><a class="level is-mobile" href="/categories/TensorFlow/"><span class="level-start"><span class="level-item">TensorFlow</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/cs224d/"><span class="level-start"><span class="level-item">cs224d</span></span><span class="level-end"><span class="level-item tag">10</span></span></a></li><li><a class="level is-mobile" href="/categories/generation/"><span class="level-start"><span class="level-item">generation</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/generative-models/"><span class="level-start"><span class="level-item">generative models</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/interview/"><span class="level-start"><span class="level-item">interview</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/machine-translation/"><span class="level-start"><span class="level-item">machine translation</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/python/"><span class="level-start"><span class="level-item">python</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/pytorch/"><span class="level-start"><span class="level-item">pytorch</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/reinforcement-learning/"><span class="level-start"><span class="level-item">reinforcement learning</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/sign-language-recognition/"><span class="level-start"><span class="level-item">sign language recognition</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/transfer-learning/"><span class="level-start"><span class="level-item">transfer learning</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/transformer/"><span class="level-start"><span class="level-item">transformer</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"><span class="level-start"><span class="level-item">数据结构与算法</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile" href="/categories/%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB/"><span class="level-start"><span class="level-item">文本分类</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"><span class="level-start"><span class="level-item">论文笔记</span></span><span class="level-end"><span class="level-item tag">40</span></span></a><ul><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/DL/"><span class="level-start"><span class="level-item">DL</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/ESA/"><span class="level-start"><span class="level-item">ESA</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/GAN/"><span class="level-start"><span class="level-item">GAN</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/MRC-and-QA/"><span class="level-start"><span class="level-item">MRC and QA</span></span><span class="level-end"><span class="level-item tag">7</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/Machine-Translation/"><span class="level-start"><span class="level-item">Machine Translation</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/NLP/"><span class="level-start"><span class="level-item">NLP</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/Transformer/"><span class="level-start"><span class="level-item">Transformer</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/capsules/"><span class="level-start"><span class="level-item">capsules</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/computer-vision/"><span class="level-start"><span class="level-item">computer vision</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/constrast-learning/"><span class="level-start"><span class="level-item">constrast learning</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/data-augmentation/"><span class="level-start"><span class="level-item">data augmentation</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/dialogue-system/"><span class="level-start"><span class="level-item">dialogue system</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/language-model/"><span class="level-start"><span class="level-item">language model</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/machine-translation/"><span class="level-start"><span class="level-item">machine translation</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/open-set-recognition/"><span class="level-start"><span class="level-item">open set recognition</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/sentence-embedding/"><span class="level-start"><span class="level-item">sentence embedding</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/text-matching/"><span class="level-start"><span class="level-item">text matching</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/vision-language/"><span class="level-start"><span class="level-item">vision-language</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li></ul></div></div></div></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/panxiaoxie.png" alt="潘小榭" height="28"></a><p class="is-size-7"><span>&copy; 2021 Xie Pan</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("zh-CN");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="回到顶端" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "此网站使用Cookie来改善您的体验。",
          dismiss: "知道了！",
          allow: "允许使用Cookie",
          deny: "拒绝",
          link: "了解更多",
          policy: "Cookie政策",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.5/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="想要查找什么..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"想要查找什么...","untitled":"(无标题)","posts":"文章","pages":"页面","categories":"分类","tags":"标签"});
        });</script></body></html>