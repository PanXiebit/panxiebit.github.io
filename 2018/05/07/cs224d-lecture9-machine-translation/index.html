<!doctype html>
<html lang="zh"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>cs224d-lecture9 机器翻译 - 潘小榭</title><link rel="manifest" href="/manifest.json"><meta name="theme-color" content="black"><meta name="application-name" content="panxiaoxie"><meta name="msapplication-TileImage" content="/img/avatar.png"><meta name="msapplication-TileColor" content="black"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="panxiaoxie"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="description" content="主要内容：  RNN Translation Model  GRU  LSTM  Towards a Better Language Modeling"><meta property="og:type" content="blog"><meta property="og:title" content="panxiaoxie"><meta property="og:url" content="https://github.com/PanXiebit"><meta property="og:site_name" content="panxiaoxie"><meta property="og:description" content="主要内容：  RNN Translation Model  GRU  LSTM  Towards a Better Language Modeling"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://www.qt86.com/cache/1625298592_187938.png"><meta property="article:published_time" content="2018-05-06T23:18:11.000Z"><meta property="article:modified_time" content="2021-06-29T08:12:08.521Z"><meta property="article:author" content="panxiaoxie"><meta property="article:tag" content="cs224d"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="https://www.qt86.com/cache/1625298592_187938.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"http://www.panxiaoxie.cn/2018/05/07/cs224d-lecture9-machine-translation/"},"headline":"cs224d-lecture9 机器翻译","image":["http://www.panxiaoxie.cn/2018/05/07/cs224d-lecture9-machine-translation/mt12.png","http://www.panxiaoxie.cn/2018/05/07/cs224d-lecture9-machine-translation/mt13.png","http://www.panxiaoxie.cn/2018/05/07/cs224d-lecture9-machine-translation/mt14.png","http://www.panxiaoxie.cn/2018/05/07/cs224d-lecture9-machine-translation/mt15.png","http://www.panxiaoxie.cn/2018/05/07/cs224d-lecture9-machine-translation/mt16.png","http://www.panxiaoxie.cn/2018/05/07/cs224d-lecture9-machine-translation/mt18.png","http://www.panxiaoxie.cn/2018/05/07/cs224d-lecture9-machine-translation/lstm.png","http://www.panxiaoxie.cn/2018/05/07/cs224d-lecture9-machine-translation/mt11.png","http://www.panxiaoxie.cn/2018/05/07/cs224d-lecture9-machine-translation/mt03.png","http://www.panxiaoxie.cn/2018/05/07/cs224d-lecture9-machine-translation/mt04.png","http://www.panxiaoxie.cn/2018/05/07/cs224d-lecture9-machine-translation/mt05.png","http://www.panxiaoxie.cn/2018/05/07/cs224d-lecture9-machine-translation/mt06.png","http://www.panxiaoxie.cn/2018/05/07/cs224d-lecture9-machine-translation/mt07.png"],"datePublished":"2018-05-06T23:18:11.000Z","dateModified":"2021-06-29T08:12:08.521Z","author":{"@type":"Person","name":"Xie Pan"},"publisher":{"@type":"Organization","name":"潘小榭","logo":{"@type":"ImageObject","url":"http://www.panxiaoxie.cn/img/panxiaoxie.png"}},"description":"主要内容：  RNN Translation Model  GRU  LSTM  Towards a Better Language Modeling"}</script><link rel="canonical" href="http://www.panxiaoxie.cn/2018/05/07/cs224d-lecture9-machine-translation/"><link rel="icon" href="/img/avatar.png"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/css/justifiedGallery.min.css"><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script><!--!--><!--!--><meta name="generator" content="Hexo 5.4.0"></head><body class="is-2-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/panxiaoxie.png" alt="潘小榭" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">主页</a><a class="navbar-item" href="/archives">归档</a><a class="navbar-item" href="/categories">分类</a><a class="navbar-item" href="/tags">标签</a><a class="navbar-item" href="/about">关于我</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/PanXiebit"><i class="fab fa-github"></i></a><a class="navbar-item search" title="搜索" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-10-widescreen"><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2018-05-06T23:18:11.000Z" title="2018/5/7 上午7:18:11">2018-05-07</time>发表</span><span class="level-item"><time dateTime="2021-06-29T08:12:08.521Z" title="2021/6/29 下午4:12:08">2021-06-29</time>更新</span><span class="level-item"><a class="link-muted" href="/categories/cs224d/">cs224d</a></span><span class="level-item">10 分钟读完 (大约1443个字)</span></div></div><h1 class="title is-3 is-size-4-mobile">cs224d-lecture9 机器翻译</h1><div class="content"><p>主要内容：</p>
<ul>
<li><p>RNN Translation Model</p>
</li>
<li><p>GRU</p>
</li>
<li><p>LSTM</p>
</li>
<li><p>Towards a Better Language Modeling</p>
</li>
</ul>
<span id="more"></span>



<h3 id="RNN-Translation-Model"><a href="#RNN-Translation-Model" class="headerlink" title="RNN Translation Model"></a>RNN Translation Model</h3><p><img src="/2018/05/07/cs224d-lecture9-machine-translation/mt12.png"></p>
<p>encoder:</p>
<p>$$h_t=\phi(h_{t-1},x_t)=f(W^{(hh)}h_{t-1}+W^{(hx)}x_t)$$</p>
<p>encoder:</p>
<p>$$h_t=\phi(h_{t-1})=f(W^{(hh)}h_{t-1})$$</p>
<p>$$y_t=softmax(W^{(S)}h_t)$$</p>
<p>corss entropy function:</p>
<p>$$max_{\theta}\dfrac{1}{N}\sum_{n=1}^Nlogp_{\theta}(y^{(n)}|x^{(n)})$$</p>
<h4 id="rnn的几点扩展"><a href="#rnn的几点扩展" class="headerlink" title="rnn的几点扩展"></a>rnn的几点扩展</h4><p>1.在encoder和decoder中，$W^{(hh)}$ 是不一样的</p>
<p>2.计算decoder中的隐藏神经元时，可以不仅仅只使用上一个隐藏层的信息，而是使用三种input来获取更多的信息</p>
<ul>
<li><p>The previous hidden state (standard)</p>
</li>
<li><p>Last hidden layer of the encoder (c = hT)</p>
</li>
<li><p> Previous predicted output word, $y^{t−1}$</p>
</li>
</ul>
<p><img src="/2018/05/07/cs224d-lecture9-machine-translation/mt13.png"></p>
<p>$$h_t=\phi(h_{t-1},c,y_{t-1})$$</p>
<p>3.使用deep rnn: 这需要更大的语料库</p>
<p>4.使用bi-directional encoder</p>
<p>5.颠倒词序进行训练</p>
<p><img src="/2018/05/07/cs224d-lecture9-machine-translation/mt14.png"></p>
<h4 id="rnn-到底做了什么？"><a href="#rnn-到底做了什么？" class="headerlink" title="rnn 到底做了什么？"></a>rnn 到底做了什么？</h4><p>we never gave this model an explicit grammar for the source language, or the target language, right? It’s essentially trying, in some really deep, clever, continuous function, general function approximation kind of way, just correlation, basically, right? And it doesn’t have to know the grammar, but as long as you’re consistent and you just reverse every sequence, the same way. It’s still grammatical if you read it from the other side. And the model reads it from potentially both sides, and so on.</p>
<h4 id="RNN的缺点"><a href="#RNN的缺点" class="headerlink" title="RNN的缺点"></a>RNN的缺点</h4><p>我们知道在传统的神经网络传递中$a^{<t>} = g(W_{a}\cdot[a{<t-1>},x{<t>}] + b_a)$, 很容易造成梯度消失，并且神经网络不擅长处理长期依赖的问题。以语言模型为例，即序列很难反向传播到比较靠前的部分，也就难以调整序列前面的计算。</t></t-1></t></p>
<h3 id="GRU-gated-recurrent-units"><a href="#GRU-gated-recurrent-units" class="headerlink" title="GRU(gated recurrent units)"></a>GRU(gated recurrent units)</h3><p>原论文：<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1406.1078v3.pdf">https://arxiv.org/pdf/1406.1078v3.pdf</a></p>
<p><img src="/2018/05/07/cs224d-lecture9-machine-translation/mt15.png"></p>
<p>这个图画的算是很好了的吧。。但是还是复杂了一点，必须对着公式才能看懂。可以看简化图：</p>
<p><img src="/2018/05/07/cs224d-lecture9-machine-translation/mt16.png"></p>
<p>$$r_t=\sigma(W^{(r)}x_t+U^{(r)}h_{t-1})\tag{reset gate}$$</p>
<p>$$u_t=\sigma(W^{(z)}x_t+U^{(z)}h_{t-1})\tag{update gate}$$</p>
<p>$$\tilde h_t=tanh(Wx_t+r_t\circ Uh_{t-1})\tag{new memory}$$</p>
<p>$$h_t=(1-u_t)\circ \tilde h_t+u_t\circ h_{t-1} \tag{Hidden state}$$</p>
<p>主要就是两个gate：</p>
<ul>
<li><p>重置门r：决定了如何将新的输入信息与前面的记忆相结合。所以它的作用对象是 $\tilde h_t$ 也就是new memory cell.</p>
</li>
<li><p>更新门u：定义了前面记忆保存到当前时间步的量。所以它的作用对象是 $h_t$.也就是当前memory cell保存 $h_{t-1}$ 和 $\tilde h_t$ 多少信息量。</p>
</li>
</ul>
<p>GRU 背后的原理：</p>
<ul>
<li><p>如果我们将重置门设置为 1，更新门设置为 0，那么我们将再次获得标准 RNN 模型。</p>
</li>
<li><p>如果重置门设为0，那么将忽视之前的隐藏状态，这意味着模型可以丢掉之前的信息，当它们与未来的信息不相关时。</p>
</li>
<li><p>更新门u控制着过去的状态对现在的影响。If z close to 1, then we can copy information in that units through many time steps!这意味着 <strong>Less vanishing gradient!</strong></p>
</li>
<li><p>Units with short-term dependencies often have reset gate very active.</p>
</li>
</ul>
<p>这几句总结可以说是道出了GRU的精髓了！</p>
<p>仍需要理解的几个问题：</p>
<ol>
<li>激活函数为什么是tanh ,sigmoid，并不能像概率图模型那样，用数学来解释，就是很玄学吧。。</li>
</ol>
<p>这篇文章写的不错～<a target="_blank" rel="noopener" href="https://www.jiqizhixin.com/articles/2017-12-24">经典必读：门控循环单元（GRU）的基本概念与原理</a></p>
<h3 id="LSTM"><a href="#LSTM" class="headerlink" title="LSTM"></a>LSTM</h3><p><img src="/2018/05/07/cs224d-lecture9-machine-translation/mt18.png"></p>
<p>这个图有点抽象。</p>
<p><img src="/2018/05/07/cs224d-lecture9-machine-translation/lstm.png"></p>
<p>这个图是来自Ng的课，将图中的 $a^{&lt; t &gt;}$ 换成 $h_t$ 就可以了～</p>
<p>三个gate以及新的记忆细胞，三个sigmoid和一个tanh</p>
<p>$$i_t = \sigma(W^{(i)}x_t+U^{(i)}h_{t-1})\tag{Input\update gate}$$</p>
<p>$$f_t = \sigma(W^{(f)}x_t+U^{(f)}h_{t-1})\tag{forget gate}$$</p>
<p>$$o_t = \sigma(W^{(o)}x_t+U^{(o)}h_{t-1})\tag{Output/Exposure gate}$$</p>
<p>$$\tilde c_t = tanh(W^{(c)}x_t+U^{(c)}h_{t-1})\tag{New memory cell}$$</p>
<p>输入门和遗忘门作用于新的记忆细胞得到最终的记忆细胞:</p>
<p>$$c_t=f_t\circ c_{t-1}+i_t\circ \tilde c_t$$</p>
<p>输出门作用于新的记忆细胞得到最终的隐藏状态：</p>
<p>$$h_t=o_t\circ tanh(c_t)$$</p>
<p>这里要理解每个gate的目的到底是啥？虽然很难用数学来解释，但是从intuitive上来理解下还是可以的～</p>
<ul>
<li>New memory cell: 在GRU中也存在，但是是有区别的，这里是通过input word $x_t$ 和 过去的隐藏状态 $h_{t-1}$ 得到的。GRU中虽然也是，但直接使用了reset gate</li>
</ul>
<ul>
<li>Input gate: 也叫更新门，因为新的记忆细胞 $\tilde c_t$ 生成时并未考虑current word是否有保留的意义，因此 $i_t$ 作用于 $\tilde c_t$.</li>
</ul>
<ul>
<li>Forget gate: 跟输入门是同样的道理，新的记忆细胞 $\tilde c_t$ 生成时并未考虑past memory cell是否有保留的意义，因此 $f_i$ 作用于 $c_{t-1}$</li>
</ul>
<ul>
<li>Final memory generation: 综合考虑了遗忘门作用后的 $c_{t-1}$ 和 输入门作用后的 $\tilde c_t$</li>
</ul>
<ul>
<li>Output/Exposure Gate: 在GRU中不存在，这里是用来区分最终的记忆细胞 $c_t$ 和 最终的隐藏状态 $h_t$ 的。因为记忆细胞中包含有很多对于隐藏状态来说不必要的信息。</li>
</ul>
<h4 id="使用LSTM的机器翻译效果"><a href="#使用LSTM的机器翻译效果" class="headerlink" title="使用LSTM的机器翻译效果"></a>使用LSTM的机器翻译效果</h4><p>很神奇！！！</p>
<p><img src="/2018/05/07/cs224d-lecture9-machine-translation/mt11.png"></p>
<h3 id="Presentation"><a href="#Presentation" class="headerlink" title="Presentation"></a>Presentation</h3><p>Towards a Better Language Modeling.</p>
<ul>
<li><p>Better inputs: word $\rightarrow$ subword $\rightarrow$ char</p>
</li>
<li><p>Better regularization/Processing</p>
</li>
<li><p>Better Model</p>
</li>
</ul>
<p><img src="/2018/05/07/cs224d-lecture9-machine-translation/mt03.png"></p>
<p><img src="/2018/05/07/cs224d-lecture9-machine-translation/mt04.png"></p>
<p><img src="/2018/05/07/cs224d-lecture9-machine-translation/mt05.png"></p>
<p><img src="/2018/05/07/cs224d-lecture9-machine-translation/mt06.png"></p>
<p><img src="/2018/05/07/cs224d-lecture9-machine-translation/mt07.png"></p>
</div><div class="article-licensing box"><div class="licensing-title"><p>cs224d-lecture9 机器翻译</p><p><a href="http://www.panxiaoxie.cn/2018/05/07/cs224d-lecture9-machine-translation/">http://www.panxiaoxie.cn/2018/05/07/cs224d-lecture9-machine-translation/</a></p></div><div class="licensing-meta level is-mobile"><div class="level-left"><div class="level-item is-narrow"><div><h6>作者</h6><p>Xie Pan</p></div></div><div class="level-item is-narrow"><div><h6>发布于</h6><p>2018-05-07</p></div></div><div class="level-item is-narrow"><div><h6>更新于</h6><p>2021-06-29</p></div></div><div class="level-item is-narrow"><div><h6>许可协议</h6><p><a class="icons" rel="noopener" target="_blank" title="Creative Commons" href="https://creativecommons.org/"><i class="icon fab fa-creative-commons"></i></a><a class="icons" rel="noopener" target="_blank" title="Attribution" href="https://creativecommons.org/licenses/by/4.0/"><i class="icon fab fa-creative-commons-by"></i></a><a class="icons" rel="noopener" target="_blank" title="Noncommercial" href="https://creativecommons.org/licenses/by-nc/4.0/"><i class="icon fab fa-creative-commons-nc"></i></a></p></div></div></div></div></div><div class="article-tags is-size-7 mb-4"><span class="mr-2">#</span><a class="link-muted mr-2" rel="tag" href="/tags/cs224d/">cs224d</a></div><!--!--></article></div><!--!--><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/2018/05/08/cs224d-lecture10-%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91%E5%92%8C%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/"><i class="level-item fas fa-chevron-left"></i><span class="level-item">cs224d-lecture10 机器翻译和注意力机制</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/2018/05/04/cs224d-lecture8-RNN/"><span class="level-item">cs224d-lecture8-RNN</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><div class="card"><div class="card-content"><h3 class="title is-5">评论</h3><div id="disqus_thread"><noscript>Please enable JavaScript to view the <a target="_blank" rel="noopener" href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript></div><script>var disqus_config = function () {
            this.page.url = 'http://www.panxiaoxie.cn/2018/05/07/cs224d-lecture9-machine-translation/';
            this.page.identifier = '2018/05/07/cs224d-lecture9-machine-translation/';
        };
        (function() {
            var d = document, s = d.createElement('script');  
            s.src = '//' + 'panxie' + '.disqus.com/embed.js';
            s.setAttribute('data-timestamp', +new Date());
            (d.head || d.body).appendChild(s);
        })();</script></div></div></div><!--!--><div class="column column-right is-4-tablet is-4-desktop is-4-widescreen  order-3"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar" src="/img/avatar.png" alt="panxiaoxie"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">panxiaoxie</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Beijing, China</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">文章</p><a href="/archives"><p class="title">117</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">分类</p><a href="/categories"><p class="title">39</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">标签</p><a href="/tags"><p class="title">36</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/PanXiebit" target="_blank" rel="noopener">关注我</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/PanXiebit"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Email" href="/ftdpanxie@gmail.com"><i class="fa fa-envelope"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="RSS" href="/"><i class="fas fa-rss"></i></a></div></div></div><!--!--><div class="card widget" data-type="links"><div class="card-content"><div class="menu"><h3 class="menu-label">链接</h3><ul class="menu-list"><li><a class="level is-mobile" href="https://github.com/PanXiebit" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">github</span></span><span class="level-right"><span class="level-item tag">github.com</span></span></a></li><li><a class="level is-mobile" href="ftdpanxie@gmail.com" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">email</span></span><span class="level-right"><span class="level-item tag">ftdpanxie@gmail.com</span></span></a></li></ul></div></div></div><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">分类</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/C/"><span class="level-start"><span class="level-item">C++</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/CSAPP/"><span class="level-start"><span class="level-item">CSAPP</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/DRL/"><span class="level-start"><span class="level-item">DRL</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/GAN/"><span class="level-start"><span class="level-item">GAN</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li><li><a class="level is-mobile" href="/categories/GAN-RL/"><span class="level-start"><span class="level-item">GAN, RL</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/ML/"><span class="level-start"><span class="level-item">ML</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/NLP/"><span class="level-start"><span class="level-item">NLP</span></span><span class="level-end"><span class="level-item tag">14</span></span></a></li><li><a class="level is-mobile" href="/categories/TensorFlow/"><span class="level-start"><span class="level-item">TensorFlow</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/cs224d/"><span class="level-start"><span class="level-item">cs224d</span></span><span class="level-end"><span class="level-item tag">10</span></span></a></li><li><a class="level is-mobile" href="/categories/generation/"><span class="level-start"><span class="level-item">generation</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/interview/"><span class="level-start"><span class="level-item">interview</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/leetcode/"><span class="level-start"><span class="level-item">leetcode</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/machine-translation/"><span class="level-start"><span class="level-item">machine translation</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/python/"><span class="level-start"><span class="level-item">python</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/pytorch/"><span class="level-start"><span class="level-item">pytorch</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/reinforcement-learning/"><span class="level-start"><span class="level-item">reinforcement learning</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/sign-language-recognition/"><span class="level-start"><span class="level-item">sign language recognition</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/transfer-learning/"><span class="level-start"><span class="level-item">transfer learning</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"><span class="level-start"><span class="level-item">数据结构与算法</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile" href="/categories/%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB/"><span class="level-start"><span class="level-item">文本分类</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"><span class="level-start"><span class="level-item">论文笔记</span></span><span class="level-end"><span class="level-item tag">40</span></span></a><ul><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/DL/"><span class="level-start"><span class="level-item">DL</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/ESA/"><span class="level-start"><span class="level-item">ESA</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/GAN/"><span class="level-start"><span class="level-item">GAN</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/MRC-and-QA/"><span class="level-start"><span class="level-item">MRC and QA</span></span><span class="level-end"><span class="level-item tag">7</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/Machine-Translation/"><span class="level-start"><span class="level-item">Machine Translation</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/NLP/"><span class="level-start"><span class="level-item">NLP</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/Transformer/"><span class="level-start"><span class="level-item">Transformer</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/capsules/"><span class="level-start"><span class="level-item">capsules</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/computer-vision/"><span class="level-start"><span class="level-item">computer vision</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/constrast-learning/"><span class="level-start"><span class="level-item">constrast learning</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/data-augmentation/"><span class="level-start"><span class="level-item">data augmentation</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/dialogue-system/"><span class="level-start"><span class="level-item">dialogue system</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/language-model/"><span class="level-start"><span class="level-item">language model</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/machine-translation/"><span class="level-start"><span class="level-item">machine translation</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/open-set-recognition/"><span class="level-start"><span class="level-item">open set recognition</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/sentence-embedding/"><span class="level-start"><span class="level-item">sentence embedding</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/text-matching/"><span class="level-start"><span class="level-item">text matching</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/vision-language/"><span class="level-start"><span class="level-item">vision-language</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li></ul></div></div></div></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/panxiaoxie.png" alt="潘小榭" height="28"></a><p class="is-size-7"><span>&copy; 2021 Xie Pan</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("zh-CN");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="回到顶端" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "此网站使用Cookie来改善您的体验。",
          dismiss: "知道了！",
          allow: "允许使用Cookie",
          deny: "拒绝",
          link: "了解更多",
          policy: "Cookie政策",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.5/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="想要查找什么..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"想要查找什么...","untitled":"(无标题)","posts":"文章","pages":"页面","categories":"分类","tags":"标签"});
        });</script></body></html>