<!doctype html>
<html lang="zh"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>论文笔记 - Attention 综述 - 潘小榭</title><link rel="manifest" href="/manifest.json"><meta name="theme-color" content="black"><meta name="application-name" content="panxiaoxie"><meta name="msapplication-TileImage" content="/img/avatar.png"><meta name="msapplication-TileColor" content="black"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="panxiaoxie"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="description" content="Attention and Augmented Recurrent Neural Networks 循环神经网络是深度学习的根基之一，她允许神经网络对序列数据进行处理，比如文本，语音和视频。 这句话形容特别贴切，意思就是rnn能将序列转换成包含了理解，语义的表示。  They can be used to boil a sequence down into a high-level underst"><meta property="og:type" content="blog"><meta property="og:title" content="panxiaoxie"><meta property="og:url" content="https://github.com/PanXiebit"><meta property="og:site_name" content="panxiaoxie"><meta property="og:description" content="Attention and Augmented Recurrent Neural Networks 循环神经网络是深度学习的根基之一，她允许神经网络对序列数据进行处理，比如文本，语音和视频。 这句话形容特别贴切，意思就是rnn能将序列转换成包含了理解，语义的表示。  They can be used to boil a sequence down into a high-level underst"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://www.qt86.com/cache/1625298592_187938.png"><meta property="article:published_time" content="2018-06-25T11:44:23.000Z"><meta property="article:modified_time" content="2021-06-29T08:12:17.025Z"><meta property="article:author" content="panxiaoxie"><meta property="article:tag" content="NLP"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="https://www.qt86.com/cache/1625298592_187938.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"http://www.panxiaoxie.cn/2018/06/25/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-Attention-%E7%BB%BC%E8%BF%B0/"},"headline":"论文笔记 - Attention 综述","image":["http://www.panxiaoxie.cn/2018/06/25/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-Attention-%E7%BB%BC%E8%BF%B0/01.png","http://www.panxiaoxie.cn/2018/06/25/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-Attention-%E7%BB%BC%E8%BF%B0/02.png","http://www.panxiaoxie.cn/2018/06/25/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-Attention-%E7%BB%BC%E8%BF%B0/03.png","http://www.panxiaoxie.cn/2018/06/25/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-Attention-%E7%BB%BC%E8%BF%B0/04.png","http://www.panxiaoxie.cn/2018/06/25/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-Attention-%E7%BB%BC%E8%BF%B0/05.png","http://www.panxiaoxie.cn/2018/06/25/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-Attention-%E7%BB%BC%E8%BF%B0/06.png","http://www.panxiaoxie.cn/2018/06/25/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-Attention-%E7%BB%BC%E8%BF%B0/07.png","http://www.panxiaoxie.cn/2018/06/25/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-Attention-%E7%BB%BC%E8%BF%B0/08.png","http://www.panxiaoxie.cn/2018/06/25/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-Attention-%E7%BB%BC%E8%BF%B0/09.png","http://www.panxiaoxie.cn/2018/06/25/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-Attention-%E7%BB%BC%E8%BF%B0/10.png","http://www.panxiaoxie.cn/2018/06/25/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-Attention-%E7%BB%BC%E8%BF%B0/12.png","http://www.panxiaoxie.cn/2018/06/25/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-Attention-%E7%BB%BC%E8%BF%B0/13.png","http://www.panxiaoxie.cn/2018/06/25/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-Attention-%E7%BB%BC%E8%BF%B0/14.png","http://www.panxiaoxie.cn/2018/06/25/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-Attention-%E7%BB%BC%E8%BF%B0/15.png","http://www.panxiaoxie.cn/2018/06/25/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-Attention-%E7%BB%BC%E8%BF%B0/16.png","http://www.panxiaoxie.cn/2018/06/25/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-Attention-%E7%BB%BC%E8%BF%B0/17.png","http://www.panxiaoxie.cn/2018/06/25/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-Attention-%E7%BB%BC%E8%BF%B0/18.png","http://www.panxiaoxie.cn/2018/06/25/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-Attention-%E7%BB%BC%E8%BF%B0/19.png"],"datePublished":"2018-06-25T11:44:23.000Z","dateModified":"2021-06-29T08:12:17.025Z","author":{"@type":"Person","name":"Xie Pan"},"publisher":{"@type":"Organization","name":"潘小榭","logo":{"@type":"ImageObject","url":"http://www.panxiaoxie.cn/img/panxiaoxie.png"}},"description":"Attention and Augmented Recurrent Neural Networks 循环神经网络是深度学习的根基之一，她允许神经网络对序列数据进行处理，比如文本，语音和视频。 这句话形容特别贴切，意思就是rnn能将序列转换成包含了理解，语义的表示。  They can be used to boil a sequence down into a high-level underst"}</script><link rel="canonical" href="http://www.panxiaoxie.cn/2018/06/25/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-Attention-%E7%BB%BC%E8%BF%B0/"><link rel="icon" href="/img/avatar.png"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/css/justifiedGallery.min.css"><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script><!--!--><!--!--><meta name="generator" content="Hexo 5.4.0"></head><body class="is-2-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/panxiaoxie.png" alt="潘小榭" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">主页</a><a class="navbar-item" href="/archives">归档</a><a class="navbar-item" href="/categories">分类</a><a class="navbar-item" href="/tags">标签</a><a class="navbar-item" href="/about">关于我</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/PanXiebit"><i class="fab fa-github"></i></a><a class="navbar-item search" title="搜索" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-10-widescreen"><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2018-06-25T11:44:23.000Z" title="2018/6/25 下午7:44:23">2018-06-25</time>发表</span><span class="level-item"><time dateTime="2021-06-29T08:12:17.025Z" title="2021/6/29 下午4:12:17">2021-06-29</time>更新</span><span class="level-item"><a class="link-muted" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/">论文笔记</a><span> / </span><a class="link-muted" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/NLP/">NLP</a></span><span class="level-item">20 分钟读完 (大约3021个字)</span></div></div><h1 class="title is-3 is-size-4-mobile">论文笔记 - Attention 综述</h1><div class="content"><p><a target="_blank" rel="noopener" href="https://distill.pub/2016/augmented-rnns/#attentional-interfaces">Attention and Augmented Recurrent Neural Networks</a></p>
<p>循环神经网络是深度学习的根基之一，她允许神经网络对序列数据进行处理，比如文本，语音和视频。</p>
<p>这句话形容特别贴切，意思就是rnn能将序列转换成包含了理解，语义的表示。</p>
<blockquote>
<p>They can be used to boil a sequence down into a high-level understanding, to annotate sequences, and even to generate new sequences from scratch!  </p>
</blockquote>
<p><img src="/2018/06/25/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-Attention-%E7%BB%BC%E8%BF%B0/01.png">  </p>
<p>基本的 rnn 在解决 long sequence 时非常挣扎，其变体 LSTM 有效的解决这一问题（但问题依然存在）。  </p>
<p>随着时间的发展，出现了各种 augument RNNs. 其中以下4种 stand out exciting.  </p>
<p><img src="/2018/06/25/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-Attention-%E7%BB%BC%E8%BF%B0/02.png">  </p>
<p>这些变体都是 RNN 有力的拓展，更令人惊奇的是，他们还能有效的结合在一起，似乎只是广阔空间中的一点。除此之外，他们都依赖于同样的 underlying trick — attention.  </p>
<h3 id="Neural-Turing-Machines"><a href="#Neural-Turing-Machines" class="headerlink" title="Neural Turing Machines"></a>Neural Turing Machines</h3><p><a target="_blank" rel="noopener" href="http://arxiv.org/pdf/1410.5401.pdf">Neural Turing Machines</a> 神经图灵机将 RNNs 和外部 memory bank 结合在一起。向量用来表示神经网络中的自然语言，memory 是向量的数组。</p>
<p><img src="/2018/06/25/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-Attention-%E7%BB%BC%E8%BF%B0/03.png"></p>
<p>如上图所示，能够看出其原理是将每一个词的向量表示存储在 memory 中。那么从 memory 中读、以及写入 memory 是怎么操作的呢？  </p>
<p>最大的难点在于让整个过程可微(differentiable).特别的是，我们希望在读出和写入的位置具有差异性，以便我们可以知道从哪儿读和写。这很棘手(tricky)，因为 memory 地址基本上是离散的。  </p>
<p>NMTs 采取了一个非常聪明的方法，每一步读和写都包括 memory 中的所有位置，只是对于不同的位置，读和写的程度不同。</p>
<p>举个例子，这里我们只关注 reading. RNN 输出一个 “attention distribution”，表示对于 memory 不同位置的读取程度。这样，读入的操作可以看作加权求和。</p>
<p><img src="/2018/06/25/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-Attention-%E7%BB%BC%E8%BF%B0/04.png"></p>
<p>$$r \leftarrow \sum_ia_iM_i$$</p>
<p>类似的，在读入的过程中也是对 memory 中所有位置。再一次，输出一个 “attention distribution” 用来表示对每个位置的写入程度。我们在一个 memory 位置获得新的 value 是旧的 memory 和写入值的 凸结合(<strong>convex combination</strong>).</p>
<p><img src="/2018/06/25/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-Attention-%E7%BB%BC%E8%BF%B0/05.png"></p>
<p>$$M_i \leftarrow a_iw+(1-a_i)M_i$$</p>
<p>其中 $w$ 是写入值(write value)。</p>
<p>但是 NTMs 如何确定去注意 memory 中的那一个位置呢？ 他们使用了两种不同的方法的结合： content-based attention 和 location-based attention. 前者允许 NMTs 通过匹配 memory 中的每一个位置，并 focus on 最 match 的位置。后者允许 memory 中的相对移动，保证 NMT 能循环。</p>
<p><img src="/2018/06/25/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-Attention-%E7%BB%BC%E8%BF%B0/06.png"></p>
<p>这种读和写的能力允许 NTM 执行许多简单的算法，而这些算法以前超越了神经网络。 例如，他们可以在 memory中存储一个长序列，然后遍历它，反向重复它。 当他们这样做时，我们可以看他们读和写的地方，以更好地理解他们在做什么：</p>
<p><img src="/2018/06/25/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-Attention-%E7%BB%BC%E8%BF%B0/07.png"></p>
<p>关于 repeat copy 的实验，可以参考这篇论文<a target="_blank" rel="noopener" href="https://arxiv.org/abs/1502.03044">Show, attend and tell: Neural image caption generation with visual attention</a></p>
<p>他们能够模仿一个 lookup table,甚至可以 sort numbers(althought they kind of cheat). 但另一方面，他们仍然不能做很多基本的事儿，比如 add or multiply numbers.</p>
<p>自从 NTM 这篇论文之后，又出现了很多相同方向的令人 exciting 的文章.  </p>
<blockquote>
<p>The Neural GPU <a href="(https://arxiv.org/pdf/1511.08228.pdf)">4</a> overcomes the NTM’s inability to add and multiply numbers.  </p>
</blockquote>
<p>Zaremba &amp; Sutskever <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1505.00521.pdf">5</a> train NTMs using reinforcement learning instead of the differentiable read/writes used by the original.  </p>
<p>Neural Random Access Machines <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1511.06392.pdf">6</a> work based on pointers.  </p>
<p>Some papers have explored differentiable data structures, like stacks and queues [7, 8].  </p>
<p>memory networks [9, 10] are another approach to attacking similar problems.</p>
<p><strong>Code</strong>  </p>
<ul>
<li><p>Neural Turing Machine<a target="_blank" rel="noopener" href="https://github.com/carpedm20/NTM-tensorflow"> Taehoon Kim’s</a></p>
</li>
<li><p>Neural GPU publication <a target="_blank" rel="noopener" href="https://github.com/tensorflow/models/tree/master/neural_gpu"> TensorFlow Models repository</a></p>
</li>
<li><p>Memory Networks, <a target="_blank" rel="noopener" href="https://github.com/carpedm20/MemN2N-tensorflow">Taehoon Kim’s</a></p>
</li>
</ul>
<p>关于这篇 paper 真的很难看懂，</p>
<h3 id="Attention-Interfaces"><a href="#Attention-Interfaces" class="headerlink" title="Attention Interfaces"></a>Attention Interfaces</h3><p>当我翻译一个句子时，我特别注意我正在翻译的单词。 当我录制录音时，我会仔细聆听我正在积极写下的片段。 如果你要求我描述我正在坐的房间，那么我会浏览我正在描述的物体。</p>
<p>神经网络能够通过 attention 机制完成上述行为，也就是 focusing on 给出信息的部分内容。举个例子，一个 RNN 能够 attend over 另一个 RNN 的输出，并在每一个时间步， focus on 另一个 RNN 的不同的位置。</p>
<p>为了让 attention 可微，我们采用跟 NTM 同样的方法，focus 所有的位置，每个位置的程度不同。</p>
<p><img src="/2018/06/25/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-Attention-%E7%BB%BC%E8%BF%B0/08.png"></p>
<p>上图中颜色的深浅表示注意的程度。</p>
<p>其中 attention distribution 是由 content-based attention 生成的。具体过程还是看英文描述吧：</p>
<blockquote>
<p>The attending RNN generates a query describing what it wants to focus on. Each item is dot-producted with the query to produce a score, describing how well it matches the query. The scores are fed into a softmax to create the attention distribution.</p>
</blockquote>
<p><img src="/2018/06/25/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-Attention-%E7%BB%BC%E8%BF%B0/09.png"></p>
<p>最经典的使用 RNNs 之间的 attention 就是机器翻译了，<a target="_blank" rel="noopener" href="https://arxiv.org/abs/1409.0473">Neural machine translation by jointly learning to align and translate</a>. 传统的 seq2seq 模型通过 RNN 将整个输入序列转化为单个向量(也就是最后一层的隐藏状态)，然后将其展开得到输出(word by word). 注意力机制避免了这一点，它允许 RNN 在生成输出时，能看到所有输入中的每一个词，并且根据他们之间的相关性，来选择性注意部分词。</p>
<p><img src="/2018/06/25/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-Attention-%E7%BB%BC%E8%BF%B0/10.png"></p>
<p>原图是可以操作的，大牛们的技术真是厉害。。。可视化也很6。。</p>
<p>这种类型的 RNN 还有很多其他的应用，比如在 语音识别上的使用<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1508.01211.pdf">Listen, Attend and Spell</a>, 使用一个 RNN 来处理音频，然后用另一个 RNN 来遍历它，并在生成一个抄本(transcript)时重点关注相关的部分。</p>
<p><img src="/2018/06/25/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-Attention-%E7%BB%BC%E8%BF%B0/12.png"></p>
<p> 这个图看不出来，不能截出那种效果。 其实可以看出对语音的识别，在生成对应的词时更关注的是对应的音频，并不像文本那种需要长时间依赖。</p>
<p>还有很多其他的应用：  </p>
<ul>
<li><p>parsing tree:<a target="_blank" rel="noopener" href="https://arxiv.org/abs/1412.7449">Grammar as a foreign language</a></p>
</li>
<li><p>conversational modeling:<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1506.05869.pdf">A Neural Conversational Model</a></p>
</li>
<li><p>image captioning: attention interface 也可以是 CNN 和 RNN 之间的，它允许 RNN 在每一个时间步生成文本时能关注图像中的不同的位置。</p>
</li>
</ul>
<blockquote>
<p>Then an RNN runs, generating a description of the image. As it generates each word in the description, the RNN focuses on the conv net’s interpretation of the relevant parts of the image. We can explicitly visualize this:  </p>
</blockquote>
<p><img src="/2018/06/25/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-Attention-%E7%BB%BC%E8%BF%B0/13.png"></p>
<p>图片来自于<a target="_blank" rel="noopener" href="https://arxiv.org/abs/1502.03044">Show, attend and tell: Neural image caption generation with visual attention</a></p>
<blockquote>
<p>More broadly, attentional interfaces can be used whenever one wants to interface with a neural network that has a repeating structure in its output.</p>
</blockquote>
<h3 id="Adaptive-Computation-time"><a href="#Adaptive-Computation-time" class="headerlink" title="Adaptive Computation time"></a>Adaptive Computation time</h3><blockquote>
<p>Standard RNNs do the same amount of computation for each time step. This seems unintuitive. Surely, one should think more when things are hard? It also limits RNNs to doing O(n) operations for a list of length n.</p>
</blockquote>
<p>标准的 RNN 在每一个时间步都做着相同的大量的计算。它貌似是很合理的，但当处理的信息很复杂时，是否可以在一个时间步考虑更多？这样同样的计算量的方式限制了 RNN 在处理长度为 n 的序列时，其复杂度也为 O(n).</p>
<blockquote>
<p>Adaptive Computation Time [15] is a way for RNNs to do different amounts of computation each step. The big picture idea is simple: allow the RNN to do multiple steps of computation for each time step.</p>
</blockquote>
<p>自适应计算时间步(ACT) 能让 RNN 在每一个时间步做不同的计算量. 它的大致原理很简单：允许 RNN 在每一个时间步做多步运算。</p>
<blockquote>
<p>In order for the network to learn how many steps to do, we want the number of steps to be differentiable. We achieve this with the same trick we used before: instead of deciding to run for a discrete number of steps, we have an attention distribution over the number of steps to run. The output is a weighted combination of the outputs of each step.  </p>
</blockquote>
<p>为了让网络学习得到每一个时间步的计算步数，我们希望这个计算步数是可微的（也就是把其步数当作学习得到的参数，然后通过反向传播来学习这个参数）。为了实现这个 trick，我们采用类似之前 NTM 的方式，相比每次计算一个离散的步数，我们使用注意力分布的机制来选择步数，输出的结果是所有步的加权求和。</p>
<p><img src="/2018/06/25/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-Attention-%E7%BB%BC%E8%BF%B0/14.png"></p>
<blockquote>
<p>There are a few more details, which were left out in the previous diagram. Here’s a complete diagram of a time step with three computation steps.  </p>
</blockquote>
<p>上图中还有更多的细节。下图是 RNN 中的在一个时间步中有3个步数的计算量。</p>
<p><img src="/2018/06/25/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-Attention-%E7%BB%BC%E8%BF%B0/15.png"></p>
<blockquote>
<p>That’s a bit complicated, so let’s work through it step by step. At a high-level, we’re still running the RNN and outputting a weighted combination of the states:  </p>
</blockquote>
<p>这个图看起来有点复杂，我们会一步一步的解释它。在更高的层次，我们依然运行 RNN 并输出一个状态的加权之和。</p>
<p><img src="/2018/06/25/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-Attention-%E7%BB%BC%E8%BF%B0/16.png"></p>
<p>S 表示 RNN 中的隐藏状态。</p>
<blockquote>
<p>The weight for each step is determined by a “halting neuron.” It’s a sigmoid neuron that looks at the RNN state and gives a halting weight, which we can think of as the probability that we should stop at that step.</p>
</blockquote>
<p>每一步的权重由一个“停止神经元”确定。这是一个sigmoid神经元，用来关注当前的 RNN 的状态以及赋予它一个权重。我们可以看作是这一步是否应该停止的概率。</p>
<p><img src="/2018/06/25/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-Attention-%E7%BB%BC%E8%BF%B0/17.png"></p>
<blockquote>
<p>We have a total budget for the halting weights of 1, so we track that budget along the top. When it gets to less than epsilon, we stop</p>
</blockquote>
<p>我们设总的停止权重为 1,依次减去每步输出的 halt 值，直到剩余的 halt 值小于 epsilon 后就停止。</p>
<p><img src="/2018/06/25/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-Attention-%E7%BB%BC%E8%BF%B0/18.png"></p>
<blockquote>
<p>When we stop, might have some left over halting budget because we stop when it gets to less than epsilon. What should we do with it? Technically, it’s being given to future steps but we don’t want to compute those, so we attribute it to the last step.</p>
</blockquote>
<p>当我们结束后，应该还会遗留一些停止值，因为我们在停止值小于epsilon时停止的。我们该怎么处理这些剩余的停止值？从技术上讲，它们应该传递到后面的计算步骤中去，但我们不想计算这些值，所以我们就把这些剩余的停止值归总到最后一步。</p>
<p><img src="/2018/06/25/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-Attention-%E7%BB%BC%E8%BF%B0/19.png"></p>
<blockquote>
<p>When training Adaptive Computation Time models, one adds a “ponder cost” term to the cost function. This penalizes the model for the amount of computation it uses. The bigger you make this term, the more it will trade-off performance for lowering compute time.</p>
</blockquote>
<p>当训练 ACT 模型时，需要给损失函数加上一个惩罚项。用来惩罚整个模型中的总的计算量。这一项越大时，它会在模型性能和计算量的折衷中倾向与减小计算量。</p>
<p>Code：</p>
<blockquote>
<p>The only open source implementation of Adaptive Computation Time at the moment seems to be <a target="_blank" rel="noopener" href="https://github.com/DeNeutoy/act-tensorflow">Mark Neumann’s</a> (TensorFlow).</p>
</blockquote>
<p>reference:</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://distill.pub/2016/augmented-rnns/#attentional-interfaces">Attention and Augmented Recurrent Neural Networks</a></li>
</ul>
</div><div class="article-licensing box"><div class="licensing-title"><p>论文笔记 - Attention 综述</p><p><a href="http://www.panxiaoxie.cn/2018/06/25/论文笔记-Attention-综述/">http://www.panxiaoxie.cn/2018/06/25/论文笔记-Attention-综述/</a></p></div><div class="licensing-meta level is-mobile"><div class="level-left"><div class="level-item is-narrow"><div><h6>作者</h6><p>Xie Pan</p></div></div><div class="level-item is-narrow"><div><h6>发布于</h6><p>2018-06-25</p></div></div><div class="level-item is-narrow"><div><h6>更新于</h6><p>2021-06-29</p></div></div><div class="level-item is-narrow"><div><h6>许可协议</h6><p><a class="icons" rel="noopener" target="_blank" title="Creative Commons" href="https://creativecommons.org/"><i class="icon fab fa-creative-commons"></i></a><a class="icons" rel="noopener" target="_blank" title="Attribution" href="https://creativecommons.org/licenses/by/4.0/"><i class="icon fab fa-creative-commons-by"></i></a><a class="icons" rel="noopener" target="_blank" title="Noncommercial" href="https://creativecommons.org/licenses/by-nc/4.0/"><i class="icon fab fa-creative-commons-nc"></i></a></p></div></div></div></div></div><div class="article-tags is-size-7 mb-4"><span class="mr-2">#</span><a class="link-muted mr-2" rel="tag" href="/tags/NLP/">NLP</a></div><!--!--></article></div><!--!--><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/2018/06/27/chapter27-Question-Answering/"><i class="level-item fas fa-chevron-left"></i><span class="level-item">chapter27-Question Answering</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/2018/06/10/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-memory-networks/"><span class="level-item">论文笔记 memory networks</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><div class="card"><div class="card-content"><h3 class="title is-5">评论</h3><div id="disqus_thread"><noscript>Please enable JavaScript to view the <a target="_blank" rel="noopener" href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript></div><script>var disqus_config = function () {
            this.page.url = 'http://www.panxiaoxie.cn/2018/06/25/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-Attention-%E7%BB%BC%E8%BF%B0/';
            this.page.identifier = '2018/06/25/论文笔记-Attention-综述/';
        };
        (function() {
            var d = document, s = d.createElement('script');  
            s.src = '//' + 'panxie' + '.disqus.com/embed.js';
            s.setAttribute('data-timestamp', +new Date());
            (d.head || d.body).appendChild(s);
        })();</script></div></div></div><!--!--><div class="column column-right is-4-tablet is-4-desktop is-4-widescreen  order-3"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar" src="/img/avatar.png" alt="panxiaoxie"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">panxiaoxie</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Beijing, China</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">文章</p><a href="/archives"><p class="title">121</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">分类</p><a href="/categories"><p class="title">40</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">标签</p><a href="/tags"><p class="title">38</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/PanXiebit" target="_blank" rel="noopener">关注我</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/PanXiebit"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Email" href="/ftdpanxie@gmail.com"><i class="fa fa-envelope"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="RSS" href="/"><i class="fas fa-rss"></i></a></div></div></div><!--!--><div class="card widget" data-type="links"><div class="card-content"><div class="menu"><h3 class="menu-label">链接</h3><ul class="menu-list"><li><a class="level is-mobile" href="https://github.com/PanXiebit" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">github</span></span><span class="level-right"><span class="level-item tag">github.com</span></span></a></li><li><a class="level is-mobile" href="ftdpanxie@gmail.com" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">email</span></span><span class="level-right"><span class="level-item tag">ftdpanxie@gmail.com</span></span></a></li></ul></div></div></div><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">分类</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/C/"><span class="level-start"><span class="level-item">C++</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/CSAPP/"><span class="level-start"><span class="level-item">CSAPP</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/DRL/"><span class="level-start"><span class="level-item">DRL</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/GAN/"><span class="level-start"><span class="level-item">GAN</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li><li><a class="level is-mobile" href="/categories/GAN-RL/"><span class="level-start"><span class="level-item">GAN, RL</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/ML/"><span class="level-start"><span class="level-item">ML</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/NLP/"><span class="level-start"><span class="level-item">NLP</span></span><span class="level-end"><span class="level-item tag">14</span></span></a></li><li><a class="level is-mobile" href="/categories/TensorFlow/"><span class="level-start"><span class="level-item">TensorFlow</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/cs224d/"><span class="level-start"><span class="level-item">cs224d</span></span><span class="level-end"><span class="level-item tag">10</span></span></a></li><li><a class="level is-mobile" href="/categories/generation/"><span class="level-start"><span class="level-item">generation</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/generative-models/"><span class="level-start"><span class="level-item">generative models</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/interview/"><span class="level-start"><span class="level-item">interview</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/machine-translation/"><span class="level-start"><span class="level-item">machine translation</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/python/"><span class="level-start"><span class="level-item">python</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/pytorch/"><span class="level-start"><span class="level-item">pytorch</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/reinforcement-learning/"><span class="level-start"><span class="level-item">reinforcement learning</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/sign-language-recognition/"><span class="level-start"><span class="level-item">sign language recognition</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/transfer-learning/"><span class="level-start"><span class="level-item">transfer learning</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/transformer/"><span class="level-start"><span class="level-item">transformer</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"><span class="level-start"><span class="level-item">数据结构与算法</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile" href="/categories/%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB/"><span class="level-start"><span class="level-item">文本分类</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"><span class="level-start"><span class="level-item">论文笔记</span></span><span class="level-end"><span class="level-item tag">40</span></span></a><ul><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/DL/"><span class="level-start"><span class="level-item">DL</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/ESA/"><span class="level-start"><span class="level-item">ESA</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/GAN/"><span class="level-start"><span class="level-item">GAN</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/MRC-and-QA/"><span class="level-start"><span class="level-item">MRC and QA</span></span><span class="level-end"><span class="level-item tag">7</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/Machine-Translation/"><span class="level-start"><span class="level-item">Machine Translation</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/NLP/"><span class="level-start"><span class="level-item">NLP</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/Transformer/"><span class="level-start"><span class="level-item">Transformer</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/capsules/"><span class="level-start"><span class="level-item">capsules</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/computer-vision/"><span class="level-start"><span class="level-item">computer vision</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/constrast-learning/"><span class="level-start"><span class="level-item">constrast learning</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/data-augmentation/"><span class="level-start"><span class="level-item">data augmentation</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/dialogue-system/"><span class="level-start"><span class="level-item">dialogue system</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/language-model/"><span class="level-start"><span class="level-item">language model</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/machine-translation/"><span class="level-start"><span class="level-item">machine translation</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/open-set-recognition/"><span class="level-start"><span class="level-item">open set recognition</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/sentence-embedding/"><span class="level-start"><span class="level-item">sentence embedding</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/text-matching/"><span class="level-start"><span class="level-item">text matching</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/vision-language/"><span class="level-start"><span class="level-item">vision-language</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li></ul></div></div></div></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/panxiaoxie.png" alt="潘小榭" height="28"></a><p class="is-size-7"><span>&copy; 2022 Xie Pan</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("zh-CN");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="回到顶端" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "此网站使用Cookie来改善您的体验。",
          dismiss: "知道了！",
          allow: "允许使用Cookie",
          deny: "拒绝",
          link: "了解更多",
          policy: "Cookie政策",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.5/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="想要查找什么..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"想要查找什么...","untitled":"(无标题)","posts":"文章","pages":"页面","categories":"分类","tags":"标签"});
        });</script></body></html>